Cluster,Subcluster_ID,Num_Summaries,Num_Resolutions,All_Summaries,All_Resolutions
14,1,18,18,"User at Purdue University Libraries & School of Information Studies is seeking assistance in migrating from their self-hosted GitLab instance to Purdue GitHub and scheduling a meeting to discuss the transition of libraries to GitHub. ||| Student cannot log into Purdue's GitHub instance (github.itap.purdue.edu) due to account suspension. ||| Inquiry about upgrading GitHub environment and access to features within the GitHub enterprise category. ||| User cannot access the Purdue Github instance using their Purdue Career Account credentials and receives an invalid LDAP credentials error. ||| A faculty/graduate student wants to move their research group's GitHub repository from a personal account to Purdue University's official GitHub organization (github.com/Purdue). ||| A collaborator from U. Illinois needs access to a repository on GitHub.itap.purdue.edu and does not have a Purdue login. ||| Cannot link Purdue github repository to Zenodo for data citation due to Zenodo requirements and potential delays in obtaining GitHub.itap organization owner's approval. ||| A Purdue University graduate student cannot log into GitHub using their career account from home, despite being connected to Purdue's VPN. ||| The EPICSGroup/name-InteractiveMap repository has reached GitHub's file size limit and users are unable to store their project software on the repository due to its large size. ||| Unable to login at https://github.itap.purdue.edu with Purdue account due to incorrect password input (possibly due to adding 'push' at the end). ||| User needs help with moving GitHub Purdue account repositories to a personal account and wants to know about retaining access to their Purdue email for an extended period. ||| Research Scientist at Botany and Plant Pathology Department is unable to access Purdue GitHub due to login issues. ||| User inquiring about availability of in-person/virtual consultation for questions related to Purdue GitHub functionalities ||| User encountered an 'Invalid LDAP ID' error when trying to log into GitHub Enterprise using their Purdue ID and requires assistance. The user is able to log into RCAC but encounters an ""invalid login credentials"" error again when accessing the Git data. ||| User is unable to access their Purdue GitHub account due to a lost Apple ID associated with the two-factor authentication authenticator app. ||| User is unable to access github.itap.purdue.edu due to an 'Invalid LDAP ID' error. ||| User inquired about the availability of Large File Storage (LFS) on repositories created in github.itap.purdue.edu and encountered an error while trying to push a file using LFS. ||| GitHub Enterprise instance is not indexed by search engines, causing a problem for a lab in Dr. Ciampitti's group and other similar groups at Purdue University who need their repositories to be easily discoverable.","To assist with the migration from the self-hosted GitLab instance to Purdue GitHub, it is recommended to schedule a meeting with the user to discuss possibilities for transitioning their libraries to GitHub. As of the provided details, they have 10 active users (38 inactive), 163 repositories, and 10 groups. It is important to note that current assignees are ITAP_RC_SUPPORT. For further assistance, please contact name, PhD Senior Computational Scientist at Rosen Center for Advanced Computing. ||| The user needs to verify their status at Purdue and respond back to the support team with this information. The account on github.itap.purdue.edu uses Purdue LDAP for queries, so providing correct information about their Purdue status is necessary to resolve the issue. ||| The ITAP Github is currently under RCAC but in Legacy Support only mode. To upgrade, users can log into GitHub with Purdue credentials where there is a verification step. Once verified as a Purdue employee, access to GitHub education in the cloud, including classroom and an option to add Teams at no cost, will be granted. It is not specified if TheDataMine organization falls into the ""Enterprise"" category for additional features. ||| The user should double-check if the issue is with GitHub.itap as there was a recent authentication problem that has been resolved. However, if the issue persists, it seems that the account on GitHub.itap is suspended. The user needs to contact IAMO for further assistance. ||| Since this would be a public repository, it is recommended to use your own GitHub account at github.com. However, the management of the Purdue repo on github.com/Purdue seems to be handled by the community for public distribution. If further setup or assistance is required, you may need to reach out to the appropriate team within your organization. ||| To grant the collaborator access to your repository, you can submit a Request for Privileges (R4P) for them. This will enable the creation of a Purdue career account for the collaborator. For more information on the R4P process, please refer to this link: https://service.purdue.edu/TDClient/32/Purdue/KB/ArticleDet?ID=33. ||| Move the repository to a personal GitHub account where full control is available, ensuring it meets Zenodo's requirements for public repositories. This resolution will require confirmation from the advisor before execution. ||| No specific resolution for the login issue was provided in the ticket message. ||| Unfortunately, the limit encountered is a hard limit imposed by GitHub, and it's not something that can be changed or adjusted on the RC Support end. GitHub enforces these restrictions for all users, and they are beyond our control. As an alternative solution, consider finding another repository service with higher file size limits, splitting large files into smaller ones, or compressing files before uploading them to the repository. ||| The user should ensure they are not including a 'push' at the end of their password when logging in to GitHub using their Purdue credentials. If the issue persists, the user is encouraged to reopen this ticket or open a new one for further assistance. ||| The user should still have active Purdue career account since they just graduated, but it will be deleted during Spring Break (for December graduates) or October Break (for May and August graduates). To transfer the Purdue GitHub repository to a personal account, follow these steps: [Link to GitHub moving repositories guide](https://www.rcac.purdue.edu/knowledge/services/github/movingrepositories). For information on signing up for an alumni email and transferring your email history, visit this link: [Alumni Email Request Form](https://alumniemail.ud.purdue.edu/AccountRegistration.aspx) ||| The researcher was advised that they may not have added ""push"" at the end of their password. A link to the RCAC user guide for Github was provided for additional assistance: https://www.rcac.purdue.edu/knowledge/services/github. After checking the password, the researcher realized their error and was able to log in successfully. ||| Users can seek help during Coffee Hour Consultations provided by Purdue IT. For more information and scheduling, visit the link: https://service.purdue.edu ||| The user can contact Purdue IT support for assistance with Career Account issues at https://it.purdue.edu/help/. For more information on who to reach out to regarding Career Account issues, refer to this IAMO page: <link to IAMO page>. If further help is needed or the user would like the ticket to be resolved, they can reply to this email. ||| The user can contact the PurdueIT service desk (https://purdueitsupport.casewise.com/ or phone number +1-765-494-6999) to reset their Duo account so that it can be linked to a new phone. Alternatively, they can try using the Purdue BoilerBot (https://boilerbot.purdue.edu/) to obtain a bypass code for self-reset attempts. After successfully linking Duo to a new device, the user should regain access to their GitHub account. ||| The user can log into other Purdue websites like myPurdue and User Account Information using a private or alternate browser. The issue is that GitHub authenticates against BoilerAD, and the user's authentication against BAD is looking at OU=BoilerADUsers. This suggests that the user may need to use their Purdue career account username (e.g., tripat60) instead of the full email address when logging into GitHub. The user should try signing in with just their tripat60 username and see if it resolves the error. If the issue persists, please contact IT for further assistance. ||| Git LFS is not enabled on the ITaP GitHub instance, as it is not supported due to potential heavy load and limited benefit in most use cases. Alternatives for handling large binary files like video, particularly when versioning is not needed, are recommended. ||| The primary issue is the HTTP headers emitted by the GitHub Enterprise application explicitly mark the entire property as do-not-crawl for search engines. As a temporary solution, it is recommended to use GitHub.com for public repositories that need to be available on the web. Additionally, in RCAC, you can search for an organization and repos for these sorts of projects (github.com/purduercac). The situation will require further updates based on the response from GitHub support."
4,2,41,41,"User 'name' is unable to log into RCAC due to an expired license and needs assistance with renewal. ||| User needs assistance to access Dr. Nemali's RCAC folder ||| User was unable to connect to scholar.rcac.purdue.edu through VPN due to an error indicating incorrect username and password, despite verifying ID and resetting password. The user is enrolled in CE 50601 and needs access to RCAC remote desktop for a GitHub assignment submission. ||| User is unable to log in to the RCAC cluster using their credentials due to a ""permission denied"" error. ||| Visiting student Xuerui Shi636 requires setup of career account and access to RCAC clusters ||| External user requesting access to Purdue RCAC clusters ||| Researcher failed to acknowledge RCAC resources in a peer-reviewed publication. ||| User is unable to schedule a Coffee Hour Consultation on the RCAC website, getting redirected back to the list of times instead of confirming a selected time. ||| User needs to set up guest access for a former PhD student, Funing, on the RCAC system to allow him to finish his work and set up long-term repositories. ||| Unable to log in to RCAC remote desktop system using the provided credentials and Duo Mobile passcode. ||| User in Ag Econ Department, name, is not receiving emails from RCAC and would like to be added to the mailing list. ||| User unable to interact with RCAC remote desktop system due to freezing issue, which persists across both personal laptop and university desktop. ||| Visiting Scholar Requests Admin Access for Professor's RCAC Account ||| User (name) is unable to access RCAC's Scholar cluster for using Rstudio in a MSBA course. ||| User needs assistance in running COMSOL through RCAC but requires access first. ||| Student research assistant at Purdue West Lafayette cannot connect to the RCAC file depot at < \\datadepot.rcac.purdue.edu\depot\ phig> using Windows Network Drive/SMB (Server Message Block) and receives an error when inputting their Career Accounts password. The student is part of the 'phig' Unix group but not the 'phig-data' Unix group, which is causing the issue. ||| Application for RCAC account is pending due to the required approval from supervisor Prof. name which hasn't been received yet. ||| The user is unable to login to Gilberth (RCAC) due to an LDAP Authorization failure despite receiving an email confirmation that their account has been created. ||| User unable to access GPU RCAC cluster due to authentication failure while using provided credentials for career account ""push2"". ||| User kkhot is unable to access Sentaurus module installed on the Bell/Negishi cluster through their RCAC account due to not being added to the CAE group with necessary permissions. ||| User is unable to access RCAC gateway portal for EAPS507 class due to account setup issues on Scholar. ||| Add a new hostname (tau.rcac.purdue.edu with IP address 172.18.132.78) to the RCAC research network in HOCK (172.18.132.0/25). ||| Student Nick Name Get Outlook for iOS cannot access RCAC and Jupyter hub account in CS 373 ||| User is unable to login to RCAC frontend using their provided ID and password; user has tried adding "",push"" after the password but did not receive a Duo push. ||| User enrolled in course MGMT 58600 needs access to Spyder on the RCAC portal but has been denied access. ||| User enrolled in MGMT 58600 (Distance) cannot access RCAC Gateway due to an 'Access denied' error. ||| User cannot connect to RCAC cluster using ssh command and needs help with the correct command line and password. ||| Write access error due to a lock on /tmp/nsight-compute-lock in RCAC A30 desktop sessions. ||| Error while accessing RCAC Jupyter Notebook from personal device through multiple browsers and both Purdue WiFi and VPN. ||| The user is experiencing an issue with requesting compute trim from RCAC Scholar for Jupyter Notebook sessions where the session starts but then immediately goes into the ""Completed"" phase without allowing interaction. ||| Unable to log into RCAC via Terminal due to password rejection ||| User unable to log into RCAC account due to denied permission with password ending with "",push"" ||| New PhD student's RCAC access request is still pending due to website issue preventing approval. ||| Unable to access mapped network location in RCAC from Windows Explorer due to freezing issues ||| User is unable to add a new graduate student to access Bell cluster resources due to a ""500 Something went wrong"" error while trying to process the page on the RCAC MyInfo page. ||| The user does not have access to an RCAC resource due to lack of faculty status or head of center status. ||| The user is unable to manage College of Science queues through the RCAC web site due to missing manager privileges. ||| User is unable to access RCAC server 'gilbreth.rcac.purdue.edu' via SSH with repeated BoilerKey authentication prompts and connection closure. ||| Unable to login into RCAC servers (Gilbreth/Bell) since last Thursday. ||| User Seohyun is unable to connect to any servers (e.g., Gilbreth) and websites related to RCAC. ||| 504 proxy error occurring when attempting to log-in to the RCAC Scholar cluster Gateway","- To resolve this issue, the user should contact the group responsible for managing licenses on RCAC. This can be done by emailing [Purdue Information Technology](mailto:Purdue.IT@purdue.edu) or calling their helpdesk at the provided number. - It is essential to provide specific details such as steps taken, error messages, and any other relevant information that might aid in diagnosing and resolving the issue. - Once the license has been renewed, the user should be able to log into RCAC with their username and regular password. ||| To gain access to Dr. Nemali's RCAC depot folder, follow these steps:
   1. Request account on the RCAC system: https://www.rcac.purdue.edu/account/request
   2. Once you have an account, inform Dr. Nemali that you need to be added to his unix groups within the depot folder. This will grant you access to the folder. ||| The user was advised to follow the Scholar login guide (<https://www.rcac.purdue.edu/knowledge/scholar/accounts/login?all=true>) to attempt logging in again. ||| To resolve this issue, verify which specific RCAC cluster the user is attempting to login to. Ask the user if they are currently active on any queue of the RCAC cluster and if their group has purchased access to the RCAC cluster from their supervisor. Providing these details will help in identifying the root cause of the problem. ||| - Contact one of the group managers (name, name Kubal, Pushkar G Ghanekar, or another faculty member with top privileges) to add Xuerui to the queues at RCAC resources. The group managers have been granted privileges for members management. - Check with HR, your local business office, or the person who entered her R4P for the status of Xuerui's career account. Her account might come with her R4P approval. - If necessary, ask a faculty member to remove any members from the group as they have the top privilege to add, promote, and remove members in their group. ||| The R4P (Research for Professionals) approval would help an external user obtain a Purdue career account. Once the user has a career account, the group manager of Negishi queue can add them to their queue, granting access to Negishi. For more information on purchasing access, visit https://www.rcac.purdue.edu/purchase and for details on the R4P process, visit https://www.rcac.purdue.edu/knowledge/negishi/accounts. ||| Encourage the researcher to include acknowledgment of RCAC resources in future publications when computational or storage resources have been utilized. ||| The user should try registering for the Coffee Hour Consultation again from the RCAC website (https://www.rcac.purdue.edu/coffee). If the issue persists, they can contact the support team either via phone at [phone number] or by email. Any Tuesday slot will work as a scheduling option. ||| To grant guest access to the RCAC system for Funing, the user should fill out an R4P (Request for Provision) form on behalf of the former student. For more information about this process, please refer to the user guide provided at this link: [R4P User Guide](https://www.rcac.purdue.edu/knowledge/bell/faq/login/questions/expiredaccount). ||| To log in to the RCAC remote desktop system, you can use either of two methods for Duo authentication. Firstly, enter your password in the password field and push to send a notification to the Duo app. Alternatively, check the Duo app, click on the Show button next to Passcode, and in the password field of ThinLinc, enter your password followed by the code. If this method still does not work, consider setting up a password-free login using SSH keys for direct access without requiring Duo authentication. You can follow this guide for assistance: [SSH Keys Setup Guide](URL_of_the_guide). ||| Add user's email address to both the Geddes users and RCAC news mailing lists. This should resolve the issue of not receiving emails from RCAC. ||| Users can consider accessing Scholar through Gateway or the native desktop app (https://anvilcloud.rcac.purdue.edu/knowledge/scholar/accounts/login/thinlinc). When logging in via the native desktop app, click on the checkbox to terminate the previous session and resolve potential frozen state issues. If the issue persists and ThinLinc is still frozen, the RCAC Support team can manually terminate the previous instance for the user. ||| To grant the visiting scholar admin access to the specified professor's RCAC account, permission from the professor is required. Once obtained, resources can be added to the account, such as shared nodes in Negishi and Gilbreth. The process for requesting these specific resources should be communicated by HPC support. ||| The user needs to contact the course staff or professor (name Boiler Up!) to gain access to the Scholar cluster. This should provide them with access to RStudio. Link to resource list for RCAC clusters: [https://www.rcac.purdue.edu/compute](https://www.rcac.purdue.edu/compute) ||| To run COMSOL jobs remotely on RCAC clusters, the user should be granted access first. If they know of any groups that have purchased access and are willing to add them to their groups, they can submit an access request via this webpage: [https://www.rcac.purdue.edu/account/request](https://www.rcac.purdue.edu/account/request) ||| - Ensure that the complete path ""\\datadepot.rcac.purdue.edu\depot\mylab"" is used in the folder location. - The student should not use 'push' at the end of their password. - The PI needs to add the student to the 'phig-data' Unix group for read/write access to the depot space. This can be done using this link: [RCAC Group Management](https://www.rcac.purdue.edu/account/groups/109/members?u=118172)
   - The student should connect to the Purdue VPN or be on the Purdue network before attempting to connect to the file depot. - In 'This PC' file explorer, map the network drive by clicking on 'Map network drive', entering '\\datadepot.rcac.purdue.edu\depot\phig' as the address and using their username 'rmedema' and their password without 'push'. ||| Instruct user to log in to the RCAC portal at https://www.rcac.purdue.edu/account/groups/3054/members?u=151376 and request their supervisor, Prof. name, to approve their application. ||| The issue with the user's account has been resolved. They can now log in. ||| The user needs to discuss with their supervisor about purchasing access to use the community clusters or GPUs at RCAC. Here are the details for Gilbreth GPUs at RCAC: [https://www.rcac.purdue.edu/compute/gilbreth](https://www.rcac.purdue.edu/compute/gilbreth)
To make an order for different GPUs, the user can visit this page: [https://www.rcac.purdue.edu/purchase](https://www.rcac.purdue.edu/purchase) ||| The user should log out and then start a new login session. After logging in, they can verify their updated group membership by running the ""groups"" command. If the output shows that the user is now part of the ""cae2"" Unix group, they will be able to load the Sentaurus module(s). ||| The user's account provisioning process was delayed and not fully set up yet. The user was advised to check their account again the next day (1~2 days) for potential resolution. ||| The user has been informed that their request is being processed internally and will be added to the internal-only network. They should confirm if this resolves the issue. ||| - The student has not received access to the account yet due to possible delays on the Purdue ACMaint side and TimeTable services. - The student is advised to ask their instructor to add them manually to the class via this link: https://www.rcac.purdue.edu/account/class
- After the manual addition, the account should be created on Scholar. ||| - Ensure that the user is entering the correct password (including case sensitivity) and trying without the ""push"" suffix if they have previously added it. - Verify the user's account status by logging in to the RCAC portal, checking for any errors or suspensions, and resolving any issues found. - If the issue persists, consider asking the user to reset their password through the RCAC portal and then attempt login again. - Check that Duo Mobile is installed on the user's device and properly configured with the correct account details. - Ensure that the user has granted permissions for notifications from Duo on their mobile device. - If the issue still persists, consider requesting the user to contact the RCAC helpdesk directly for further assistance. ||| The accounts should be ready to be processed and activated based on course enrollment after a batch process is run later on tonight. The user is advised to check back some time on Saturday to see if their account has been granted. The user is also encouraged to reach out to their professor about this issue. ||| Log in to the RCAC Gateway using the following link: https://gateway.scholar.rcac.purdue.edu/. Enter your password followed by `,push` when prompted. This will trigger a Duo Push for authentication. For additional help, consult the User Guide available at: https://www.rcac.purdue.edu/knowledge/scholar/gateway. ||| The user needs to ask their PI to add them to the cluster they have access to. Once added, they can access using the ssh command and when it prompts for a password, they need to append ',push' to their password. For example, if the password is ""abcde"", they should insert ""abcde,push"" and press enter. They will then need to approve the verification alert in the Duo app to gain access. ||| To resolve the write access error caused by a lock on the /tmp/nsight-compute-lock file, you can try creating a new session on the RCAC A30 desktop. If the issue persists, it might be necessary to clear or release the lock manually. Here's how to do that:
   - First, check if the process holding the lock is still running using the command: `ps aux | grep nsight-compute-lock`. - If a process is found, try killing it with the command: `kill <process_id>`, where `<process_id>` is the ID of the process returned by the previous command. - After killing the process, the lock should be released, and you should be able to work on your session without any issues. ||| To resolve the issue with accessing the RCAC Jupyter Notebook, please ensure you are using a supported browser (Google Chrome, Mozilla Firefox, or Safari) and ensure that you have connected to either Purdue WiFi or VPN. If the problem persists, try clearing your browser cache and cookies, then attempt to access the Notebook again. If this does not work, reopen this ticket for further assistance from Purdue RCAC Support team. ||| To resolve this issue, the support team needs to investigate and address the underlying cause that prevents the user's Jupyter Notebook session from becoming interactive after the initial start-up. Once resolved, the user should be able to interact with their session as expected. If the issue persists, the user is advised to open a new trouble ticket for further assistance. ||| To access Bell with ssh in the terminal, when prompted for a password, type your password (career account) followed by "" ,push "". Your Purdue Duo will then receive a notification to approve the login. If you don't have Duo Two factor authentication set up on your phone, you can do so here: https://service.purdue.edu/TDClient/32/Purdue/KB/ArticleDet?ID=454. For more information regarding the cluster, refer to the Bell User Guide at https://www.rcac.purdue.edu/knowledge/bell/accounts/login/purdue_login. ||| The user's password for the RCAC account may not be the same as their Purdue account password. It is recommended that the user reset their RCAC account password using the appropriate process (e.g., visiting the RCAC account management page and following instructions). For more information on managing your RCAC account, please refer to: https://service.purdue.edu ||| The HPC support team acknowledged the issue with approving pending requests on the accounts page and is working on a resolution. In the meantime, the support team added the student's group advisor as a contact on the ticket so that they can grant approval manually. After receiving the approval from the group advisor, the request was manually processed by the HPC support team, which takes around 1-2 hours to complete. The user guide for Gilbreth is provided here: https://www.rcac.purdue.edu/knowledge/gilbreth Once the accounts and access are ready, the HPC support team will notify the user. ||| Data Depot had issues with Samba connections yesterday, but the vendor is reportedly working on a fix. The user was advised to try connecting again to see if it works. If successful, this issue can be resolved without further intervention. ||| To resolve this issue, please try accessing the following URL again: https://www.rcac.purdue.edu/account/myinfo. If the problem persists, kindly contact RCAC Support for further assistance. ||| To gain access to an RCAC resource, the user must have a Primary Professor who can place the order and then add the user with permissions. The user should contact their primary professor directly for this process. ||| The issue was resolved by a staff member re-enabling the missing box in the backend system. The user should now be able to access the management tabs for the queues on the RCAC website. If the issue persists, the user should contact support again. ||| The user should attempt to log in to the cluster again. If the issue persists, it may be necessary to check the status of the SSH keys and their association with the correct account on the server. It would also be beneficial to ensure that the user's password is up-to-date and correctly entered during the BoilerKey authentication process. If the problem remains unresolved, please reopen the support ticket for further assistance. ||| The issue was related to ongoing account provisioning issues. The support team restarted the provisioning process and made sure it completed successfully. To fix a missing scratch directory (`mccar219`), the user was instructed to run the following commands:

```bash
name@bell-zfs:[bell] $ sudo mkdir mccar219
name@bell-zfs:[bell] $ sudo chown mccar219 ./mccar219
name@bell-zfs:[bell] $ sudo chgrp student ./mccar219
name@bell-zfs:[bell] $ sudo chmod 700 ./mccar219
```

Once these commands were executed, the user should be able to login again. ||| The West Lafayette campus experienced a widespread power outage over the weekend which affected all RCAC clusters. Power has been restored to campus and the clusters are back online and accepting jobs. For more details on the power outage, please refer to this link: https://www.rcac.purdue.edu/news/7225 ||| The Scholar gateway has been fixed. If you continue to see any issues, please let me know."
13,3,12,12,"User requests extension of Gilbreth panli-k queue and job time limit to 45 days. ||| The user (name) has reported that the alta-k and name-k accounts are giving an error when submitting jobs, despite being informed that these issues were resolved earlier. The user also inquired about the number of GPUs available on both queues. ||| Long pending time for jobs submitted on debug(gilbreth) cluster, with more than 2.5 hours of waiting when all nodes were shown available. ||| Error in job submission on Gilbreth HPC with specified command due to issues with user associations. ||| User's two jobs (4608967 and 4608970) are hanging on the perc for about two days due to reservation for maintenance on Gilbreth cluster, despite no notification received regarding the scheduled maintenance. ||| User 'name' is experiencing an error when submitting a job using the sinteractive command on account 'standby'. The queue associated with user's account has expired, and the user needs assistance to renew it or gain access to another queue. ||| Unable to submit SLURM job through sbatch command in debug queue due to ""slurm_load_jobs error: Unable to contact slurm controller (connect failure)"" ||| Job submission error in pi4d-h queue and requesting more cores than the queue limitation ||| Jupyter Notebook via Gilbreth is immediately completing after starting, and the user is experiencing job cancellations. ||| Jobs are being prevented from running on Gilbreth due to cooling issues in the facility housing the hardware. The error message reported is ""PartitionDown"". ||| Job containerization issue while submitting jobs to the Gilbreth cluster, specifically with /tmp/ directory. ||| Job submission failed due to CPU count per node not being satisfied on Gilbreth-F partition","The request for extending the time limit for the panli-k queue and individual job has been denied due to HPC policies designed for efficient usage of computational power and optimization of job management and scheduling. An alternative solution is to optimize the workload or discuss potential strategies for the user's computational tasks with the specified contact. If a user has an existing job running on this queue, they can request extending the wall time of the job when it reaches its end day. ||| Run the ""slist"" command to check the resources available for each queue. For alta-k, there are 36 GPUs accessible. The error with name-k is caused by a QOS limit with 0 CPUs and 0 GPUs in place, preventing jobs from being started in this queue. To see details on different node types, use the ""sfeatures"" command. Once the job (4075763) running in the name-k queue is completed, changes to this queue will be reflected in the output of the ""slist"" command. The user should check their account's slist report using the provided command and contact support if they have further questions or need assistance. ||| The issue was caused by a power and water outage in the data center that led to Gilbreth being powered off. The job (4227463) waited about 2 hours and 13 minutes before it started, but the wait time is reasonable due to busy compute nodes. To check pending reasons when jobs are waiting, use the ""jobinfo <job_id>"" or ""squeue -lj <job_id>"" command. The job (4227463) completed successfully with an exit code of 0 and used a total of 00:00:29 of walltime. The job was allocated on gilbreth-h011 node with 30 cores and 2 GPUs, using 48.32% for computation and 51.64% for I/O. If you have any further questions, please do not hesitate to contact support. ||| To resolve this issue, try resubmitting your jobs on the Gilbreth HPC after the reported resolution has been implemented. The updated command for submitting a job should be: `sbatch --nodes=1 --gpus-per-node=1 --cpus-per-gpu=1 --time=4:00:00 Run_Experiment.sh`. ||| The user was instructed to try requesting shorter walltimes and resubmit the jobs as they had requested a walltime of 14 days which would take them past the Jan. 24th maintenance period. The jobs were pending due to being reserved for maintenance. After resubmitting with a reduced walltime, the jobs started running. Here is an example command for submitting a job:

```
$ qsub -l walltime=02:00:00 myjobscript.sh
```

Replace `walltime=02:00:00` with the desired walltime in hours:minutes:seconds and `myjobscript.sh` with the name of your job script file. ||| To resolve this issue, discuss with your Project/Student (if applicable) about renewing the bera89-i queue or granting access to the bera89-k queue. This action will regrant their access to Gilbreth. For more information about account management at Purdue University, please refer to: [CS Purdue Queue Management](https://cs.purdue.edu/~ab). ||| To resolve this issue, check if the SLURM service is down. If it is, wait for the name group to address the problem. In case of prolonged downtime or immediate need to run a job, consider submitting it to another queue (e.g., normal, batch) that is currently operational and has available resources. For more information about SLURM commands and queues, consult the [SLURM User Guide](https://slurm.schedmd.com/quickstart.html). ||| Try changing the number of requested cores from -n 32 to -n 11 in the batch script. Check the limitation for the queue by executing ""sacctmgr show QOS pi4d-h-default"" command, which will display the CPU core and GPU limitations as cpu=11,gres/gpu=1. Use the same or lower number of cores while submitting jobs in this queue to avoid errors. ||| The user has confirmed that they do not have a custom '.bashrc' or '.bash_profile'. It is recommended to check the 'output.log' file for any errors related to this issue (the attached log file named ""output.log"" has been provided). If the problem persists, the user can schedule a meeting with support (preferably on Teams) to further investigate the environment. For now, the user can try using Jupyter Lab instead of Jupyter Notebook. ||| Gilbreth has been returned to normal service and is now accepting jobs again. If any further issues occur, please report them for assistance. ||| To resolve this issue, try running your jobs on the yunglu-k account instead of Gilbreth. ||| The issue appears to be caused by the requested node configuration exceeding the available resources in the Gilbreth-F partition. To resolve this, modify the job script to request less memory (within the limit of 192GB per single node on that partition) as follows:

```bash
#SBATCH --mem=192G
```

Additionally, ensure that other resource requests (such as CPUs and GPU) are also within the available limits for the Gilbreth-F partition. After making these changes, resubmit your job script to the Gilbreth-F partition."
8,3,14,14,"User's process (""slurm_gpustat"") keeps dying after a few hours and the user would like to keep it running for multiple days. The process is launched using ""nohup"" command in the front-end of Gilbreth. ||| The user's process named ""slurm_gpustat"" in the /home/gauenk/Documents/packages/slurm_gpustat/ directory keeps dying after a few hours, despite being launched with a ""nohup"" command and running multiple processes without issue. The goal is to capture GPU usage on Gilbreth for an extended period (e.g., a week). ||| Student is unable to submit jobs to Gilbreth cluster due to an unspecified error, encountering ""sbatch: error: Batch job submission failed: Unspecified error."" ||| ML model training is being killed without errors after the first run on Gilbreth A10 cluster's front-end node (gilbreth-fe03). ||| User is experiencing an issue with hyperparameter tuning in Gilbreth using name Tune, where the process is frequently aborted and results in a ""resource temporarily unavailable"" error. ||| User needs to submit CPU-only job on Gilbreth cluster but is being asked for GPU number by Jupyter Notebook and MATLAB Gateway. ||| Jobs stuck in pending state when submitted for GPU execution on Gilbreth cluster's cgb2-n queue ||| The user Berk is unable to see the output of their batch job submission when using 'sbatch' on Gilbreth. They used to see the output of the Python script and it was updated as they refreshed the page, but now they can only see the message ""the session was killed"". ||| Jobs in dkihara-k queue on Gilbreth cluster are not running as expected despite 4 GPUs being available. The jobs (6750219 and 6750221) have been pending for over half an hour and were later cancelled. ||| User named 'name' is experiencing an issue with Maestro simulation jobs failing on Gilbreth HPC due to backend error. The user also received a notification about connection issues to Maestro, as shown by the attached screenshot of the work log (TEP100_1U76_MD_multisim.log). ||| Job launches failed due to an issue with the gilbreth-k021 node. ||| Job 8484742 stuck in ""PENDING (launch failed requeued held)"" state using Slurm scripts on Gilbreth cluster. ||| The user's job on Gilbreth keeps getting killed after an hour due to resource allocation issues. ||| Submitted job on Gilbreth node kept failing with error message suggesting account lock due to cancelled jobs.","To ensure the process stays alive, the user should submit the job into the computing nodes instead of running it on the front-end of Gilbreth. This will allow setting a running time for the job. The user can find instructions about how to submit a job on Gilbreth with SLURM in this guide: [Gilbreth Job Submission Guide](https://www.rcac.purdue.edu/knowledge/gilbreth/run/slurm/submit). Additionally, the script's ""UNIX double fork method"" will put itself in the background without the need for anything like `nohup`. Be cautious about tracking the process from time to time and not duplicating it unintentionally. The user is also reminded to be careful when launching processes on different nodes, as it might cause issues due to the shared /home file system. Front-ends may get rebooted occasionally, so they are not ideal for running daemons. If the user continues to run the gpu-stat collection on the front-ends, it would be helpful to understand its purpose. The user has found a workaround by writing a program that remotely checks if their daemon is running on Gilbreth and relaunches it if necessary. ||| To ensure the process stays alive over multiple days, the user has resolved their issue by monitoring and relaunching the program remotely when it stops, instead of relying solely on the ""nohup"" command. ||| The student should use 'araghu-m' instead of 'araghu' as the account/queue name for their job submissions on the Gilbreth cluster. They can verify that 'araghu-m' is the owner queue by checking with 'slist' on Gilbreth. ||| To resolve this issue, it is recommended to avoid running jobs on the front-end nodes as they might not have a stable connection. Instead, follow the guidelines and training provided by Purdue University's Research Computing for submitting jobs on the Gilbreth cluster. You can find the required information at [Gilbreth Cluster Submission Guide](https://www.rcac.purdue.edu/knowledge/gilbreth/run) and [Purdue Clusters Training](https://www.rcac.purdue.edu/training/clusters201). If you have run your code with an interactive job, please provide your job ID so that the support team can check the status of your job. ||| The user should modify their job script to specify memory, subcluster, etc., as the issue may be due to a lack of specificity in the current configuration. The team suggests that the threads/processes/file descriptors in name Tune might be leaking, causing the resource unavailability error. Additionally, since name is sensitive to memory and other resources, specifying these details more precisely may help resolve the issue. ||| Unfortunately, it is not possible to submit jobs without a GPU on the Gilbreth cluster as all defined QoS settings require a minimum of one GPU per job. There does not seem to be a CPU-only QoS available on Gilbreth at this time. ||| To troubleshoot the issue of jobs being stuck in the pending state when submitting to run on GPUs with the cgb2-n queue on the Gilbreth cluster, check the job submission scripts and ensure they have been properly configured for GPU execution. Verify that the appropriate module(s) required for GPU usage are loaded before job submission. Also, double-check if there's any specific resource request (e.g., memory, CPU cores) that could be conflicting with the available resources in the queue. ||| The user can try setting separate stdout and stderr files for their SLURM job by adding these lines to their submission script:
   ```
   #SBATCH -e slurm-%j.err
   #SBATCH -o slurm-%j.out
   ```
   Ideally, the logs would go to the .out file and the error message would go to the .err file. The user should check their output files after running their job. If this does not resolve the issue, they may need to provide additional information or consult further documentation: https://slurm.schedmd.com/documentation.html ||| It appears that the jobs were started but then cancelled. This could be due to the K nodes being busy at the time of submission, which is considered normal since the jobs got started within 4 hours. ||| To assist with this issue, it would be helpful if the user provides details regarding the specific process within Maestro they are running and their submission method for jobs to backend worker nodes. The user should also specify whether they are requesting resources, using ssh, or configuring Maestro to work with SLURM. They should locate the working directory of this job as it contains more detailed information on the failed job. Requesting an interactive allocation using the ""sinteractive"" command and then running Maestro directly using ""maestro -SGL"" might alleviate problems with frontend-backend communication. If the user is still encountering issues, they should respond to this ticket for further assistance. ||| To resolve this issue, try resubmitting your job using a different node (e.g., #SBATCH --nodelist=gilbreth-k038,gilbreth-k047,gilbreth-k049,gilbreth-k050). The reported issue on gilbreth-k021 was resolved by rebooting the node. If you continue to experience issues after resubmitting your job, please reach out for further assistance. ||| The issue seems to be related to the node issues that occurred over the weekend on the Gilbreth cluster, affecting job allocation and causing jobs to remain in a pending status. Since those nodes have been fixed, you should resubmit your job (8484742) to see if it now completes successfully. ||| To prevent the jobs from being killed, you can reserve more memory for the job using the `--mem` flag or specify the job to use the node's entire pool of memory with the `--exclusive` flag. For details on how to use these flags, refer to this documentation: https://www.rcac.purdue.edu/knowledge/gilbreth/faq/jobs/questions/no_--mem0 When running your next job, try increasing the amount of reserved memory using these methods and report back if it helps with the issue. ||| The issue was caused by several Gilbreth-k nodes being set to drain due to a problem affecting those nodes. The user was advised to resubmit their jobs, and once the issue with the affected nodes is resolved, they will return to service."
15,3,22,22,"User unable to access Negishi cluster due to authentication failure ||| User encountered LDAP authentication error on Negishi cluster due to maintenance. ||| User unable to log into Negishi cluster via ThinLink client, receiving an error message about an unreachable session and incorrect user/password. ||| User is unable to access Firefox browser on Negishi cluster. ||| User request for user 'name' to be granted access to Negishi Cluster ||| User was unable to sign in to Negishi cluster using Gateway sign-in method for approximately 5 hours, but has been able to resolve the issue by trying again and waiting until the server issues were resolved. ||| User is unable to access EDEM software on Negishi clusters after successfully setting up ThinLinc app. ||| User Prof.name cannot access shared folders on server mapsweb.lib.purdue.edu/wpvlibmaps01.it.purdue.edu from Negishi cluster due to a potential firewall issue. ||| User is unable to log into the Negishi and Bell clusters due to a partially approved account issue. ||| User is unable to access HSI (High Performance Storage System) to connect to Fortress from the Negishi cluster due to an authentication error. ||| User cannot access Negishi cluster nodes and is unable to log out from currently used nodes, causing a hold on available resources. ||| User is experiencing issues accessing the eparkins group cluster on negishi.rcac.purdue.edu due to either missing permissions or an IAMO office issue. ||| The lab cannot login to the Negishi cluster using ThinLinc or terminal due to an LDAP authorization check failure error. ||| User unable to login to Negishi cluster due to LDAP authorization check failure. ||| User cannot log into Negishi cluster using their Purdue credentials despite successful Bell login. ||| Purdue PhD student (username jiew) cannot access the High-Memory partition on Negishi cluster with account rkhir. ||| User (roger377) cannot log in to Negishi cluster and map its scratch drive to their local computer; also experiencing login issues with Bell cluster. ||| User unable to connect to Negishi cluster due to incorrect username and password; unsure if hardware issues are occurring. ||| Unable to login to ThinLinc cluster using specified username and password ||| Samba connection permission denied error on Negishi Cluster after maintenance ||| Addition of users Jaden and name to the Negishi node group and subsequent login issues due to shells set to /bin/false. ||| User is unable to access data depot located in the Negishi lab and receives an 'Access denied' error message.","The user has been added to the reppertm (Negishi) queue via the web portal and their account on Negishi will be created during an overnight batch run. The user should be able to access Negishi tomorrow morning. There is no need for any further action at this time. ||| The issue is caused by the scheduled maintenance on the Negishi cluster today. Users are advised to check the news at https://www.rcac.purdue.edu/news/6189 for updates regarding the resolution of this problem. ||| The user needs to ensure they have checked 'End existing sessions' before clicking the login button in the ThinLink client. If using a passcode,push as the password, replace it with the correct username and password combination. ||| If the error message when opening Firefox is ""Firefox is already running, but not responding. xxx"", please refer to our user guide (https://www.rcac.purdue.edu/knowledge/negishi/faq/jobs/errors/firefoxalreadyrunning) for resolution steps. ||| Add user 'name' to the Negishi Cluster using appropriate HPC command (e.g., `module add <module>` followed by `modify accounts -a name`). Ensure that 'name' is added to the appropriate access control groups on the cluster. ||| The user was able to resolve the issue by attempting to sign in again after some server issues had been resolved on the Negishi cluster. No specific commands or configuration details were provided. ||| In the ThinLinc terminal, execute the following commands:
   ```
   $ source ~/.bashrc
   $ edem
   ```
   If this doesn't work, please share the error you're receiving for further assistance. ||| The recommended solution is to transfer files between the server and Negishi using SMB (Samba File System) method. Detailed instructions can be found at https://www.rcac.purdue.edu/knowledge/negishi/storage/transfer/cifs. If further assistance is required, please do not hesitate to ask. ||| After receiving incomplete approvals, the user should wait until the next central university runs (scheduled for early tomorrow morning) for their full account access to be granted. The support team will monitor the account to ensure proper functionality. ||| Run the command 'fortresskey' on the Negishi cluster and then try to use 'hsi' again. This command might resolve the authentication issue. ||| To resolve this issue, the user needs to release their held resources on the Negishi cluster. They can do so by executing the following command within the current terminal session on their local machine:

```bash
module purge
qdel ALL.q@[cluster-name]
```

Replace `[cluster-name]` with the actual name of the Negishi cluster (e.g., negishi). The above command will remove all jobs associated with the user and release any held resources on the cluster. Additionally, to confirm that the issue is resolved, the user can check if their jobs have been successfully deleted by using the following command:

```bash
qstat -u [username]
``` ||| The user was informed that their permissions look appropriate but the support staff will investigate further. Additionally, it was suggested that the user tries creating an SSH key by following this link: https://www.rcac.purdue.edu/knowledge/negishi/accounts/login/sshkeys. If the issue persists, the IAMO office may have to clear a potential jam in the system again. The support staff will get back as soon as possible with more information. ||| After reporting the issue, the engineer team has fixed both the login issue for thinlinc and browser versions of Thinclinc, as well as the Gateway. The user should now be able to sign on to the Negishi cluster using either method. ||| The user was instructed to try logging in again after a system change was made to address the issue. The user reported that they were able to successfully log in after following these instructions. ||| The user is advised to try logging in again as a change has been made to the system to address this issue. ||| The user's jobscript should be revised to remove the specification of memory for the partition. Instead, use the following script format:
```bash
#!/bin/bash
#SBATCH -p b
#SBATCH -A rkhir
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=128G
#SBATCH --time=24:00:00
#SBATCH --job-name=Test
#SBATCH --output=%x-%J.out
#SBATCH --error=%x-%J.err
module --force purge
module load anaconda
srun python test.py
```
Also, note that memory will be associated with the number of cores used, so it does not need to be specified explicitly in the script. After making these changes, resubmit the jobscript and try again. If further help is needed, please let us know. ||| The user should verify if they have appended "",push"" to their password when logging in to the clusters. If this is already done, the issue may take some time to resolve as it has been addressed by an administrator and will require propagation time. The user is advised to try again later and report any persistent issues. ||| The issue is likely a result of maintenance being performed on the Negishi cluster. Users should check the status of the maintenance at https://www.rcac.purdue.edu/news/7106. It is recommended to try connecting again after 5 pm when maintenance may have concluded. ||| The issue appears to be due to ongoing maintenance on the Negishi cluster. Check the status at https://www.rcac.purdue.edu/news/7106 for updates. In the meantime, try logging in later when the maintenance is completed or contact support if assistance is needed. ||| To resolve the issue, try reconnecting to the Negishi cluster using Samba again. If the connection works correctly, the problem should be fixed. ||| - Initiate the addition of users Jaden and name to the Negishi node group. - Obtain an email of approval from Professor [name, PhD Assistant Professor Associate Reactor Director, PUR-1 Director, Nuclear Engineering Radiation Labs School of Nuclear Engineering Purdue University West Lafayette, IN 47906]. - Add the users to their respective Negishi queues. - Upon successful addition, check if the user shells are not set to /bin/false (as this would prevent login). - If the shell is set to /bin/false, log in to Halcyon and correct the issue by updating the shell to a valid one (e.g., /bin/bash or /bin/tcsh) using the command: `chsh -s /bin/bash [username]` or `chsh -s /bin/tcsh [username]`, where `[username]` is the username of the affected user. - Once the shell has been updated, test the login for each user to ensure proper functionality. ||| When logging in at the terminal on the Negishi system, ensure that you are entering your password followed by your Duo passphrase (if applicable). Using the passphrase will send a notification to your phone for approval. Here is the link to the RCAC documentation on accounts and login procedures for the Negishi system: [RCAC Negishi Accounts and Login](https://www.rcac.purdue.edu/knowledge/negishi/accounts/login/purdue_login)"
10,3,44,44,"The user is experiencing issues with Gilbreth nodes for Vasp, suspected to be due to communication problems between openMPI and new version SLURM after maintenance. ||| The user is experiencing slow speed and freezing issues with Gilbreth, including trouble logging in, removing files, and starting Jupyter notebook kernels. They also mention that they are facing these problems along with other lab members. They need a solution as soon as possible due to an upcoming deadline. ||| The issue was with the degraded performance of Data Depot on Gilbreth, causing slowdowns in the workflow and making it impossible to make meaningful progress on the cluster. ||| The user is unable to request the Gilbreth training node as required nodes are not available. They suspect there might be issues with the Gilbreth-j nodes. ||| User is unable to install mpiicc into a container on Gilbreth Cluster and requests a one-on-one consultation ||| Gilbreth connection was disconnected temporarily ||| Gilbreth Cluster Scratch Storage Issues ||| User is experiencing issues with the Gilbreth cluster and believes it may be down. No maintenance notice has been received. ||| User is unable to allocate resources and start a session on Gilbreth cluster, with the issue persisting after multiple attempts. ||| User is unable to access the Gilbreth Cluster despite requesting for a 48-hour allocation, with the dashboard showing that the allocation starts but does not continue. ||| User is unable to allocate GPU resources on Gilbreth computing clusters due to a full home directory and cannot start Jupyter sessions through Gilbreth OnDemand. ||| The user is unable to run jobs on the Gilbreth cluster due to an invalid account error. The issue is caused by not specifying the correct account name in the srun command. ||| User encountered an error while updating packages on the Gilbreth cluster and is unable to create new sessions due to insufficient space in their HOME directory. ||| The user was unable to run a code on the Gilbreth cluster due to an error related to the GCC compiler version. ||| User (Zach) cannot find instructions on how to access the Gilbreth HPC node, despite having the required permissions for their research group. ||| User is unable to install a specific Python package (asleep) on the Gilbreth Cluster due to the requirement of Java 8 and assumes that Java is not installed on the cluster. ||| Gilbreth cluster user is unable to allocate nodes from the 'standby' queue and waiting for three days while colleagues can do so quickly. ||| The user cannot submit jobs on the Gilbreth Cluster using 'sbatch' command at 3:28pm, as shown in the screenshot provided. ||| Gilbreth Cluster Access Error - Cannot start session using interactive app ||| The user is unable to access or connect to a Jupyter notebook on the Gilbreth cluster due to an import error from packages installed under `~/.local`. ||| The user is experiencing an error with the Lmod module system on the Gilbreth cluster, which indicates that the MODULEPATH variable may not be set or is not pointing to valid paths. ||| User is experiencing issues with a Ph.D. project environment on the Gilbreth cluster, specifically encountering ""version 'GLIBC_2.27' not found"" error. ||| The user's HOME variable is not correctly set when logging into the Gilbreth cluster for user mathur72. ||| The user is unable to access the Gilbreth cluster and open Jupyter notebook, despite peers being able to do so. The user receives an error message ""503 Service Unavailable"". ||| User is unable to access Gilbreth cluster and Depot storage for research work under Professor Tricoche due to an error encountered during the request through the RCAC website. ||| User is unable to access their home directory and files within on the Gilbreth cluster due to login credentials not working after a recent update. ||| User cannot log into the cluster through the gateway on Gilbreth. ||| User needs access to Gilbreth cluster and wants to become co-manager for an account (Haddock Group). ||| User li4255 is unable to connect to the Gilbreth cluster using ssh and receives a ""Connection closed by..."" message. ||| User pate1539 experiencing difficulty in SSHing into the Gilbreth cluster, receiving a connection closed error related to port 22. Mentioned trying to send a local file into the cluster and canceling it before encountering issues. ||| User was removed from the Gilbreth cluster queue by the system due to a new security policy requiring their PI to email an approval for continued access. ||| User with ID 'name' was removed from the Gilbreth cluster allocation and is unable to SSH into the cluster. ||| User 'name' unable to access Gilbreth cluster due to removal from allocation ||| User has lost ssh access to Gilbreth-K cluster but can still map drive and access directories in SCRATCH and HOME. ||| The user is unable to access the wanglei-k account on the Gilbreth K-cluster due to their job requests getting stuck in queue forever. The error message shown with `jobinfo` is ""Launch failed requeued held"". ||| User is unable to log in to the Gilbreth cluster due to account not being assigned to any queues. ||| User cannot access Gilbreth cluster due to inactive user removal error. ||| Customer cannot log in to Gilbreth Cluster due to an issue related to account removal after inactivity. ||| The user is unable to access the Gilbreth cluster remotely on either VPN or directly. Access was working prior to April 17, 2025. ||| Network/firewall issue preventing outbound TCP port 443 from the gilbreth front-end and GPU nodes to Cloudflare IP ranges serving api.openai.com. ||| Unable to connect to Gilbreth cluster (neither via remote desktop nor SSH) due to restricted shell access. ||| User is unable to access the Gilbreth cluster, either through the web interface or shell access, receiving an ""Access denied"" message and a connection termination when trying to use shell access. ||| Gilbreth cluster account does not work due to expired trial allocation. ||| Account access issue with the Gilbreth cluster at Purdue University for user gong220.","To resolve the issue, the team is conducting tests and having discussions to find a workaround. They are also investigating the possibility that the updated cuda driver might not be compatible with the previous compiler used for VASP GPU (HPC SDK 22.7). The user has been added as a contact in another ticket (TDX #6981) where they can find updates and communicate further. It's recommended to use VASP 6.4.1 on Gilbreth, which is currently available for calculations. ||| To troubleshoot the issue, try switching to another login node on Gilbreth. If the problem persists, provide specific details such as affected servers and slow directories for further investigation. Monitor the behavior and report it to the relevant team if necessary. Keep in mind that this is an ongoing issue and updates will be provided accordingly. ||| Data Depot performance has returned to normal levels. If there are still problems with Data Depot usage, users are encouraged to report them. The link to the news update about this issue can be found at https://www.rcac.purdue.edu/news/5934 ||| Instruct the user to avoid adding a constraint for 'j' nodes in their job submission (i.e., avoid using -C 'j') and try again. For the time being, the user can request for Gilbreth-C nodes only by adding -C 'c' into their submission. ||| The user can follow the definition files provided by Apptainer (Apptainer and MPI applications — Apptainer User Guide 1.0 documentation) for installing MPI within their container. The support agent is available for a one-on-one consultation tomorrow morning from 11 am to 12 pm. The user should reply with the preferred time to schedule the meeting, as the support agent has sent a Teams meeting invitation. ||| The issue with the Gilbreth connection has been resolved. To check for further updates, please visit the following webpage: https://www.rcac.purdue.edu/news/6409. ||| The Gilbreth cluster was experiencing issues with its scratch storage over the weekend. These problems have been resolved by our engineers. If you continue to experience difficulties, please check the RACAC news page (https://www.rcac.purdue.edu/news/6423) for updates and consult the information provided there. Regards, name, PhD Senior Computational Scientist Rosen Center for Advanced Computing ||| To confirm the status of the Gilbreth cluster, please use the following command in a terminal to check its availability: `ssh gilbreth.rcac.local`. If the issue persists, please contact RCAC Support and provide any error messages or output from the above command for further investigation. ||| The user should try requesting a session for the minimum time allowed. If this does not resolve the issue, check if there is any problem accessing the Jupyter Notebook from the Gilbreth shell. In case of an issue with the Jupyter Notebook, follow these steps to access it:
   - Connect to the Gilbreth login node (e.g., ssh username@login.gilbreth.rcac.uri.edu)
   - Once connected, you can start a Jupyter notebook session using this command: `module load singularity; singularity exec --pwd /scratch/username /cluster/apps/software/jupyter-notebook jupyter-notebook` (Replace 'username' with your username)
   - The above command will start the Jupyter Notebook locally on the Gilbreth login node, and you can access it using a web browser by navigating to https://login.gilbreth.rcac.uri.edu:8888 from another device connected to the same network as the login node. ||| To resolve this issue, please ensure you have submitted a successful job request using the SLURM batch system (`sbatch`) on Gilbreth. If the problem persists, verify your allocation and quota usage by checking the `myquota` command output. For more information about SLURM on Gilbreth, consult the official documentation: https://docs.hpc.rcac.sfu.ca/display/RCACSLURM/Getting+Started+with+SLURM ||| Move the '.local/lib/python3.9' directory from the user's home directory to '.local/lib/python3.9.bak'. This should resolve the issue and allow the user to allocate GPU resources and start Jupyter sessions on Gilbreth OnDemand. The solution was provided in response to the user moving the '.cache' directory within their home directory, which did not resolve the issue. ||| To resolve this issue, the user must include the correct account name in their srun command using the --account option. Here's how they can do it:

   ```
   srun --account=accountname -n 1 --gres=gpu:1 --cpus-per-task=4 --mem=8000M --partition=debug --pty bash
   ```

   The user is advised to check their available accounts and partitions by using the `slist` command. For example, to list current number of GPUs, nodes, accounts, total queue, running jobs, free resources, max walltime, and types for account `rpujari`, they can run:

   ```
   slist rpujari
   ```

   Keep in mind that the `standby` queue has a maximum of 4 hours time limit and `debug` is only half an hour, while `csit-h` is the account where the user has priority on the resources. Use 'sfeatures' command to see details on different node types. ||| The user's HOME directory has exceeded its storage limit, preventing them from creating any more Open OnDemand sessions on the Gilbreth cluster. To resolve this issue, the user should clear some space in their HOME directory. Here are the steps to check and clean up their directories:

   a) Check current disk usage with the command:
      ```
      nshan@gilbreth-fe01:~ $ myquota mmirfara
      ```

   b) The output shows that the user's home directory (mmirfara) has reached its 25GB limit. Clean up any unnecessary files, archiving them or moving them to a different location as needed. To free up space effectively, consider focusing on large files and directories that are not frequently used. c) After cleaning up, re-run the 'myquota' command to ensure there is enough space available. If the issue persists, it may be necessary to contact the Research Computing team for additional assistance. ||| To resolve the issue, the user can load updated versions of the GCC compiler by executing the following commands in their terminal:
   - $ module spider gcc to view available GCC versions on Gilbreth. - $ module load <desired_GCC_version> (Replace `<desired_GCC_version>` with the desired version number.) After loading a more recent GCC version, the user reported that the problem was resolved. ||| To access the Gilbreth cluster, Zach can use SSH with a client such as PuTTY or Terminal (links provided below). If Zach prefers to access graphical applications or run graphical interactive jobs, they can use ThinLinc or Open OnDemand (also links provided below). For more information about Gilbreth, including detailed user guide and training resources, visit the RCAC website. - SSH client: https://www.rcac.purdue.edu/knowledge/gilbreth/accounts/login/sshclient
   - SSH keys setup: https://www.rcac.purdue.edu/knowledge/gilbreth/accounts/login/sshkeys
   - ThinLinc: https://www.rcac.purdue.edu/knowledge/gilbreth/accounts/login/thinlinc
   - Open OnDemand: https://www.rcac.purdue.edu/knowledge/gilbreth/gateway
   - Complete user guide: https://www.rcac.purdue.edu/knowledge/gilbreth
   - Training resources: https://www.rcac.purdue.edu/training/clusters101 ||| The user can verify that Java 8 (OpenJDK 1.8.0_402) is already installed on the Gilbreth Cluster by running `java -version` command. To install the package in a conda environment, follow the instructions provided here: <https://www.rcac.purdue.edu/knowledge/gilbreth/run/examples/apps/python/packages> If the user still encounters issues with installation, they should share the error message for further assistance. ||| The user's job is submitted to the shared 'standby' queue, which has lower priority compared to owner queue jobs. To ensure higher job priority, it is recommended that the user submits their job on owner queues instead. Here's a link to the Gilbreth documentation on Slurm queues: [Gilbreth Documentation - Queues](https://www.rcac.purdue.edu/knowledge/gilbreth/run/slurm/queues) ||| The user should wait for the Zoltan Nagy Group to resolve the issue. They are currently handling it. ||| The issue with accessing the Gilbreth cluster was resolved under ticket TDX-474297, where a team member assisted in adding you to the queue. You should now have full access to the system. If you encounter any further issues or if there's anything else required on your end, please reach out. For extending your access time, your PI can request an extension through our business office, and they will be able to review and process that request. ||| Remove or rename the `.local` folder (e.g., `mv ~/.local ~/local_backup`) so system jupyter will not be confused, and restart the Jupyter notebook. The detailed error log can be found in the session folder: '/home/skhokha/ondemand/data/name/dashboard/batch_connect/name/bc_jupyter/gilbreth/output/97f28a43-2911-444e-ba33-514536ef015c/output.log'. ||| The user should try running the following command to check if the issue persists: `module avail`. If the error message still appears, it is recommended to source the corrected module path by running the command: `source /etc/profile.d/modules.csh`. If this does not resolve the issue, contact RCAC support for further assistance. ||| Run the command `ldd --version` to check the current GLIBC version. If the returned version is 2.17 (as mentioned in this ticket), there might be a compatibility issue with the required software. To resolve this, it would be necessary to either recompile or find a compatible version of the software that supports GLIBC_2.17. The user should also provide any logs or additional information related to their environment and job submissions (such as submit1.slurm) to assist with diagnosis and resolution of the issue. ||| Set the correct HOME variable for user mathur72 on the Gilbreth cluster using the command `module unload cray-envvars` followed by `export HOME=/home/mathur72`. This change should persist across login sessions, but you can also set this in your .bashrc or .cshrc startup file to make it permanent. ||| After several attempts, the user was instructed to uninstall 'jinja2' from their local python packages. If this does not resolve the issue, a meeting is scheduled with the support staff for further assistance. The user should check their email for a Microsoft Teams invite. ||| The user needs to have their PI purchase access to Gilbreth (and thus Data Depot) as it is not a free resource. Pricing information can be found at this URL: https://www.rcac.purdue.edu/orders/products?search=&category=22&restricteddata=*&public=1 It's recommended to clarify any plans with Data Depot before proceeding with the purchase. ||| User should now be able to access Gilbreth without any further action needed. If the issue persists, please reach out for assistance. For more information about Purdue IT services, refer to https://service.purdue.edu. ||| The user was asked to double check their access to the cluster and report if they still have issues. If the issue persists, the user should share their availability so a meeting can be scheduled for further assistance. No specific resolution details were provided in this exchange, but it was later mentioned that the problem might be due to exceeding the 25GB limit of the home directory. The user was advised to move some data and report back on the status. ||| The user's account on the Gilbreth cluster is ready to go, and they are already a co-manager of the Haddock Group. There was no further issue reported in this ticket. ||| The user should follow this user login guide (<https://rcac.stanford.edu/wiki/UserLoginGuide>) to ensure they have followed the correct steps for connecting to the cluster. If issues persist, further assistance can be requested from RCAC Support. ||| It is possible that the user's account has been removed due to inactivity on computing nodes for more than 8 months, as part of a recent cleanup on Gilbreth. To continue accessing the cluster, users should ask their supervisor to add them back to the queue. If the user has recently run jobs with GPUs, the account removal might have been a mistake; in this case, the user should inform their supervisor to rectify the situation. ||| The user should contact their Principal Investigator (PI) and request them to send an email for re-addition to the Gilbreth cluster queue. Once the PI sends this email, there will be no further issues in continuing to use the Gilbreth cluster. ||| The user can either have their PI re-add them to the group's Gilbreth queue or they can request access again via the link: https://www.rcac.purdue.edu/account/request ||| The user can either have their PI re-add them to the group's Gilbreth queue or they can request access again via the link: https://www.rcac.purdue.edu/account/request ||| The user needs to either have their PI re-add them to the group's Gilbreth queue via the accounts page or request access again using the following link: https://www.rcac.purdue.edu/account/request. If there are any questions regarding this process, additional help is available. ||| The issue was resolved after an issue with several frontend nodes of Gilbreth that were not responding was fixed. The user was advised to try launching a new Jupyter session, which is now running successfully. To avoid similar issues in the future, it is recommended to monitor job queues and partition usage on the cluster using commands like `squeue -p gilbreth-k`. ||| Re-add the user to the Gilbreth accounts associated with their group (Lilly Computational Group and name group), which have Gilbreth allocations. This process can take around 1-2 hours for provisioning, after which the user should be able to log in to Gilbreth. ||| The user's account was removed from the Gilbreth cluster due to a system error that flagged inactive users for removal, even if they were still actively using the cluster. Access can be restored through their Principal Investigator (PI) submitting a request to have them re-added to the cluster. If this does not work, continue following up with the helpdesk for assistance. It is also important to note that the Gilbreth Operating System has been updated to Rocky 9, which may require updating job scripts and re-building any software built against the previous system libraries. For more information on Gilbreth, please refer to the user guide at [www.rcac.purdue.edu/knowledge/gilbreth](http://www.rcac.purdue.edu/knowledge/gilbreth). ||| The customer's account on the Gilbreth Cluster has been removed because it had no active jobs on computing nodes for more than 8 months. To resolve this issue, ask your supervisor to add you back to the queue to continue your work. ||| - Attempt to reconnect to the Gilbreth cluster again. If the issue persists, contact the Purdue IT Service Desk for further assistance. - In case of network connectivity issues or outages, check the service status page at https://it.purdue.edu/status/ before reaching out for support. ||| The user has been advised to use the following command as a workaround: HTTPS_PROXY=squid.rcac.purdue.edu:3128 openssl s_client -connect api.openai.com:443 -servername api.openai.com < /dev/null
It is also mentioned that the correct port number should be 3128 instead of 443 when using the proxy. This workaround might resolve the issue temporarily. The user has been informed that a permanent solution is expected this week. ||| The user's shell access was restricted during a cleanup of inactive Gilbreth users. To resolve the issue, re-apply the necessary permissions for the account by reaching out to PurdueIT | RCAC support team. After this, test the connection and report back if any further troubleshooting is required. ||| The user appears to have been affected by a recent internal cleanup of inactive accounts on the cluster. A fix has been applied to Halcyon, and the user is advised to retry accessing the Gilbreth cluster. If the issue persists, please contact RCAC for further assistance. ||| The issue is due to the expiration of the trial allocations on the Gilbreth/Negishi queues in Rajeev's name group, which occurred in February. To resolve this, Rajeev needs to join a research group with active queues or allocations on Gilbreth. If Rajeev's research group is interested in purchasing an allocation, they can find information here: https://www.rcac.purdue.edu/compute/gilbreth ||| The account provisioning process for the user gong220 was experiencing an error related to ongoing issues documented here: https://www.rcac.purdue.edu/news/7110. The account has been restarted and should be retested in 1-2 hours."
4,0,53,53,"Assistance needed to identify the Cisco Secure Endpoints admin for RCAC department at Purdue University to schedule a meeting regarding policy changes and connector management options. ||| Inquiry about bulk pricing promotions for Gilbreth A100-80GB GPU Access units. ||| Request for specific retirement date of the name cluster in 2023. ||| PhD student needs access to faster computing resources for ANSYS simulations as the current desktop computation is slow. ||| User inquiring about access to unlisted community clusters (Bell) at RCAC Purdue, seeking additional information and pricing details for potential future use. ||| PhD student, name, is requesting temporary access to the RCAC GPU cluster (Gilbreth) for research purposes as their advisor does not have funding to purchase access. ||| Researcher needs assistance with a free trial on Gilbreth cluster for molecular dynamic simulations using GROMACS software and Jupyter notebook or mac terminal. ||| Unable to submit poster for RCAC Cyberinfrastructure Symposium Poster Session and unsure if PDF submission is required. ||| User needs to sync Box folder data with RCAC cluster for collaboration purposes. ||| The RCAC (High Performance Computing system) has been unavailable since yesterday and new tasks have been in pending status for the Ph.D. Student in PurSec Lab. ||| PhD student in the name Dick group seeks assistance on running Gaussian jobs using Anvil cluster and guidance on Slurm usage at Purdue University. ||| A PhD student at Purdue ECE department is unsure if the purchased Geddes-GPU provides dedicated access to an A100 GPU or operates on a queue-based system. ||| A continuing lecturer in the physics and astronomy department is interested in purchasing computing time on a computing cluster with an intel fortran compiler for research projects involving undergraduate students. ||| User requires information on purchasing and using Ansys Workbench software on advanced computing resources at Purdue University ||| PhD student inquiring about access and usage of Gilbreth HPC service, specifically for machine learning tasks, with questions regarding dedication of resources, access methods, sharing resources within a group, and trial options. ||| Incoming MS student in Computer and Information Technology at Purdue University is seeking information about available graduate assistantships or part-time roles within the Rosen Center for Advanced Computing (RCAC). ||| Inquiry about billing for access and usage of specific queue on HPC cluster Negishi ||| Clarification on the cost of housing for RCAC REU program and potential conference travel costs ||| Inquiry about housing and conference expenses for the Anvil REU program in 2024 ||| A recent MS graduate from Purdue Statistics needs access restored to the ""statdept"" queue and associated machines on the RCAC clusters due to loss of access after graduation. ||| Request for guidance on filling out R4P forms for collaborators' access to Bell cluster resource at Purdue University ||| User needs guidance on citing RCAC resources for publications resulting from using Bell Computing resources. ||| User request to extend job running time on Standby Queue beyond 4 hours on Gilbreth HPC. ||| Proposal for a low-cost GPU as a Service (GPUaaS) cloud option for HPC needs, particularly for ML training and inference tasks using Nvidia H100 GPUs. ||| A visiting scholar requires continued access to the RCAC cluster after their program at Purdue University ends. ||| User from Purdue Indy (IU-HPC) requests allocation for accessing RCAC resources for transitioning to Purdue HPC ||| Request for installation of HINT-ATAC library through GitHub repository on the HPC system, with a preference for centralized installation as a Biocontainer in the future. ||| User needs access to RCAC community for calculation resources, specifically for running MATLAB scripts. ||| User is interested in full-time or research assistantship opportunities at RCAC ||| A Purdue Computer Science student is seeking information on using available GPUs for personal machine learning projects, specifically inquiring about the process and which GPUs are accessible. ||| Visiting Scholar needs access to Purdue's RCAC resources for one year following the end of their program. ||| User needs assistance with accessing an HPC system for teaching MGMT 288 and creating accounts for their class. ||| A PhD student, Malle, needs guidance on setting up the environment for machine learning and deep learning models, accessing GPUs for efficient model training and inference, best practices for submitting jobs to the queue, managing resource allocations, and optimizing performance for computations on Gilbreth cluster. ||| Request for cancellation of RCAC Order Management Team's monthly order series effective Nov 1, 2024, and deletion of associated resources from Geddes namespace. Additionally, data backups are to be destroyed to comply with NIJ's data requirements. ||| Graduate student at DRUG's Low lab seeks to streamline access management of lab members to RCAC resources by having staff provide approval when requested by Dr Low. ||| Request for installation of GPUDirect RDMA on user's own nodes in the RCAC cluster for enhanced GPU-based data transfer capabilities. ||| User needs guidance on submitting jobs for CP2K and ORCA on the RCAC Anvil cluster, specifically seeking example sbatch files or templates for CPU and GPU usage configuration. Additionally, user requests information about any specific modules or configurations for optimal performance with CP2K and ORCA on the Anvil cluster. ||| Grad student needs to set up automatic backup of their local home directory on an RCAC machine running Ubuntu to a remote directory on either the depot or Fortress using Globus or rsync and cron jobs. ||| User is unsure if they are in the queue for RCAC cluster access (gpu.scholar.rcac) and wants to confirm if it's available 24/7, including over weekends. They also want to expedite the process as they have an assignment due soon that requires access. ||| A third-year PhD student at the School of Materials Engineering at Purdue wishes to bring their wife to an R workshop offered by Purdue RCAC. The wife does not require a Purdue account or travel reimbursement. ||| User in economics department requires access to the RCAC cluster (Bell Cluster) and wants to add a co-author with PUID and username. ||| User requires assistance with installing the inferCNV package on the HPC system. ||| Request for granting guest access to RCAC for a former graduate student who needs to complete some work and set up long-term repositories on PURR. ||| Undergraduate student in CS 577 does not have access to scholar.rcac.purdue.edu for submitting SLURM job, requests access. ||| Request for access to RCAC High-Performance Computing Cluster for co-expression network analysis ||| PhD student requires access to GPU computing resources for research on artificial intelligence, specifically with NVIDIA H100 GPUs. The student cannot find purchasing information for Rossman cluster and wishes to purchase access through the RCAC website but is unaware of how to do so. ||| User is requesting information about the ""Quantum name school program"" collaboration between RCAC and Arizona State University. ||| User is interested in applying for a role at RCAC and seeks guidance on how to proceed with the application process. ||| A team of sophomore CS students are seeking RCAC support for their project that involves running a transformer model (FinBERT) to analyze the sentiments of top 20 S&P 500 stocks regularly. They require compute resources, model deployment, backend hosting & infrastructure, data processing & storage, and access to research tools for financial sentiment analysis. ||| Poster presentation registration status confirmation at the RCAC Cyberinfrastructure symposium was not received despite submission and the survey link saying it had expired. ||| Undergraduate student seeking guidance on access to GPU-enabled clusters for self-driven research project ||| User needs extension of their Purdue account and RCAC resources access due to ongoing research work in India. ||| Request for hourly or daily access to GPUs from Purdue RCAC compute clusters like Gilbreth (or other GPU- and CUDA-enabled clusters) for running experiments on LLM inference.","To resolve this issue, contact the appropriate individual at RCAC (RCAC department's Cisco Secure Endpoints admin) to arrange a meeting. Discuss potential dates and times that work best for all parties involved. Once the contact has been made and the meeting scheduled, update the meeting details in name and close this ticket. ||| Currently, there are no ongoing promotions for purchasing multiple units of the Gilbreth A100-80GB GPU Access. We recommend checking the RCAC website periodically for any updates on promotions or contacting us directly if you have any further questions regarding pricing and availability. ||| The name cluster is planned to be retired in November, 2023. However, there is no exact date available at this time. ||| The user may request access to several clusters (Negishi, Bell, Gilbreth, name and Data Workbench) at RCAC if their advisor has purchased access. Access can be requested via this webpage: https://www.rcac.purdue.edu/account/request or through the account portal by the advisor. The user should contact ECN for information about any other resources that might be available. However, the Scholar cluster (intended for instructional use only) cannot be used for research purposes anymore after the course ended. More details on Scholar can be found at: https://www.rcac.purdue.edu/policies/scholar. ||| The user was informed that the unlisted clusters have been sold out. However, they were advised to ask their PI or collaborators if they have purchased access to those clusters or are willing to share their computing resources by adding the user to their group account. For future reference, the user can check the up-to-date price via this link: RCAC - Orders: Community Clusters. The current price for Negishi is $4,200 per 64-core share, through its lifetime. A 2-week free trial access for the group can be arranged if needed to evaluate its suitability for their needs. ||| To grant temporary access to the Gilbreth cluster for the user ""name"", create a compute queue named ""ghafoor-k"" with access to 1 A100-80GB GPU. Have Professor Arif Ghafoor contact RCAC to set up a group account on the cluster. The user can then request access via the RCAC - Request Access link, and once approved, will be able to log into Gilbreth using Open OnDemand Gateway, ThinLinc Remote Desktop, or SSH. For instructions on login via SSH, refer to the Gilbreth User Guide: Accounts. The queue expires on 2023-10-01 00:00:00 but has been extended to 2023-10-10 00:00:00. For additional resources and training materials, visit the provided links. ||| The research group can proceed with the two-week free trial on the Gilbreth cluster for their molecular dynamic simulations. To access the cluster, a colleague (name) will assist with the setup process. It should be possible to run the simulations through the mac terminal or Jupyter notebook. For more specific chemistry questions, another expert (name) has been looped into the ticket. More details about Gilbreth can be found at: https://www.rcac.purdue.edu/compute/gilbreth ||| The link to the RCAC Cyberinfrastructure Symposium Poster Session Call-Out has been fixed. To submit the abstract, please access the form via this link: https://purdue.ca1.name.com/jfe/form/SV_78Od9AZsLj4LX94. At this point, you do not need to submit the full poster itself for the first step. ||| Unfortunately, it is not possible to connect Box to our clusters as Box is run by a commercial company. The alternative solutions suggested are using Data Depot or Fortress space, both linked to Purdue clusters. Depot is faster than Fortress if there is lots of I/O processes. The cost for Depot is $70 per 1TB per year. ||| The reported issue on Gilbreth nodes has been fixed. The user can now see jobs running normally. Apologies for any inconvenience caused. ||| The Computational scientist has offered to schedule a virtual meeting to discuss the necessary resources, instructions for choosing the appropriate cluster (Anvil) for free Gaussian job submission, and how to utilize Slurm in the Purdue University HPC environment. The student should expect a response from the Computational scientist early next week and can arrange a meeting by sending a meeting link. ||| The Geddes HPC system has only one type of A100 GPU, according to the system's information available at https://www.rcac.purdue.edu/compute/geddes. It is not specified in the provided message whether it operates on a queue-based system or provides dedicated access. Users can refer to the linked documentation for more details about Geddes system configuration and usage. ||| The Rosen Center for Advanced Computing (RCAC) does not sell Scholar as it is intended for education purposes, not for research. Bell is currently unavailable. However, Negishi, another RCAC cluster, is equipped with Jupyter notebook and can be used for the purpose described. To purchase time on Negishi, visit the RCAC purchase page at https://www.rcac.purdue.edu/purchase upon login. ||| The support assistant has scheduled a Webex meeting at 8:00 AM EST on Nov. 21 to discuss the details of accessing advanced computing resources for Ansys Workbench software. The user will receive an invitation to this meeting in their Purdue email account. ||| - The Gilbreth purchase will provide priority access to the specified GPU(s), but not dedicated 24/7 access to an actual machine or cluster. Jobs may still need to wait for some time (up to 4 hours) due to shared queues, but idle GPUs will be available for all users. - The Gilbreth user guide (<https://www.rcac.purdue.edu/knowledge/gilbreth>) includes information on various services and remote desktop access. - Upon purchasing resources, the PI and group managers can add/remove/control group members' access through the web portal. - The assistant will confirm A100 availability with the business office and offer a 2-week free trial on an A30 GPU for exploration purposes. The student is encouraged to consult their PI regarding this option. ||| The RCAC team suggested checking the Purdue career website (https://careers.purdue.edu/) regularly, as all jobs (full-time and part-time) from RCAC would be posted there. ||| The initial payment grants access to the alta and Negishi queues on the HPC cluster. There will be no additional charges for jobs submitted to these queues, unless the group chooses to acquire more resources. Jobs can also be submitted to the standby queue for free, taking advantage of idle resources on the cluster, but they may have longer wait times when the cluster is busy due to lower priority in resource allocation. ||| The housing cost for $200/week will be fully covered by RCAC, located at Hawkins [Housing Name]. If REU students attend a conference (e.g., PEARC24), the total cost will also be covered by RCAC. The organizer has provided further contact information to confirm details if needed: name, PhD Senior Computational Scientist Purdue Information Technology. ||| The entire cost of housing (assuming you utilize the Purdue Residence provided) is included in the Anvil REU program, with no required contribution from you to secure the housing for the duration of the Anvil REU program. Travel costs to a conference may be provided but will be determined during or potentially post the program if there's a paper or other contribution to a conference. For further information or questions, contact the specified Research Computing Project Manager via email, MS Teams chat/call, or Slack chat/huddle at the given email address. ||| To restore access, the user is advised to contact the current manager of the ""statdept"" queue (name). If a collaborator could be added, they should discuss it with them. However, a valid Purdue career account is required for a user to be added to the queues and access the community clusters. If the user's Purdue career account has been deactivated, they can work with their departmental business office to submit a Request for Privilege (R4P) to reactivate their account. For more information about the R4P procedure, please refer to this article: https://service.purdue.edu/TDClient/32/Purdue/KB/ArticleDet?ID=33 ||| To grant your collaborators access to the Bell cluster resource at Purdue, you will need to apply for a Remote Access for Purdue (R4P) account. The process can be initiated by filling out the R4P forms available here: https://www.purdue.edu/apps/account/r4p

Regarding your questions about the form:
- For the Org Unit, list the department you are affiliated with as your collaborators are working with you. In this case, it would be the School of Business (DSB) (4015) and Marketing (15010500). Although these units may not appear on the list provided in the form, they are valid departments within Purdue University. - The field for a person's SSN is optional in the R4P request form. You do not need to provide this information when filling out the form. For additional assistance or instruction, you can refer to this document: https://www.purdue.edu/hr/buspur/supportingDocs/r4pRequestorInstructions.pdf ||| The user should cite the community cluster program in their papers with the following reference:
   ```
   @article{McCartney2014, author = {McCartney, Gerry and name and name, Baijian}, journal = {Educause Review}, title = {{Empowering Faculty: A Campus Cyberinfrastructure Strategy for Research Communities}}, year = {2014}, url = {https://er.educause.edu/articles/2014/7/empowering-faculty-a-campus-cyberinfrastructure-strategy-for-research-communities} }
   ```
   Researchers are also asked to inform the RCAC research services team whenever any such research receives professional exposure. The user can find more information about acknowledging their usage of RCAC resources at: https://www.rcac.purdue.edu/about/acknowledge ||| Unfortunately, we are not able to extend jobs' walltime beyond 4 hours on the standby queue of Gilbreth. As a workaround, consider optimizing your current workflow by splitting tasks into different jobs with dependency settings. You can do this using the '--dependency' option in the sbatch command (see <https://slurm.schedmd.com/sbatch.html>). This allows continuing jobs to run after the previous one has completed. If you have further questions, please feel free to ask. ||| To consider the offer, gather information on the proposed solution from the provider, including details about pricing, consulting calls, and potential visits. The provider claims to be the country's 3rd largest GPUaaS cloud service with over 24,000 H100 GPUs in production across 5 geo-diverse Tier 3 data centers. They offer a low-cost dedicated private GPUaaS cloud for sensitive data and an elastic, self-service public GPUaaS cloud that is gaining popularity. The provider also offers free name support and solutions engineering services directly via messaging, without the use of ticketing systems. There are no ingress or egress fees, and the parent sponsor is non-for-profit. ||| The access to the RCAC cluster is linked with the scholar's Purdue credentials. If the scholar loses their Purdue credential, they will also lose access to the RCAC cluster. After the program ends, the scholar's Purdue account might not be active anymore. However, if the scholar wants to continue working with Prof. Hilkka and have access to Bell, they can ask Prof. Hilkka to file a R4P form on their behalf. Once the R4P form is approved, it will keep the scholar's Purdue credential active. For more details about how to apply for R4P for collaborators outside Purdue, please refer to this link: https://www.rcac.purdue.edu/knowledge/bell/faq/login/questions/expiredaccount ||| - A virtual meeting was scheduled between the user and a Senior Computational Scientist at RCAC for an introduction to their resource at RCAC. The meeting will take place on July 1st, from 11:00AM-12:00PM EST. - An invitation for the Teams meeting has been sent to the user. If necessary, they can reschedule the meeting for another time by contacting RCAC. - The user's group has been provided access to two queues: Negishi queue (1 node/128 CPUs) and Gilbreth queue (1 A30 GPU with 8 CPUs). These resources will be free due to the user being from IUPUI campus, but there may be additional subscription costs when these nodes get retired. - The user is designated as the group manager of their newly created group and can add/remove members at this link: https://www.rcac.purdue.edu/account/groups/3375/members?u=98107
   - User should familiarize themselves with the cluster usage by checking the user guides for both Negishi and Gilbreth clusters (https://www.rcac.purdue.edu/knowledge/negishi and https://www.rcac.purdue.edu/knowledge/gilbreth) as well as useful trainings provided by RCAC at these links: https://www.rcac.purdue.edu/training/purdue-indianapolis-resources and https://www.rcac.purdue.edu/training ||| An `rgt` biocontainer module has been deployed to the clusters and is currently available on the frontend nodes. The HINT-ATAC library should be accessible through the `rgt-hint` command. It is recommended to let the support team know if any issues are encountered with the container. ||| To gain access to the RCAC community, please ask the group managers of accounts Bell and Negishi from the Department of Physics to add you. ||| To learn about open positions at RCAC, the user should keep an eye on the RCAC website (https://www.rcac.purdue.edu/careers) for updates. ||| To use GPUs provided by RCAC at Purdue University for personal machine learning projects, you will need to have an account added from either a faculty member or your department. The Department of Computer Science has an account on Gilbreth that provides access to Nvidia A10 GPUs, and accounts on Bell and Negishi provide access to AMD GPUs. To get access, it is recommended to reach out to the group manager (name) of your department and inquire about adding you to their account. ||| To maintain access to Purdue's community clusters and storage systems after the program ends, the PI (in this case, Prof. Hilkka I. Kenttamaa) needs to fill out a Request for Privileges (R4P) form on behalf of the user. The R4P process is handled through the Identity and Access Management Office (IAMO). Here's a link to instructions on requesting an R4P: [https://www.purdue.edu/hr/buspur/supportingDocs/r4pRequestorInstructions.pdf](https://www.purdue.edu/hr/buspur/supportingDocs/r4pRequestorInstructions.pdf) ||| Use the Accounts for Classes tool to create accounts for your class. You do not need to request access again as you should now have it. ||| To set up a Python environment, refer to the user guide at https://www.rcac.purdue.edu/knowledge/gilbreth/run/examples/apps/python. For resource requests and job submission, please see the user guide at https://www.rcac.purdue.edu/knowledge/gilbreth/run/slurm. Additionally, recommended training materials on various topics can be found at https://www.rcac.purdue.edu/training. If further information is needed, please let the support team know. ||| - To cancel the monthly order series, user 'name' has cancelled order #14091, which had been renewed before cancellation. It is recommended to follow up with the team to ensure that any backups of the user's data are handled appropriately. - To delete all project resources from Geddes namespace, user 'name' has deleted deployments, databases, web endpoints, and data, which is irrecoverable. ||| It is possible for RCAC staff to add or remove permissions based on the PI's requests. Additionally, they can grant managerial permissions to anyone in the group at the PI's request. The graduate student has submitted a request to provide managerial permissions to their lab manager. ||| The installation of GPUDirect RDMA is permitted centrally onto nodes that the user owns, preferably in their home directory or in their project's allocated space. It's recommended to install any required python modules onto the home directory as well. Due to restrictions on kernel-modifying software, it's highly suggested to use containers to load modules onto its kernel. The user is advised to contact support for further help if needed. ||| To help you set up job submissions for CP2K and ORCA on the RCAC Anvil cluster, you can find examples of sbatch files in the [Slurm User Guide](https://slurm.schedmd.com/sbatch.html). For CPU usage, you may use the default Slurm job script, while for GPU usage, you might need to load specific modules and specify GPU resources in your sbatch file. For optimal performance with CP2K, ensure you have the required modules loaded:
```bash
module load cp2k/X.Y.Z
```
Replace X.Y.Z with the appropriate version number. For ORCA, you can load the module using:
```bash
module load orca/X.Y.Z
```
Again, replace X.Y.Z with the appropriate version number. You may find additional information about configuring jobs for CP2K and ORCA on the Anvil cluster in the [Anvil User Guide](https://docs.google.com/document/d/19RjUbM8NpPx40Q7iYGZO4y3vJ_Cf6-aqcRjh5wJz2zE). Additionally, consider reading the [Anvil User FAQ](https://support.access-ci.org/hc/en-us/categories/115001798011-FAQs) for common issues and solutions related to the Anvil cluster. To submit your job on the Anvil cluster, use the sbatch command followed by your prepared script:
```bash
sbatch my_job_script.sh
``` ||| To set up an automatic backup of your local home directory, you can use one of two methods: (1) Install Globus on your local machine and create a transfer timer using this guide: https://docs.globus.org/cli/reference/timer_create_transfer/. (2) If your local machine is a Linux system, you can use rsync in combination with cron jobs. You can learn how to use rsync here: https://www.geeksforgeeks.org/rsync-command-in-linux-with-examples/ and how to use cron jobs here: https://www.freecodecamp.org/news/cron-jobs-in-linux/. Globus option may be easier with a shorter learning curve, but you can choose either method. ||| To verify and get access to the gpu.scholar.rcac.purdue.edu cluster, the user should confirm with their professor if they have been requested for access. If so, the user can utilize job submission to the gpu queue using sbatch/sinteractive commands from the command line or use interactive apps on gateway.scholar. For more detailed information about job submission and usage of these commands, please refer to the appropriate documentation:
- [Using Slurm (sbatch/sinteractive) at RCAC](https://docs.rcac.purdue.edu/gpu/slurm/)
- [Gateway Scholar User Guide](https://docs.rcac.purdue.edu/gateway/scholar/) ||| Anyone can attend the Purdue RCAC workshop either in person or virtually, provided they do not require a Purdue account or travel reimbursement for the event. ||| - The user already has access to the Bell cluster, but their co-author is not listed on that resource. They can add the co-author using the ""add member"" feature. This will allow both of them to access Bell. - Here's the link to the Bell User Guide for further assistance: RCAC - Knowledge Base: Bell User Guide: [Bell User Guide](https://rcac.purdue.edu/documentation/bell-user-guide/)
   - The support team has arranged a Teams call, and they will send the meeting invite to the user at an agreed-upon time (originally 2:30 PM EST, but later changed to 4:00 PM EST on Friday). The user should also resend the invite to their co-author. ||| The user can install the inferCNV package in their home directory or their lab's data depot since it is not listed among the popular software on the system. To do so, follow the instructions provided by the linked resource to install software privately. Keep in mind that you should be able to install any software wherever you have writing permissions as long as the software does not require root privilege. ||| Complete a Request for Privileges (R4P) procedure for the former student. The R4P should be submitted before adding the former student to RCAC. Once the R4P is processed, the former student will gain access to RCAC. ||| The student was able to access SLURM using the alternative URL queue.cs.purdue.edu instead. No further assistance was required from RC Support. ||| To obtain access to the RCAC high-performance computing cluster, the user can consider two potential options: Negishi (https://www.rcac.purdue.edu/compute/negishi) and Negishi II (https://www.rcac.purdue.edu/compute/negishi-ii). The user is encouraged to schedule a meeting with an RCAC engineer to discuss the specific requirements of their work before proceeding. To arrange a meeting, visit this link: <https://outlook.office.com/bookwithme/user/?anonymous&ep=bwmEmailSignature>. ||| The Rossmann cluster may not be suitable due to its design for projects with heightened security requirements. Instead, the student should consider Gautschi or Gilbreth clusters which are well-suited for AI and high-performance computing workloads. The student's PI can purchase access through the RCAC website under Purchase → Community Clusters. If assistance is needed with the purchasing process, the Lead Bioinformatics Scientist at RCAC is available to help. ||| The user has been provided with a link to the NSF award page (<https://www.nsf.gov/awardsearch/showAward?AWD_ID=2417292&HistoricalAwards=false>) that contains more information about the program. It is suggested that the user reaches out to the PI for further details. ||| The user is advised to regularly check the RCAC career website (https://www.rcac.purdue.edu/careers) as they frequently post job openings there. ||| The student can schedule a video call with an RCAC representative for discussions on available services. RCAC has the necessary systems and platform services at Purdue to deploy such a project, but it isn't an open-access system. Faculty usually use their grant funding to provision allocations on compute and data storage systems. For projects requiring large AI models, there is a Kubernetes cluster called Geddes built for on-demand inferencing. If the student does not have faculty/departmental sponsorship, they may be able to prototype this project using CS resources on their Gilbreth cluster. However, this isn't usually used for coursework, and it would require talking with the CS Student Org coordinator that manages HPC resources for clubs. ||| The issue was resolved by the user, likely upon receiving a response from the support team confirming their poster presentation registration status and the availability of the survey. There were no specific technical details mentioned in this ticket message, as it pertains to an event registration and not HPC system issues. ||| The user needs to submit a project proposal through the ACCESS website (<https://www.rcac.purdue.edu/compute/anvil>) for their self-initiated machine learning-based algorithmic trading system research. They are advised to request a higher end of their estimated GPU hours, as the likelihood of the project being accepted is not known. ||| For the user's Purdue account and access to RCAC resources to remain active beyond the program end date, their professor must submit an updated Request for Privileges (R4P) form on their behalf through the Purdue business office. The R4P form will extend the user's primary Purdue career account, which in turn will automatically grant continued access to RCAC resources. The user should follow up with their professor regarding this process if needed. ||| The Gautschi AI cluster at Purdue University is the only system where access is calculated based on GPU hours. Available purchase options for Gautschi AI include Full GPU Hours, Half GPU Hours, and Quarter GPU Hours. These options are offered for 5 Years of GPU hours. For more details, visit: [https://www.rcac.purdue.edu/orders/products?category=22](https://www.rcac.purdue.edu/orders/products?category=22) . The support agent has suggested setting up a meeting to discuss specific options."
2,1,48,48,"User is unable to install Python packages in an Anaconda environment due to insufficient permissions. ||| User is experiencing intermittent slow response on Gilbreth cluster and having trouble with Conda-installed libraries not found during import. ||| Unable to perform 'pip install' or 'pip3 install' on Bell HPC cluster at Purdue University. ||| User is unable to install rsome package under Python using conda and requests assistance in creating a conda environment with Python 3.9.6. ||| User needs to run a Python2 script on Anvil HPC system and wants to know if there is a module available or how to install Python2. ||| Unable to install PyAudio package on Bell server under Dr Kais due to command not found error when using sudo apt-get. ||| User is unable to install a Python package called fitter using conda due to insufficient permissions on the specified directory. The user also mentions an error related to pip and suggests it may be caused by different group access issues. ||| User has upgraded Python but their kernel keeps dying and needs help troubleshooting or resetting it. ||| User is unable to install the python library ""xesmf"" in their conda environment named 'polaris_soil' due to a slow terminal process and failed package dependency solve. ||| User in the Purdue Basic Medical Sciences department is facing issues related to updating Conda/Anaconda software as the current system does not have plans for updates due to user's impending retirement on Nov 8, 2023. ||| Account du335 cannot connect to glibreth SSH and encountering a disk quota exceeded error during installation of ""accellergy/accellergy-neurosim-plugin"" package using command ""python3 setup.py build_ext && pip install . "". ||| User is unable to install pymeshlab and pyqt5 on gilbreth, getting a link problem error when trying to import pymeshlab. ||| User is unable to upgrade Python using sudo apt command on our cluster, specifically wanting to upgrade from version 3.8 to 3.11 for use with the 'poetry' package. ||| User is unable to install Python package ""cartopy"" on the Bell cluster using either Conda or pip. ||| User unable to install certain Python packages using Conda, specifically 'skopt', 'functools', and 'json'. ||| Unable to install 'trena' package on RStudio server (Negishi) due to permissions error and dependencies issue. ||| User is unable to install packages using pip, anaconda, git on Gilbreth and encounters an error while using anaconda. ||| User needs to install Python version >=3.7 but the default is 3.6.8. The user wants the default python version updated for all users. ||| Unable to install 'shiny' and 'gridExtra' packages in RStudio due to an issue caused by using the Launch RStudio Beta Server. ||| Error with running pytest on software test files due to dependency or library version conflicts within Conda environment. ||| User is unable to install the latest version of gpjax using Python and suspects it's due to the current Python version. ||| The user is experiencing an ImportError when trying to use the 'numpyro' package in a Python script on the Bell HPC system. The error message suggests a mismatch between the required and available versions of the C++ Standard Library (libstdc++). ||| Graduate Research Assistant is unable to connect Python 3.11 in Anaconda with PyTecplot in Tecplot 360 and getting ""Failed to connect to TecUtil Server"" error. ||| User wants to clone an existing Conda environment and module while maintaining the original environment and module intact. ||| User is unable to install and use the pyhdf package in their Conda environment (ThesisEnv) on RCAC-Bell HPC system for reading hdf4 files in Python. ||| User is trying to install 32-bits libraries on a Linux system but cannot use sudo commands directly. ||| Researcher needs help in setting up Python environment with specific versions and scheduling scripts on Purdue cluster (Negishi) ||| User is unable to find and load the Bokeh package in a central location on Negishi and Gilbreth, but would like to install it in their Anaconda environment for use with Jupyter notebooks. ||| Assistance needed in installing the latest version of TC-python on Negishi and Bell clusters. The installation files are located in the home/abejjipu/downloads directory. ||| Unable to install Python in an RCAC remote desktop using the regular method, and no installation window appears after downloading and extracting the latest version of Python. ||| Unable to install TASMANIAN due to lack of RWX permissions in the /usr/local/include directory. ||| A PhD student at Purdue University is experiencing issues with a large web scraping project on the semi-dark web, potentially due to computing power limitations. The error messages indicate either a timeout or invalid syntax in Python. ||| ModuleNotFoundError when trying to import pystata in a Python script within a Conda environment. ||| The user is encountering an ImportError while running a Python script in the Negishi cluster due to package conflicts between Python3.11 and Python3.9, specifically with the NumPy package. ||| User needs to upgrade their Python version on the Purdue Anvil GPU from 3.8.8 to a version >= 3.10 in order to install Nvidia-cudaq. ||| User is having trouble compiling a new code and suspects an issue with Anaconda, specifically when running on the executable located at /depot/jdelph/apps/Guoliang_JointPackage/Jon_testGL/MCMC_JOINT_bk2024. ||| Spyder (Python 3.8) is producing an untrusted application launcher error when launched via Krannert Remote Desktop (RCAC). ||| The module 'spidermodule' has lost functionality on Scholar, causing it to hang indefinitely when loaded with the command 'module spider'. ||| User cannot use Python in their virtual environment and reinstalling doesn't resolve the issue. ||| User needs Python library dmlab2d on their project but current OS has an incompatible version of glibc. ||| User is unable to install Python packages and encounters errors in their code. ||| Anaconda module was updated to Conda, resulting in an error 'No module named ""numpy""' when trying to run a Python script with Conda. ||| The user is experiencing an issue with the Pyperclip module not found in Spyder on the Scholar HPC system at Purdue University. This issue started after a change from Anaconda to conda, which requires separate installation of python libraries. ||| The user is facing issues with environment modules not being available post-server update, specifically anaconda/2020.11-py38, cuda/11.7.0, and gcc/6.3.0. The user requires these specific versions for their project but the newer versions are now provided after the update. ||| The user is unable to install Python libraries or packages within JupyterLab interactive session and now none of the kernels are loading properly. ||| The user is experiencing an error when running Python on the cocosys partition of the Gautschi cluster, specifically a LookupError: no codec search functions registered: can't find encoding. This error occurs after the first batch of jobs and persists despite setting PYTHONPATH within the job launcher script. The user suspects that the issue is due to the scratch space being purged, leading to the deletion of their Conda environments. ||| Unable to install Python package ""pymablock"" on Bell system using pip ||| The user is unable to run the 'monitor/2.3.1' module due to an error referring to an incorrect Python interpreter path in the script.","To resolve this issue, the user should follow the instructions provided at https://www.rcac.purdue.edu/knowledge/workbench/run/examples/apps/python/packages to install Python packages in an Anaconda environment. In order to create a Conda environment, use the following command:

```bash
conda create -n myenv
```

Replace ""myenv"" with the name of your desired environment. To activate the newly created environment, run:

```bash
conda activate myenv
```

To install a specific package, use the following command format:

```bash
conda install -c conda-forge package_name
```

Replace ""package_name"" with the desired package name. If you encounter any errors during installation, please provide screenshots of the error messages for further assistance. Additionally, loading the correct modules might help resolve the issue; share them if available. ||| - The user suggests that changing login nodes might help to resolve the issue of intermittent slowness in the cluster. - To address the library loading problem, the user was installing packages using both Conda and pip within their depot/prism/data/nguye713 folder on the Gilbreth cluster. It is recommended that users ensure they have the necessary environment variables set and load the appropriate modules before trying to import the libraries. - If the problem persists, it will be reported to the relevant team for further investigation. ||| The recommended solution is to install packages using conda install instead of pip. A guide for this process can be found here: [https://www.rcac.purdue.edu/knowledge/bell/run/examples/apps/python/packages#installing_with_conda]. Additionally, it's recommended to use 'python -m pip install' command instead of 'pip install', as this ensures that the package is installed under your own conda environment which should resolve permission issues. ||| The user can create a conda environment with the desired Python version (3.9.6) by running the following command:

```bash
conda create -n xxx python=3.9
```
Replace `xxx` with an environment name of your choice. For more information, refer to the official conda documentation here: https://docs.conda.io/projects/conda/en/4.6.0/commands/create.html ||| The user can create a new conda environment (e.g., 'conda create -n xxx python=2.XX' or 'conda install python=2.xx') on Anvil HPC system to run Python2 scripts. They should ensure to create a separate environment for this purpose to avoid conflicts with their existing environments. It is recommended to use the ACCESS Help Desk (https://support.access-ci.org/open-a-ticket) for future Anvil-related issues. ||| To install PyAudio, first purge all loaded modules using the command `module purge`. Then load Anaconda module with version 2020.11 and Python 3.8 by running `module load anaconda/2020.11-py38`. Create a new environment for PyAudio using `conda-env-mod create -n pyaudio`. Load your own modules using `module load use.own` and then load the specific environment with PyAudio and Python 3.8.5 by executing `module load conda-env/pyaudio-py3.8.5`. Lastly, install PyAudio within the new environment created by running `conda install -c anaconda pyaudio`. For more information about using Python packages on Bell server, please refer to: <https://www.rcac.purdue.edu/knowledge/bell/run/examples/apps/python/packages> ||| To resolve this issue, the user needs to change the path from '/depot/mylab/apps/mypackages' to '/depot/gdsp/apps/mypackages'. However, it seems that the user may not have access to the '/depot/gdsp/apps/' folder. In this case, the user needs to ask the group manager to add them to the gdsp group on RCAC's website (https://www.rcac.purdue.edu/account/groups/2557/members?u=115522). Once added, the user will have access to the folder and can install their packages there. Additionally, the user mentions an error related to pip, and it is suggested that they upgrade pip via the command 'pip install --upgrade pip'. This should only be necessary if the user has not already upgraded pip in their current environment. If the user continues to experience issues with pip after attempting this resolution, it may be best to register for an online coffee hour consultation (https://www.rcac.purdue.edu/coffee) to discuss their specific situation and get further assistance from a senior computational scientist. ||| To trace or reset the kernel issue, it is recommended to have a meeting with the user. The support assistant suggests scheduling a Teams meeting for next Thursday (9/14) after 2pm. If more immediate assistance is required, the user should provide additional details such as error messages or logs for further investigation. ||| The user can try creating a new conda environment with all required packages (esmpy, xarray, numpy, shapely, cf_xarray, sparse, numba, and xesmf) specified in one go to reduce the dimensionality of the dependency solve. Additionally, the user may experiment with using 'mamba', a new solver library that can improve Anaconda environment build performance, for future environments. ||| To resolve this issue, the user might consider installing a new version of Anaconda on their own space. Instructions for setting up an account and installing software can be found at <https://www.rcac.purdue.edu/news/6163>. ||| To resolve this issue, the first step would be to clean up some spaces in the home directory by either deleting or moving out files from the home directory. This can be achieved through gateway.gilbreth -> Files -> Home Directory. After freeing up space, try reinstalling the ""accellergy/accellergy-neurosim-plugin"" package without encountering the disk quota exceeded error. If you still face issues or need further assistance, feel free to reopen this ticket within the next 7 days. ||| To resolve the issue, it seems that the user has created an Anaconda environment named ""tree"" using the following command: `module load use.own module load conda-env/tree-py3.9.7 module load gcc/9.3.0 module load cuda/12.1.1 conda activate tree`. However, the issue still persists. To properly install pymeshlab and pyqt5 in this environment, please follow these steps:

   a. First, ensure that you have both libraries (pymeshlab and pyqt5) listed in your environment's requirements file (e.g., `environment.yml` or `environment.txt`). If they are not already there, add the required packages as follows:

      ```
      name: tree-py3.9.7
      channels:
        - conda-forge
      dependencies:
        - python=3.9.7
        - pymeshlab
        - pyqt
      ```
   b. Create a new environment using the requirements file with the following command: `conda create --name tree-py3.9.7 --file environment.yml`. c. Activate the created environment: `source activate tree` or `conda activate tree`. d. Install the required packages:
      ```
      conda install -c conda-forge pymeshlab pyqt5
      ```
   e. Now, you should be able to import the library without any issues: `python3 -c ""import pymeshlab""`. If you still encounter problems, double-check that the installed version of Qt is compatible with pymeshlab by running the following command:

      ```
      python3 -c ""from pymeshlab._init_ import *; from pymeshlab.lib import meshlab_common; print(meshlab_common.meshlabVersion())""
      ```
   If the output doesn't indicate a Qt version compatible with libQt5Core.so.5, try reinstalling pymeshlab and pyqt5 in your environment using the latest versions available from Conda Forge channel. ||| The user doesn't have sufficient privileges to install anything on the cluster. It is recommended to either use `--prefix` option or create a separate environment while installing packages. For further guidance, check out the Python user guide provided by the Rosen Center for Advanced Computing (RCAC) at this link: [RCAC Python User Guide](https://www.rcac.purdue.edu/knowledge/bell/run/examples/apps/python). ||| The user can refer to our user guide about python package management at https://www.rcac.purdue.edu/knowledge/bell/run/examples/apps/python for instructions on how to install packages. Additionally, there is a recorded training session available on this topic at https://www.rcac.purdue.edu/training/python-packages. ||| The user was informed that the intended package 'skopt' is named 'scikit-optimize' in the conda-forge channel. After recognizing that the names for skopt during installation and import are different, the user was able to install the packages successfully. It is recommended to verify the package names during installation to avoid confusion. ||| To resolve the issue, try installing the required packages into your personal library using `install.packages()`. For example, if you want to install a specific package called 'myPackage', you can run the following command:

```bash
install.packages(""myPackage"", lib = "".libpath"")
```
Replace `""myPackage""` with the name of the package you wish to install. Replace `"".libpath""` with your personal library path. After installing the required packages, attempt re-installing the 'trena' package again. If you still encounter issues, consult with our applications group for further assistance. ||| This issue was related to networking on Gilbreth and has been resolved. The user should double-check if the problem persists by trying to install packages again. If the issue still occurs, they can reach out for further assistance. It is recommended to ensure that the correct system is being used (Gilbreth). ||| The user can install a newer version of Python (e.g., 3.12.0) within their own Conda environment by activating the environment and running 'conda install python=3.12.0'. Alternatively, to create a new Conda environment with Python 3.12.0, use the command 'conda env create -n xxx python=3.12.0'. Before using Python in either case, check the version with the commands 'which python' and 'python --version'. ||| Login to ThinLinc and open a terminal. Load the necessary modules with the command `module load r rstudio/2023.06`. Then, open RStudio 2023 with the command `rstudio`. In the new RStudio session, try to install the two apps ('shiny' and 'gridExtra') again. ||| Create a new Anaconda environment by specifying packages in the `conda create` command. This will give Anaconda the best chance at resolving any library version issues automatically. Example of creating a new environment and installing pytest:

```bash
conda create -n myenv pytest
conda activate myenv
conda install -c conda-forge pytest
``` ||| The user is suggested to create a custom Conda environment for installing Python libraries. A related user guide can be found at https://www.rcac.purdue.edu/knowledge/negishi/run/examples/apps/python/conda. If the user encounters any issues, they should feel free to reply and seek further assistance. ||| First, ensure that you are using the correct Python version within your conda environment by checking your '.sub' file and loading the necessary modules. If needed, use the following command to load the correct environment:

```bash
module load anaconda/2020.02-py37
module load use.own
module load conda-env/mypackages-py3.7.6
module load gcc/12.3.0
```

If you have already done this and still encounter the error, it is likely that you are using the system's Anaconda installation instead of your own within the conda environment. To check the Python version, run the following command:

```bash
which python
```

Ensure that the output points to the Python interpreter within your conda environment. If it does not, you can set the PATH variable for Python by using the following command:

```bash
export PATH=/path/to/your/conda_env/bin:$PATH
```

Replace '/path/to/your/conda_env' with the path to your specific conda environment. After this, try running 'import numpyro' again and see if the error persists. If it does, you might want to consider scheduling a meeting with IT support for further assistance. ||| The issue can be resolved by ensuring that the server is available (i.e., having ""Accept connections"" checked on the Tecplot side) and running the Python code on the same node where Tecplot is running. To install PyTecplot, follow these steps:
   1. Load the required Anaconda module: `module load anaconda/2024.02-py311`
   2. Create a new Conda environment for PyTecplot and install necessary packages:
      ```
      conda create -n pytecplot python pip
      conda activate pytecplot
      pip install pytecplot
      ```
   3. Activate the Conda environment where Tecplot is installed:
      ```
      module --force purge
      module load anaconda/2024.02-py311
      conda activate pytecplot
      ```
   4. Run your Python script using the activated PyTecplot environment:
      ```
      python
      import tecplot
      tecplot.session.connect(port=7600)
      ... (Your code) ...
      ```
   If you still face any issues, please provide more details for further assistance. ||| The user can export the environment configuration file from the existing environment using the 'conda env export > my_env.yml' command. Then, they can use the 'conda env create -f /path/to/my_env.yml' command to create a new environment with this configuration file. Replace '/path/to/my_env.yml' with the actual path where you want to save the exported file. ||| To resolve this issue, the user can follow these steps:
   - Load the required modules:
     ```
     module load hdf/4.2.15 anaconda/2020.02-py37
     ```
   - Install pyhdf from the conda-forge channel:
     ```
     conda install -n ThesisEnv -c conda-forge pyhdf
     ```
   It is important to read the messages from Conda before proceeding with the installation to avoid any conflicts with existing packages in the environment. If the user encounters issues during the installation, they may need to resolve dependency conflicts or seek further assistance. - The pyhdf package can be found on PyPI (<https://pypi.org/project/pyhdf/>) and the conda-forge channel (<https://anaconda.org/conda-forge/pyhdf>). ||| To resolve the issue, the user should set up a container using Apptainer (also known as Singularity). This will provide root privileges within the container. More information about setting up and using Apptainer can be found at this link: https://www.rcac.purdue.edu/knowledge/negishi/run/examples/apps/apptainer ||| - To set up the Python environment with specific versions, the researcher can use their provided yaml files. - For submitting jobs to the Negishi cluster, the researcher is advised to check out the RCAC - Clusters 101 and RCAC - Clusters 201 training materials. The Negishi user guide could also be helpful. - The meeting has been scheduled for Thursday afternoon at the specified time (refer to original message for exact date and time). ||| To get access to Bokeh, users should install it in their own Anaconda environment. ||| Move the .run file from the home/abejjipu/downloads directory to /depot/coe-mse/data, then execute the binary_install_thermocalc.sh script located in the home directory to complete the installation process. The steps are as follows:
   - Rename the .run file to reflect the latest version
   - Move the .run file to /depot/coe-mse/data
   - Execute the binary_install_thermocalc.sh script located in the home directory. ||| Install the latest version of Python in a custom Conda environment by following these instructions at the provided link: https://www.rcac.purdue.edu/knowledge/scholar/run/examples/apps/python/conda. If any issues occur during the installation process, please reply to this email for further assistance. ||| To gain write access to the /usr/local/include directory, follow these steps:

   a. Open a terminal and type `sudo nano ~/.bashrc` or `sudo vi ~/.bashrc`, depending on your preferred text editor (nano is more user-friendly). b. Add the following line to the end of the file: `export TMPDIR=$TMPDIR/$(whoami)`. Save and exit the file. c. To apply the changes, type `source ~/.bashrc` in the terminal. d. Now you should be able to write files in the /usr/local/include directory. You can proceed with the installation of TASMANIAN. If you encounter any issues during the installation process, refer to the instructions provided at https://github.com/ORNL/TASMANIAN. e. For more information on software installation at RCAC, please visit https://www.rcac.purdue.edu/training/software-installation. Best regards, the RCAC team. ||| To address this issue, it is recommended that the user optimizes their code for better performance and reduces resource consumption. This might involve techniques such as using multiprocessing, reducing memory usage, or implementing pagination. Additionally, the user should ensure their code is written correctly by checking syntax and fixing any potential errors. The user can seek help with Python programming from other resources such as online tutorials, documentation, or forums. ||| After loading the Stata module using 'module load stata' and verifying it is loaded with 'module list', you should be able to import pystata. However, if the issue persists after following these steps, add '/apps/external/apps/stata/18/utilities' to your PYTHONPATH by editing your .profile or .bashrc file. Ensure the path is added in the format 'PYTHONPATH = $PYTHONPATH:/apps/external/apps/stata/18/utilities'. After these changes, Python should be able to find and import the pystata module. ||| To resolve this issue, ensure that the correct version of Python (3.9) is being used when running the script. First, check the currently active environment by using the command `module list`. Identify the module that provides the correct version of Python 3.9 (e.g., python/3.9.0). Then, use the `module load` command to activate that specific module before running your script:

```bash
module unload anaconda
module load python/3.9.0
```

After activating the correct Python environment, run your script again. If you are using a conditional import for NumPy in your code (e.g., `from {numpy_version} import numpy as np`), make sure to adjust the version number accordingly. Additionally, confirm that you have the correct module lists in both environments causing the error and working fine by running the command `module list` in each environment. ||| To upgrade the Python version, follow these steps:

* Load the Conda module for your desired version (in this case, 2024.09):
```bash
module load conda/2024.09
```
* Verify that you have loaded the correct version of Conda with the command `conda info`. Look for the ""active environment"" section to check the current Python version. * Upgrade your Python environment using the following command (replace 'env_name' with your desired environment name):
```bash
conda env create -f /path/to/your/python3.10_environment.yml
```
If you do not have a YAML file, create one by running `conda env export > python3.10_environment.yml`. This will save the current environment and its dependencies. After creating or updating your YAML file, you can recreate the environment with the new Python version. * Activate the newly created or updated environment:
```bash
conda activate env_name
```
* Verify that the upgrade was successful by running `python --version`. The output should display a version number >=3.10. Please send Anvil-related tickets through ACCESS Help Desk (https://support.access-ci.org/help-ticket) instead of rcac-help for assistance with Anvil issues. ||| In this instance, it appears the user has privately reported that the issue has been resolved. However, for documentation purposes, we would recommend the following steps if a similar issue arises:
   - Check that Anaconda is properly installed and configured in the system's environment. This can be done by running `conda info` to verify the presence of the Anaconda distribution. - Ensure that the code's dependencies, including any necessary modules or packages, are correctly specified and available within the active conda environment. - Make sure the correct compiler is being used for compiling the code. This can be achieved by setting the appropriate compiler flags in the build process (e.g., using `cc` or `g++` commands). - If necessary, consult the provided documentation related to the specific codebase for additional guidance on building and running the application. Examples might include project-specific configuration files or guidelines within the software's repository. ||| To resolve the issue with Spyder launching from the Krannert Remote Desktop, please ensure that the desktop file for Spyder is located in a secure directory and marked as executable. If it's not currently marked as executable, you can do so by using the `chmod +x` command in the terminal on the remote desktop. For example:

```bash
chmod +x ~/.local/share/applications/spyder3.desktop
```

If the issue persists, it may be helpful to try launching Spyder using the full path instead of the desktop file. To do this, open a terminal session on the remote desktop and navigate to the installation directory for Spyder, then run the following command:

```bash
/path_to_spyder3/bin/spyder3
``` ||| Run the command `module load spidermodule` again. If the issue persists, there might have been a temporary delay. ||| The user is advised to remove their Conda environment and start from scratch. If the user encounters issues during the installation of packages, they should attempt this process again. ||| There are two solutions provided:
   - Wait until the OS is upgraded from CentOS 7 to Rocky 9 by the end of February. - Use a container with a newer OS. Details on how to do this can be found at [this link](https://www.rcac.purdue.edu/knowledge/gilbreth/run/examples/apps/apptainer). ||| The user can resolve the issue by loading the required Python modules using the `conda load` command. For instance, if the user wants to load a specific module named 'my_module', they can use the command `conda load my_module`. If the user encounters any difficulties, they can refer to the documentation provided by Purdue IT at [this URL](https://service.purdue.edu). ||| To resolve this issue, activate your environment using the following command (replace `myenv` with your actual environment name):

```bash
conda activate myenv
```

Then install the numpy package by running:

```bash
conda install numpy
```

If you encounter any further problems, let us know. For more information on Conda, you can refer to their official documentation at <https://docs.conda.io/>. ||| To resolve this issue, the user should follow these steps:
   - Start a new desktop
   - Open a terminal and activate the necessary environment by running `module load conda` and `conda activate /apps/external/conda-env/py3.12-base`. - Install pyperclip by running `pip install pyperclip`. ||| The support team recommends using Conda instead of Anaconda on the clusters as Conda provides similar packages. They also suggest using containers to have all the packages with different versions as the user's program would need to run. ||| To resolve the issue with installing Python libraries or packages in JupyterLab, you may need to ensure that the necessary environment modules are activated before running your code. If error messages are encountered during installation, providing more details about these errors can help identify the problem. When attempting to install packages, using commands like `!pip install <package_name>` within a JupyterLab cell should work if you have the correct permissions. However, if none of the kernels are loading properly after making changes, it may be necessary to restart JupyterLab or check for any configuration errors in your environment settings. If you continue experiencing issues, consider reaching out again with more details about your setup and error messages, as needed. ||| To resolve this issue, the user should store their Conda environments in their /depot space instead of the SCRATCH or home directory. This is because the SCRATCH space is purged and has a 25G quota, while the home directory has a 25G quota as well. The user can set up and load .conda from depot/joshi157 (or replace joshi157 with their own username) to avoid this issue. Additionally, it is recommended to remove unused Conda environments using the command `conda env remove`. If the user encounters any questions regarding depot usage, they can refer to the relevant documentation for further assistance. ||| Install the package in a Conda environment by following these steps:
   - Create an environment in Conda: `conda create --name myenv`
   - Activate the environment: `source activate myenv`
   - Install the package using 'conda install pymablock' command. This will install the package to your active Conda environment. ||| Update the shebang line in the monitor script located at '/apps/external/monitor/2.3.1/bin/monitor' to point to the correct Python path, which is currently at '/apps/external/monitor/2.3.1/libexec/bin/python'. This task has been delegated to PurdueIT's applications team for resolution. It should be noted that this tool (and potentially other Python-based tools) is not relocatable."
21,2,20,20,"User requires access to COMSOL on their PC as part of joining a new group ||| Request for COMSOL license permission ||| User requires access to COMSOL software and is encountering a ""license not found"" error when attempting to use ThinLinc. ||| User needs help in downloading Comsol software onto a device, whether personal or Purdue-owned or RCAC clusters. ||| User needs assistance in accessing COMSOL software on either Negishi or Bell cluster and understanding how to use the software once they have obtained access. ||| COMSOL Multiphysics crashes after opening on Negishi Cluster. ||| User requires COMSOL version 6.2 on Bell but current version is 6.1 and user needs it updated. ||| User needs to inquire about the purchasing process and potential costs for additional modules (Heat Transfer, Semiconductor, Ion Transport) within COMSOL software. ||| Unable to access COMSOL GUI on Negishi cluster due to window crash after executing specified commands. ||| User has been granted access to COMSOL 6.1 on Negishi cluster but encountered a license error for the acoustic module. The user inquires whether the Purdue license of COMSOL 6.1 covers the acoustic module or if a separate license is required. ||| Request for quote and cost information for purchasing COMSOL licenses for a cluster ||| The user encountered COMSOL errors related to configuration location on Bell system, and received an error message stating ""Invalid Configuration Location"". ||| User is encountering a license error when using COMSOL on Bell and Negishi HPC systems, specifically unable to access the CAD Module due to user limitations. ||| User from Subbarayan-Shastri-Group requested access to COMSOL software but could not load it through the rcac account on their assigned nodes (Gilbreth and Negishi). ||| User is unable to access COMSOL software on the Negishi cluster due to license restrictions and needs urgent resolution. ||| PhD student using Comsol in Negishi cluster is unable to load the software due to an error and receiving a warning upon loading. The software was working fine previously. ||| User requested access to COMSOL license via RCAC but is unable to load the module despite being in a senior design class. ||| The user is unable to access COMSOL 6.0 on the Bell cluster due to its replacement with COMSOL 6.2, but they only have a license for version 6.0 and cannot run their simulations on any other version. ||| Graduate student (kim4368) cannot access COMSOL license as their account was not provisioned until May 20th and it appears that the registration of the COMSOL license may have failed when initially requested on May 15th. ||| The user is unable to launch COMSOL Multiphysics GUI on the negishi cluster due to a license error for versions 6.1 and 6.2. They believe access should be available through the College of Engineering but are encountering issues.","To grant access to COMSOL for the user, follow these steps:
   - Log into the Rosen Center for Advanced Computing (RCAC) system as an administrator
   - Navigate to the user management section
   - Locate the user's account and add them to the appropriate COMSOL group
   - Ensure the installed version of COMSOL is compatible with their operating system on their PC
   - After the changes have been applied, ask the user to restart their workstation if it is currently running
   - Inform the user that they should now be able to access and run COMSOL from their local machine once they log back in ||| The user had already resolved the issue and confirmed it. ||| To gain access to COMSOL, the user must be affiliated with the College of Engineering or collaborating with faculty from the College of Engineering. If this applies to the user, they should inform the support team for further action. ||| It appears that the user requires assistance with downloading Comsol software onto their device. However, it's important to note that Comsol needs a license. The College of Engineering at Purdue has purchased the license for Comsol. To obtain the software, please contact the appropriate party within the College of Engineering or RCAC for assistance in obtaining the licensed version of Comsol. ||| To access COMSOL software, the user should submit an access request via this link: https://www.rcac.purdue.edu/account/request If their advisor is interested in purchasing into Negishi, arranging a meeting to discuss details can be arranged. ||| Try opening a new terminal session and run COMSOL Multiphysics again to see if the issue persists. If the issue continues, it might be related to environment pollution at your current session. In such case, consider cleaning up or reinitializing your environment before running COMSOL Multiphysics. If the problem still persists after attempting these steps, please feel free to re-open this ticket for further assistance within the next 7 days. ||| To address the issue, please follow these steps:
   a. If you have the source code for COMSOL 6.2, install it in your own depot space. b. If encountering difficulties during installation, reach out to us for assistance. Note: We are still waiting for approval from the College of Engineering regarding the source code and license information for COMSOL 6.2 on Bell. As we do not have an estimated time of availability (ETA), it is suggested that you consider this option if you need immediate access to COMSOL 6.2. ||| To obtain a quote or information regarding additional features of the COMSOL license, you should contact the College of Engineering at Purdue University. RCAC is not responsible for purchasing COMSOL. ||| To access the COMSOL GUI, it is recommended to login to Negishi through Gateway (<https://gateway.negishi.rcac.purdue.edu>) or ThinLinc. Once logged in, select either ""Interactive Apps"" >> ""COMSOL"" or ""Interactive Apps"" >> ""Desktop."" In a Desktop session and ThinLinc, you will need to run the following commands in a terminal:

```bash
module load comsol
comsol
```

If further assistance is required, please let us know. ||| To clarify the licensing situation for the acoustic module in COMSOL 6.1, users are advised to contact the Engineering Computer Network (ECN) at this URL: <https://engineering.purdue.edu/ECN/Support> If questions about running jobs with Comsol fall under support category, users should address them through the usual support channels for Negishi cluster. ||| The requestor should direct their inquiry about COMSOL license pricing to the Engineering Computing Network (ECN) via their support page at https://engineering.purdue.edu/ECN/Support/KB/Docs/ComsolLicensing. The ECN team will be able to provide a quote for the COMSOL base + AC/DC + RF modules. It is not possible to obtain this information from RC Support. The cluster being referred to was not specified in the ticket message, so further clarification is needed on that front. ||| The issue was resolved when the user deleted some items from the .comsol file in their home directory that had filled up the quota. It is recommended that users monitor their quota usage regularly to avoid similar issues in the future. ||| The issue appears to be related to a license limitation, specifically the number of users currently utilizing the license has reached its maximum. To resolve this, it is recommended to check the following:
   - Verify if you are using your own license or the central license (i.e., ensure that no additional setup was done for license management). - If necessary, coordinate with your lab or department to increase the number of available licenses or reconsider the usage schedule to avoid simultaneous usage by multiple users. ||| The user encountered an issue loading Comsol software due to being assigned to nodes (Gilbreth and Negishi) where it is not available. To resolve this, the user should request interactive nodes on the Scholar or Bell node in their Professor's account to access COMSOL. If the user still encounters issues with the module load command, they can try using `module --ignore-cache load ""comsol""` and make sure that all modulefiles written in TCL start with the string ""#%Module"". The user should also check the spelling or version number of the module and verify that Comsol is installed on the node by checking if its modulefile starts with ""#%Module"". It is also possible that the cache file is out-of-date, so the user may try `module --ignore-cache load ""comsol""`. For more information, please visit https://service.purdue.edu. ||| The user has two options to resolve this issue:
   - Install their own version of Comsol that points to their own license file. - Contact Purdue's ECN to get the license issue worked out. Once the user contacts ECN and gets approved for access, they will be added to the correct group, and access should propagate through the system (which could take up to a day). The user should receive an email about it when it happens. ||| To troubleshoot the issue, it is recommended to check if any changes were made to the user's .bash_profile or .bash_rc files recently. Additionally, ending the current thinLinc session might help resolve the problem. If ending the session does not work, consider trying to use the gateway instead. However, the user experienced a stuck software issue when attempting to use the gateway. The application is now working with a warning message being displayed, but the PhD student has confirmed that it functions fine despite the warning. ||| The user should contact their instructor and request that they register the senior design class in Scholar. Once this is done, the instructor may be able to add the user to the account allowing them to use the COMSOL license on the HPC Clusters. ||| Reinstall COMSOL 6.0 on the Bell cluster or provide access to COMSOL 6.2 if it can be used with the existing license. The user has attached an image for reference (image.png). They are using the Acoustic Module of COMSOL and have reported a license error when trying to use COMSOL 6.2. A temporary solution is to deploy Comsol 6.0 on Bell, although it's not officially supported on Rocky 8. The user is encouraged to test if it works for them. ||| The PIER licensing team has confirmed that the student's professor hasn't purchased a dedicated research license for COMSOL. Instead, the three shared research licenses available in the College of Engineering can be used. However, these licenses are not applicable to individuals outside of the College of Engineering. The student would need to purchase a dedicated research license if they wish to use COMSOL. The estimated costs can be found at this link: [COMSOL Licensing](https://engineering.purdue.edu/ECN/Support/KB/Docs/ComsolLicensing). To initiate the purchase process, the student is advised to reach out to the RHTS team directly. ||| - Verify that the user is working on the correct cluster by running ""module spider comsol"" on the terminal to see what versions are available on the negishi cluster. - If necessary, request access to the bell cluster where COMSOL 6.0 is installed. The user should have activate queue on Bell (pi4d) and has been added to cosmos groups there, allowing them to use it. - To resolve the issue of unavailability of COMSOL 6.1 and 6.2 on the negishi cluster, bring the request to an application meeting for discussion and stay updated on any progress."
2,2,47,47,"User reports sluggish response from bell, intermittent issues loading modules (RCAC or bioinfo), and delays in listing files in both scratch and depot spaces on Bell HPC system at Purdue University. ||| The user is unable to run the command 'inspxe-cl -collect mi3 -result-dir ./inspector_results -- mpiexec -n 1 nemo small.in' on a system named 'name-a017', and an error message about an internal error and missing or empty result directory is returned. The user suspects the problem may be related to the result directory specified in the command, but has also tried running the command without this option with similar results. ||| User is unable to compile a module called qmlcode using either Intel or GCC compilers due to errors related to missing blas, lapack libraries, and lpthread file. The issue persists even after loading the required modules (intel-mkl, netlib-lapack, openblac). ||| A Ph.D. student at Purdue University is facing runtime problems with MPI functions when using gcc or intel compilers on the cluster 'name'. The code was optimized for LF95 compiler and requires changes to optimize MPI routines for gcc. ||| User is unable to install FPLO on Bell cluster's depot space due to missing dependencies (qt4-dev-tools, libncurses5-dev, libncursesw5-dev, python-pip, python.h) and lack of permission to use yum for installation. ||| User is unable to run ./hetero-enm due to a missing external library (Lapack). The user suspects the issue might be due to using an old version of the Intel compiler. ||| The Intel compiler is hanging without displaying anything when used on the system 'name'. The user has reported consistent issues with the Intel compiler and finds it more reliable to use GCC. ||| User requires installation of the latest version of iqtree2 with the -DUSE_LSD2=ON option for divergence time estimation functionality (lsd2). ||| HPC user is encountering compatibility issues between their application and PETSc libraries on the Bell cluster. The user is trying to run an application that requires at least version 10 of the GNU fortran compiler, but the default on Bell is gcc/9.3.0. ||| User is unable to use a locally downloaded Boost library with CMake for compilation due to cmake using the pre-installed version of Boost instead. ||| Unable to load GMT module due to an error related to the ""curl/7.85.0--openssl"" module dependency. ||| User requires an older version (Intel/18.0.2.199) of the Intel compiler for their Fortran code on the Anvil system, due to compatibility issues with the current Intel/19.0.5.281 version. The user is concerned about the impending deadline and prefers an older compiler to avoid troubleshooting issues. ||| User unable to load clusterProfiler package version 4.7.1.003 on RStudio instances launched from command line via ThinLinc on cluster nodes(pccr). ||| The user is experiencing compilation errors when running Fortran code on Bell using gcc/9.3.0 or above due to an internal error related to the file init.f and a possible out-of-bounds array access issue. The user received a segmentation fault when using lower versions of gcc. ||| The user is experiencing memory issues when compiling and running a Fortran code on Bell due to increasing the size of a variable in the code, resulting in relocation errors. ||| Error while loading shared libraries for iuhcell on Negishi due to missing libgfortran.so.3 file ||| Update DeepTools package to version 3.5.5 on Bell cluster. ||| Error when attempting to load amdgpu module in an interactive session on BELL cluster ||| Requested update of snpsift package to version 5.1 due to compatibility issues with SnpEff 5.1 ||| Research group in Engineering requires the latest version of PGI Fortran Compiler. ||| User is unable to install Scalapack 2.2.0 on cluster Negishi due to a Fortran compiler error during build process. ||| User was unable to install elpa on Negishi HPC cluster due to AVX512 compile error with GCC. ||| User is unable to install msmpisetup and lampps-6 bit in the correct order on their system. ||| Unable to load modules on HPC cluster negishi due to 'command not found' error ||| The user is encountering an error while training a machine learning model on Gilbreth due to the missing GLIBC_2.27 version in /usr/lib64/libm.so.6 and the associated issue with torch-sparse. ||| Unable to correctly detect C compiler during software installation using GCC on a cluster ||| User is unable to perform bgzip compression on vcf files due to missing htslib package. ||| User is experiencing issues building the DFT-FE package on HPC system Negishi at Purdue University. ||| User requires GLIBC versions 2.27, 2.29, and 2.18, but the operating system of Bell only supports version 2.17. ||| User encountered an error while implementing changes suggested in ticket #518834 on Purdue Anvil GPU project with allocation CIS240824 ||| User at Purdue is having trouble installing VOTCA using Spack, specifically with libecpint dependency. ||| The user needs to confirm the GLIBC version used by Anvil nodes and inquire about the planned OS update. ||| User is encountering a module compatibility issue with DeepSpeed after Gilbreth maintenance, due to missing libaio development libraries and headers. ||| User needs to update Glibc version on Bell cluster to a version higher than 2.29 for their software requirements. ||| User is encountering a Runtime Error while loading the Scanpy package on the pccr and highmem queues in the Bell cluster. ||| User is unable to install and create a QIIME2 environment due to an error about glibc not being the correct version (>= 2.8), while their current version is v.2.1.7. ||| Intel 2024.1 module load fails due to missing libstdc++.so.6 library, which is located in an alternative path. ||| User cannot find Intel MKL modules after system update ||| The user is experiencing an issue with loading older versions of samtools (specifically version 1.8) on the Bell system after the OS migration due to a module dependency problem involving gcc/14.2.0. This issue impacts their bioinformatics pipeline, which previously worked with samtools 1.8. ||| User requires reinstallation of the older Intel compiler (icpc) version 19.0.5.281 on Bell HPC system due to difficulties in modifying code for compatibility with the newer icpx version and significant impact on research progress. ||| Request to Reinstall Older Intel Version (19.0.5.281) for compatibility with previous codebase ||| ""Module load command is broken after system update"" ||| User is unable to get CP-FFT program to work on Gautschi due to missing fftw3-mpi.lib file and inability to find Lapack libraries. The user suggests installing CP-FFT and its required libraries on their lab group's depot for accessibility from multiple clusters. ||| User is unable to compile a code on the Bell cluster due to the lack of Fortran support in the new HDF5 installed. ||| A user needs help installing FFTW/2.1.5 library on Bell HPC system as FFTW/3 is not backwards compatible with their code. ||| User is having trouble compiling their code using a custom installed FFTW 2.1.5 library on Bell HPC system due to linking errors. ||| Module loads are hanging on Bell and access to /depot via samba is slow","The user is advised to test the system by logging into different front-end nodes to verify if the problem persists. Additionally, it is suggested that the issue may be related to Depot degraded performance in the past week but has since returned to normal levels. Users can refer to this link for updates on RCAC news: [RCAC News](https://www.rcac.purdue.edu/news/5934). If problems with Depot usage still persist, the user should reach out again for further assistance. ||| To resolve this issue, verify that the specified result directory (/scratch/name/tkubis/code2/prototype/debug_general/inspector_results/inspector_results.inspxe) exists and is not empty before running the command. If necessary, create the directory manually or use an absolute path for the result directory in the command. Here's an example of how to specify an absolute path using 'pwd' (print working directory):

```bash
mkdir -p /path/to/result_directory
inspxe-cl -collect mi3 -result-dir /path/to/result_directory -- mpiexec -n 1 nemo small.in
``` ||| After investigation, it was found that the missing pthread file might be associated with Intel compiler on Bell. Here are some steps to try resolving the issue:
   - Load the netlib-lapack module before compiling the code: `module load netlib-lapack`
   - If you are using Intel compiler, there is a reported issue and patches for qmlcode in this link (https://github.com/qmlcode/qml/issues/124). - If using GCC, try compiling with gcc/9.3.0: `module load gcc/9.3.0 anaconda/2020.11-py38 netlib-lapack/3.6.0` and activate the rdkit-gcc environment: `conda activate rdkit-gcc`. Then, import qml with Python: `python >>> import qml`. ||| To resolve this issue, the application group needs to be consulted for suggestions. If available, installing the LF95 compiler in the user's space on the filesystem (anywhere they have write permissions) may help solve the problem. However, it is important to note that LF95 is an outdated Fortran compiler, nearly 20 years old, and might not be available for contemporary Linux systems. If there's an updated version of the application targeting LF95, it should be investigated. ||| Schedule a consultation meeting with the user to discuss the installation of the missing dependencies in the depot space. Since these packages are Python packages, a conda environment might be required for their installation. The user should also ensure that they have access to the necessary tools (e.g., Teams) for the meeting and should check their calendar availability. If the user is not available during the proposed time slot, they should inform the support team to reschedule the meeting accordingly. In the meantime, keep the ticket open for future reference. ||| The user was instructed to load the intel module and set the LINK_LAPACK variable before running ./hetero-enm. If this does not work, the user's question is being escalated to the applications group for further assistance. The code is located in /home/zhu1241/allP/heteroENM/heteroENM_version8f/. The given commands are:
```bash
module load intel
export LINK_LAPACK=""-L${MKLROOT}/lib/intel64 -lmkl_intel_lp64 -lmkl_intel_thread -lmkl_core -liomp5 -lpthread""
```
If the problem persists, recompilation of the executable might be required. The user was asked to provide more information about how hetero_enm is generated. If the user has the source code, they should compile it with the command:
```bash
gcc hetero-enm-src/*.c hetero-enm-src/*.h -o hetero-enm -llapack
``` ||| The delay in loading the Intel compiler is due to it requiring a license for use, whereas GCC is open-sourced and immediately ready. The issue with intermittent slowness caused by communication with the license server on 'name' is being investigated. As a temporary solution, the user can download the new Intel OneAPI toolchain from the Intel website, which includes a more recent version of the classic Intel compiler for use without a license. This installation is easy as it's just a shell script and can be used immediately. It's recommended to download these tools now while waiting for central deployment in the near future. ||| Load the necessary modules (biocontainers/default and cmake/3.20.6), compile iqtree2 using CMake with the specified flags (-DEIGEN3_INCLUDE_DIR, -DIQTREE_FLAGS, and DUSE_LSD2=ON), and load the newly deployed module (iqtree2/2.2.2.9) for use. The command sequence would look like this:

```bash
module load biocontainers/default cmake/3.20.6
cmake -DEIGEN3_INCLUDE_DIR=/depot/heqixin/apps/eigen-3.4.0 \
      -DIQTREE_FLAGS=mpi -DUSE_LSD2=ON <path-to-iqtree2-source>
make && make install
module load iqtree2/2.2.2.9
``` ||| The user needs to uncomment ""module load gcc/10.2.0"" in their environment to use the fortran compiler from this module. If the user encounters further issues after recompiling their application, they should provide more details about the error and seek assistance again. ||| Ensure even after unloading the ""boost"" module, you do not have references to boost headers/libraries in any of your relevant environment variables (LIBRARY_PATH, LD_LIBRARY_PATH, CPATH). Remember that these search paths are searched in the order that the directories appear. If a directory containing the boost directory you do not want to include headers from is present in CPATH, remove it or rearrange the order of the directories such that it appears last. Let me know if you have any further questions. ||| To resolve this issue, follow these steps:
   - Run the command `module --ignore_cache load ""curl/7.85.0--openssl""` to load the required module. - Then, try loading the GMT module by running `module load gmt`. Alternatively, if the issue persists, you can try using an updated version of the GMT module from a different location. Here's an example of how to do this:
   - First, use the command `module use /depot/itap/jin456/modules` to set the module path. - Then, load the updated GMT module by running `module load gmt/6.2.0-new`. ||| The requested older version of the Intel compiler (Intel/18.0.2.199) cannot be made available on Anvil at this time, as support for older compilers has been discontinued by Intel. The team is planning to support Intel OneAPI compilers on Anvil going forward. If the user requires assistance with other issues or questions related to Anvil, they should submit a ticket through the ACCESS Help Desk (https://support.access-ci.org/open-a-ticket). ||| To resolve this issue, the user can try using a lower version of clusterProfiler (e.g., 3.6.1, 4.1.3, or 4.2) in their RStudio instance launched from command line via ThinLinc on pccr cluster nodes. However, since this specific function requires the higher clusterProfiler version-4.7.1.003, it is recommended to escalate the issue to the applications group for further assistance. Additionally, if disk space becomes a concern during the process, files can be stored in the user's /depot/ space instead of Desktop. ||| Compile the Fortran code with the flag `-fsanitize=address` to make the executable print detailed information about bad memory accesses. If this does not work, clean the existing compilation files by running `make clean`, and try again using a newer version of gcc. If the issue persists, consider using a different tool called `valgrind` (https://valgrind.org/docs/manual/quick-start.html) to hunt down the cause. Additionally, the user is missing some library files that are needed for the compilation process; specifically, /usr/lib64.libsan.so.0.0.0. To resolve this issue, ensure that the necessary module or library is loaded before compiling the code. ||| To resolve this issue, try using additional compiler flags `-fPIE -pie` which makes the program's memory layout more flexible. You can add these flags to your Makefile in the specified directory. Here is an example line that can be included in your Makefile for gfortran 9.3:
```
fflags = -mcmodel=medium -O -fPIE -pie -ffixed-line-length-none -fsanitize=address
``` ||| To resolve this issue, it is recommended to recompile the iuhcell program on Negishi since the current version has not been updated since the migration from name to neghisi. Before running the program, please ensure you are using the correct commands to invoke iuhcell. If your group has not re-compiled this program on Negishi, it is possible that you may be running a personal version. For more information or assistance with recompiling the program, please contact name, PhD Senior Computational Scientist at Purdue University. ||| The DeepTools 3.5.5 package is now available on both Bell and Negishi frontends. Over the coming hours, it will roll out to the compute nodes as well. However, if there are any issues with the upgrade, please let us know immediately. ||| To suppress the error message and run the command without accessing the `amdgpu` drivers, update it to only use the CPU by modifying the script or command line options as follows:

```bash
#BSUB -A gpu  # This line should be removed if you don't need GPU resources
module load cpu_only     # Load CPU-only module (if available)
import name.data as rd
```

Alternatively, submit the job to a node that has an AMD GPU and configure it to use only the CPU:

```bash
#BSUB -A gpu  # This line is required for nodes with GPUs
module load cpu_only     # Load CPU-only module (if available)
import name.data as rd
``` ||| SnpEff 5.2, 5.1d, and 5.1 versions of the snpsift package will be rolled out to Bell and Negishi servers overnight. For more information about using snpsift, refer to the documentation at https://biocontainer-doc.readthedocs.io/en/latest/source/snpsift/snpsift.html ||| The PGI compilers have evolved into the NVIDIA HPC SDK (<https://developer.nvidia.com/legacy-pgi-support>). To obtain the latest NVIDIA HPC SDK, download the installer(s) via the following webpage: <https://developer.nvidia.com/hpc-sdk-downloads>. ||| The user was trying to compile Scalapack using GCC/11.2.0, but it only supports GCC > 10. Here is the suggested command sequence for compiling Scalapack with GCC/10.3.0:

```bash
cd scalapack-2.2.0
mkdir build
cd build
cmake '-DBUILD_SHARED_LIBS=ON' '-DBUILD_STATIC_LIBS=OFF' '-DBUILD_TESTING=OFF' \
      '-DCMAKE_C_COMPILER=cc' '-DCMAKE_Fortran_COMPILER=ftn' \
      '-DCMAKE_C_FLAGS=-fPIC -march=znver3' '-DCMAKE_Fortran_FLAGS=-fPIC -march=znver3 -fallow-argument-mismatch' \
      '-DUSE_OPTIMIZED_LAPACK_BLAS=ON' '-DBLAS_LIBRARIES=$(which libblis.so)' '-DLAPACK_LIBRARIES=$(which libflame.so)' \
      '-DCMAKE_INSTALL_PREFIX=$INST' ..
make -j16
```

Replace `$INST` with the installation prefix directory as per your environment. ||| The user should follow the instructions provided in the dftfe installation guide (<https://github.com/dftfeDevelopers/install_DFTFE/tree/perlmutterScriptDealii9.5.2_withPetscSlepc>). During the installation, they needed to add additional flags `cflags=('-march=native' -fPIC -O2 -I'$MPICH_DIR'/include '-mmmx -msse -msse2 -msse3 -mssse3 -msse4.1 -msse4.2 -msse4a -msha -maes -mavx -mfma -mavx2' '-mavx512f -mavx512dq -mavx512ifma -mavx512cd -mavx512vl -mavx512bw')` to fix the AVX512 issue. ||| The user should ensure that they install msmpisetup before installing lampps-6 bit. After installing msmpisetup, they can proceed with the installation of lampps-64bit. If necessary, seek further guidance on the specific installation process for your personal or lab computer from the HPC support team. ||| To resolve the issue, log into the correct server (negishi.rcac.purdue.edu) instead of desktop.negishi and attempt to load the desired module again. This should correctly load the required modules on the HPC cluster. ||| To resolve this issue, you can try updating the GLIBC library by running the following command as a root user (use `sudo` if you are not):

```bash
sudo yum update glibc
```

After updating the GLIBC library, reinstall the affected conda environment and dependencies:

```bash
conda env remove -n cent7
conda create -n cent7 python=3.8 torch geometric
```

Finally, activate your new conda environment and ensure that the issue with torch-sparse has been resolved:

```bash
conda activate cent7
pip install torch-geometric -f https://data.pyg.org/whl/torch-1.8.1+cu102.html
``` ||| To resolve this issue, try the following steps:
   - Navigate to the directory where your software is installed or being built: `cd <software_installation_directory>`
   - Ensure that the PATH environment variable includes the correct compiler binaries by modifying it as needed. For example, you can add the following lines at the beginning of your shell startup file (e.g., ~/.bashrc):
     ```
     export PATH=$/apps/spack/negishi/apps/openmpi/4.1.4-gcc-11.2.0-e4mnuo4/bin:$PATH
     export LD_LIBRARY_PATH=$/apps/spack/negishi/apps/openmpi/4.1.4-gcc-11.2.0-e4mnuo4/lib:$LD_LIBRARY_PATH
     ```
   - After modifying the PATH environment variable, source your shell startup file to apply the changes: `source ~/.bashrc` or equivalent command for your specific shell. - Re-run the software installation command to verify if the C compiler is now being detected correctly. ||| The htslib package can be found and installed on the system through the following steps:
    - Access the HTSlib package on RCAC by using the provided link: [HTSlib on RCAC](http://www.htslib.org/download/)
    - Follow the installation instructions provided in the official documentation to install htslib on your system. - Once installed, you should be able to use bgzip command for compressing vcf files. If you still require assistance, please let us know! ||| To resolve this issue, the user should first ensure that they have loaded the required modules for compilers (gcc/12.2.0), MPI (openmpi/4.1.4), CMake (3.24.3), and Intel Math Kernel Library (intel-mkl/2019.9.304). This can be done using the following command:

```bash
module --force purge module load gcc/12.2.0 openmpi/4.1.4 cmake/3.24.3 intel-mkl/2019.9.304
```

The user should also define the library PATH on their `setupUser.sh`. Additionally, libxc libraries are built under gcc/12.2.0 on Negishi and can be found in the folder:

```bash
/apps/spack/negishi/apps/libxc/5.2.3-gcc-12.2.0-kgicpou
```

Once these steps have been taken, the user should attempt to reinstall DFT-FE and see if they can successfully build it. ||| To obtain the required versions of GLIBC, the user should use a container with an operating system that supports the desired versions. For more information on using containers on Bell, visit this link: https://www.rcac.purdue.edu/knowledge/bell/run/examples/apps/singularity ||| The user is advised to submit any Anvil-related issues through the ACCESS support portal at https://access-ci.atlassian.net/servicedesk/customer/portal/2. The response does not provide a specific resolution for the error mentioned in the message. ||| To resolve the issue, it was found that spack had issues installing libecpint, which caused an unsuccessful installation of VOTCA. After resolving the issues with libecpint, VOTCA was successfully installed. The user attempted to solve the problem again before the scheduled meeting and managed to get it resolved independently. ||| Anvil uses GNU libc version 2.28. The HPC support team plans to eventually update Anvil's operating system to something like Rocky Linux 8/9, but a specific date has not been provided yet. For future reference, the user is advised to send Anvil-related tickets through ACCESS Help Desk (https://support.access-ci.org/help-ticket). ||| Load the newly deployed libaio module. Use the following command to load the module: `module load libaio`. This module should contain both the required libraries and headers for DeepSpeed. ||| After the upcoming maintenance on Bell cluster, Glibc version will be upgraded to 2.28. If that doesn't meet your software requirements, using a container with an operating system that supports a newer version of Glibc would be recommended. You can learn more about using containers on Bell here: https://www.rcac.purdue.edu/knowledge/bell/run/examples/apps/singularity ||| The user is asked to run `which python` command to identify the location of the Python used in their current environment. Once they provide this information, the error may be resolved by ensuring that the correct version of Python (compatible with Scanpy) is being used in the specified cluster queues. ||| To resolve this issue, the user should build and use an Apptainer container on the cluster. Here's a detailed explanation of the steps to create and use such a container:
   - Create a directory for the container: `mkdir -p /tmp/lewis789`
   - Navigate into the newly created directory: `cd /tmp/lewis789`
   - Build a new Apptainer container with the necessary files and software (in this case, QIIME2):
     ```bash
     apptainer build --fakeroot --sandbox qiime2/ docker://ubuntu:latest
     ```
   - Create directories for scratch, apps, and depot within the container:
     ```bash
     mkdir -p qimme2/{scratch,apps,depot}
     ```
   - Download the Miniforge3 installer script (replace `latest` with the actual version if necessary):
     ```bash
     wget https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh
     ```
   - Shell into the newly created container with writing permissions and run the Miniforge3 installer script:
     ```bash
     apptainer shell --fakeroot --writable qiime2/ Apptainer> apt-get update
     Apptainer> apt-get upgrade --yes
     Apptainer> bash Miniforge3-Linux-x86_64.sh -b -p /opt/conda
     Apptainer> /opt/conda/bin/conda env create -p /opt/qiime2 --file https://data.qiime2.org/distro/amplicon/qiime2-amplicon-2024.10-py310-linux-conda.yml
     ```
   - After successfully creating the container environment, you can re-pack it as a single executable (immutable) using:
     ```bash
     mkdir -p ~/apps
     apptainer build ~/apps/qiime2.sif /tmp/lewis789/qiime2/
     ```
   - Finally, you can run the container with this command:
     ```bash
     apptainer exec ~/apps/qiime2.sif /opt/qiime2/bin/qiime2
     ```
   You could also take that and put it in a script named ""qiime2"" on your path or as part of a module for easy access. ||| To resolve this issue, it's recommended to update the LD_LIBRARY_PATH environment variable to include the path where the required library is located. In this case, set LD_LIBRARY_PATH to `/apps/spack/bell -20231031 /apps/gcc/12.3.0-gcc-4.8.5-zhxpuq3/lib64` before running the Intel 2024.1 module load command. Here's an example of how to set LD_LIBRARY_PATH:
```
export LD_LIBRARY_PATH=/apps/spack/bell -20231031 /apps/gcc/12.3.0-gcc-4.8.5-zhxpuq3/lib64
module unload openmpi
module swap gcc
module load intel/2024.1
module load intel-mkl/2024.1
module load impi/2021.12
module load vtune/2024.1
``` ||| Run the command `module spider intel-oneapi-mkl` to locate and load the Intel MKL module. ||| To resolve this issue, there are two potential approaches:
   - Investigate and fix the module dependency problem for samtools/1.8 by looking into the user's personal modules or depot space to see if it is available as a non-containerized module. - Alternatively, use samtools/1.9, which is containerized, as a viable alternative since it will work in this case. If the pipeline requirements can be met with version 1.9, it may serve as a suitable replacement for version 1.8. ||| Provide deprecated software as-is, with no support. Run command 'source /apps/cent7/rocky8-compatibility/switch-to-old-dangerous-unstable-centos7-modules.sh' to modify shell and look at the cent7 (old OS) modulefiles, removing the Rocky 8 (new OS) module files from the path. If the software does not work, update the code to utilize the newer software. ||| To reinstall the older Intel version, users should run the command 'source /apps/cent7/rocky8-compatibility/switch-to-old-dangerous-unstable-centos7-modules.sh'. This script changes the current shell to look at the CentOS 7 module files, but does not affect other sessions or future sessions. To return to using Rocky 8 modules, users can open a new terminal or ssh session, as the script affects only the current shell. If users want the script to be run automatically on each login, they can place it in their '.bash_profile' file. ||| ""To verify if the issue persists, try running 'module avail' command. If the output shows an error or expected modules are not listed, please reload the LMod module by executing 'module reset Lmod/sh'. If the problem still persists after trying these steps, it is recommended to check the environment settings and consult the LMod documentation at <http://lmod.readthedocs.io> for troubleshooting tips."" ||| To resolve the issue, consider these steps:
   - Discuss with the user about scheduling a call this week or next to discuss installing CP-FFT and its required libraries (such as fftw3, Lapack) on their lab group's depot (depot/msangid/apps). This will allow the program to be run from any cluster without requiring specific modules to be loaded. - Make sure to load the necessary modules (intel/2019., impi/17.1.132, fftw/3.3.8, openblas/0.3.8) on Negishi for creating a copy that can be ready to load from the depot. - Keep in mind that building a shared version across clusters might require sacrificing many performance optimizations and more library builds. - Upon successful installation of CP-FFT on their lab group's depot, users should be able to call the program from any cluster without encountering issues related to missing files or libraries. ||| The user should load the appropriate Fortran module files for HDF5 on Bell after starting a new terminal session. ||| To install the FFTW/2.1.5 library on Bell, follow these steps:

   - Load the appropriate module for the compiler you are using (e.g., if using gcc, load `module load gcc`)
   - Download the FFTW source code from its official repository (<https://www.fftw.org/download.html>)
   - Extract the downloaded archive and navigate to the extracted directory
   - Configure and build the FFTW library by running the following commands:
     ```
     ./configure --prefix=/path/to/installation/directory
     make
     make install
     ```
   Replace `/path/to/installation/directory` with the desired directory where you want to install the FFTW library. - After successful installation, users should be able to link their code with the FFTW library using the following command (assuming the FFTW library is located in the standard location):
     ```
     g++ -o output_file source_files -lfftw3
     ```
   Replace `output_file` with the desired output file name and `source_files` with the names of your source files. If you installed FFTW to a custom directory, adjust the library path accordingly. ||| The user should verify that the LD_LIBRARY_PATH environment variable includes the directory containing the necessary libraries (`$HOME/fftw-2.1.5/fftw-2.1.5/lib`). Also, ensure the compiler command is using the correct flags to link with the FFTW libraries:

```bash
mpicpc -DMPICH_IGNORE_CXX_SEEK -g -o psxtal psxtal.o -Bdynamic -L$LD_LIBRARY_PATH -ldfftw_mpi -L$HOME/fftw-2.1.5/fftw-2.1.5/fftw/.libs -ldfftw
```

If the issue persists, it might be helpful to recompile the FFTW libraries with the correct compiler and MPI flags, as described in their documentation (<https://www.fftw.org/install/source.html>). ||| Investigate the module load hang and slow /depot access on Bell system. Continue monitoring the system for any lingering issues. If still experiencing problems, re-open this ticket within the next 7 days."
15,1,19,19,"Request for clarification on purchasing nodes in Negishi cluster and timeline of access after purchase. ||| Installation of sshfs on Negishi cluster for mounting to another cluster (e.g., NSF) for convenient file access and code version maintenance. ||| The user is unable to extract .zip files on the Negishi Cluster and requests an alternative method, and there is a need for clarification about downloading large .zip files via the Negishi Gateway. ||| User needs clarification about the behavior of purchasing multiple half-nodes on Negishi cluster and the sudo permissions for a single half-node. ||| User needs help installing or using armadillo library with g++ compiler on Negishi cluster. ||| Assistant Professor in ABE department at Purdue wants to add a student to the Negishi Cluster lab queue ||| Hari G. name requests to create a project/file directory/folder within the Negishi cluster for several members of the Energy and Transport Sciences Lab to utilize for a group project. ||| Postdoc in Dept. of Biological Sciences needs assistance to access Negishi cluster nodes purchased by their PI. ||| Request for trial access to Negishi cluster and setup for running COMSOL and LiveLink on MATLAB ||| Requester needs assistance in setting up a trial on Negeshi Clusters and requires approval from PI, also requests a virtual meeting with the Negeshi team. ||| Add user Ram to Negishi Cluster for accessing computing resources ||| Add a new student into Negishi cluster under Dr. name's group ||| Undergraduate student at Purdue ME seeking help to set up Altair EDEM software on Neigishi cluster for CFD simulations and learn how to interface with it via Gateway. ||| Inquiry about job submission and resource allocation on Negishi cluster for a single purchase of two ""half-nodes"". ||| Data loss on Negishi and Gilbreth clusters due to user's files being removed from the Scratch storage without prior notice or warning. The data was crucial for the user's research paper. ||| User requires assistance in choosing between the Negishi cluster and the Gautschi cluster for running Abaqus simulations and Python scripts. ||| A PhD candidate and their advisor need guidance in choosing between the Negishi cluster and the Gautschi cluster for running ABAQUS simulations and Python scripts without a GUI. ||| User (name) is transitioning from full-time to adjunct position at Purdue and wants to understand how this will impact their access to the HPC clusters, specifically the paid Negishi cluster access. ||| User Bijoy needs help to access and use Pix4DMapper application on the Negishi cluster.","The process to buy nodes in the Negishi cluster is similar to that of Gilbreth purchase. The timeline for access after purchase depends on how fast the business office takes care of the order. Once the order has been processed, they will be fulfilled as soon as possible. ||| The user has been advised to use the rsync command as part of their workflow to synchronize files between both clusters instead of installing sshfs due to the convenience, transfer progress display, and avoidance of maintaining two versions of code. Here is a suggested command format for the user to run:

```
rsync -ah --info=progress2 SOURCE DESTINATION
```

For example, if you are on Negishi and want to update it with the version of your files on the NSF cluster, you would run a command like:

```
rsync -ah --info=progress2 nsfcluster.edu:/path/to/vtk/files ${CLUSTER_SCRATCH}/nsf_files
```

For more information on common usages of rsync, the user can refer to this link: https://www.rcac.purdue.edu/knowledge/negishi/storage/transfer/globus ||| To unzip files on the Negishi Cluster, open a terminal and use the 'unzip' command followed by the name of the .zip file. For instance, `unzip filename.zip`. If you want to download large .zip files from the Negishi Gateway that exceed the stated limit, consider using Globus transfer service. You can check the user guide for Globus at this link: [https://www.rcac.purdue.edu/knowledge/negishi/storage/transfer/globus](https://www.rcac.purdue.edu/knowledge/negishi/storage/transfer/globus). ||| If your lab submits an order for two half-nodes, your lab does not own that one node. The purchase is for the access. To run jobs on exactly ONE node without sharing cores between different nodes, set parameters in your submit script using `#SBATCH --nodes=1` and `#SBATCH --ntasks=[number of cores]`. For example: `#SBATCH --nodes=1 #SBATCH --ntasks=128`. The waiting time for any lab queue on Negishi won't be longer than 4 hours if users submit jobs correctly. Users on Negishi will not gain sudo access to any node. ||| The gcc compiler is available on Negishi and gets automatically loaded when you log in to the cluster. To check the currently loaded modules, use the command 'module list'. You can search for a module for an application using the 'module spider xxx' command, where xxx is the name of the application. If armadillo is not available as a module, you can install it on your own HOME space as a user. For more details about Negishi usage, refer to the user guide at <https://www.rcac.purdue.edu/knowledge/negishi>. ||| To add or remove members to your lab queue on Negishi Cluster, log into the RCAC website (<https://www.rcac.purdue.edu/account/groups/2989/members?u=146001>). Under the Members tag, click 'Add Member', search for the desired member, check the Unix group, and hit save. The membership will be ready on the cluster overnight. ||| Ask your PI about how your research group can utilize the Data Depot space that your team possesses. The collaborative directory that your group is already paying for can be used for this purpose. If you run into any issues, please let RCAC Support know. ||| The postdoc should ask their PI (Dr. name) to add them to the group on the RCAC website after logging in. This process may take a day or two for the changes to propagate to the cluster. There are multiple ways to access Negishi, including using SSH keys and ThinLinc. The following wiki articles provide more information on these methods:
   - SSH Keys: <https://www.rcac.purdue.edu/knowledge/negishi/accounts/login/sshkeys>
   - ThinLinc: <https://www.rcac.purdue.edu/knowledge/negishi/accounts/login/thinlinc> ||| To set up the trial access for the Negishi cluster, your PI needs to send a request. COMSOL is already installed on the clusters as shown here: <https://www.rcac.purdue.edu/knowledge/applications/comsol>. Once you gain access, you will be able to access the B clusters. For pricing details, look under the ""Purchase"" section on the RCAC website. The staff is willing to help set up a meeting to answer any additional questions. To schedule a meeting, please provide available times in the next week, Monday and Tuesday being preferred. ||| The requester has been scheduled for a virtual meeting with someone from the Negeshi team on Friday at 10am EDT. To proceed with the trial, they need to get approval from their supervisor and provide it to the support team so that a temporary Slurm account can be set up. They are also instructed to request access to COMSOL via the following webpage: https://www.rcac.purdue.edu/account/software. After obtaining access, they will be able to launch COMSOL on Negishi once the trial is started. ||| To grant user 'Ram' access to the Negishi Cluster, follow these steps:
   - Navigate to the RCAC website and go to the ""My Groups"" page under the ""ACCOUNT"" section. - Adjust user permissions as needed on this page for user 'Ram'. - User 'Ram' should have access to the Negishi Cluster by tomorrow morning. ||| To add the student (name) into the Negishi cluster under Dr. name's group, login to the RCAC web interface at https://www.rcac.purdue.edu/account/groups/1849/members?u=113032. The group manager has the privilege to add or remove members. You (or Dr. name) should log in and follow the instructions on the website to add the student (name). ||| To set up Altair EDEM software on the Neigishi cluster and learn how to interface with it via Gateway, attend the Coffee Hours scheduled at the Convergence Center on 10/7. For more details, visit https://www.rcac.purdue.edu/coffee. ||| The user will receive one entire node with 128 cores in total upon purchasing two ""half-nodes"" on the Negishi cluster. The user can use all purchased resources for a single run and submit a job in parallel over this node. ||| To attempt recovery of the lost files, the user can utilize the `flost` command if the files were not stored on Scratch and they have access to snapshots. If the files are not found using this method, the user can manually browse their snapshots on their desktop. However, it is important to note that there is no way to recover deleted files from the Scratch storage. The service team deeply sympathizes with any inconvenience caused by this issue but unfortunately, there is no possible resolution for the data recovery in this case. Additional Information:
- Command to attempt file recovery: `flost`
- Documentation URL: [Purdue IT Services](https://service.purdue.edu) ||| The response provides details on the specifications of both clusters, highlighting that Gautschi has enhanced specifications (192 cores per node versus 128 cores in Negishi) which may offer improved performance for Abaqus simulations due to its focus on higher core counts and memory. However, it is noted that Gautschi is more of an AI-focused cluster with NLP and NN processing in mind. The user is advised to consider their research group's maximum required processing power and potential future needs before making a decision. A call can be arranged to discuss this further. For reference, the URL for Purdue IT services is provided: https://service.purdue.edu ||| The user has been offered a trial period on both Negishi and Gautschi clusters. They can start the trial period by reserving a spot on the Senior Computational Scientist's calendar, who will then help them set up the new scripts and run jobs on each cluster to determine which one works best for their needs. The user should add name (mentioned in the message) to the queue at https://www.rcac.purdue.edu/account/groups/448/members?u=64088 upon login, and checkboxes for their account should be sufficient. The trial will expire on 4/12/2025. ||| The user should retain their current access to the HPC clusters as an adjunct faculty member. However, when the department or specific individual (not specified in the message) reaches out to discuss transferring the cluster queue group, the user will remain the manager of the cluster queues until that point. There will be no interruption in their account access for active projects on the clusters. ||| Run Pix4DMapper from the location `/depot/phig/uasdata/pix4D` on the Negishi cluster. If it works, let Josh know the result."
31,0,16,16,"Abaqus jobs are waiting in a queue for tokens while using Hypershell, causing delays in job execution. ||| The physics-h queue on Gilbreth has expired and is no longer available for job submission. ||| User reports jobs taking a long time to be scheduled on Gilbreth's standby queue. The queue is growing larger and only a few jobs are running at a time despite multiple free GPUs. ||| User is unable to submit job on 'mylab' queue due to QOS policy violation with Gilbreth HPC system. ||| User submitted job requests ""dbernaln-k"" and ""alam"" but they remain queued past several hours. ||| The user's jobs on the Gilbreth alta-k queue are waiting in the queue for an unexpectedly long time due to insufficient GPUs for owner queues and some offline nodes. ||| User is unable to submit jobs to the jgmakin-n queue due to an error stating that CPU count per node cannot be satisfied, despite only requesting one CPU and one GPU. The user has also been experiencing this issue on the jgmakin-h queue. ||| Job submission with exclusive node request in amannodi-f account is not being scheduled due to QOSGrpCpuLimit state. ||| The user's job submission is not starting due to memory requirements that exceed the available resources in the current queue. ||| Interactive job submission in asaparov-n queue fails to start on Gilbreth cluster. ||| Job scheduling issue on the dkihara-k queue of gilbreth. The job has been pending for over an hour despite there being free GPUs available. ||| User's access to HPC queues (debug, standby, gupta869-b) and OnDemand Gateway interactive apps appears to have been temporarily unavailable. ||| Job pending despite resources available in Gilbreth debug queue due to cooling system issues affecting scheduling on Negishi, Bell, and Gilbreth clusters. ||| Job 8494416 is queuing since 1 day on the ribeirob-k queue due to a duplicated job. ||| Submitted HPC jobs on Gilbreth cluster are in a pending state due to launch failures and resource allocation issues with specialized nodes. ||| User wants to utilize the 3-day duration of the training queue for a job that takes about 2 and a half days to complete and is seeking approval to do so as they have an upcoming deadline on the 19th of May. The user has provided a tested script located at https://gateway.gilbreth.rcac.purdue.edu/pun/name/dashboard/files/fs//home/wu1491/norm-r1/scripts/train/auto_relaunch_full_grpo.sh.","The user is experiencing issues with Abaqus jobs waiting in a queue for tokens while using Hypershell to run multiple parallel tasks across multiple nodes. Despite having available backend licenses, some of the Abaqus jobs are taking hundreds of seconds to begin execution. The issue seems to be related to the distribution of tokens among the parallel workers. To resolve this issue, it's recommended to investigate the token allocation process in Hypershell and optimize it for better performance when running multiple Abaqus jobs concurrently. It may also be necessary to adjust the number of tasks per node or modify the configuration settings to ensure that each task receives an appropriate amount of tokens. Additional suggestions include verifying that there are no other issues causing jobs to be OOM (out-of-memory) killed, as mentioned in a separate ticket. The user should also double-check their work and ensure they are addressing the correct issue by checking the ticket details before proceeding with any troubleshooting steps. Relevant documentation for Student Org Processing can be found at:
[https://lpviamutl01-int.itsp.purdue.edu/mediawiki/index.php/Student_Org_Processing](https://lpviamutl01-int.itsp.purdue.edu/mediawiki/index.php/Student_Org_Processing) ||| The Department of Physics discontinued the subscription to Gilbreth, preventing any members added to the physics group account from submitting jobs on Gilbreth. Members can still log into the front-ends for data transfers but cannot run jobs. There are no further actions needed from the user at this time. ||| Jobs are now being scheduled normally. Best regards, name Senior Computational Scientist Purdue Information Technology ||| The user needs to modify their batch script to request the appropriate number of cores for the lin491-h queue. In this case, since the queue has access to up to 11 cores, the user should change their script as follows:

Replace this line:
```bash
#SBATCH -N 1
```
with
```bash
#SBATCH -N 11
```

Additionally, consider modifying the time limit to accommodate your job's needs:

Change this line:
```bash
#SBATCH -t 10:00
```
to a longer duration if necessary. After making these changes, resubmit the job using 'sbatch' command and verify that it runs without errors. If issues persist, seek further assistance. ||| A maintenance activity is scheduled for the Gilbreth system on January 24th. Any jobs with an end time beyond this date will not be initiated due to the maintenance. To ensure a smooth process, users should review their job details by running 'jobinfo jobid' for additional information and submit any job with an end time set earlier than 8:00 AM on January 24th. For more details about the maintenance, please visit https://www.rcac.purdue.edu/news/6369. ||| The issue can be resolved by adjusting the workflow to request smaller amounts of resources, using other types of GPUs from the 'standby' queue with shorter walltime, or waiting for the engineering team to fix the node issues and bring them back online. The user is advised to check the availability with the command 'sinfo -s'. ||| To resolve this issue, the user should ensure they are requesting a proportionate amount of memory for the requested GPUs instead of using `--mem=0`. Here's an example of how to set the memory in Slurm submission script:

```bash
#SBATCH --gres=gpu:1
#SBATCH --cpus-per-task=1
#SBATCH --mem=<memory_in_GB>GB
```

In addition, the user should confirm that they have been added to the jgmakin-n queue by their PI through the member management portal at https://www.rcac.purdue.edu/account/groups/1989/members. ||| Remove the `--exclusive` directive from your script to allow the job scheduler to allocate a node without requiring the entire node. If the `--exclusive` directive is necessary for your job, consider submitting to the standby queue with less walltime (less than 4 hours). Specify GPU type using `#SBATCH -C 'F' (e.g. for gilbreth-f) if you need specific GPUs. Adjust your script as per these suggestions and resubmit your job. ||| The user should revise their job script to request a lower memory limit (e.g., 16GB instead of 32GB) or submit the job to the standby queue, which allows for more memory usage. To use 128GB or access multiple GPUs, the user's professor may need to purchase additional resources for their account. The user can also try using the standby account if they require frequent resource usage. Here is an example of how to modify the #SBATCH directive for memory request:

```bash
#SBATCH --mem=16G  # Change this line to request 16GB of memory
```

And here is how to submit a job to the standby queue:

```bash
sbatch -A standby -t 0-24:00:00 -N 1 -c 8 -J myjob run.sh   # Replace ""myjob"" with your desired job name
``` ||| The user is experiencing issues with interactive job submissions using the command `srun --nodes=1 --gpus-per-node=1 -A asaparov-n --pty /bin/bash`. A suggested workaround provided by RCAC Support is to use the command `sinteractive --nodes=1 --gpus-per-node=1 -A asaparov-n`. The user should check the available GPUs using the command `slist` before submitting their job and wait for resources to be allocated. If the issue persists, they may consider attending the provided RCAC Training Resources (Clusters 101 & 201) sessions for detailed explanations on job scheduling and resource management. ||| The job scheduling is currently paused due to cooling system problems in Negishi, Bell, and Gilbreth queues. To check the status of your job, run the command ""jobinfo jobID"", replacing ""jobID"" with the id of the job in question. No timeframe for when the problem will be resolved has been provided yet. ||| To confirm if the issue has been resolved, the user can try running the 'slist' command again. If access is restored, it should list the queues (debug, standby, gupta869-b). For using interactive apps on OnDemand Gateway, after reconfirming HPC queue access, the user should check if the account dropdown now contains the necessary accounts. ||| To check the status of your job, run the command `jobinfo jobID`, replacing `jobID` with the id of your specific job. ||| The user has two jobs with the same name running (8494415 and 8494416). The running job is 8494415, which is using only 1 GPU. Once job 8494415 finishes, job 8494416 will begin executing. To check the status of jobs, users can use the command `squeue -A ribeirob-k`. For more information on managing jobs, refer to the [PurdueIT RCAC documentation](https://rcac.purdue.edu/documentation/batch). ||| The pending jobs encountered launch failures due to high demand for the requested specialized nodes (A100 80GB GPU and A30 GPUs) and were automatically requeued by the scheduler. Since these jobs are submitted to the standby queue, they have low scheduling priority and will only start when matching resources are idle and not needed by higher-priority jobs. The user can improve scheduling times by adjusting job submission parameters (e.g., removing strict GPU feature requirements if their code allows). Alternatively, after canceling and resubmitting the jobs, the new jobs ran successfully. ||| To grant the user access to the training queue, verify the provided job ID (8459448) is still running and check the GPU usage for the past two days or so to confirm that it has been mostly utilized. After verifying, add the user to the training queue."
8,1,26,26,"Error running 'module' command due to incorrect interpreter used in job submission file ||| A Ph.D. student is experiencing issues with a Singularity image running their code in a specific HPC cluster (Gilbreth). The issue occurs inconsistently across job submissions and seems to be related to the activation of a conda environment within the image. ||| A Management / Stats PhD student wants to run multiple codes simultaneously for a simulation study. The user is new to HPC and clusters and needs guidance on how to do this using job arrays and Slurm. The user currently has no access to resources at the moment but hopes to use the Bell queue in their school of management. ||| NetLogo experiments on Negishi using OpenJDK are running out of heap space despite increased allocated heap space and high degree of parallelism. ||| Student group at the Data Mine is experiencing HTTP timeout errors when running web scraping using batch jobs with Anvil on the RCAC side. The issue doesn't occur when running it locally or through Jupyter Lab. ||| User is experiencing an error while running jobs using 'mpirun' command on Bell HPC cluster. The user believes that the problem might be related to 'mpirun', as a change in the number of cores used did not affect the simulation. ||| Error running parallel simulation on Scholar computing cluster due to unsupported Intel instructions. ||| User reports an error when submitting a job on Bell HPC system using 'mpirun' command, suggesting that the number of cores specified in the script does not reach the program (cm1.exe). ||| New Purdue scholar needs assistance in submitting an Abaqus job using the slurm system with multiple cores and nodes on Bell cluster. ||| User wants to run a job in parallel using OpenMP and needs guidance for creating a job script and loading required modules. ||| Amiga analysis job getting killed on Negishi HPC cluster due to resource limitations while running through frontend. ||| HPC User Encountered an Error Submitting a Job on Anvil Due to Accounting/QOS Policy Violation ||| The user's Python package fails to import 'pyDOE' when submitted on the HPC system using Conda environment 'myenv27', while it works fine on the login node and with an alternate Conda environment (Anaconda/2020.02-py37+). ||| Simulation overwriting due to re-execution after completion on HPC cluster using ANSYS/LS-DYNA. ||| User is experiencing issues with large molecular dynamic simulations on alta-k HPC cluster, specifically encountering the error 'cudaErrorMemoryAllocation'. The user suspects the issue may be related to using a single GPU image of LAMMPS in their HOME directory and requests advice. ||| User is unable to run a code on Negishi Highmen without the job being terminated due to a Kernel killed error and an Out of Memory (OOM) error. ||| Job using more than 24 CPU cores on Bell cluster fails with a Segmentation fault error when submitted with `mpirun -np [number greater than 24] sub_multiple_DAILY_CC.sh`. ||| The user is experiencing job terminations due to memory limitations while running a large number of repetitions on Negishi HPC cluster. ||| Submission of a job using multiple threads with PDNS executable is only utilizing one core in user's settings while working correctly on others. ||| User needs guidance on batch processing jobs using Ansys22R2 on Negishi HPC cluster ||| Job submission on `lilly-comp-g` cluster requires specific CPU and memory settings for GPU usage. ||| User is unable to launch ANSYS using command in CPU account due to it being primarily for GPU jobs, leading to pending job submissions. ||| HPC user's scheduled jobs using shell require 20 hours, 30ish nodes, and 350gb ram in highmem but have not started yet. Simultaneously, the same codes run immediately on R Studio Server with 55 nodes and 20 hours. ||| User is unable to submit a job to request an A100 GPU in sub-cluster K due to an ""Invalid account or account/partition combination specified"" error and receiving an Out of Memory (OOM) Killed error when using MATLAB's Parallel Computing Toolbox. ||| Failed interactive job submissions on HPC cluster for Ph.D. student ||| The user is facing issues with the PyTorch dataloader on a GPU cluster when running with more than 1 worker and encountering warnings about potential slowdowns or freezes. Additionally, the user is having trouble monitoring GPU usage and encountering an error using utilities monitor. There's also a runtime warning related to os.fork() and JAX.","Change the current interpreter from '#!/bin/bash' to '#!/bin/sh -l', or add the lmod initialization command 'source /etc/profile.d/modules.sh' in the submission file before using the 'module' function (before the 'module purge' line). ||| The student should remove the conda environment from their image and install necessary packages in the default paths. This change is expected to resolve the inconsistent behavior when launching the container on various cluster nodes. If the container only needs one conda environment, it's recommended not to create it and instead install everything to the base environment to simplify the setup inside the container. ||| To run multiple codes simultaneously, the user should consider using a job array with Slurm (Slurm Array-Jobs). The user needs to discuss this with their collaborator in the Management school about being added to their Bell queue/account so they can utilize the supercomputer for running the code. For more information on how to script and submit job arrays using Slurm, the user is encouraged to study relevant tutorials available on the RCAC homepage (<URL_TO_SLURM_TUTORIAL>). ||| Reduce the number of threads launched by NetLogo from 108 to 54. The user is instructed to keep the existing ""#SBATCH --cpus-per-task=108"" line in place, but modify the ""--threads 108"" command to ""--threads 54"". The user should also maintain the current maximum heap size and report the outcome of this experiment. ||| The user has been added to a related ticket in the ACCESS ticketing system (Ticket #XXX) that is already escalated to engineers for investigation. In the meantime, if you have any further questions about Anvil, please submit a ticket at https://support.access-ci.org/open-a-ticket. ||| The suggested resolution is for the user to try using 'srun' instead of 'mpirun -np xxx'. In this context, replace 'xxx' with the desired number of processors. For example, replace 'mpirun -np 128' with 'srun -n 128'. The user is advised to check if this change resolves the issue. ||| To resolve the issue, compile the model during an interactive session on the same machine that will be used for running the simulation. This should ensure the correct SIMD instructions are targeted. For example:

```bash
salloc -C A|B --time=01:00:00 --qos=standard your_username
module load your_required_modules
./your_compile_command
```

Replace `your_username`, `your_required_modules`, and `your_compile_command` with appropriate values. After compiling, submit the job for parallel execution as usual:

```bash
sbatch batchscriptTEST
``` ||| Replace the 'mpirun' command with 'srun' command in the job script to bypass the error. It is recommended to use 'srun sbatch -n [number of cores] your_job_script.sh' instead of 'mpirun'. For example, use 'srun sbatch -n 128 your_job_script.sh'. The exact reason for this workaround is still under investigation, but it appears to resolve the issue for now. ||| The user has successfully run a script for Abaqus 2023 using SLURM, but the attached scripts were not received. Here's the working script provided by the user:

```
#!/bin/tcsh
#SBATCH -N 1-1
#SBATCH -n 48
#SBATCH -t 10:00:00
#SBATCH -A zavattie
#SBATCH --job-name=Job-17
module load intel/19.0.5.281 abaqus/2023
cd $SLURM_SUBMIT_DIR
unsetenv SLURM_GTIDS
abaqus interactive job=Job-17 cpus=48 scratch=$RCAC_SCRATCH
```
To use multiple nodes, modify the `#SBATCH -N` line (e.g., `#SBATCH -N 2-1` for 2 nodes with one GPU each). The number of cores per node remains constant at 48, so no changes are needed to the `cpus=48` line. Note that 'n' represents the total number of cores across all nodes in this script. The last two lines set up the Abaqus environment and run an interactive session on the specified job. For email notifications, check the `--mail-user` and `--mail-type` options on the SLURM page: <https://slurm.schedmd.com/sbatch.html>. To check the status of your jobs, use the 'squeue --me' command (see more at: <https://www.rcac.purdue.edu/knowledge/bell/run>). For further information on SLURM and Abaqus, consult their respective manuals: <https://classes.engineering.wustl.edu/2009/spring/mase5513/abaqus/docs/v6.5/books/gss/default.htm?startat=ch02s03.html> and <https://slurm.schedmd.com/sbatch.html>. ||| To create a job script that runs your program in parallel with OpenMP, refer to the following link: <https://www.rcac.purdue.edu/knowledge/bell/run/examples/slurm/openmp> In your job script, you will need to load Intel compiler and OpenMP module. Additionally, consider looking at RCAC training materials Clusters 101 and Clusters 201 on the RCAC website: <https://www.rcac.purdue.edu/training> For example, to load the Intel compiler and OpenMP modules using the SLURM (Slurm Workload Manager) batch system, use the following command:
```bash
#SBATCH --ntasks=4
module load intel/compiler
module load impi/<version_number>
```
Replace `<version_number>` with the appropriate version number of your Intel MPI library. You can find this information in the documentation when you compiled your program. Once you have created and tested your job script, submit it using the SLURM batch system. ||| To resolve this issue, submit a job request to Negishi with sufficient resources for the workflow. The user guide for job submissions can be found at https://www.rcac.purdue.edu/knowledge/negishi/run. ||| The user is encountering an error when submitting a job on the Anvil HPC resource due to violating accounting/QOS policy, specifically with job submit limit, user's size and/or time limits. To resolve this issue, the user should consult the ACCESS User Support Portal (https://support.access-ci.org/open-a-ticket) for assistance with Anvil issues. ||| To help identify the issue, add the following directives in the job submission script and resubmit the job:
   - Use ""module --force purge"" to forcefully remove any previously loaded modules before loading the needed ones. - Check the version of Python with ""python --version"". - Identify the location of the interpreter using ""which python"". - Find the activated Conda environment with ""echo $CONDA_PREFIX"". This will help in determining if the correct Python version and environment are being used during job submission. ||| Add the ""--no-requeue"" option in the job submission script or command when running simulations with LS-DYNA on the cluster. Here's an example of how to modify the provided script:

```bash
#!/bin/tcsh
#SBATCH -N 1-1
#SBATCH -n 48
#SBATCH -t 60:00:00
#SBATCH -A zavattie
#SBATCH --job-name=Run33
module load ansys/2023R1
cd $SLURM_SUBMIT_DIR
unsetenv SLURM_GTIDS
lsdyna i=CONTROL_DATABASE_CONTACT.k s=CZSD ncpu=48 --no-requeue
``` ||| Verify if the user's custom LAMMPS image can run with multiple GPUs, as the GPU being used on alta-k (A100) has 80GB memory. Investigate the difference between successful and unsuccessful simulations to identify potential causes for failure. Consider adjusting model structure or parameters for the failed jobs. If necessary, consult LAMMPS documentation for troubleshooting tips with multiple GPUs: <https://lammps.sandia.gov/doc/GPU_intro.html> ||| The issue seems to be caused by the job exceeding its one-day maximum runtime on high-memory nodes. Request more cores for the job to avoid the timeout. However, it appears that this is not the root cause of the current problem as the user has stated they still had runtime left after encountering the error. Regarding the OOM error, further investigation into the user's workflow is required to provide accurate guidance. Consider attending next Monday's in-person coffee hour for a more detailed discussion about this issue: [Coffee Hour Link] ||| Try submitting the job using either `mpirun -np $SLURM_NTASKS` or `srun -n $SLURM_NTASKS` instead of specifying a fixed number of cores when more than 24 are required. This should help in avoiding the Segmentation fault error encountered with the original submission method. ||| To assist with troubleshooting the issue, it would be helpful to have a detailed understanding of the user's workflow. Specifically, if the user can share their code and any relevant configuration details, this may provide insights into potential memory bottlenecks. The support team is available for an online meeting (preferred) or email communication to discuss the issue further. The user has suggested an availability starting at 1:30 PM tomorrow, with a preference for a 2 PM meeting time, and availability next week except for Tuesday 10-11 AM. Additionally, the support team has offered to have an expert available during Monday's coffee hour to help with this issue. If the user is unable to attend the coffee hour, the support team can set up an alternative meeting. ||| Check the OpenMP environment configuration to ensure it's properly set up for your local HPC system. Investigate if there are any differences in module loading, MPI settings, or other factors that may cause the inconsistency. To verify the proper functioning of OpenMP, you can utilize the following command:

```bash
export OMP_NUM_THREADS=3 && ./PDNS
```

If this doesn't help, consider scheduling a coffee hour consultation with RCAC support to review your settings and configuration. Link for appointment booking: https://www.rcac.purdue.edu/coffee ||| The user is advised to refer to the Ansys manual for instructions on how to use the batch mode in Ansys. No specific resource for Negishi was found, hence users are encouraged to look through their own copy of the Ansys manual. ||| To ensure successful job execution on the `lilly-comp-g` cluster, modify the SLURM script to include both the required CPU and memory settings:

```bash
#SBATCH --cpus-per-task=64  # This specifies the number of CPUs per task
#SBATCH --mem=256GB        # This specifies the required memory for the job (assuming 256 GB is required per GPU)
```

In this specific case, the issue was caused by an inconsistency between the requested CPU numbers and the amount of memory. Matching the number of CPUs to the required memory (64:256GB per GPU in the user's account) will help avoid similar issues in the future. ||| The user should request CPUs from an account that allows CPU jobs instead of the current GPU account. This is because the command used by the user was requesting CPU resources in a queue designated for GPU jobs, which caused their interactive job to be pending due to violating the account's minimum requirements. ||| The user may be encountering an issue where their scheduled jobs are not prioritized or are experiencing resource contention. To troubleshoot this problem:
   - Verify that the job queue is not full or overloaded. Check the HPC system's job queue status using a command like `qstat` and ensure there are enough available resources for the job to run. - Examine the user's batch script (or SLURM job script if applicable) for any errors, such as incorrect resource requests or syntax issues. Check that the requested resources (nodes, RAM, time, etc.) match the needs of the job. - Consult the HPC system documentation or reach out to your system administrator for guidance on optimizing job submission and scheduling. - If necessary, adjust job priority settings in the batch script or contact your system administrator to request higher priority for the specific job(s). - To avoid potential resource contention with other users' jobs, consider breaking down large jobs into smaller tasks that can be submitted concurrently and run sequentially. This approach may help ensure timely completion of computationally intensive analyses. ||| To resolve the issue, ensure that the user has been added back to the queue. If necessary, contact HPC support to verify this. For the OOM Killed error, increase the number of cores allocated to the job to accommodate larger memory requirements. Use the command ""sbatch --nodes=1 --gpus-per-node=1 --constraint=k -n 32 myjob.sub"" where ""-n 32"" specifies the use of 32 cores (associated with 1 GPU for K node). This should help prevent Out of Memory errors when running memory-intensive tasks such as computing the SVD of a large matrix using MATLAB's Parallel Computing Toolbox. ||| The jobs submitted using the command `sinteractive -A schaterj-k -N1 -n32 -t 14-00:00:00 --gpus-per-node=1` failed while still in the queue with IDs 8437152, 8442843, and 8444658. It is unclear why this occurred, but it appears that jobs started and failed at the 17-second mark. The behavior has been observed for a few weeks. It is recommended to check job logs for error messages or contact support for further assistance. ||| To resolve the issue with the PyTorch dataloader on a GPU cluster, you should request more CPUs for your job (at least 4, one for each worker). Modify your submission script by adding `#SBATCH --cpus-per-task=5`. This will allocate 5 CPUs per task in your job. To use 4 workers with the pytorch dataloader, add a sample script provided below to your job submission file:
```bash
#!/bin/bash
#SBATCH -A testpbs
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --gpus-per-node=1
#SBATCH --cpus-per-task=5
#SBATCH --gres=gpu:1
#SBATCH --mem=256GB
#SBATCH --time=04:00:00
echo ""have access to $(nproc) CPUs!"" #Will be ntasks*cpus-per-task! /path/to/python test.py
```
This should help you utilize the GPUs efficiently and avoid potential slowness or freezing due to excessive worker creation. Regarding monitoring GPU usage, since utilities monitor is not available on Gilbreth, try using `rocm-smi` while SSH'd to the compute node your job is running on:
```bash
rocm-smi
```
For addressing the os.fork() and JAX issue, consider reviewing your code or consult with a developer or HPC expert for further guidance."
10,2,30,30,"Request for information on purchasing and adding a node with A100 80GB RAM to an existing account in Gilbreth cluster (kildisha). ||| Request to install COMSOL simulation tool on the Gilbreth HPC cluster. ||| The user requests confirmation of access to two Nvidia A100 cards on the Gilbreth cluster and wants to know how many Ansys licenses are needed for optimal usage of these GPUs. ||| The user is inquiring about the core count for a single purchase of Gilbreth nodes, specifically the A30 and A100 GPUs, and if there are other purchasing options available. They also ask whether it's possible to customize the purchase nodes into different accounts with varying wall-time limits. Lastly, they seek clarification on their understanding about the concurrent jobs and retirement time of these nodes for a 5-year package. ||| User is unsure if each sub-cluster in Gilbreth cluster has identical CPUs and wants confirmation that all nodes within a sub-cluster use the same CPU model. The user is conducting OpenCL and MPI development on Gilbreth cluster, targeting both CPU and GPU of multiple nodes, and requires consistency in CPU performance for strong scalability testing. ||| A Master's student in ECE is seeking information on pricing for GPUs on Gilbreth HPC cluster and if there are any benefits for grad students. ||| Associate Professor from ME department requests assistance in setting up computational resources on Gilbreth cluster for data processing and GPU computing, as they are new to HPC systems ||| The Gilbreth cluster has been offline since October 17th and the user is concerned about the availability of the cluster for their project's training process which has a rapidly approaching deadline. ||| User needs assistance in requesting specific Sub-Cluster nodes when using Gilbreth. ||| Request for 2-week trial of an NVidia GPU A30 node on RCAC cluster (Arnabb-b) for quantum circuit simulation project under the DOE Quantum Science Center grant ||| A research group is considering purchasing access to a GPU on the Gilbreth cluster and needs clarification about the nature of the purchase (full node or specific GPU), how clusters are assigned, if they have access to standby nodes, interactive mode, and check-out capabilities. ||| Research group interested in purchasing A100 nodes on Gilbreth cluster and seeking clarification about program details, usage, and workflow changes. ||| University Faculty member seeks access for class to shared GPU resources on Scholar cluster for teaching generative AI technologies in visual artifacts. ||| Requires clarification on the account requirements for purchasing and administering a node on the Gilbreth cluster, specifically in regards to using a shared account and setting up an email inbox for the shared account. ||| Research Group Requires Purchase Access to Gilbreth Clusters ||| The user is unable to run the shared example script from a new Conda environment on Gilbreth due to disk quota limitations and wants to know how to get around this problem or use their advisors' quota. ||| Request for Allocation on Gilbreth Cluster by Ph.D. Candidate from Purdue University Electrical and Computer Engineering ||| Request for standby access to Gilbreth cluster for deep learning research by PhD student She (Student ID: 037868481) ||| User wants to specify a list of nodes in their sbatch script to run their job on specific Gilbreth partitions (D, E, G, H, J, and K). They also have reproducibility concerns about the node settings being similar to that of the Department of Statistics' account (statdept-h) in terms of CPU, memory, and GPU. ||| User is experiencing a size distribution error in their simulations on Gilbreth clusters and believes it may be due to the open file limit, which they report as currently set at 20480. ||| Request for two-week trial on the Gilbreth cluster (A10 GPU) and assistance in setting up Unreal Engine. ||| Graduate Research Assistant Vlachos Research Group needs access to Gilbreth cluster on RCAC ||| User requesting increase in CPU cores for their project running on the N node of the Gilbreth server, beyond the current limit of 72 CPU cores. ||| User inquired about Gilbreth cluster maintenance on Feb 25th and its relation to previously scheduled maintenance, as well as when they can use the cluster again. ||| A student is having trouble using the correct command syntax for requesting computing nodes on the Gilbreth supercomputer, specifically for the k sub-cluster, and needs clarification on how to use this resource. ||| Researcher requires access to the Gilbreth cluster for training and running a neural network model, under Dr. Voicu Popescu's supervision. ||| User needs more storage space for their research on the Gilbreth compute cluster at Purdue University. ||| Request for access to the Gilbreth cluster ||| Ph.D. Student requires access and confirmation of Gurobi compatibility on Purdue's computing resources (Gilbreth Community Cluster or Gautschi cluster) for large-scale optimization problems. ||| Avi needs an efficient way to transfer a large dataset (400-500 GB) from an SSD to the Gilbreth cluster as regular SSH/SFTP clients take a long time.","The process for purchasing a Gilbreth K GPU(s) is as follows:
   - The PI will log into the RCAC website and navigate to the Purchase page (<https://www.rcac.purdue.edu/orders/products?search=Gilbreth&category=22&restricteddata=*&public=1>)
   - Select the product 'Gilbreth A100-80GB GPY Access' (5 years or annual subscription), adjust the quantity (the unit is per GPU/half K node) and add to cart
   - Proceed with the purchase by entering account number, notes, etc. - The business office will first take actions on the account part and once it's done, it will be routed to our business office to fulfill the order
   - Once the order was fulfilled, the resources on Gilbreth will be set and added to PI's group (i.e. kildisha)
   - Let us know if you have further questions. ||| Unfortunately, due to lack of GPU support for COMSOL on the Gilbreth cluster at this time, it is recommended to use a CPU cluster for CPU-only work related to COMSOL. No installation update is available as of now. ||| To verify the availability of the Nvidia A100 GPUs, run the command `slist` on the cluster. The user can check their current number of GPUs by looking at the output of this command. For example, if using the account 'rodri646', you would run:

```
$ slist rodri646
Current Number of GPUs Node Account Total Queue Run Free Max Walltime Type ============== ================================= ============== ====== canli-k 1 0 0 1 14-00:00:00 K debug 182 0 0 182 00:30:00 B,D,E,F,G,H,I standby 272 1125 64 151 04:00:00 B,D,E,F,G,H,I,K
```
Here, you can see that the user has access to one (but not two) A100-80GB GPU on Gilbreth. Regarding your questions about Ansys licenses, contact the Engineering Computer Network (ECN) for assistance since they manage the Ansys licensing. ||| The user can find detailed specifications of Gilbreth nodes at this link: RCAC - Compute: Gilbreth The number of cores per node depends on the specific type of node purchased, and it is possible to calculate the proportional share according to the GPU count per node and cores/memory per node. Currently, the listed options are what is being offered. If the user is looking for monthly subscription options, those can be accommodated as well, but may cost more for long-term use. The maximum walltime limit for a lab/group's queue (Slurm account) is 14 days, but users may request less than 14 days for their jobs. If the user purchases access to 1 A100-80GB GPU, they can submit jobs to their lab/group queue requesting various walltimes, e.g. 5 hours or 2 days. However, it is important to note that Gilbreth is configured for GPU jobs only and each job must request at least 1 GPU. If the user purchases access to 1 A100-80GB GPU, they will get a queue in the K partition (sub-cluster), allowing them to run 1 job on 1 GPU at a time in their lab/group queue. For each of their jobs, they can request up to 32 cores (proportional to the core/GPU ratio). In the standby queue, multiple concurrent jobs and requests for multiple GPUs with less walltimes (up to 4 hours) are allowed. The K partition is planned to be retired in 2028, so there will still be 5 years until then. If the user is interested in getting a free two-week trial access for their group to familiarize themselves with the job submission system and test if their workflow works on Gilbreth, they may contact the support team to arrange that. ||| To verify if each sub-cluster uses exactly the same CPUs, run the following command `scontrol show node` with the specified sub-cluster (e.g., `gilbreth-k`). This will provide detailed information about the CPU model on each node within the sub-cluster. Ensure that all nodes have the identical CPU model for consistent performance when running MPI jobs across multiple nodes. The user can also modify their batch script options to request specific CPUs or sub-clusters using `--exclusive` and `--constraint` flags:

Example:
```bash
#SBATCH --nodes=4
#SBATCH --exclusive
#SBATCH -C k  # Use gilbreth-k sub-cluster (replace with the desired sub-cluster)
```

For more information about Gilbreth cluster architecture, refer to: https://www.rcac.purdue.edu/compute/gilbreth ||| To check the prices for different GPUs on Gilbreth, the user can log in to the RCAC website at this URL: https://www.rcac.purdue.edu/purchase. The purchase must be made by a faculty member at Purdue. Once the purchase is fulfilled and the order completed, the faculty member can add the graduate student into the queue on Gilbreth. This will grant the student access to the desired GPU. ||| An account named ""dguilden-k"" has been created for the user's group on Gilbreth cluster with access to 1 A100-80GB GPU and 32 cores. The account will be active from October 30, 2023, to November 15, 2023. To grant access to other users and manage the queue, use the RCAC management portal at https://www.rcac.purdue.edu/account/groups/3040/members. The user can find the Gilbreth User Guide at https://www.rcac.purdue.edu/knowledge/gilbreth and previous training materials at https://www.rcac.purdue.edu/training. A Data Depot directory (""/depot/dguilden"") has been created for the user's group, and the Data Depot user guide can be found at https://www.rcac.purdue.edu/knowledge/depot. The user should use 'slist' command to check their account status and 'myquota' command to view their quota usage. The user should also be able to submit jobs to the dguilden-k queue now. ||| Gilbreth cluster has returned to service as of last Friday (October 20). The user is advised to confirm if it is working fine for them and to let the support team know if they have further concerns. (https://www.rcac.purdue.edu/news/6175) ||| To get assigned to a specific Sub-Cluster node while submitting a job on Gilbreth, use the option '--constraint' (or '-C') with your command. For example:
   - To request an A100 GPU from any sub-cluster equipped with A100 GPUs: `sinteractive -A standby -N 1 -n 8 --gpus=1 -C 'A100' -t 04:00:00`
   - To request a GPU from Gilbreth-E: `sinteractive -A standby -N 1 -n 8 --gpus=1 -C 'E' -t 04:00:00`
   The available constraints can be checked using the command 'sfeatures'. ||| - To create a trial queue, go to Gilbreth cluster and create the queue named ""arnabb-b"". The requester will be added as the group manager. - After the queue is created, add members to this queue at https://www.rcac.purdue.edu/account/groups/1865/members?u=116782 upon login. ||| The team has been proposed to have a virtual meeting next week (either on 1/29/2024 from 11am-12pm or on 2/2/2024) to discuss their questions regarding the purchase and cluster usage. It is advised that they confirm their availability for this meeting with the provided dates and times. The team will have an opportunity to learn more about how cluster access, including standby nodes, interactive mode, and check-out capabilities work during the virtual meeting. ||| - Set up a virtual meeting with the researcher's contact (Prof. Ukkusuri or student) for discussion on Gilbreth access purchase. The meeting is scheduled for 3pm-5pm on Thursday, March 7, 2024 or 11am-12pm on Friday, March 8, 2024. To confirm the time slot and send a meeting invitation, contact the researcher (name, Ph.D. Candidate Transportation Engineering and Infrastructure Systems Lyles School of Civil Engineering, Purdue University). ||| The Gilbreth cluster is mainly for research use and groups need to purchase access to it. However, for instructional purposes, the RCAC offers access to the Scholar cluster for instructors and students. The Scholar cluster contains several NVIDIA V100 and A30 GPUs that are shared by users. To gain access to Scholar, the professor needs to create a class account via the user portal: https://www.rcac.purdue.edu/account/class. Once the class account is created, students will automatically get access to Scholar within 1~2 days if the course has started. Please refer to the specifications of Scholar at this webpage: https://www.rcac.purdue.edu/compute/scholar. For more information about the usage policy, visit: https://www.rcac.purdue.edu/policies/scholar. ||| The user can setup a department account on Gilbreth instead of using individual accounts to manage members of the whole department. No explicit mention was made about needing to send/receive emails from/to this account or setting up an email inbox for the shared account to administer the cluster. For more information and to submit an order, the user can log in at https://www.rcac.purdue.edu/purchase. ||| To purchase access to the Gilbreth clusters, the Ph.D. student's supervisor should log in to https://www.rcac.purdue.edu/purchase and submit an order. After the order is submitted, it will be reviewed by the business office. Once the order has been approved, the RCAC staff will create a lab queue for the group, appointing the supervisor as the group manager. The supervisor can then log in to the RCAC website and manage group members to the lab queues. ||| To resolve this issue, follow these steps:
   - Run the command `ncdu $HOME` on Gilbreth to see your disk usage in detail. It seems your ~/.cache directory is taking up about 16GB. Delete files from ~/.cache and subdirectories within it as necessary, being cautious not to delete any data that you need. - You might also want to remove files from ~/.conda/pkgs, which are package caches. - It's recommended to install software in the /depot/feixue and /depot/wangxiao directories to save space in your home directory. First, check with your PIs if they are okay with it. If so, proceed with the installation. - Keep this ticket open in case you have any further questions within the next 7 days. ||| To create an allocation on the Gilbrath cluster, please provide the name of your PI/PhD Advisor, and their primary affiliation (IU or Purdue). Once this information is received, a new allocation can be created. ||| To gain access to the Gilbreth cluster, it is required to request access via the user's Principal Investigator (PI), who should have access to Gilbreth. If further questions arise, please contact the RCAC support team. ||| - To run the job on specific Gilbreth partitions, add the following line to your sbatch script: `#SBATCH -w gilbreth-d[000-007],gilbreth-e[000-015],gilbreth-g[000-011],gilbreth-h[000-015],gilbreth-j[000-001],gilbreth-k[000-051]`
   - To match the node settings of the Department of Statistics (statdept-h), use the `slist` and `sfeatures` commands to check all cluster queues and details on different node types respectively. You can find more information in the Gilbreth Sub-Clusters chart on the Gilbreth RCAC page. ||| The open file limit for user's account on the Gilbreth cluster is already unlimited as confirmed by a system administrator. The reported issue appears not to be related to the open file limit. ||| The user has been set up with a two-week trial on the Gilbreth cluster for an A10 GPU. It may take a day for the setup to propagate through the system, after which they will receive an email confirmation. The user also requested assistance in setting up Unreal Engine on Gilbreth. While the assistant mentioned that they are working with a student to help with this issue, no specific resolution was provided in the ticket message. The user has been informed to get back if they have any questions or need further assistance. ||| To obtain access to the Gilbreth cluster, follow these steps:
   1. Navigate to the RCAC website (https://rcac.purdue.edu) and log in using your Purdue account credentials. 2. Click on ""Request Access"" and follow the provided steps for submission. 3. Let us know if you require further assistance with this process. ||| The user can request for more CPUs using the `#SBATCH -n` command in their slurm job submission. For example, to get 32 cores/cpus, they should use `#SBATCH -n 32`. However, due to a hard limitation of the GPU machines, it is not feasible for the user's group queue to have more CPU cores than the current limit of 72. If the entire group requires more CPU cores for their workflows, they should reach out for further discussion. ||| The Gilbreth maintenance is scheduled for Tuesday, February 25th, at 8:00 am EST through Wednesday, February 26th, at 5:00 pm EST. For more information, please refer to this news article: https://www.rcac.purdue.edu/news/6965 ||| To run a simulation on the Gilbreth supercomputer's k sub-cluster, the student should use the following command syntax: `sinteractive --partition=gilbreth-k --account=ashirvad --gres=gpu:1 --cpus-per-task=16 --mem=24G --time=24:00:00`. It is important to note that the account will have a specific allocation, and the sinteractive command's parameters must match up with the allocations' parameters. Failure to do so may result in the job either failing or not processing the request as it will attempt to find non-existing allocations. The student is encouraged to read the official documentation surrounding `sinteractive` and `sbatch` (from SLURM) as well as the RCAC documentation for more detailed information. Links to these resources are provided:
  - SLURM documentation: <https://service.purdue.edu> ||| - To grant access, contact Dr. Popescu or anyone they have designated as a ""group manager"" within their member group on Gilbreth. - Alternatively, add Dr. Popescu to this ticket thread, and once we have their permission, the researcher can be added to their group with desired permissions. - A two-week trial for Gilbreth has been set up and the trial ends on March 14 at 12:00 pm. After that, it will be the group's choice whether to make a purchase or not. - Dr. Popescu will serve as the group manager for the account on Gilbreth. The researcher can add other individuals with necessary permissions by going to Purdue RCAC. - An extension of the trial period has been granted until March 28. - More information about Gilbreth and other clusters' purchase prices can be found at https://www.rcac.purdue.edu/purchase ||| The home directory on Gilbreth has a 25GB limit, but the user has access to scratch space with a 200TB quota. The user can use the 'myquota' command on Gilbreth to view all storage options, including Depot storage space. A guide for mapping the scratch space can be found at this link: [https://www.rcac.purdue.edu/knowledge/gilbreth/storage/transfer/cifs](https://www.rcac.purdue.edu/knowledge/gilbreth/storage/transfer/cifs) ||| The user needs to contact their PI (Professor Pavlos Vlachos) to confirm if they have access to the Gilbreth cluster. If the PI has access, they should be able to grant the user access. ||| The user is not currently affiliated with a research group with direct access to Purdue's computing resources, but there is another GPU-powered cluster called Gautschi available. To utilize this cluster, the user should confirm if their PI intends to purchase computing resources with RCAC support team. At the time of writing, Gilbreth Community Cluster, which is primarily optimized for GPU-intensive applications, does not appear to support Gurobi for large-scale optimization problems directly; however, the user may inquire about this possibility with their PI or RCAC support team. ||| Use Globus (https://www.rcac.purdue.edu/knowledge/gilbreth/storage/transfer/globus) for transferring data from a local computer to Gilbreth. The computer should be kept powered and awake during the entire transfer process."
31,1,18,18,"Unable to access name-g queue on Gilbreth due to incorrect command syntax. ||| Two queues ('name-h' and 'name-k') on Gilbreth have not been propagated to SLURM despite being set up through Halcyon. The issue might be related to a potential problem with the SLURM side (qcontrol) or a cronjob that failed to pick up configuration changes. ||| User is unsure whether they have access to Gilbreth through their own group queue and Eli Lilly partnership. ||| User lost access to Gilbreth queue due to expired trial period. ||| The tdm-merck queue on Gilbreth does not appear for users who login and type ""slist"", because it was expired on 12/07/2022 and did not get renewed due to order #9817 being cancelled. ||| Access to Slurm queues (tgrogers-l and standby) on Gilbreth has been lost by the user (name, cc'd). ||| User 'name' does not have access to the ""statdept"" queue on RCAC cluster, despite submitting an R4P form. ||| User Y was added to HPC group ""ychu-n"" but unable to access queue on Gilbreth ||| The user is unable to receive emails for job notifications on Gilbreth Compute Desktop. ||| Users ahmed202 and wang4015 cannot log into Gilbreth cluster ||| PhD student in Computer Science cannot access ""RCAC/Gilbreth csml-b queue"" through OpenOndemand interface or SSH and requires assistance to resolve the issue. ||| The user, a manager of the 'name' group, has access to a queue named 'name-g', but not 'name-n' on Gilbreth HPC system. They require assistance to gain access to the 'name-n' queue. ||| Account user does not have access to any queues on Gilbreth and Rowdy clusters despite having an account. ||| Graduate assistant Ivan cannot access the Gilbreth cluster due to being removed from the allocation. ||| User has no access to queues in Gilbreth while using Alta, seeking clarification on whether this is a bug or if separate access request is required. ||| Seohyun lost access to Gilbreth queues for cgb research group due to a purge of inactive users in April. ||| The user, Ahaan, is unable to access the schaterj-k queue on Gilbreth and schedule jobs. The queue also does not show up in the slist command. ||| User has been waiting over an hour for an interactive session on the Gilbreth cluster without success due to a power outage.","To resolve the issue, use the following updated command: 'sinteractive -A name-g xxx'. Note that instead of using 'sinteractive -A name', you should now include '-g' after your username (name). Additionally, check the queue status with the 'slist' command. For future reference, it may be helpful for an error message to indicate that the specified queue doesn't exist if there is a misspelling or typo in the queue name. ||| The issue was resolved by 'name, PhD Senior Computational Scientist, RCAC Purdue Information Technology'. It appears that the problem occurred due to a halt in calls to Halcyon's API, which might have been caused when systems were powered down during the water leak incident on October 17th. It is recommended to check if the control did not restart when Gilbreth was brought back up. ||| The user can confirm Gilbreth access by logging in to the system and running the 'slist' command in a terminal. They have access through the queues 'abuganza-h' and 'lilly-comp-g'. ||| The user's supervisor, [name], needs to make a purchase for the Gilbreth cluster. Until the order is processed by the business office and fulfilled by RCAC staff, the user cannot regain access to their queue. It is recommended that the user backup data stored in the Scratch folder to prevent regular purging that occurs every month. The order number is 12409. ||| Resubmit the purchase request for the tdm-merck queue on Gilbreth. [Please check with Nick Rosenorn ( ) regarding the status of the resubmitted purchase request.] ||| The issue appears to be due to expired queue(s) on Gilbreth. It is recommended to extend or renew the access to the affected queues for the user. Additionally, it seems that the user is also awaiting an updated node image and support for GPU profiler on H100 nodes. To resolve this issue, contact the system administrator or the named individual in the ticket messages and request a queue extension and update on the status of the requested features. ||| To resolve this issue, user 'name' should contact one of the group managers (Tadd N Colver, Doug [last name], or [another person's name]) to have their account added to the ""statdept"" queue on RCAC. The group manager can do this by logging in at https://www.rcac.purdue.edu/account/groups/916/members?u=82098 and adding 'name'. ||| To resolve the issue, the user should wait up to four hours for LDAP synchronization with their new allocation. The following command confirms that the user has been added to the appropriate groups:

```bash
groups obasit
```

The expected output would show `ychu-n`. To check available queues and resources, run the following command:

```bash
slist obasit
```

After waiting for the specified time, the user should be able to access and submit jobs on their PI's allocation. ||| At the moment, job emails cannot be sent out from Gilbreth. The issue has been shared with experts and will be updated when it is resolved. The user is advised to check if the job emails are blocked on Gilbreth if they continue to experience issues. ||| The users' accounts on the Glbreth cluster will be created during an overnight batch run. They should be able to log into Gilbreth tomorrow. It is recommended to use the guptask-k queue, as guptask-h and guptask-i queues do not have active resources at this time. ||| Reach out to your PI (Principal Investigator) for confirmation if you have been properly added as a member to the ""RCAC/Gilbreth csml-b queue"". If the addition has been confirmed, there is no further action needed from your side. If not, please contact RCAC support again once the issue is resolved. ||| Add the user to the appropriate group for the 'name-n' queue by executing the following command:

```bash
gmod -m /path/to/group_file add name
```
Replace '/path/to/group_file' with the actual path to the file that contains group information on Gilbreth. After adding the user to the correct group, they should be able to access the 'name-n' queue. To check their available queues, use the following command:

```bash
slist name
``` ||| On Gilbreth, since the user is not affiliated with a research group, they do not have access to a queue on Gilbreth as there has been no order submitted by their PI yet for purchasing access to Gautschi. For Rowdy, the user and lab mates were manually added to the account after an oversight was recognized, enabling them to submit jobs moving forward. ||| To resolve this issue, the graduate assistant can either ask their PI to re-add them to the group's Gilbreth queue or submit a new request via the following link: https://www.rcac.purdue.edu/account/request ||| The user's account hasn't been assigned to the Alta group's Gilbreth queue. To gain access, one of the Alta group managers can assign them to the queue, or they can submit a request via this link: [Request Link](https://www.rcac.purdue.edu/account/request). After the group manager assigns the user to a queue or approves their submitted request, they will gain access to the Alta Gilbreth queue. ||| To regain access to the Gilbreth queues for cgb's group, go to https://www.rcac.purdue.edu/account/request and request to be added to the Gilbreth queues. Search for ""cgb"" and select the appropriate Gilbreth resources. Seohyun's advisor must approve the request. Once approved, Seohyun will regain access to the resources. ||| The West Lafayette campus experienced a widespread power outage over the weekend which affected all RCAC clusters. Power has been restored to campus and the clusters are back online and accepting jobs. For more details on the power outage, please refer to this link: https://www.rcac.purdue.edu/news/7225. If you still see this issue this morning, it is recommended to check again. ||| The power outage on West Lafayette campus affected all RCAC clusters and prevented any interactive sessions from running. Power has been restored, and the clusters are now back online and accepting jobs. To launch an interactive session again, user should try starting it once more and it should launch in a reasonable time. For details about the power outage, users can refer to: [https://www.rcac.purdue.edu/news/7225](https://www.rcac.purdue.edu/news/7225)"
24,1,31,30,"The user's research group has not been able to access the ordered Gilbreth-K capacity despite an order being placed and processed. ||| User is unable to access the Gilbreth cluster via https://gateway.gilbreth.rcac.purdue.edu/ ||| User is unable to access Gilbreth server through ThinLinc due to incorrect username or password error. ||| Unable to delete virtual environments created in scratch directory on Gilbreth and unable to see some of these envs in the file system using Gateway, despite them being visible through 'conda env list'. ||| User unable to access Schrodinger on Gilbreth account via ThinLinc and terminal due to lack of module files in their current group depot space. ||| User with PUID REDACTED cannot access Gilbreth due to LDAP authorization failure. ||| Unable to log on the Gilbreth server due to an SSH connection issue. ||| Postdoc user from Math department cannot access Gilbreth or Negishi clusters due to missing home directory and lack of departmental resources. ||| A PhD student cannot access Gilbreth cluster through Gateway and cannot submit jobs to the standby queue. ||| Unable to access Gilbreth server due to lack of queue membership and LDAP authorization failure. ||| Account access issue for a user on the Gilbreth cluster. The user is unable to log in due to the account being removed from the queue. ||| The user is unable to access interactive apps or Jupyter notebooks in the RCAC gateway on the gilbreth home page. ||| User has not been granted access to the Gilbreth cluster despite PI approving the request. ||| User needs access to VASP on Gilbreth as they believe their email is associated with the VASP License but currently does not have access. ||| User needs help transferring files to their Gilbreth account using a method other than Thinlink and cannot load the VSCode module or locate Jupyter or VSCode on their account. ||| The user is facing a NameError when trying to import PyTorch on Jupyter Notebook in their Gilbreth account, specifically with the command 'cudaRuntimeGetVersion()' not found. ||| User cannot connect to test environment ""gilbreth-fe05"" due to a ""Connection timed out"" error when using SSH command from any Gilbreth's front end nodes. ||| User unable to access Jupyter Notebook via Gilbreth Gateway service due to ""Service is unavailable"" error ||| Student at Purdue University is unable to access the CMS depot on Gilbreth through the cluster home. ||| User is unable to log in to Gilbreth, despite being granted access by a professor. ||| User mahan6 cannot SSH into the Gilbreth cluster due to missing home and scratch directories. ||| User cannot access Gilbreth Cluster due to permission denied error. ||| The user is unable to log into Gilbreth due to an error in the initial provisioning of their account and a missing home directory folder. ||| User Tunaz could not access or use Gilbreth cluster for the first time and received an error. ||| User (huan1720) is unable to access Gilbreth cluster due to potential removal of credentials from inactivity last year. ||| User Lena cannot access her account on Gilbreth using the terminal, but can do so via the gateway. ||| Request for Gilbreth account access as a student working with Prof. name has been delayed due to an error during the provisioning process ||| The user (Berk) is unable to connect to Gilbreth server via Visual Studio Code (VS Code), while they can connect successfully through terminal. ||| The user (name) and colleague (amiguel) are encountering access denied issues when accessing the Gilbreth cluster via duo push approval. ||| Connection issues when trying to SSH to Gilbreth for user name Lipton ||| User (Varadharajan) is unable to access Gilbreth system via VS Code Remote or RCAC website due to an account issue.","The dkihara-k queue should now have access to 9 A100-80GB GPUs. ||| The Scholar and Data Workbench clusters have returned in service, but the Gilbreth cluster remains down and gateway.gilbreth.rcac.purdue.edu is currently inaccessible. For the latest updates, please visit https://www.rcac.purdue.edu/news/6175. The user should be able to access the Gilbreth Open OnDemand gateway once the cluster returns in service. ||| The user's Purdue username should be used instead of the server's specific username for logging into Thinlinc. To log in, follow these steps:
   - Enter your Purdue username as the username. - When prompted for a password, type your password followed by "",push"". - Your Purdue Duo client will receive a notification to approve the login. - Thinlinc also supports key-based authentication for added security. If you encounter glitches, you may want to set up a password-free login with SSH using detailed instructions found here: [SSH Key Setup Documentation](URL_for_documentation)
   - Accessing Gilbreth through Gateway should only require Duo for login. ||| It appears that the user's $HOME is full, which may be causing issues with any functions involving writing (such as conda history writing). To resolve this issue, it is recommended to use `ncdu` under the user's $HOME and decide which folder/data could be deleted. After doing so, try running `conda clean`. This should help in managing the virtual environments and allow for successful deletion of any unwanted virtual environments. ||| To use Schrodinger from the group depot space, execute the following commands in the terminal:

```bash
module use /depot/zhan2438/apps/modulefiles/
module load schrodinger
```

This will allow you to access Schrodinger as it is installed under your previous group's depot space (zhan2438). Alternatively, contact your current group and inquire about the location of their Schrodinger installation. Most likely, it is from another group depot space, such as your previous group's (zhan2438). For more information, consult with your current or previous group for further assistance. ||| The user can resolve this issue by submitting an Access Request at https://www.rcac.purdue.edu/account/request. Alternatively, the user can ask Dr. name (group manager of the queue) to add them as a member. If the user has already submitted a request but has not received access yet, they should have Dr. name check the pending requests at this link: https://www.rcac.purdue.edu/account/groups/645/members and approve the request. After approval, the account should be set up correctly. The user is advised to never share their PUID in the ticketing system, as it is sensitive data. Verification of the account can be done using only the email address. ||| Regenerate a new SSH key using the directions provided here: https://www.rcac.purdue.edu/knowledge/gilbreth/accounts/login/sshkeys. If further issues persist, please let RCAC Support know. ||| To gain access to the Gilbreth and Negishi clusters, the user must contact their group manager for departmental resources. The group manager will need to add the user to the respective queues on these clusters. The user should not follow any further instructions from the initial login webpage until they have been added to the clusters by their group manager. ||| The user should first confirm that their group's Gilbreth queues have not expired, as this appears to be the issue preventing access. If the queues have indeed expired, the user can contact their professor for assistance in renewing them. Once the queues are renewed, they should be able to submit jobs to the standby queue via Gateway. ||| To resolve this issue, the user needs to have Dr. Goldwasser add them to the Gilbreth queue by following these steps:
   - Navigate to https://www.rcac.purdue.edu/account/groups/1456/members
   - Locate their name and check the ""dgoldwas-n (Gilbreth)"" checkbox in front of it. - Allow a few hours for the user's data to sync with the cluster. ||| The support team has confirmed that the user (name) and another user have been added back to the sseetha-k (Gilbreth-K) queue. The user should now be able to access the Gilbreth cluster. If there are further issues, they should contact the support team for assistance. No additional action is required from the user at this time. ||| To resolve this issue, the user should click 'Restart Web Server' under the 'Help' menu in the top right of the RCAC gateway interface. If the problem persists after restarting the web server, the support team may need to investigate further to diagnose a root cause. ||| The user should confirm with their PI that they have added them to the Gilbreth access list and provide the PI's email address for further verification. If the account has already been created, the user should let the support team know so they can close the ticket. ||| The user has been asked to try adding the alias 'vasp@rcac' to their email account. If that fails, they should double-check if their email is linked to the VASP License and inform support about it. Once the issue is confirmed, the RCAC Support team will add the user to the VASP group on Gilbreth. ||| The user may need to ensure that the necessary CUDA runtime libraries are properly installed and set up in their environment on the Gilbreth account. To verify this, they can check if the 'nvcc' compiler is available by running `which nvcc` in a terminal. If it's not found, they should follow the instructions provided in the CUDA installation guide for their specific Linux distribution: https://docs.nvidia.com/datacenter/cuda-installation-guide-lin

Once the CUDA runtime libraries are installed and set up correctly, the user should be able to import PyTorch without encountering the 'NameError'. If the problem persists, they may need to reload their environment or restart their Jupyter Notebook session. ||| The user is experiencing issues connecting to the test environment because it has been set up for application rebuild and testing in preparation for an upcoming operating system upgrade from CentOS 7 to Rocky Linux 9. To connect to the test environment, use the command `ssh gilbreth-fe05` from any Gilbreth's front end nodes. The user may experience longer wait times due to a limited number of available test nodes. If the issue persists, please reach out to the Gilbreth support team for assistance. ||| After backend fixes, the user was able to access Jupyter Notebook via the Gilbreth Gateway service. ||| The user was advised to un-check and re-check their access to the CMS depot. This action might send emails to group managers as well as the user, but it could potentially fix the issue. ||| The user's role for Gilbreth was not created correctly within the system's LDAP search. The support team will fix this issue and get back to the user as soon as possible. If the user still needs assistance on this issue within the next 7 days, they can re-open it. ||| The user was instructed to try connecting again as their account on Gilbreth has been fully processed, and they now have a home directory and scratch directory. If there are any issues, they should contact Josh from PurdueIT | RCAC. ||| To gain access to the Gilbreth Cluster, the user is required to request access from their research PI. ||| The HPC support team has identified the issue, re-triggered the user's Gilbreth account creation process, and is monitoring its completion. Once resolved, the user should be able to log into Gilbreth. To test access, the user can try connecting again and report any issues. If there are no further problems, the account will be ready for use. ||| - Add user Tunaz to the ""csml-b (Gilbreth)"" queue by running the command `modifyuser -a csml-b tunaz` on the cluster. - Send an email to Professor Goldwasser and/or support team member name if any requests are made through the [RCAC website](https://www.rcac.purdue.edu/) since their email notifications have been broken for a while. - User Tunaz should read the [Gilbreth documentation](https://www.rcac.purdue.edu/knowledge/gilbreth) for accurate and up-to-date information. - After following these steps, user Tunaz was able to access the Gilbreth cluster. ||| To resolve this issue, the user should contact their supervisor in the ""name"" group and request to be added back to the Gilbreth queue. This will allow them to continue working on the cluster. ||| The issue was caused by Lena's account not being assigned to any Gilbreth queues. To resolve this, Lena's PI can re-add her to the queue, or if they approve it here, the IT team can do so as well. Alternatively, Lena can request access again via the link: https://www.rcac.purdue.edu/account/request. ||| The support team is re-applying the provisioning process for the user's Gilbreth account, and the issue should be resolved within a 1-2 delay while this processes. The team will keep watch over the process and reply once it has completed successfully. In case of further difficulties, users are encouraged to reach out to the support team. ||| Delete any existing saved SSH configs in VS Code and try connecting with a fresh SSH connection. ||| To resolve this issue, the user's PI can re-add them to their groups' Gilbreth queue via the accounts page at https://www.rcac.purdue.edu/account/request. The same process should be followed for colleague amiguel. After submitting the request, access should be granted within a few hours. The user is advised to try logging in (via Open OnDemand, SSH, etc.) and let the support team know if they encounter any difficulties. ||| To troubleshoot the connection problem experienced by user 'name Lipton', run an SSH command with the verbose flag (-vvv) to get detailed information about the connection process. ```bash
ssh -vvv name@Gilbreth
``` ||| The user's account was missing from the Gilbreth system. After being re-instated, the user should be able to connect again. If the connection still fails, they can refer to this documentation for potential issues and solutions: https://www.rcac.purdue.edu/news/7110"
16,2,17,17,"Graduate Worker in Department of Entomology at Purdue University was unable to run jobs on files located in the scratch folder due to exceeded quota. ||| User encountered an error while running COMSOL on a bell cluster node due to insufficient space in their home directory. The error prevented the user from re-opening COMSOL. ||| Unable to launch Jupyter on Bell Cluster due to a full home directory. ||| User is unable to access depot space 'hamakerb' on Bell cluster due to permission denied error. ||| The user was experiencing a ""No space left on device"" error while saving files to the Bell cluster's scratch directory and needed help resolving this issue. ||| User is unable to access Bell cluster shell and cannot navigate to the scratch directory in file explorer. ||| User is unable to start a new R Studio session on Open OnDemand due to disk quota exceeded error caused by a full capacity home directory. ||| Permission error when compiling a program on university cluster due to insufficient write access to /apps/spack/bell/external/ openfoam/OpenFOAM-9_2022.1229/ OpenFOAM-9-20211122/platforms/ linux64Gcc93DPInt32Opt/bin/ directory. ||| The user, msajjan@bell, has encountered an error with vim editor on the HPC cluster at Purdue University while trying to save files due to the ""/home/msajjan"" directory being full. ||| The user's files in the directory /scratch/bell/yu864/name/Converge Test Files/2024/plot_code/ and /home/yu864/python_plot_code/ have been deleted, and they would like to know if there is a possibility of recovering them. ||| User is unable to view and edit on the Bell cluster due to a problem with their terminal path setup in `~/.bashrc`. ||| Unable to sign in to the Bell cluster due to a full home directory ||| User is experiencing issues logging into Gateway portal and submitting jobs in batch mode on Bell cluster due to permission denied error related to profile.sh file. ||| User li4897 encountered 'no space left on the device' error on bell-fe06, affecting auto-fill of file names with ls and shell script generation. ||| User has exceeded home directory size limit on Bell Cluster, causing issues with starting new interactive sessions and incorrect quota usage display. ||| Users 'name ()' and 'Priyanshu name ()' are unable to access their home directories on the Krannert Queue of the Bell cluster due to the error message ""Could not chdir to home directory /home/pkadu: No such file or directory"". ||| Proposal for system cgroup limit on ""/tmp"" folder in Bell HPC cluster to prevent nodes from being brought down due to user workflows, specifically R jobs from user ""siddiq60"".","The issue was resolved when the user removed some files from their scratch folder, allowing them to meet the quota and proceed with running their jobs. The Depot service has also recovered. ||| Clean up space in the user's home directory by deleting unnecessary files, and make sure that there is enough free space (at least 10%) for the operation to run smoothly. Run the command 'ncdu' to help identify large files or directories taking up space in the home directory. Alternatively, change the default recovery folder for COMSOL from the user's home drive to their scratch space, and remove the recoveries from their home drive. This is suggested as an immediate solution if the user doesn't have enough time to clean up their home directory. ||| To resolve this issue, you need to free up some space in your Home directory. You can do this by deleting unnecessary files or moving them to another location. For instance, you could use the following command to move 100 files from your current directory to a new directory called ""old_files"":

```bash
mv * (seq 1 100) old_files/
```

Once you have made room in your Home directory, try launching Jupyter again. If the issue persists, please check the permissions of your Home directory and ensure that you have sufficient storage quota. For more information on using the Bell Cluster, refer to the [Bell Cluster User Guide](https://docs.bellcluster.org/). ||| The reason for the permission denied error was that the user had not been added to the necessary groups ('hamakerb', 'hamakerb-data', and 'hamakerb-apps') controlling access to the depot space. Dr. Lavanya Reddivari was asked to add the user into these groups accordingly to grant them access. The user should have access to the depot space within a few hours after being added. ||| The issue with the Bell cluster's scratch filesystem has been resolved. The user can check their storage using the ""myquota"" command to monitor their usage, especially in their home directory which is almost full. Running the ""ncdu $HOME"" command can help identify which files or directories are taking up the most space. Deleting some files or moving them to other long-term storage spaces like Data Depot or Fortress might be necessary for resolving the issue. ||| The issue was caused by a maintenance on the Bell cluster that occurred the previous day. Once the maintenance had been completed, the user should have been able to access the Bell cluster again. If the user encounters any other issues, please do not hesitate to contact us again. ||| To resolve the issue, create space in your home directory either by deleting or moving files through one of the following methods:
   - Via gateway.bell: Navigate to Files -> Home Directory and perform necessary actions to clear up space. - Using SSH to bell: Connect via SSH to bell and perform the required cleanup in your home directory. ||| To resolve this issue, users should specify a location where they have write access, such as their home directory, when compiling their program instead of using the /apps directory which is only intended for scientific applications deployed by the cluster administrators. ||| To resolve this issue, safely remove the ""/.cache"" directory from the home directory ""/home/msajjan"", which will free up approximately 2.3 GB of space. If this does not resolve the issue, further assistance may be required. ||| Backups are not taken for scratch directories (/scratch/bell/). The user's files at /scratch/bell/yu864/name/Converge Test Files/2024/plot_code/ cannot be recovered. Regarding the files in their home directory (/home/yu864/python_plot_code/), the user may refer to this article: https://www.rcac.purdue.edu/knowledge/bell/storage/recover/flost for recovery instructions. If they encounter any issues, they should reach out for further assistance. ||| Edit the file `/usr/bin/vim ~/.bashrc` and change the line `export PATH=~/usr/bin/:$PATH/depot/bharpur/data/projects/name/GWAS/DosageConvertor/cmake-3.20.0/bin/` to `export PATH=""~/usr/bin/:/depot/bharpur/data/projects/name/GWAS/DosageConvertor/cmake-3.20.0/bin/:$PATH""`. Also, edit the file `/usr/bin/vim ~/.bash_profile` with the same change if necessary for the issue to be resolved. ||| The user is experiencing issues logging into the Bell cluster because their home directory is full. To resolve this issue, the user should log in and clean up their home directory to free up some space. If needed, they can move or delete files to make room. After cleaning up the home directory, the user should be able to log in successfully. ||| To resolve the issue, the user should verify if they are part of the correct group by running the command `id -Gn` or `groups`. If they are not a member of the appropriate group, they can request to be added using the following command: `userman groupname` where `groupname` is the desired group. Additionally, ensure that the user has proper permissions for the file ""/depot/dziviani/etc/profile.sh"" by changing the ownership and permissions using the commands `chown [username] /depot/dziviani/etc/profile.sh` and `chmod 755 /depot/dziviani/etc/profile.sh`. If the user still encounters issues, they may need to contact their system administrator for further assistance. ||| The issue was due to the '/tmp' directory being full on bell-fe06. It has been remediated, and the user should no longer encounter this problem. ||| To resolve the issue, user needs to reduce the current size of their home directory by removing some or all files and transferring them to the depot space. After removing files, user was able to start new sessions. However, it is noted that although the issue seems resolved for now, the home directory has reached its limit, so help may still be required in transferring files. ||| To resolve this issue, it is recommended to ensure that the home directories have been correctly created for the users on the Krannert Queue of the Bell cluster. If the home directories already exist, run the command `module restore default` followed by `module load environment-module-fcst-2018b` and then try accessing their home directories again. If the problem persists, contact the Bell cluster administrators for further assistance. ||| To implement a system cgroup limit that reserves 20% of ""/tmp"" for all Bell nodes and users only get a maximum of 80%. This can be achieved by using the Slurm module job_container/tmpfs, which creates a bind mount from /tmp to /localscratch/slurmjob/$jobid/_tmp inside of the job's cgroup. The nodes are provisioned such that the real /tmp is 10GB, and /localscratch is ~700GB. This setup allows the system to survive /tmp filling and enables Slurm to clean up after the job is complete. It is important to note that this approach has not been tested on Bell yet, and there might be potential impacts on existing workloads that heavily utilize /tmp. For further discussion or clarification, users are encouraged to communicate over Slack."
25,1,28,28,"The user is unable to authenticate when connecting to a MongoDB deployment using mongosh and environment variables, receiving the error ""UserNotFound: Could not find user 'root' for db 'admin'"". ||| User cannot access a specific page (""biography of Gautschi"") on the RCAC (Research Computing and Cyberinfrastructure) Gautschi cluster webpage due to an ""Not Authorized"" error. ||| User is experiencing SSH login issues with DUO and ThinLinc when attempting to copy public key to the cluster. ||| User ding343 and group member kimty cannot log in to the new Gautschi cluster and do not have a scratch directory under '/scratch/gautschi'. ||| User requests access to Abaqus module on Gautschi server ||| Unable to log in to Gautschi gateway with account zhan5096 despite account approval. Error message received upon attempting access. ||| User Utkarsh was unable to ssh into the HPC cluster after being added to a group on Gautschi, receiving an authentication failed error. ||| User is unable to log into Gautschi with an error message ""connection closed ... port xx"". ||| Unable to SSH into Gautschi or use the Gateway portal due to disconnections. ||| User 'abibler' has access issues on Gautschi HPC system due to non-existent home directory and inability to SSH or ThinLinc sign-in. ||| Account not ready for access to Gautschi Server, access denied error message upon login attempt ||| Students unable to log into the Gautschi cluster due to missing directories in /home ||| User unable to connect to Gautschi using thinlink online portal ||| User is unable to log into the Gautschi cluster due to a ""Permission denied"" error when using ssh with their Purdue career account password and receiving a message about public key, gssapi-keyex, gssapi-with-mic, keyboard-interactive, and hostbased permissions. ||| The user 'name' from the Subbarayan-Shastri Group is unable to log in to their account on the Gautschi cluster. ||| User mrisques unable to log into Gautschi due to missing homedir. ||| PhD student in Prof. name's lab group is unable to log in to the gautschi cluster using ssh command due to permission denied error messages. ||| User (Harrison) cannot access the new cluster after order for Gautschi was fulfilled, and payment is still pending. ||| User is unable to use VASP on Gautschi due to license restrictions. ||| User (name) cannot access the new cluster (Gautschi), and their RCAC account. The user's order for Gautschi is still pending payment confirmation. ||| PhD student (Username: harihar4) cannot access the gautshi cluster due to lack of access to the queue within the user group. ||| User was unable to log into Gautschi due to access denied error, followed by an issue where they could not access the Gautschi desktop, and eventually unable to access the Gautschi shell via Gateway. ||| The user is experiencing intermittent issues with the remote desktop login on Gautschi, specifically with Thinlinc and SSH connections. The error message shown is ""Access denied. Please contact your system administrator"", but Gateway login works fine. ||| Unable to log in to Gautschi's remote desktop ||| User unable to SSH into Gautschi server due to connection being closed by Port 22. The user is a student in the School of Electrical and Computer Engineering at Purdue University. ||| Anamika Lochab was unable to access the Gautschi Cluster due to a permission denied error after approving push notifications. ||| User was unable to access Gautschi using Globus after being added to the supercomputer user group. ||| SSH sessions on Gautschi cluster were terminated due to home directory quota being reached.","To resolve this issue, it appears that the user may need to properly configure their MongoDB authentication settings. The user should ensure that a user named 'root' exists in the 'admin' database and check if the password specified in the environment variables matches the one set for the 'root' user. If necessary, create or update the 'root' user with appropriate permissions using commands like `db.createUser()` or `use admin; db.updateUser(""root"", { roles: [ { role: ""readWrite"", db: ""admin"" } ] })`. Additionally, it is recommended to verify that the MongoDB deployment environment variables are correctly set and being passed when starting the container. For instance, the user should check if the `MONGO_INITDB_ROOT_USERNAME` and `MONGO_INITDB_ROOT_PASSWORD` variables are correctly defined in the container startup script or within the cluster setup. It would also be beneficial to ensure that the MongoDB image being used supports authentication, as specified in its documentation. For further assistance, you can refer to the official MongoDB documentation on [Authenticating with MongoDB](https://docs.mongodb.com/manual/core/security-authentication/) and [Connecting to a Replica Set or Sharded Cluster as a Mongos Router User](https://docs.mongodb.com/manual/tutorial/connect-to-a-replica-set-or-sharded-cluster-as-a-mongos-router-user/). ||| The issue is being addressed by the RC Support team. They are awaiting confirmation from the CS (Computer Science) department before publishing the requested page. Users are encouraged to check the website again at a later time for updates. ||| The issue has been resolved. Users are now able to log in using their SSH keys through the DUO app without encountering any errors. ||| To resolve this issue, the user is advised to try logging in again as the problem has been fixed. The student (ding343) could log in but did not have a scratch directory. For creating a scratch directory for ding343 and kimty, follow these steps:
   - Navigate to the Gautschi cluster (e.g., ssh gautschi.rcac.purdue.edu)
   - Use the 'mkdir' command to create a new directory under '/scratch/gautschi'. For example, `mkdir /scratch/gautschi/ding343` and `mkdir /scratch/gautschi/kimty`. - If necessary, modify the permissions of the newly created directories using the 'chmod' command (e.g., chmod 755 /scratch/gautschi/ding343). ||| The user should wait for Abaqus 2024 to be installed on the Gautschi server. Once installed, they can attempt loading the Abaqus module using the same commands (`module load intel; module load abaqus`) as on the Negishi server. ||| The issue has been resolved by the RCAC Support Team. It is recommended that you try logging into your account again at https://www.rcac.purdue.edu/compute/gautschi to verify if it works as expected. ||| The issue was caused by an error state some students in the group entered due to backend processes. The administrator (name) corrected Utkarsh's account and also resolved similar issues for Sakshi and another user (not specified). The other users will be ready in a few minutes. ||| The issue was resolved and the user can now log in. It appears that this problem was caused by a short time outage on Gautschi, during which some login nodes decided to stop working. The user is advised to check if everything is fine before attempting to log in again, and they are thanked for their patience. ||| The issue has been reported to the engineering team for resolution. Users are advised to try again after a short while and contact support if further assistance is required. ||| The user has been granted access on the Gautschi HPC system. However, the scratch directory is still missing and might require some time to populate. It is recommended that the user checks their scratch directory tomorrow and reports back if they are still experiencing issues. For SSH or ThinLinc sign-in, users should attempt to access again after the home directory has been created and populated. ||| User was added again and requested to check later in the afternoon. If issue persists, it has been reported to the relevant team for resolution and user will be informed once it is fixed. ||| To resolve this issue, create directories for the affected users (chen2967 and aolivepe) under the /home directory. Once created, the users should be able to login successfully. However, it was suggested that they try again the next day as the home directory may need some time to populate fully. ||| The user should verify their correct sign-in and Duo authorization. If they have been running jobs with GPUs recently, their account may have been mistakenly removed due to inactivity on computing nodes for over 8 months. The supervisor should add the user back to the queue (group ganeshs) to continue their work on Gautschi. It's also recommended to check Purdue IT's service status page for any potential outages affecting Purdue technology: [https://it.purdue.edu/status/](https://it.purdue.edu/status/) ||| The user needs to be added to a queue group for the Gautschi cluster as they are currently not part of any queue group. They can request access by using the following link: [Request Access](https://www.rcac.purdue.edu/account/request) After approval, they should be able to log into the Gautschi cluster successfully. ||| The issue with 'name's account on Gautschi has been resolved. It was found that there was an error during provisioning of the account. After investigating, the problem was fixed and the user has been granted access to their shell and the group's Gautschi queue. If 'name' encounters any further trouble with logging in, they should reach out for assistance again. ||| The issue was resolved by creating a home directory for the user. It is recommended that the user tests their login credentials to confirm the resolution. ||| After checking the account and shell of the affected user, a potential access issue was identified and resolved by the lab point of contact. ||| After reviewing the account, the process is currently marked as 'pending collection'. Once the payment is collected, the allocation will be created for the research group. The user can contact RCAC support again to confirm when the payment has been processed. There's no action required from the user until the payment is collected. ||| To use VASP on Gautschi, the user needs to provide an email address associated with a valid VASP license. The support team can then add the user to the appropriate group on Gautschi. If the user does not have a valid VASP license, they should ask their supervisor (Prof. name) to add them to one. Additional Information: The email address for this purpose is not provided in the ticket message. It is recommended that the user contacts their supervisor in the CHE department to provide the necessary information. ||| - To access the Gautschi cluster, the user must wait for the order payment to be confirmed by the system (Order #14967). - The user should not have any issues accessing their RCAC account now. This issue was resolved at 1pm on Friday. ||| The user needs to reach out to their supervisor, Prof. [name], to ensure they are correctly added to the appropriate queue that has access to the gautschi cluster. ||| The user was instructed to try logging in to the Gautschi Gateway and send a screenshot of any errors encountered. After providing the requested screenshot, the user was asked to attempt accessing their Gautschi shell via the menu bar ""Clusters"" -> ""Gautschi shell access"". The user then sent another screenshot for error output there. Despite not finding an obvious error message, the issue was eventually resolved by addressing a problem with Thinlinc. The user was asked to try logging in again to confirm the resolution. ||| To further diagnose the issue, the user has been instructed to use the command `ssh -vvv` for debug output when trying to log in via SSH. The user should send this output to the support team for analysis. Additionally, after using their push pin, they were able to log in to the system but were prompted for a second push pin entry before being granted access. This is not expected behavior and may be related to the login issue. After troubleshooting with remote desktop, it seems that the Thinlinc login issue has been resolved. The user should try logging in through remote desktop again to confirm if the problem persists or has been fixed. ||| After experiencing issues with Gautschi thinlinc connections earlier, it appears the problem has been resolved. The user is advised to attempt logging in again to confirm if the issue has indeed been fixed. ||| The issue was resolved by adding the user's advisor, Professor [advisor name], as a contact on the support ticket. Once the professor approves the request, the user should be added to their PI's Gautschi queue, allowing them to access the server. If the user still encounters issues after this point, they are advised to reach out for further assistance. ||| After purchasing resources that started on May 6th, Anamika should now be able to access the Gautschi Cluster. If the issue is still unresolved, it can be reopened within the next 7 days for further assistance. ||| The issue was resolved by confirming that both the user's and Kavin's Gautschi accounts were created successfully. It was suggested that the user check for any Depot location path, as this might be causing the problem when accessing with Globus. There is a 1-2 hour window where provisioning processes run to set up new accounts and home/scratch directories, and connection attempts during this window may fail if the processes haven't finished yet. ||| To resolve this issue, navigate to the Gateway for Gautschi (https://gateway.gautschi.rcac.purdue.edu/) and remove unnecessary files from the home directory to free up space. This should allow the connections to begin working again."
10,0,26,26,"Jobs are being delayed in the pending queue, sometimes for an hour or more, despite no apparent reason or competition for nodes. ||| The user, Assistant Professor Elmore, needs to monitor GPU usage and identify the compute node address of a specific job in the ""nanox-K"" queue on the Gilbreth cluster, without affecting the existing resource allocation for GPU jobs. ||| GPU error on gilbreth-k003 node; CUDA not available through Pytorch installation ||| The user is experiencing degraded performance and power usage issues with the NVIDIA-SMI tool on H100 nodes and has difficulty specifying 64 cores without explicit memory requests in SLURM configuration. ||| User (name) needs access to Gilbreth GPUs for research purposes but is not currently in an active queue on the cluster. ||| Unable to run jobs on kildisha-k queue due to no available GPUs. ||| User 'name' encountered a segmentation fault when starting their program on Gilbreth node j000, and one of the GPUs is not functioning correctly. ||| User Rishi is unable to enable display for debugging Python programs using Visual Studio Code and Spyder on Gilbreth node on a mac M1 Pro laptop, having installed Xquartz. ||| Unable to queue multiple jobs on Gilbreth due to lack of Pip and inability to utilize idle GPUs from the ""standby"" queue. ||| User is experiencing a time limit error when running jobs on the Gilbreth cluster and wants to increase the maximum walltime to 2 weeks. ||| User cannot submit GPU jobs to Gilbreth training queue due to a drained node (gilbreth-j000) with A100 GPUs. ||| User's job is running slowly due to another user occupying both GPUs on gilbreth-k040 and potentially other nodes, causing resource contention. ||| User is unable to use jgmakin-h queue for training machine learning models due to CPU count error and insufficient wall time in standby queue. The user provided a script named `training_submit.sh` for running jobs, but there was an unsupported option `--mem=0`. ||| User, Becca, needs a two-week trial for one A30 GPU on Gilbreth Cluster to run DeepLabCut, a Python package that uses deep neural networks and requires tensorflow. ||| The user's interactive job (7088947) requiring one A100 GPU and waiting in the queue is not progressing due to all CPUs assigned to the specified QoS being in use. ||| Customer is unable to access A100 GPU on Gilbreth-j node due to the node (gilbreth-j-j000) being in drain state. ||| The Jahanshahi Group's jobs in the ""jahansha-n"" queue are not producing output on some nodes (specifically Gilbreth-n003) while other jobs with the same script produce output on other nodes (e.g., Gilbreth-n004). ||| Multiple HPC nodes (B011, B014, E000, E006, E008, K025, N001, N018) are in DOWN/DRAIN state on Gilbreth, impacting GPU availability. ||| User is unable to submit jobs without specifying any GPU on the Gilbreth Cluster and is seeking guidance on how to submit a job with number of GPUs set to 0. ||| Out of memory issues when running moderately sized programs on Gilbreth with low reported max memory usage ||| A user with access to the Gilbreth computing clusters from PI4D cannot allocate resources and request a session due to a pending job that has been queued for 3 days. The user requires access to the GPU. ||| Job with QOSGrpGRES reason has been waiting in the SLURM queue for a while, while other jobs submitted later have started running; Seeking clarification about what 'GRES limit' refers to and how to ensure true FIFO queue ||| User is unable to use Torchrun with multiple nodes in PyTorch, resulting in a timeout during the connection process, possibly due to an incorrect rendezvous IP and node configuration. ||| Group 'name-k' and 'lin491-h' are experiencing out-of-memory errors while running CPU-intensive functions on a Gilbreth cluster node with 1 GPU. The issue is due to limitations in CPU memory allocation in the current setup, as they do not have access to the full node. ||| Unable to request node on Gilbreth-K due to queue being under heavy load for several days, causing training model to be delayed ||| The user is unable to run jobs on the GPU in the Gilbreth Cluster due to an issue with the bitsandbytes version of their software not being supported by the available GPUs. Additionally, they believe that someone from their group may be using the GPUs without their knowledge.","The delay in job start is due to SLURM trying to fit jobs into appropriate slots. This waiting time for owner queue jobs can be up to 4 hours, as resources occupied by shared queues ('debug' and 'standby') are released within this period. Users can check the availability of different nodes using the command `sinfo -s`. ||| - To get a Slurm job on a particular host (for monitoring), use the command `sinteractive -A nanox-K -w <nodename> ...--gpus-per-node=1`. However, this requires an empty GPU on that node. - Monitoring an existing job can only be done by the user who owns the job. The user can find the host the job is running on using the command `jobinfo x`, where 'x' is the job ID of the running job. After that, the user can directly SSH to that host to run the monitoring tool of interest. - To check which user is currently using the queue, use the command `squeue -A nanox-K`. - For real-time usage monitoring of a job, utilize the monitor utility as explained by the colleague: <https://www.rcac.purdue.edu/index.php/knowledge/gilbreth/run/examples/slurm/monitor>. For tracking GPU usage trends over time, check out XDmod at <http://xdmod.rcac.purdue.edu/>. Note that the user may need to set up a personalized xdmod page for detailed information. ||| Reboot the gilbreth-k003 node to resolve the issue with the A100 GPU and unavailability of CUDA during a Pytorch installation. If the issue persists, further investigation will be needed. ||| The issue with the SLURM configuration was resolved by reducing the default mem/core value by 40MB. This should prevent memory exhaustion at around 63 cores. For the nvidia-smi output issue, the support team has reseated the GPUs in the nodes and is now no longer seeing the ""nvidia-smi"" ERR message. The user is advised to check if they notice a difference in performance after this change. ||| To use Gilbreth GPUs, user should be in an active queue either from their supervisor or other group. If the user's group does not have an active queue on Gilbreth, they need to talk to their supervisor to purchase the access. The supervisor can log in to the RCAC purchase page to submit an order for the required access. ||| To resolve this issue, consider submitting jobs to the kildisha-e queue instead, as there are available resources on this queue at the moment. The command to submit a job is `sbatch script_filename.sh`, where ""script_filename.sh"" is the name of your submission script file. ||| Rebooting the node (j000) has been scheduled after all current running jobs have completed. Once rebooted, the user can try restarting their program to see if the issue with the segmentation fault and non-functional GPU is resolved. ||| To enable the display for debugging Python programs on Gilbreth node with Visual Studio Code (VSC) or Spyder on a mac M1 Pro laptop, follow these steps:
   - Ensure that XQuartz is installed and running on your local machine. - Connect to the Gilbreth cluster using ssh. - Forward the X11 display to the remote server by adding the following flag to your ssh command: `-X` or `-Y` (the latter only works with OpenSSH clients). Example: `ssh -X user@gilbreth.example.com`. - Once connected, start VSC or Spyder as usual. They should now be able to utilize the forwarded display for debugging purposes. ||| Install the latest version of pip using Conda. If you have not already created a Conda environment, do so with the command `conda create -n myenv`. Once the environment is created, activate it using `source activate myenv` and then install pip using `conda install pip`. To submit jobs to the ""standby"" queue containing idle GPUs, use the command `qsub -A standby <job_script>`. ||| To take advantage of the extended walltime for cjanjigi-h account, the user needs to change their account name in their submit script. The following is an example of how to do this using SLURM's `srun` command:

```bash
#!/bin/bash
#SBATCH --account=cjanjigi-h
#SBATCH --time=1200:00:00    # Set the desired walltime to 2 weeks (1200 hours)
# Other SLURM directives...
srun your_job_command
```

By modifying the `--account` directive, the job will be submitted using the cjanjigi-h account, allowing for extended runtimes. The user should replace ""your_job_command"" with their desired command to be executed on the cluster. For more information about SLURM, consult the documentation at: https://docs.rcac.purdue.edu/wiki/Slurm ||| The specified node was intentionally brought down by our engineers for scratch system fixes. It will be restored once the fix is completed. In the meantime, please try submitting your jobs to another suitable queue or node based on your requirements. For more information about available queues and nodes, refer to the [Purdue HPC documentation](URL_to_the_documentation). ||| The root cause of the issue is that Gilbreth does not have GPU control while you SSH back to your job landing node. As a temporary solution, the team will contact the users causing this unfair usage to ensure they are using resources they have been allocated for jobs. A more permanent solution to prevent this issue from happening again is being discussed, but it may take some time. ||| - Ask the PI to add the user into the new resource queue (jgmakin-n). - Remove the unsupported option `--mem=0` from the job submission script named `training_submit.sh`. - Consult this page for more information on using Machine Learning Gilbreth: https://www.rcac.purdue.edu/index.php/knowledge/gilbreth/run/examples/apps/learning?all=true ||| To initiate the trial, the user should include their PI in this ticket. If approved, the Senior Computational Scientist will create a queue for the group for two weeks. The user can then add group members to use it. The DeepLabCut package needs to be installed by the user themselves, as the cluster already has python, cuda, and tensorflow installed. ||| To resolve this issue, the user can consider canceling or resubmitting the job with fewer CPU cores (less than 64) if it doesn't require that many resources. The command `scontrol show job <job_id>` can be used to check the status and reason of the job. Replace `<job_id>` with the actual job ID number (7088947 in this case). ||| The support team has restarted the affected node (gilbreth-j-j000). Customers are encouraged to confirm the node status on their side. ||| To investigate whether the issue is node-specific, try resubmitting the job on a specific node using the command `-w node-name (e.g., -w gilbreth-n004)` in the submission script. Additionally, ensure that your job runs on your lab queue by including the command `$SBATCH --account=jahansha-n`. Also, verify that the exact modules and versions are loaded for each job using `module list`. If you're still encountering issues, double-check to make sure that your transition from a trial account to a purchased queue has been properly implemented. The changes made during this transition remain in the same queue (i.e., jahansha-n). ||| The team identified the problem as requiring memory repairs for the affected nodes. The resolution will not be a simple reboot and resuming of these nodes, but rather a more complex repair process due to the underlying issue. Users are advised to wait for the repairs to complete before requesting GPUs on the standby queue. ||| Users cannot submit a job with no GPUs (0) on the Gilbreth cluster. They must specify the number of GPUs using the `--gpus-per-node` option and should always use at least 1 GPU for any jobs run on Gilbreth. This is a QOS policy that applies to all jobs run on Gilbreth. ||| To resolve the out of memory issues, it is recommended to allocate more cores when submitting jobs on Gilbreth-h. This will increase the available memory for the job since each node has 512GB of memory and allocating more cores allows a job to access a larger portion of that memory (e.g., with 32 cores, a single core job can only access approximately 16GB). It is also suggested to extend the wall time for the job to ensure it has enough time to complete without being terminated due to the time limit. If the issue persists after making these adjustments, share the Session ID with support for further investigation. ||| To determine the reason the job is still pending, run the command 'jobinfo jobID' where 'jobID' is the number in parentheses next to 'Jupyter' on the dashboard. If someone else is using the GPU in the PI4D-h queue, you will have to wait for them to finish or use the 'standby' queue instead. To use the standby queue, select 'standby' in the queue dropdown menu. Be aware that the maximum time limit for jobs in standby is 4 hours and you may get any GPU on the cluster, including an A100 or a V100. If the current session with user 'jain488' does not finish soon, it might take about 2 days before your job can run. ||| The term 'GRES' refers to General Resources in SLURM. In this context, the 'GRES limit' is the maximum amount of general resources (such as number of CPUs or GPUs) that a specific job queue can consume at any given time. To ensure a true FIFO (First-In-First-Out) queue, you should consider adjusting your job requirements to match the available resources in your cluster, particularly if they are limited. This will allow more jobs to start running in order of their submission time. You can adjust job requirements using the '--gres' option when submitting jobs with sbatch or srun commands. For example:

```bash
sbatch --gres=gpu:1 your_job_script.sh
```
In this example, the command specifies that the job requires one GPU for its execution. Adjusting the number of requested resources will help to ensure a more efficient scheduling and minimize queue time for jobs. For further information about using SLURM, consult the official documentation at: [SLURM User Guide](https://slurm.schedmd.com/userguide/index.html) ||| Modify the submitted job script as follows:
- Update the number of nodes from 2 to the actual required number (e.g., 4 for 4-node setup). - Set the `--nnodes` option in Torchrun to match the updated number of nodes. For example, if you are using 4 nodes, set it as follows: `torchrun --nnodes=4 --nproc_per_node=1`. - Update the `rdzv_endpoint` option in Torchrun to specify the IP address and port of the head node (the first node in the cluster). You can obtain this information using the script provided. For example: `--rdzv_endpoint=$head_node_ip:29500`. - Make sure the modules needed for Torchrun are loaded correctly before running the script by including a `module load` command for them. If necessary, add relevant module commands to the script. - Book a meeting with the RCAC support team using the provided link (if available) to discuss the issue and troubleshoot any remaining issues. ||| To address this issue, it is recommended to increase the number of cores requested for each job to maximize the available CPU memory. This should help prevent out-of-memory errors when running CPU-intensive functions. The user is also advised to use the 'monitor' tool to get real-time memory consumption data, as the output of `jobinfo` may not be accurate when a job runs out of memory. Increasing the number of cores subject to the user's limits should help resolve the issue; however, further exploration of potential alternatives might be necessary if increasing the core request does not improve the situation. ||| Add the following line in the submission script `#SBATCH --qos=normal`. This will help in allocating resources and running the job as normal QoS is a valid flag for the SLURM scheduler on this cluster. For example, the revised submission script should look like:

```bash
#!bin/bash
# ...
#SBATCH --qos=normal
# ...
``` ||| - To check if another member of your group is using the GPUs, run the command `squeue -A li4017` to show all jobs running under your group's allocation. If you want to search by a specific user, use `squeue -u username` to see their running/pending jobs. - To resolve the issue with the bitsandbytes version of your software not being supported, follow the instructions provided in the linked documentation: https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend
- If a job you submit isn't running when there are free resources, please send the SLURM job ID and/or the job submission script for review."
16,1,21,21,"The user is encountering a failure during the execution of their parallel CFD analysis workflow using OpenMPI and ADflow on Bell Cluster. They are requesting help to resolve the issue. ||| Cannot load custom kernel in OnDemand Jupyter Notebook on Bell Cluster ||| Request to update package ""cactus"" on the Bell cluster from version 2.5.2 to 2.6.4 ||| User is experiencing an error with executing an edited version of Sandia Lab's SPARTA code on the Bell cluster due to missing libmxm library during runtime. ||| Graduate Research Assistant is unable to set up an environment on Bell and install specific packages due to a conflict with_glibc. ||| User is unable to run funannotate on Bell Cluster due to an error related to genemark. ||| User is unable to load the Wannier90 package on the Bell cluster and requires help with its installation or alternative solutions to connect it with VASP. ||| User wants to install a newer version of LAMMPS than the ones currently available on the Bell cluster. ||| A grad student is encountering an error while trying to restart simulations on the bell cluster after a node failure. The error involves a missing shared library file (libpmi2.so.0) required by openmpi when running mpirun. ||| User is unable to run Converge programs using a batch script on either Intel 2019 or Intel 2017. The error messages are file not found (Intel 2019) and segmentation fault (Intel 2017). ||| The QIIME2View webpage on the Bell Compute Cluster fails to load output files after the June 26 update, resulting in a 404 Error upon file upload. ||| User is experiencing an issue when using ANSYS 2023 R1 on the Bell HPC cluster with more than one node, specifically with ""Shared Memory on Local Machine"" as the parallel option. The error occurs during Fluent launch and appears to also happen on the Negishi cluster. ||| The user is experiencing an issue with File Manager unresponsiveness and slow computational times while using the Bell cluster for CFD simulation. ||| Graduate student in Altman Lab wants to update Schrodinger Software from version 2021-1 to 2024-4 and needs installation instructions for the cluster. ||| User is unable to run Schrodinger 2024-4 GUI on the Bell Cluster due to missing Qt platform plugins and a fatal Python error. ||| User is unable to run scripts in a 'bin' folder due to missing libnetcdf.so.18 library when loaded with shared libraries. ||| Herwig7 high energy physics model installation failure due to missing ""development version of Python"" on Bell cluster. ||| The user's physics model (Herwig7) is facing dependency problems on the updated Bell cluster after recent maintenance. Specifically, it can't find the required library gsl and encounters an error with the ""gcc-runtime/8.5.0-u6ywdr3"" and ""glibc/2.28-3kybixu"" modules. The user needs to solve this issue so they can build a development environment for their program. ||| CONVERGE CFD v3.0 user on Bell cluster encountered an error while submitting a job submission script and requires assistance in modifying the script to use correct module versions. ||| The user is encountering errors when running the EMBOSS fuzznuc tool (version 6.6.0) on the Bell cluster for rDNA pattern search in a genome due to BusyBox conflict and ACD file issues. ||| Errors encountered when running CANDOCK simulations on Bell Cluster after recent maintenance, resulting in a segmentation fault within the cd_${_sub_program} binary from CANDOCK v0.4.3.","The issue appears to be caused by not correctly using the requested number of cores when submitting the Python job. To solve this, the user should use ""srun -n 128 python /path/to/script.py"" instead of ""mpirun -n 1"". This will allocate and utilize all 128 cores as intended. It is also suggested to load the Anaconda module within the script if it has not been loaded already, following the instructions provided at this link: [https://www.rcac.purdue.edu/knowledge/bell/run/examples/apps/python](https://www.rcac.purdue.edu/knowledge/bell/run/examples/apps/python) . The user should consult with their team or visit the Convergence Center for further assistance if necessary. ||| - Attempt to add the conda environment to the kernel by running 'ipython kernel install --user --name=my-kernel-name' (replace 'my-kernel-name' with your preferred kernel name) within the conda environment. - Check if the custom kernel appears and connects to the conda environment in OnDemand Jupyter Notebook. ||| Install the updated version of package ""cactus"", specifically version 2.6.4, on the Bell cluster by following these steps:
   - Download the latest version of the package from the provided GitHub link: https://github.com/ComparativeGenomicsToolkit/cactus/releases
   - Transfer the downloaded package to the appropriate directory on the Bell cluster
   - Unpack the archive containing the updated version, if necessary
   - Update the modulefile for the ""cactus"" package in the appropriate modules directory to include the new version details
   - Load the updated module for the ""cactus"" package using the 'module load' command
   - Verify that the updated version of the package is installed and functioning correctly by running relevant tests or commands as needed. ||| To resolve this issue, try recompiling the code on Bell cluster or share the executable file for analysis. It is recommended to compile the code with the appropriate MPI and Mellanox libraries to ensure compatibility with the Bell cluster's configuration. If necessary, consult relevant documentation or reach out to a technical expert for assistance. ||| The user should first check the [RCAC user guide about installing packages with conda on Bell](https://www.rcac.purdue.edu/knowledge/bell/run/examples/apps/python/packages). If the issue persists, providing more details like the error message and commands taken would help in diagnosing the problem. Additionally, the user can request a consultation through one of the online coffee hour sessions or schedule a virtual meeting for further assistance. ||| The user should verify if their corresponding funtest.out file mentions a license key. If not, they are advised to run the job again and check if the issue persists. It is also suggested that the user considers using funannotate version 0.8.15 as it has fixed some bugs present in version 0.8.13. ||| The Wannier90 package has been installed on the Bell cluster. The user should now be able to load the module using the command ""module load wannier90"". If any issues are encountered, please reach out for further assistance. ||| The current software installation policy does not allow for the installation of software that is not in high demand. The user can find more details about this policy here: [Software Installation Policy](<URL_OF_POLICY>). On the Bell cluster, the available versions of LAMMPS are lammps/2022.5.04, lammps/20200721, and lammps/20201029. If these versions do not meet the user's needs, they can attempt to install the latest software version themselves in their home directory or within their allocated project space. Additionally, the user might consider building a Singularity container with their preferred version of LAMMPS using the tutorial available at [RCAC Tutorial on Containers](<URL_OF_TUTORIAL>). Pre-built LAMMPS Docker images can be found on [Docker Hub](<URL_OF_DOCKER_HUB>), and these can be converted into Singularity containers using the steps outlined in the tutorial. ||| Add the /usr/lib64 directory to the LD_LIBRARY_PATH environment variable in the jobscript, resubmit the job and verify that the LD_LIBRARY_PATH includes the /usr/lib64 directory by running ""echo $LD_LIBRARY_PATH"". If necessary, execute ""export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib64"" to add the directory. Also, provide the JobID of the job that failed with this error for further assistance if required. ||| The user should try adding 'export I_MPI_DEBUG=10' before the 'mpirun -np ...' line in their submit script and also add 'module list' after module load impi/2019.5.281. It is suggested to put the error messages into a text file or snapshot image for easier review. ||| The issue is not related to the cluster's Firefox browser, as access to it has been successfully restored using the `unlock-firefox` command. However, the problem persists when trying to load files on the QIIME2View webpage within the cluster environment. To resolve this issue, the user should follow these steps:
   - Disable any Firefox extensions that might interfere with the QIIME2View webpage functionality. - Check if the path to the output files is correct and accessible within the cluster's file system. - Verify that the output files are properly generated using the QIIME2 analysis pipeline. - Share an example file for troubleshooting purposes with the support team, who will collaborate on resolving the 404 error. - Arrange a virtual meeting to discuss further if necessary (1PM EST tomorrow). If no issues arise in the next 7 days, this ticket can be reopened for additional assistance. ||| To resolve the issue, the user tried two solutions:
   a) Changing from using Intel MPI compiler to openmpi. b) Changing the format of the machine list given to Fluent. The new format is for each machine name (just node number e.g. a123) to be on a separate line instead of one line per process. This previous format worked before but stopped functioning due to an unknown reason, possibly an update in MPI. ||| There are ongoing issues with the Bell Scratch cluster across the entire system, which the support team is actively working to resolve. The user is advised to wait for updates and contact the support team if they have any urgent needs or questions in the meantime. It is also suggested that the user checks whether their computational case setup may be causing the issue as there have been problems with Bell storage recently, particularly over a specific time period referred to as 'name'. ||| Follow these steps to install Schrodinger software on the RCAC cluster:
   - Navigate to the following link: [https://www.rcac.purdue.edu/training/software-installation](https://www.rcac.purdue.edu/training/software-installation)
   - Follow the instructions provided for installing Schrodinger software on the cluster. - If you encounter any issues or require further assistance, please let us know. ||| To resolve this issue, follow these steps:
   - Ensure that the required Qt platform plugin, ""xcb"", is installed on the system. You can install it by using the following command: `sudo apt-get install libqt5x11extras5`. - If the above command does not work or if there are any issues with the package dependency resolution, you can try to manually download and install the required library. The library can be found at this link: <https://askubuntu.com/questions/284934/how-do-i-install-libqt5x11extras5>
   - After installing the required Qt platform plugin, try to run Schrodinger again. If you still encounter issues, it might be due to a conflict with other installed Qt plugins. In that case, you can try to unload or disable other Qt plugins before running Schrodinger. To unload a Qt plugin, use the following command: `qtstopplugin libqt5x11extras5`. - If the issue persists, it might be due to an incompatibility between Schrodinger and your system's Python version. Try downgrading or upgrading your Python version according to the official documentation of Schrodinger: <https://www.schrodinger.com/support/documentation-resources/software-downloads>
   - If none of the above solutions work, please reach out again for further assistance. ||| The user needs to ensure that the correct version of the netCDF library (libnetcdf.so.18) is installed on the Bell Cluster. To do this, the following steps can be taken:
   - Check if the required library is already available by running `locate libnetcdf.so.18` or `find /usr/local -name libnetcdf.so.18`. - If it's not found, reinstall the netCDF library version 4.5.0 with the correct shared object file (libnetcdf.so.18). This can be done by following the instructions provided in [the official netCDF installation guide](https://www.unidata.ucar.edu/software/netcdf-c/downloads/netcdf_4_5_0_installation.html) or by contacting your cluster administrator for assistance. - Once the correct version of libnetcdf is installed, update the LD_LIBRARY_PATH environment variable to include its location. For example: `export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/path/to/netcdf-4.5.0/lib`. - After updating the LD_LIBRARY_PATH, reload the terminal or run your scripts again to see if the issue is resolved. ||| Attempt installing Python using Conda package manager. On Bell cluster, load the Conda module and find the path to the installed Python version using the 'which python' command. If the issue is resolved, use the loaded Python version for running Herwig7 simulations. Here's an example of how to check the installed Python version using Conda:

```bash
module load conda
which python    # Output: /apps/external/conda/2025.02/bin/python
python --version  # Output: Python 3.12.8
``` ||| To resolve this issue, follow these steps:
   - Create a new Conda environment with the required Python version (e.g., 3.12.8) and dependencies using the following command:
     ```
     $ ml conda
     $ conda-env-mod create -n myenv
     $ module load use.own
     $ module load conda-env/myenv-py3.12.8
     ```
   - Install the required Python package(s) using Conda inside the created environment:
     ```
     conda install package_name
     ```
   If your program requires additional dependencies, you can install them inside your environment using the same command format (replace `package_name` with the appropriate name for each dependency). - If you encounter any issues or need further assistance, please reach out to RCAC Support. ||| To resolve this issue, modify the job submission script as follows:

```bash
# Load required modules
module load intel-oneapi-compilers/2024.2.0
module load openmpi/4.1.6
# Load CONVERGE module
module load converge/3.0.16
# If mkl library is needed, use this:
module load intel-oneapi-mkl/2024.2.2
```

This updated script ensures the correct module versions are used to avoid the encountered error. ||| Update the EMBOSS container on Bell/Negishi to resolve the reported issues. To try the updated container, use the following commands:
   - `apptainer exec /apps/biocontainers/images/quay.io_biocontainers_emboss:6.6.0--h8719169_4.sif fuzznuc -help` or
   - Load the EMBOSS module and call it directly using these commands:
      ```
      $ ml --force purge
      $ ml biocontainers
      ```
     User guides for each biocontainer module can be found in [RCAC's documentation](https://www.rcac.purdue.edu/knowledge/biocontainers). - Verify the container's execution by running `ml emboss` and then `fuzznuc --version`, which should display EMBOSS:6.6.0.0. Please let us know if you face any further issues. ||| - Details about the CANDOCK installation (system-based, personal/local build, or container), along with the module being loaded if applicable. A module list output from the job would be helpful. - Input files used for the simulation, including ligands, receptor, etc., to confirm they are the same as those used previously without error. - The full SLURM submission script (submit_candock_module.sh), SLURM error (slurm-xxxxxx.err) and output (slurm-xxxxxx.out) files. Not just screenshots are required for effective troubleshooting. - Confirmation if you're using the system-installed version of CANDOCK or a personal/local build. If available, you can also run the job under gdb or valgrind to isolate the fault. Once we have this information, we will investigate further and provide guidance on how to resolve the issue. If needed, feel free to sign up for a coffee hour through this link: https://www.rcac.purdue.edu/coffee for additional assistance."
