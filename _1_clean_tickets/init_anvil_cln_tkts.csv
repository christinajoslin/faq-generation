issuenumber,title,datesubmitted,dateclosed,customernote,submittedby,submittername,assignee,teamassigned,resource,numbermessages,timeopen,weeknumber,year,weekstart
ATS-8841,Compiling GENE code on Anvil,2024-06-21,2024-11-18,"Hello Cheers, Zach Williams ; ^GENE\\_docs.pdf] ^ORIGINAL\\_new\\_machine.mk ; Hi, Thank you for contacting us. Sorry but we could not help on specific source code compiling. I went through the user guide and didn't find any specific requirements for this software (i.e. it does not require admin privilege and all the dependencies should have been installed on Anvil as modules). So I would encourage you to test the compilation process yourself and ask any questions you have regarding dependencies on Anvil. Best regards, name Senior Computational Scientist Purdue Information Technology ; Hello name, Thanks for the reply Cheers, Zach ; Hello Cheers, Zach ; Hi, Sorry for the delay. All the dependents you mentioned have been deployed as modules on Anvil. What you need is to load those modules (e.g. {{module load fftw}}) before compiling your codes. Ideally, the env paths and flags needed for compilation are defined in those modules so you could just use them. You may check what have been defined in a module with {{module show xxx}}. e.g. for {{fftw}}: $ module show fftw ; /opt/spack/cpu-20211007/openmpi/4.0.6-3navcwb/gcc/11.2.0/fftw/3.3.8.lua: ; whatis(""Name : fftw"") whatis(""Version : 3.3.8"") whatis(""Short description : FFTW is a C subroutine library for computing the discrete Fourier transform (DFT) in one or more dimensions, of arbitrary input size, and of both real and complex data (as well as of even/odd data, i.e. the discrete cosine/sine transforms or DCT/DST). We believe that FFTW, which is free software, should become the FFT library of choice for most applications."") help(FFTW is a C subroutine library for computing the discrete Fourier transform (DFT) in one or more dimensions, of arbitrary input size, and of both real and complex data (as well as of even/odd data, i.e. the discrete cosine/sine transforms or DCT/DST). We believe that FFTW, which is free software, should become the FFT library of choice for most applications.) depends\\_on(""openmpi/4.0.6"") prepend\\_path(""PATH"",""/apps/spack/anvil/apps/fftw/3.3.8-gcc-11.2.0-wmcvzic/bin"") prepend\\_path(""LIBRARY\\_PATH"",""/apps/spack/anvil/apps/fftw/3.3.8-gcc-11.2.0-wmcvzic/lib"") prepend\\_path(""LD\\_LIBRARY\\_PATH"",""/apps/spack/anvil/apps/fftw/3.3.8-gcc-11.2.0-wmcvzic/lib"") prepend\\_path(""CPATH"",""/apps/spack/anvil/apps/fftw/3.3.8-gcc-11.2.0-wmcvzic/include"") prepend\\_path(""MANPATH"",""/apps/spack/anvil/apps/fftw/3.3.8-gcc-11.2.0-wmcvzic/share/man"") prepend\\_path(""PKG\\_CONFIG\\_PATH"",""/apps/spack/anvil/apps/fftw/3.3.8-gcc-11.2.0-wmcvzic/lib/pkgconfig"") prepend\\_path(""CMAKE\\_PREFIX\\_PATH"",""/apps/spack/anvil/apps/fftw/3.3.8-gcc-11.2.0-wmcvzic/"") setenv(""FFTW\\_HOME"",""/apps/spack/anvil/apps/fftw/3.3.8-gcc-11.2.0-wmcvzic"") setenv(""RCAC\\_FFTW\\_ROOT"",""/apps/spack/anvil/apps/fftw/3.3.8-gcc-11.2.0-wmcvzic"") setenv(""RCAC\\_FFTW\\_VERSION"",""3.3.8"") setenv(""FFTW\\_CPPFLAGS"",""-I/apps/spack/anvil/apps/fftw/3.3.8-gcc-11.2.0-wmcvzic/include"") setenv(""FFTW\\_LOADLIBES"",""-L/apps/spack/anvil/apps/fftw/3.3.8-gcc-11.2.0-wmcvzic/lib -lfftw3 -Xlinker -rpath -Xlinker /apps/spack/anvil/apps/fftw/3.3.8-gcc-11.2.0-wmcvzic/lib"") setenv(""FFTW\\_MPI\\_LOADLIBES"",""-L/apps/spack/anvil/apps/fftw/3.3.8-gcc-11.2.0-wmcvzic/lib -lfftw3\\_mpi -lfftw3 -Xlinker -rpath -Xlinker /apps/spack/anvil/apps/fftw/3.3.8-gcc-11.2.0-wmcvzic/lib"") All executables are added to system {{PATH}} (so the system will recognize executables directly from current session) and library files added to {{LD\\_LIBRARY\\_PATH}}. You may use env variable {{FFTW\\_CPPFLAGS}} for the flag that requires {{./include}} and {{FFTW\\_LOADLIBES}} for flag requiring {{./lib}}. Similar ideas applied to other dependents. Please give it a try and see how it goes. name ; Dear name, Thank you so much for the detailed response\ Cheers, Zach ^anvil.mk \\_(4 kB)\\_ ; Hi Zach, Apologize for the delay but looks like it's looking for intel-mkl library. Not sure which step inside of the makefile is looking for intel-mkl specifically but might worth a try with intel and intel-mkl modules and see how it goes (i.e. change compiler to intel) as all the mentioned library files are included inside of the intel-mkl folder: $ ls /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mkl/lib/intel64 ... libmkl\\_gf\\_lp64.a libmkl\\_core.a libmkl\\_sequential.a name ; \\*\\*PRIVATE NOTE\\*\\* Anvil Application Team: https://access-ci.atlassian.net/jira/people/team/0f5fcf8a-26ef-4d24-a346-4a2ef3a7afda?ref=jira$&src=issue ([~accountid:id ~accountid:id ~accountid:id:id-bd45-4e12-b7de-6550f017a297 ~accountid:id:id-0296-44c2-8aaa-9a36b2662a58 ~accountid:id ~accountid:id:id-5a0e-4ef9-9dae-4ff21198071b ~accountid:id ~accountid:id:id-c12e-4112-bfdf-3503868fdf94 ~accountid:id ~accountid:id ~accountid:id ~accountid:id) Hi team, Please take a look at the issue and see if you could have a solution. Thank you. Best, name ; Hi, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name ;",zrwill@access-ci.org,Zachary Williams,Guangzhen Jin,Purdue University,Anvil,10,107,25,2024,2024-06-17
ATS-13780,AnvilGPT Access Request,2025-02-05,2025-03-10,"Experimentation with using LLMs for Stratolaunch hypersonics research. allocation account number is cis220051. I would like access to both API and the UI. ; Hi, Thank you for reaching out. I have granted you access and you should be able to access the AnvilGPT UI. For API documentation please refer to the following link - https://www.rcac.purdue.edu/knowledge/anvil/anvilgpt/api: https://www.rcac.purdue.edu/knowledge/anvil/anvilgpt/api|smart-link Best, name ;",kma3,Kevin Ma,Mihir Ahlawat,,Anvil,2,24,6,2025,2025-02-03
ATS-9661,request for storage space on ANVIL,2024-07-31,2024-07-31,"I am just about to submit my request for a renewal (deadline midnight tonight). I am requesting computing time on ANVIL CPU and I see where on the website to do that. However, I do not see where to request storage on ANVIL. I see places to request storage on other machines, but not ANVIL. How do I request storage on ANVIL ; Hi name, The Purdue Anvil resource does not allocate their storage via the ACCESS program, once and Anvil compute award is made the Anvil staff will work directly with you and your storage needs. Ken Hackworth - ACCESS Allocations ;",pmarcus@access-ci.org,Philip Marcus,Ken Hackworth,,Anvil,2,1,31,2024,2024-07-29
ATS-1668,"When I submit I a simulation, it give me an error like this",2023-07-06,2023-08-11,"It's my first time submitting a sbatch on Anvil. The error says the minutes limit and the user's size and time limit. May I know the specific reason why I got the error like this? Thanks a lot ; Hi Aojia, It means your required running time is longer than the queue limit. Please check this partitions page for the limits for each queue: https://www.rcac.purdue.edu/knowledge/anvil/run/partitions: https://www.rcac.purdue.edu/knowledge/anvil/run/partitions|smart-link Best, name ; Hello, It has been a while since last time we hear from you. This ticket would be tentatively marked as resolved. Feel free to submit a new ticket to Anvil Help Desk: https://support.access-ci.org/user/login?destination=/open-a-ticket if you have questions in the future. Thanks! ;",jiangaojia@access-ci.org,Aojia Jiang,Nannan Shan,Purdue University,Anvil,4,27,27,2023,2023-07-03
ATS-1793,Access to VASP in Anvil HPC,2023-07-11,2023-08-07,"I'm a postdoc of Professor name Zunger at University of Colorado, Boulder and need to use VASP in the Anvil HPC. Prof. Zunger should have a VASP license. What should I do to apply for the confirmation of the license? Thank you. ; Also I would like to know how to SSH my Anvil account by keeping the address in the list of my MobaXTerm. Now I can only log in by SSH-key. But if I edit the SSH directly in MobaXTerm, it will remind me to enter the avil password. I tried my ACCESS password but it does not work. ; Another question is on using some loaded software such as gnuplot. After I module load it in Anvil and try to plot as a test, it shows the error ""qt.qpa.xcb: could not connect to display"", ""qt.qpa.plugin: Could not load the Qt platform plugin ""xcb"" in """" even though it was found.', and ""This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem."". No X11 window appears. How can I fix this error? ; Hi name, Thanks for reaching out! For your first question about VASP, you can ask your supervisor to add you into the valid VASP license. Then let us know your email address you used for VASP license, we will need your email address to verify your license. After verified, we can add you into VASP groups on Anvil. For your second question, Anvil does not have password, you need to set up ssh keys. About how to login, feel free to check our user guide about different options. https://www.rcac.purdue.edu/knowledge/anvil/access/login: https://www.rcac.purdue.edu/knowledge/anvil/access/login|smart-link For X11 display, the error means your X11 display is not set up properly. If you are using MobaXterm, it should come with X11 display. You can also use another ssh client, ThinLinc, to login Anvil, which is also equipped with X11. https://www.rcac.purdue.edu/knowledge/anvil/access/login/thinlinc: https://www.rcac.purdue.edu/knowledge/anvil/access/login/thinlinc|smart-link Hope this helps, Cheers, name, PhD Sr. Computational Scientist Purdue University ; Hi name, Do you have further questions? Are we okay to close this ticket? Cheers, name ; Dear name, Thank you! I would like to know how my supervisor operates in detail to add me in the VASP license list? Best, name ---- ; Dear name, I think we have been added into the VASP license list (I cc this email to MD support for check). Here are our information: 1. Me: name, postdoc of Prof. name Zunger at CU Boulder, email 2. Xiuwen name: Assistant professor of Prof. name Zunger at CU Boulder, email . Could you please help us check whether we have been in the list or what else do we need to do? Much appreciated. Regards, name ---- ; Dear name, Thank you very much for the list. Could you please correct a mistake of my email address (the current one) in the list, which should be """"? Regarding Xingang and Linding's license, let's hear from my supervisor Prof. Zunger. Best, name ---- ; Thanks name! Best, name, Since we are discussing the same questions on another ticket, https://access-ci.atlassian.net/browse/ATS-1912. So I would close this one, which is duplicated with another one, to keep everything in one place. Cheers, name ; Hi name, Yes you can close this ticket. We can just leave the Ticket ATS-1912 active. Regards, name ---- ;",jxiong1,Jiaxin Xiong,Nannan Shan,Purdue University,Anvil,11,20,28,2023,2023-07-10
ATS-1632,vasp,2023-07-05,2023-07-06,"Hi , I was just added to a vasp 6 license 23-0223 5-2069. > > Would you mind adding this new license for me? thank you! > > > License owner's institution: University of Michigan > > user: wyuxuan > > User's email: : mailto: > > VASP vendor: VASP Software GmbH > > License owner's name ; Hi Yuxuan, Thanks for reaching out! You have been added to vasp6 group on Anvil. Your membership will be ready within a few hours. Please check our user guide for VASP calculations on Anvil. Please make sure you also added 'module load hdf5' to your submit script while you use VASP6. https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/vasp: https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/vasp|smart-link Cheers, name, PhD Sr. Computational Scientist Purdue University ; Thank you for your help! ;",wyuxuan,Yuxuan Wang,Nannan Shan,I do not know the RP,Anvil,3,2,27,2023,2023-07-03
ATS-1636,Need quota increase on Anvil $SCRATCH,2023-07-05,2023-07-12,"Hi, I am in need of a significant quota increase for the number of files on Anvil scratch space. I have to generate a lot of files with my simulations because each processor dumps out its own data cubes. 1,000k files is not nearly enough. Is there any way to either increase this quota to something like 1e9 files or getting rid of the quota altogether? Note that each of these files are quite small and thus I don't anticipate that I will need more storage space at this time. name ; Hi name, Thanks for reaching out name, Ph.D. Assistant Professor Department of Physics and Astronomy Iowa State University A327 Zaffarano Ames, IA 50010, USA + www.jbsimon.com ""What we think, we become."" - Buddha =================================== On Jul 5, 2023, at 12:04 PM, ACCESS Ticket Submission wrote: ; Hi name, Did you get my response to your email yesterday. I just wanted to make sure. And I am very sorry to rush you, but I do need to push these simulations through as quickly as possible for a collaboration meeting in mid-name. If you didn't get my message, here it is: \\_Hi name,\\_ \\_Sure. So, my current setup asks for 2048 cores. Each core dumps its own data. By the end of one simulation, each core will have about 3000 files in them. There will also be ~60,000 other files (give or take a handful). So, for one simulation, this amounts to about 6.2e6 files per simulation.\\_ \\_In calculating this, I just realized that I don't need anywhere near 1.e9 (I estimated it incorrectly before\ name, Ph.D. Assistant Professor Department of Physics and Astronomy Iowa State University A327 Zaffarano Ames, IA 50010, USA + www.jbsimon.com ""What we think, we become."" - Buddha =================================== On Jul 6, 2023, at 4:45 PM, ACCESS Ticket Submission wrote: ; Hi again, Is there something currently wrong with the scratch filesystem? I am trying to access my directory: $SCRATCH/IMF\\_COLLAPSE/640.per.H/t0.03.a-3.5.z0.06/no.par.del And it's just hanging…. name, Ph.D. Assistant Professor Department of Physics and Astronomy Iowa State University A327 Zaffarano Ames, IA 50010, USA + www.jbsimon.com ""What we think, we become."" - Buddha =================================== On Jul 7, 2023, at 8:56 AM, Automation for Jira wrote: ; I think it may have been a GPFS glitch. I think it got fixed around 5pm Purdue time, could you please give it another try and see if things are back to normal? Thanks, name ; Hi name, I think it's back to normal. Thanks! name, Ph.D. Assistant Professor Department of Physics and Astronomy Iowa State University A327 Zaffarano Ames, IA 50010, USA + www.jbsimon.com ""What we think, we become."" - Buddha =================================== On Jul 7, 2023, at 7:49 PM, ACCESS Ticket Submission wrote: ; Awesome, thanks for confirming! I'll go ahead and tentatively mark the ticket s resolved then, but as always, please reach out if problems persist. name ;",jbsimon,Jake Simon,Nannan Shan,,Anvil,12,6,27,2023,2023-07-03
ATS-1643,How to get access into new supercomputer system for benchmarking projects,2023-07-05,2023-07-05,"Hi, Currently, there is a notice that the TACC stampede2 system will stop functioning from this fall 2023. So for our next year \\*Maximize Access renewal proposal\\* (deadline 15 July), we want to use another supercomputer system like \\*Purdue's Anvil CPU\\* for benchmarking our projects, but I have no idea how to access that system or run code there. Can you help me with this problem? Thank you for your time. ; \\*\\*PRIVATE NOTE\\*\\* Hi Team, I think users have questions about how to get allocations from Anvil. This might fall into allocation application or management? Thanks, name, PhD Sr. Computational Scientist Purdue University ; Hello, I hope your Wednesday is going well. TACC recently found out there will be a Stampede3. We recommend that you remain on Stampede2, and you can move to Stampede3 when it becomes available. TACC is expecting there will be very little or no downtime for the transition from Stampede2 to Stampede3. Let us know if you have any questions along the way. If you have any questions in the future, please visit this site (https://access-ci.atlassian.net/servicedesk/customer/portal/2): https://access-ci.atlassian.net/servicedesk/customer/portal/2) and submit a ticket. name Pusateri ACCESS Allocations ; Hi, Currently we are preparing the proposal with benchmarking on Stampede2 and plan to move on Stampede3 when it becomes available. But I heard that Stampede3 will be a much smaller system than Stampede2 and we fear that the SUs we get might be less and waiting times of job might get too long in stampede3 (it's already long in Stampede2). That's why I wanted to test other supercomputer systems (like \\*Anvil\\*) and see whether it will be a good choice for our projects. And If it is, we might move some of the projects in there (Anvil) which will reduce the workload pressure on stampede3. So, can you give me an idea/outline as to what needs to be done to get access and run codes in Anvil? Thank you for your time. ; Hello, I hope your Thursday is going well. If you would like to test out the Anvil resource, you can submit a Supplement to get SUs on Anvil to test it out. When you submit the Supplement, please add a Progress Report. The Progress Report should describe how the PI's current allocation was used and summarize the findings or results. Follow these steps to submit a Supplement: Starting at the ACCESS Home Page \\* Login to ACCESS: https://allocations.access-ci.org: https://allocations.access-ci.org/ \\* Once on the ACCESS Allocation page, click on ""Manage Allocations."" \\* Within ""Manage Allocations,"" click on ""Manage My Projects."" Now Starting at the List of Allocation Request Page \\* Go to the List of ACCESS Allocations Requests page: https://allocations.access-ci.org/requests: https://allocations.access-ci.org/requests. \\* There you will see your allocations listed. Look for the Allocation you would like to take action on. You should see a button that says ""Choose New Action."" Click the ""Choose New Action"" button. \\* You should see the option: Supplement. \\* Once we receive this and get it reviewed, you will receive a notification of the reviewer's decision. Let us know if you have any questions along the way. If you have any questions in the future, please visit this site (https://access-ci.atlassian.net/servicedesk/customer/portal/2: https://access-ci.atlassian.net/servicedesk/customer/portal/2|smart-link ) and submit a ticket. name Pusateri ACCESS Allocations ;",topojit@access-ci.org,Topojit Debnath,brandonp,,Anvil,5,1,27,2023,2023-07-03
ATS-1726,Anvil Filesystem issue,2023-07-09,2023-09-07,"Hi, I see that the filesystem of Anvil is not working when I copy a file to a new-created directory. The file I am trying to copy is not a big size. I attached a image of my terminal. It looks like it is in the process but it is not ending. The current directory is /anvil/projects/x-che190065/sry/name/h2o-to-oo/local-pH-neutral/initial-structure-oo-rep-nearby-h2o/0.1V/sg/analysis/ Thanks for your help, Saerom name ; Hi, Thank you for contacting us and reporting the issue. We are seeing some glitches for the Anvil GPFS filesystem which are impacting /anvil/projects and /anvil/scratch folders. Our engineering team is workin g on it and I will get back to you when there is an update. Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi, While our storage team is still working with vendors to locate the root cause and try to fix it, several tweaks have been made to Anvil file system so the performance should be normal at the moment. I will resolve the ticket but further updates will be sent out to Anvil users when this issue gets fixed by the vendors. Best, name ;",stsr@access-ci.org,Saerom Yu,Guangzhen Jin,I do not know the RP,Anvil,4,44,27,2023,2023-07-03
ATS-1758,Anvil filesystem stalls when I try to access some directories/files,2023-07-10,2023-09-07,"I'm using Anvil (Purdue's supercomputer) and I often have issues listing files in a folder (with {{ls}}), seeing the size of a folder (with {{name}}), or evening using {{vim}} to see the file contents. This has happened maybe 5x now and I've only been using it for 10 days. The system seems to stall. I can exit out with {{Cntrl-C}} from {{name}} and {{ls}} but the only way to exit {{vim}} when it stalls is to close a session and {{ssh}} in again, which is very annoying. Can you diagnose / fix this issue? One folder I have this issue is /anvil/scratch/x-samlobo/SARS1/01\\_NPT\\_equilibration ; Hi, Thank you for contacting us and reporting the issue. We are seeing some glitches for the Anvil GPFS filesystem which are impacting /anvil/projects and /anvil/scratch folders. Our engineering team is workin g on it and I will get back to you when there is an update. Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi, While our storage team is still working with vendors to locate the root cause and try to fix it, several tweaks have been made to Anvil file system so the performance should be normal at the moment. I will resolve the ticket but further updates will be sent out to Anvil users when this issue gets fixed by the vendors. Best, name ;",samlobo,Samuel Lobo,Guangzhen Jin,I do not know the RP,Anvil,4,44,28,2023,2023-07-10
ATS-15652,Have no permission to access PROJECT directory,2025-04-09,2025-04-09,"We don't have permission to access our project directory: /anvil/projects/x-mcb130189 ; \\*\\*PRIVATE NOTE\\*\\* Thanks for reporting. Our engineer has worked on the fix, and now it is good to go. Please try it again and let us know if you need more help. https://www.rcac.purdue.edu/index.php/news/7098: https://www.rcac.purdue.edu/index.php/news/7098|smart-link Best, name ;",wding2@access-ci.org,Wubin Ding,Xiao Liu,,Anvil,3,1,15,2025,2025-04-07
ATS-1829,Do not have access to a directory,2023-07-13,2023-08-31,"Hello. I was a part of the Data Mine in a collaboration between Purdue and ASU this spring semester. The project we worked (Molecular Stethoscope) on was extended through the name. I need access to the files and I am not able to get to them. I am attaching a screenshot with the rejected access, where you will be able to see the path to the directory that I need access to. Just in case here is the path: +anvil/projects/tdm/corporate/molecular-stethoscope+ Your help would be really appreciated ; \\*\\*PRIVATE NOTE\\*\\* Couldn't find any user under {{x-tmd-molecular}} unix group. And this folder belongs to that group. $ amie\\_group\\_members x-tmd-molecular All members of X-TMD-MOLECULAR according to ACCESS AMIE: Members on Anvil: Members on Anvil-GPU: ; Hi, It appears that you are a member of the project in question. However, we have seen some issues with TDM subgroup file access through the OnDemand file browser. Can you try accessing the files through a desktop session in OOD, or via Globus, or really any way other than the web interface? I believe the issue may be limited to that one method. Thanks, -name ; Hello, Thank you for your response\ Filip Krastev ; We believe this issue is now resolved even for the OnDemand file management interface. Let us know if you are still seeing issues with this. Thanks, -name ;",fkrastev@asu.edu,Filip Krastev,Kevin Colby,Purdue University,Anvil,6,36,28,2023,2023-07-10
ATS-1834,Purdue Anvil Job Composer Error,2023-07-13,2023-07-17,"Hi, I was using my ACCESS allocation on the Purdue Anvil machine this week when, around 3pm EDT on Tuesday, the Anvil machine failed (or my access to it failed). I can log in through the dashboard, but when I access the Job Composer through the dashboard link, it shows the linked error message When I use Anvil Shell Access from the dashboard, it allows me to navigate but not modify files. I checked the outages page (https://www.rcac.purdue.edu/news/outages-and-maintenance: https://www.rcac.purdue.edu/news/outages-and-maintenance|smart-link) and didn't see anything about this today, yesterday, or Tuesday, unless the Fortress maintenance downcycle started 17 hours earlier than scheduled and also interrupted the job composer. If this isn't caused by an outage, is there something I've done on my end to cause my job composer and shell access to crash? If it is caused by an outage, why is it not listed on the outages page and when can I expect it to be usable again? I contacted : mailto: about this issue yesterday morning, approximately 25hrs ago, and have yet to receive any reply. ; Hi name, It might be because your home directory is 100% full: $ myquota x-ddickson Type Location Size Limit Use Files Limit Use home x-ddickson 25.3GB 25.0GB 101% - - - scratch anvil -108544KB 100.0TB -0% 0k 1,000k 0.01% projects x-phy230080 0KB 5.0TB 0% 0k 1,048k 0.00% You can remove some files from your home directory and see if it works. Best, name ; Ah! Thank you! I didn't think to check that ;",x-ddickson@access-ci.org,David Dickson,Yang Hong,Purdue University,Anvil,4,3,28,2023,2023-07-10
ATS-1844,Strange error: Binding more processes than CPUs,2023-07-13,2023-08-01,"I submitted a job to run a short MD simulation. I've submitted about 10 successful simulations on Anvil using this same procedure and submission file. However this time I get the following in my error file: ""A request was made to bind to that would result in binding more processes than cpus on a resource: Bind to: CORE Node: a004 #processes: 2 #cpus: 1 You can override this protection by adding the ""overload-allowed"" option to your binding directive."" Why is the cause of this? Do I need to add something new to my submission file? I'm submitting to the 'shared' queue. ; Hi name, Thanks for reaching out! Would you like to share you job ID, so I can check this job? Cheers, name, PhD Sr. Computational Scientist Purdue University ;",samlobo,Samuel Lobo,Nannan Shan,Purdue University,Anvil,2,14,28,2023,2023-07-10
ATS-6086,Need to setup Anvil S3 storage.,2024-02-12,2024-02-21,"Greetings, Could you please set up S3 storage for the namespace axin-hub on Anvil? We will use it for the Triton server deployment. ; Hi name, there is an issue with provisioning new users in the Anvil S3 storage. Sam is looking into it and hopes to have it resolved in the next day or so. If you need immediate access to S3 storage we can provision you keys for the RCAC object storage instead. Let me know. -name ; Hi name, I could wait for it to be resolved. Thanks! ; Hi name, I got the issue resolved and have sent you the new S3 keys via filelocker. Let me know if you run into any problems. - Sam ;",nujwoo@access-ci.org,Shin Jaewoo,Erik Gough,Purdue University,Anvil,4,8,7,2024,2024-02-12
ATS-1849,Re: ATS-1844 Strange error: Binding more processes than CPUs,2023-07-14,2023-08-31,"2247387 is one of the failed jobs. Thank you ~accountid:id ; Hi name, Thanks for reaching out! Somehow your tickets was slipped from the normal routing process and got to our queue until a few days ago. Sorry about the delay. About your question, we need to run tests and see if we could re-produce the errors and find some workarounds here. Would you mind to share input files for us to test? Cheers, name, PhD (She/Her) Sr. Computational Scientist ;",,,Nannan Shan,Purdue University,Anvil,5,35,28,2023,2023-07-10
ATS-1874,Requesting multiple high-memory node access on Anvil,2023-07-17,2023-08-14,"Hello Anvil support, I reached out in April and was granted access to multiple high-memory nodes for a single job (ticket ATS-184). That access was incredibly helpful to my research and I was hoping I could again utilize this resource. I see that the high-memory node partition currently has 28 idle nodes. If I could gain access to 16 of these nodes again for a high-resolution multiphase fluid dynamics simulation, it would greatly aid my research. I appreciate the time and effort you put into my previous request and your consideration of this request. I look forward to hearing back. Thank you, Brendan Christensen ; Hi Brendan, Thanks for reaching out! Based on the current Anvil traffic, we think it should be okay to create a special queue for you, like we did previously. How long do you think you need for this job? Do you think the 48h walltime for single job is still okay for you? Cheers, name, PhD Sr. Computational Scientist Purdue University ; Hi name, Thank you so much for getting back to me so quickly! 14 days would be perfect if that is possible. And 48hr walltime works well again. Could we plan to start the queue tomorrow so I have just a little time to get things set up? Thanks, Brendan ---- ; Hi name, If we could start the allocation on Wednesday, that would actually work better. Thank you, Brendan ---- ; Hi Brendan, The queue has been created. Would you like to try to submit jobs with {{-q wide-highmem}} in your submit script? Let me know if this did not work for you. Cheers, name ; Hi name, I got the error: sbatch: error: QOSMaxCpuPerJobLimitsbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits) I seem to remember this error previously. You said it was a problem with where the limit is defined. I can send my batch script if you need it. Thanks for getting this set up and working with me. Cheers, Brendan ---- ; Hi name, I just wanted to follow up on this email. Do you need anything else from me to help figure out what the problem with this queue is? Thank you, Brendan ---- ; Hi Brendan, Sorry for the delay. I am on the conference at Portland right now. I think I setup something wrong for this specific queue. Let me talk to the experts in our group and find a way to correct it. Thanks, name ; Hi Brendan, I am looking into this request, Would you mind sending the submission script that is causing this error? Kind regards, name ; Hello name, Thank you for getting back to me. Here is the sbatch script I used: #!/bin/bash #SBATCH -A mch220029 # specify the account to use #SBATCH --job-name=diesel\\_huge # job name #SBATCH -q wide-highmem #SBATCH -p highmem # queue partition to run the job in #SBATCH --nodes=16 # number of nodes to allocate #SBATCH --ntasks=2048 # CHANGE THIS number of descrete tasks - keep at one except for #SBATCH --time=2-00:00:00 # Maximum job run time #SBATCH --mem=1000G # Memory per node #SBATCH --output=anvil-%j.out #SBATCH --error=anvil-%j.err #SBATCH --mail-user= #SBATCH --mail-type=all echo Starting init\\_flow mpiexec -np 2048 ~/name\\_ms\\_ehd/bin/init\\_flow input > init\\_flow.out echo Starting arts mpiexec -np 2048 ~/name\\_ms\\_ehd/bin/arts input > name.out Thanks, Brendan ---- ; Hello Brendan, Thanks for providing that to me! I believe I have identified what was going wrong, and it should now work for you. Could you please give it another try and let me know the result? Kind regards, name ; Hi name, I am now getting this error message: sbatch: error: CPU count per node can not be satisfied sbatch: error: Batch job submission failed: Requested node configuration is not available Thank you for working with me on this. Brendan ---- ; Hi Brendan, Could you please remove the #SBATCH --mem=1000G"" line from the jobscript and let me know what happens? Kind regards, name ; Hi name, It looks like it is working. I am still running into errors, but I think they are on my end. I can let you know when I get it running fully. Thank you for your help with this. Brendan ---- ; Hi Brendan, I am happy to hear that it's working. The issue you encountered with respect to the memory request is because technically the nodes give just under 1 TB of memory to reserve some for the OS. If you just request a certain number of tasks you will be given memory proportional to your request, and this memory will be the maximum. Kind regards, name ; Hello Anvil support, Thank you for working with me on setting up this special partition. I am running into unforeseen problems with my program, and I do not want to use all of my allocations to troubleshoot. I think it will take some time to work out, so you can close the wide high-mem queue now. I will likely reach out at a later date to request this again. I understand access to this special queue will depend on availability at that time and is not guaranteed. Again, I appreciate your time and support on this project. Thank you, Brendan ---- ;",bchristensen,Brendan Christensen,Nannan Shan,,Anvil,16,21,29,2023,2023-07-17
ATS-1882,Compiling a custom version of PETSc on Anvil,2023-07-17,2023-08-29,"Dear Anvil Support, My group and I use an in-house parallel CFD code that relies heavily on a specific version of PETSc, version 3.4.5. Originally, our code was written and used on intel17 compilers. We've recently been able to get everything up and running on CU Boulder's Alpine (intel22), and now that we're moving to Anvil I'm working on compiling our version of PETSc against Anvil's intel19 compilers. I have my former installer script from Alpine (install\\_alpine.sh) as well as my current draft of an installer script for Anvil (install\\_ANVIL.sh) located in /anvil/projects/x-phy230057/software/lib\\_src/petsc-3.4.5 and I'd like to ask if someone could take a look at this draft with me and advise me on how to set the variables for Anvil. I'd be very appreciative if someone would be willing to have a short Zoom chat with me so I could thoroughly understand the solution, but I'm also more than happy to communicate via email. Thank you in advance for your time and help name ; Hi name, Let's schedule a Microsoft Teams call to discuss your questions. I am available on Thursday morning this week. Let me know if this works for you or we can find a time next week. Cheers, name ; Hi name, Yes ; Hi name, I sent a Teams link to you. Talk to you tomorrow. Cheers, name ; Hi name, Just want to check if everything works out. Are we good to close this ticket? Cheers, name ; Hi name, Thanks for checking in, I was actually just about to email you. It looks like there were no error messages related to Anvil's modules (MPI or Python) so the sbatch job (2582935) ran its full course; however, the configuration failed apparently due to some settings/flags set in the install script. I've been trying to make sense of the output file but I'm not really sure what it means. The output file is slurm-2582935.out located in /anvil/projects/x-phy230057/software/lib\\_src/petsc-3.4.5 , what do you think of this? ; Hi name, I just wanted to touch base and see if you might have any insights as to why the PETSc configuration failed? Thanks for your help! ; Hi name, It looks the error related to the fftw library. On the install\\_ANVIL.sh file, it downloads the fftw, can we just use the fftw module on Anvil instead of downloading? I am not sure if fftw is required for PETSc installation. Hope this helps, name ;",adha3409,Adam Harris,Nannan Shan,Purdue University,Anvil,15,32,29,2023,2023-07-17
ATS-1884,out of memory when using VASP on Anvil,2023-07-18,2023-08-01,"Hi, I am running VASP on ANVIL. However, almost all my jobs stop after a short time (but the job looks still running on the node until requested time end) and gives the followings error: ""srun: error: a789: task 16: Out Of Memory"". Although my jobs do not need big memory, I also tried to increase number of nodes; but it did not work. For an example job, you can check the files at the location: ""/anvil/scratch/x-mgsensoy/ti4o7/doping/name/O-int/conf5"". I would be happy if you help me to solve this issue. Sincerely, ; ^job.slurm ^myjob.e2235736 ; Hi name, Thanks for reaching out! Would you like to share your job ID for failed job? Thanks! Cheers, name, PhD Sr. Computational Scientist Purdue University ; Hi name, Thanks for the quick reply. Actually, I have seen the error message for all my jobs. But, you can check the job ID 2235736, and I am also sharing the job error file. Best Wishes name ^myjob (d0ba6d59-4ce3-4763-a7e6-4fbfd8561615).e2235736 \\_(0.0 kB)\\_ ; Hi name, For job 2235736, it was running for 30 name as you requested and aborted after time-out. I did not see any problem with this. You can let the job run longer time to avoid TIMEOUT message. jobinfo 2235736 Name : O-int/name/conf5 User : x-mgsensoy Account : che220049 Partition : wholenode Nodes : a776,778 Cores : 256 GPUs : 0 State : CANCELLED,TIMEOUT,OUT\\_OF\\_MEMORY ExitCode : 0:0 Submit : 2023-07-12T03:33:43 Start : 2023-07-12T03:33:43 End : 2023-07-12T04:03:59 Waited : 00:00:00 Reserved walltime : 00:30:00 Used walltime : 00:30:14 Used CPU time : 5-07:17:43 % User (Computation): 99.09% % System (I/O) : 0.91% Mem reserved : 491040M Max Mem used : 2.46G (a776) Max Disk Write : 7.30M (a776) Max Disk Read : 13.44M (a776) Cheers, name ; Hi name, Thank you for your reply. You are right, you can not see anything when you look at the information that you see and share with me. However, this simulation on VASP stopped working after 5 minutes, but the job kept running on the node until requested time ended. When I carefully checked the slurm 'stderr error file', I saw an error like ""out of memory"" 5 minutes later. FYI, it has been seen many times in other jobs. May it be because of compiling issue in VASP? Thank you Gokhan ; Hi Gokhan, Thanks for the information. Well, I do not think there are problems with VASP compilation on Anvil because no users reported any issues since we compiled it on Anvil. I would recommend to double check your INCAR for each tag. You can start with a small job and see if it can run. If small jobs could run, which means some setup for large jobs needs to be changed. Cheers, name ; Hi name, Thanks for the advice. I will check my jobs with different combinations. Have a nice day Gokhan ;",mgsensoy,Mehmet Sensoy,Nannan Shan,Purdue University,Anvil,8,11,29,2023,2023-07-17
ATS-1885,Reproducible routing errors on Anvil back-end nodes,2023-07-18,2023-08-01,"Hi all, I'd noticed serious issues when trying to do certain network operations on Anvil back-end nodes and have found a way reproduce it. I am unable to reproduce the same problem on front-end nodes, which don't use Infiniband on their default route, and don't use 1 to 1 NAT. To see the problem, connect to an anvil back-end node and run: while true; do nc -N -v retool.the-examples-book.com: http://retool.the-examples-book.com 443 < /dev/null ; date; sleep 0.3; done You'll see something like: a020.anvil ~ $ while true; do nc -N -v retool.the-examples-book.com: http://retool.the-examples-book.com 443 < /dev/null ; date; sleep 0.3; done Connection to retool.the-examples-book.com: http://retool.the-examples-book.com (3.14.187.131) 443 port tcp/https] succeeded Again, I wonder if network issues could be causing/contributing to the ongoing GPFS issues. Regards, Doug ; Hi again name, FYI, I saw name in passing today and he said they resolved the network issue yesterday, which explains why it started working again ^\\_^ Cheers, name ;",dgc,Doug Crabill,Nannan Shan,Purdue University,Anvil,5,11,29,2023,2023-07-17
ATS-1894,Loading Needed Anvil Modules,2023-07-18,2023-08-15,"I am currently trying to compile and run the hydrodynamical code ENZO on Anvil. I have successfully compiled and ran it on Stampede2 with the following modules loaded: # git/2.24.1 3) cmake/3.26.3 5) TACC 7) intel/17.0.4 9) python2/2.7.14 # autotools/1.1 4) xalt/2.10.37 6) libfabric/1.7.0 8) mvapich2/2.3.4 10) hdf5/1.8.16 Some of these are just intrinsic to Stampede2. I did need these versions of intel, python, mvapich2, and hdf5 to run the Enzo code. I've tried to simply load these into Anvil, which does not work. Is it possible to be able to load in these older versions of the intel, hdf5, mvapich2 and python onto Anvil? ; Hi name, Thank you for contacting us! Which version of Enzo you are trying to install? I checked the 2.6 version documentation. It looks like the dependency library versions are not restricted to specific versions. Have you tried compiling it with our current version modules? Also, different from Stampede2, Anvil is a GCC cluster, you may also try to install it with GCC compiler. Best, name ; Hi name, Thank you for the response. The version of Enzo I am using is older (I believe v. 2.5). I know in particular it uses mercurial to compile, which at least on Stampede requires a python2 module to be loaded in. This in turn is what made the older versions of the other modules necessary. I'm not sure if there is a different workaround that wouldn't require the older modules. I can try again to compile on Anvil but I don't think it will work without the older python module. Best, name ; Hi name, I am not sure if it is possible to install python2 with conda, something like: conda create -n xxx python=2.XX And then add that to {{$PATH}} and/or {{$PYTHONPATH}} Or can you please try installing the newer version of Enzo? Usually, the newer version will be compatible with most of input files from the old version, so your old workflow may not need to change much. Best, name ; Hello, I managed to get the version of Enzo to compile. The newer modules worked fine. I just had to create a python2 environment, as you described above. I am still not managing to submit the job successfully. My submission fails. Is this something I need to submit another help request for, or are you able to help me further with that. If you are, what would be the easiest way to share the issue? The new submission script (enzo\\_cont.sh) and the old stampede one (enzocont\\_stampede.sh) are both located in the following directory:/anvil/scratch/x-jsullivan1/EnzoRunJul17. Thank you for all your help, name ; Have not received response and want to make sure this hasn't been lost. ; Hi name, Since name left our site, I'd take this ticket. It seems you have another ticket with us, https://access-ci.atlassian.net/browse/ATS-1960: https://access-ci.atlassian.net/browse/ATS-1960|smart-link, I assume you are referring the same questions, if so, I'd like to close this ticket (ATS-1894) and keep all the communications in one place. Let's discuss your questions on https://access-ci.atlassian.net/browse/ATS-1960: https://access-ci.atlassian.net/browse/ATS-1960|smart-link. Cheers, name, PhD (She/Her) Sr. Computational Scientist ;",jsullivan1,James Sullivan,Nannan Shan,Purdue University,Anvil,7,21,29,2023,2023-07-17
ATS-1900,Namd2 job failure,2023-07-18,2023-08-01,"Hello, Recently, several namd2 jobs submitted to Anvil failed because of the reason captured in the attached screenshot, and I would much appreciate your kind assistance in this regard. Thank you ; Hi name, Thanks for reporting this to us. I am guessing this error is related to our recent network failure on Anvil. It should be fixed yesterday. Please keep track your job status and let us know if the situation consistent. Thank you! Cheers, name, PhD Sr. Computational Scientist Purdue University ;",lakshani123@access-ci.org,Rasanjali Ranawaka,Nannan Shan,Purdue University,Anvil,3,11,29,2023,2023-07-17
ATS-1901,"When I submit I a simulation, it give me an error like this",2023-07-18,2023-08-01,"Hi there, I was trying to run a simulation on Anvil. It give me an error like this. I have received the info for the limitation on the https://www.rcac.purdue.edu/knowledge/anvil/run/partitions: https://www.rcac.purdue.edu/knowledge/anvil/run/partitions|smart-link I checked my sbatch file. I think they are follow the rules on that website. It also work as one of my college using it successfully before. Could you please give me some hint on how to deal with issue like this? I appreciate it your help ; Hi Winona, Thanks for reaching out Best, Aojia (I forgot to change my name when submitted the ticket.) ---- ; Hi Aojia, From the submit script, I saw you are submitting jobs to {{-A x-mch220004}}. This allocation is inactive on Anvil. You have another active allocation, {{x-cts200043}}, for your jobs. Account name should include {{x-}}. Hope this helps, name ;",winona@access-ci.org,Winona Snapp-Childs,Nannan Shan,Purdue University,Anvil,5,11,29,2023,2023-07-17
ATS-1903,Didn't find a proper place to submit the final report ,2023-07-18,2023-07-20,"Hi, I was trying to submit a final report but didn't find a proper way to do that. The only thing I found is to submit the report through a ""SUPPLEMENT"" option. However, it seems that the system thinks I'm asking for more allocation and saying the 'request is declined'. So I wonder if you can provide a way to submit the final report properly. Note: the allocation number is MCH220028CH22002 ; Hello, I hope your Wednesday is going well. You do not need to submit a final report to move on to the next ACCESS Opportunity. This is how the Allocations Team recommends moving forward: You should first use up all of your ACCESS Credits. You have used up all your ACCESS Credits, so you do not need to worry about that. Next, you should try to use up all your SUs on the current Explore Allocation because they do not carry over to the Discover Renewal Allocation. Once you use up about 90% of your Allocation, please reply to this ticket, and we can give further details on moving up to the next ACCESS Opportunity. If you want to move up now, please let us know, and we can start the graduation process. PLEASE REMEMBER SUs DO NOT GET CARRIED OVER TO THE NEW ALLOCATION. Let us know if you have any questions along the way. If you have any questions in the future, please visit this site (https://access-ci.atlassian.net/servicedesk/customer/portal/2): https://access-ci.atlassian.net/servicedesk/customer/portal/2) and submit a ticket. name Pusateri ACCESS Allocations ; Hi name, Thank you so much for your reply. I think maybe my supplement material confuse the reviewer. I was trying to submit a final report, serving as a record to show what research progress have been made with the ACCESS allocation. I did not find a proper place to upload the document, so I have to choose 'supplement' option, I guess that made the reviewer think I'm asking for more resource. I have used up 90% of my allocation, but I think I don't need more for now. So if a final report is not necessary, then you can close this ticket. Thank you so much! Best, Yongkai On Jul 19, 2023, at 8:07 PM, ACCESS Ticket Submission : mailto: wrote: |---- \\*External Email\\*: Use caution with attachments, links, or sharing data ---- | ;",x-chen1305,Yongkai Chen,brandonp,Purdue University,Anvil,3,3,29,2023,2023-07-17
ATS-1912,Access to VASP in Anvil HPC,2023-07-19,2023-08-31,"I'm writing to request the permission to use VASP in ANVIL HPC. In my last Ticket \\*ATS-1793\\*, I have forwarded the request to Materials Design and got the permission check from them. Can you please check that Ticket for my permission? The VASP related email is : mailto: for name, and : mailto: for Xiuwen name. Thank you. ; Here is the reply from Materials Design: ---- Dear name, Our records show the following people on name Zunger's VASP license: |First Name|Last Name|Email|VASP Source| |name|Zunger|: mailto:|Licensee| |Xingang|name|: mailto:|User| |name|: mailto:|User| |Xiuwen|name|: mailto:|User| |name|: mailto:|User| From your message, I see that you only listed yourself and Xiuwen. Should I keep or remove Xingang and name from the license? Best, name Tow, PhD Support and Application Scientist MATERIALS DESIGN, INC. 12121 Scripps Summit Drive Suite 160 San name, CA 92131 www.materialsdesign.com: https://nam10.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.materialsdesign.com%2F&data=05%7C01%7Cjia-name%40colorado.edu%7Cf6d309c5f36d4ce1e21608db87ba94f9%7C3ded8b1b070d462982e4c0b019f46057%7C1%7C0%7C638253007655498404%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=jC%2BdZIrciRm35w1wFlxz2bj54OGNXfvFtrqe69U%2F2PQ%3D&reserved=0 Schedule a meeting: https://calendly.com/gtow: https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F%2Fcalendly.com%2Fgtow&data=05%7C01%7Cjia-name%40colorado.edu%7Cf6d309c5f36d4ce1e21608db87ba94f9%7C3ded8b1b070d462982e4c0b019f46057%7C1%7C0%7C638253007655498404%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=Jqjkb6ndkod1V8rXrvUrRrDJqx0Q6hwozO3WVtnBq%2Bw%3D&reserved=0 -- MedeA 3.7 — ""Material Performance Can you confirm the email address is correct? Also, do you also want to add other people to Anvil as well, for instance, Xiuwen name? Cheers, name ; Another email, : mailto:, does not work as well. ; Hi name, I forwarded this email to Mr. name Tow at Materials Design support to check my information again. My email address has updated from the mistake """" to the correct one """". Dear name, could you please check my VASP license for name at ACCESS Anvil HPC support? Thank you. Best, name ---- ; Hi name, Thank you. We need to verify your license on our end as well. Please share your correct email address associated with a valid VASP license in this manner. To add users to VASP license, the holder of VASP license needs to login VASP portal to manage the members. Cheers, name ; Dear name, Thanks. Let me ask my supervisor professor name Zunger and then reply to you. Best, name ---- ; Hi name, Did you get something from your professor about the license? Should we keep this ticket open? Cheers, name ; Hi name, Thanks for asking. My professor is busy and did not give me response on the license yet. Is the license document a PDF or picture which can only be obtained by my professor by logging into the VASP portal? We wonder whether the system of VASP license in Anvil is another independent system which is different from that in Materials Design, because we have been confirmed by them that we are already in their VASP license system. Actually that's the way (confirming by Materials Design) we get the usage permission of VASP in other HPC such as NERSC. Best, name ---- ; Hi name, Thanks for the updates. I believe NERSC would require a confirmation email from VASP license team to verify the license, at least that is what I did while I was using NERSC before. We did something different here. You just need to tell us your email associated with your license. We do not need snapshot or pdf thing, we need \\*YOUR\\* email, which you used under the VASP license. To be clear, this is the VASP I am thinking of https://vasp.at/: https://vasp.at/|smart-link Cheers, name ; Hi name, Thank you for the explanation. My email with VASP license is . It was mistaken to be but has now been corrected. This information with corrected email with VASP license is confirmed by the VASP team, Materials Design. Best, name ---- \\*发件人:\\* ACCESS Ticket Submission \\*发送时间:\\* Wednesday, July 26, 2023 6:31:59 PM \\*收件人:\\* name \\*主题:\\* ATS-1912 Access to VASP in Anvil HPC ; Hi name, I still cannot find you on VASP data base, check the attached snapshot. I am not sure what happened here. You can email vasp license group with this snapshot and ask them what is going on with your license. Again, I need to verify you before I added you into VASP groups on Anvil. Regards, name ; Thanks for checking and sending me the snapshot, name. I'm forwarding your feedback to Mr. name at Materials Design Support. Dear name, sorry to bother you again. But as you can see the previous feedback from name at ACCESS Anvil HPC Support, she cannot find me on the VASP database as shown in the snapshot. Do you have any ideas why this could happen? Can you kindly help me figure this out? Thank you very much. Best regards, name ---- ; Dear name, Thank you very much. Let's see if name can find the updated information in the VASP database or whether we need other qualification proofs. Best, name ---- ; I confirm that dr name from my group should be on the list of Vasp users from my group as soon as possible or earlier. Thank you ---- ; Hi name, Any updates for this? Should we keep this ticket open? Cheers, name ; Hi name, I assume you were advancing this issue since you can see from the previous reply forward to you from both my supervisor professor name Zunger and Mr. Garatte from Materials Design to confirm my license qualification. Especially, Mr Garatte provides the link https://calendly.com/gtow: https://calendly.com/gtow for you to arrange a online meeting with him for the any further confirmation you might need. I'm not sure what update you still need from my side. I understand I may not be on the list of VASP portal and only on the list of Materials Design. But since both Materials Design and my professor confirmed my qualification, I should have been added to the VASP portal list. May I ask if you have that access? Sincerely, name ---- ; Hi Garette, Thank you very much. I'm forwarding your email to name, could you please check this confirmation from Mr. Garette from Materials Design? For the previous email confirming by Mr. Garette, if you didn't receive it, I can also forward it to you. Thanks. Best, name ---- ; Hi name, Thanks for sharing the information. I do not think I received Mr. Garette's message about the license or about the meeting. However, I would like to reiterate our policy for Anvil VASP users. \\*We need to confirm your license status through VASP portal because VASP license team REQUIRES us to do so\\*. We cannot grant user access to VASP on Anvil until we verify them over VASP portal. For VASP license, we have agreement with VASP team, and I am not sure how VASP team relates to Material Design BTW. Thanks, name ; Hi name, Mr. name from Materials Design has opened a new Ticket ATS-2185 from his side to make sure the information he sent would not be missed by Anvil Ticket system. There are some misunderstandings he mentioned and I'd like to list them here for your attention: 1. ""The Zunger VASP license records are held by Materials Design and NOT the VASP group.""--This means you cannot find us (name and Xiuwen name) in VASP portal database. 2. ""If name asks the VASP group if Materials Design is indeed a distributor of VASP, they will reply in the affirmative.""--This is an explanation of legal identity of Materials Design for VASP license confirmation. 3. Mr. name also left his phone number and a Microsoft Teams meeting for your communication in his new Ticket. I hope this email can clarify the misunderstandings and push forward the permission process. Sincerely, name ---- ; Hi name, I'm not sure what this is for, but I think you have Cc'd the wrong name. Please let me know if I am misunderstanding something here. Thank you. \\* \\*name Palmer\\*\\* Building Manager \\* \\*Sustainability, Energy and Environment Community\\*\\*: https://seec.colorado.edu/ \\* \\*\\* \\*(SEEC/SEEL)\\*\\* \\* \\*University of Colorado Boulder\\*\\* \\* \\*609 UCB, Room C229\\*\\* \\* \\*Boulder, CO 80309\\*\\* \\* \\*email:\\*\\* \\* \\*\\*\\*: mailto: \\* \\*phone: \\*\\* ; Hi name, Thanks for sharing all the information and previous responses in ATS-2185. I think you are right, the ticket system filtered the previous responses and I did not see them until today. Regarding to VASP license validation, I am following the workflow that VASP team shared with us in their consistent communications. In their guidance, they only mentioned ONE WAY to verify the license, which is through VASP portal. They did not mention other approaches. This morning, I contacted VASP team and ask them to share guidance about how to deal with your situation associated with license from Materials Design, Inc. We would follow all guidances VASP team shared to manage VASP users on our site to avoid any legal arguments. I would let keep you posted about VASP's response about this. Cheers, name ; Hi name, Thanks for your update. Please let Garratt or me know if more action is needed during the process. Best, name ---- ; Hi name, Unfortunately we won't grant users access to Anvil VASP module groups if they are with MedeA workflow from Materials Design. If you want to use VASP on Anvil, you can either compile it on Anvil or work with Materials Design to use MedeA workflow on Anvil. You might want to reference the user guide to compile VASP on Anvil. https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/vasp: https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/vasp|smart-link Hope it helps, name ; Hi name, We need to check whether Professor Zunger's group is with the MedeA workflow of VASP. We never use MedeA but only use VASP. Dear Garatte, do you know whether the VASP that our group is qualified should be with the MedeA workflow? Best, name ---- ; Thanks Steve! Hi name, I just attached what Steve from Materials Design replied in case you couldn't receive it due to the Anvil support system: ""Hi name and name, Your group purchased a perpetual VASP 6 source code license. Therefore, you should be using VASP 6 standalone executables. At all other computer centers, access is granted to the existing VASP executables compiled on those platforms. (Just as it is for customers who purchased VASP directly from VASP GmbH.) Best regards, Steve"" Our group should have the access to VASP standalone without need to be in the MedeA workflow. Sincerely, name ---- ; Hi name, If users are with the license of VASP from Materials Design (either with MedeA or not), we cannot add them into our vasp groups on Anvil. You have to get the source codes of VASP from Materials Design and compile it on Anvil. Feel free to reference our user guide while you try to compile it on Anvil. Let me know if you have questions regarding to the compilation. https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/vasp: https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/vasp|smart-link Thanks, name ; Hi name, The VASP source code from Materials Design, Inc. is identical to that from VASP GmbH - that is where we get it from. However, if you insist on recompiling it that is between you and the end users. MD provide no support for the compilation of VASP source. Best regards, Steve ; Hello Steve, We have been instructed by VASP team not to share our installation unless they are listed on VASP portal. If you have any questions or concerns, please talk to VASP team. Thanks, name ; Hi name, Is the attached email not sufficient authorization? Best regards, Steve ^MD May Authorize VASP Usage.pdf \\_(0.0 kB)\\_ ; Hi Steve, I guess I did not make myself clear. We follow the instructions from VASP team to manage users on our site and currently the instruction said the ONLY way to verify license is from VASP portal. If you have questions about this process, please contact VASP team and ask them to inform us more approaches. Hope this makes sense. name, if you do not have further questions, I would close this ticket. Regards, name ; Hi name, We do not seem to be communicating clearly. I did ask the VASP team and they sent the email attached stating the MD can authorize users of VASP. Why is this not sufficient? Best regards, Steve ^MD May Authorize VASP Usage (8823b23b-0b81-4d43-958c-88f76dba9631).pdf \\_(0.0 kB)\\_ ; Hi Steve, Because VASP team did not tell us to do so. We only take the instructions from VASP team directly. Thanks, name ; Hi name, The email from the VASP group (below) was sent to you at [: mailto:. Did you receive it? Best regards, Steve From: Licensing Sent: Wednesday, name 16, 2023 2:47 AM ;",jxiong1,Jia-Xin Xiong,Nannan Shan,Purdue University,Anvil,36,32,29,2023,2023-07-17
ATS-1930,Need Vasp5 and Vasp6 access,2023-07-20,2023-08-01,"We have vasp6 license and lincense number is 22-0089 ; Hi name, Thanks for reaching out! Can you share your email address associated with this VASP license. We need your email to verify you license. Cheers, name, PhD Sr. Computational Scientist Purdue University ; You have been added to vasp5 and vasp6 groups on Anvil. Your membership will be ready within a few hours. Please check our user guide for VASP calculations on Anvil. Please make sure you also added 'module load hdf5' to your submit script while you use VASP6. https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/vasp: https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/vasp|smart-link Cheers, name ; Thank You sir for providing vasp access. I am trying to run vasp through script given below; I am not sure what should I write in front of \\*FILENAME:\\* and \\*#SBATCH -A myallocation\\* Could you please guide me for that and check the given script is this right or wrong? The script used is given below #!/bin/bash #FILENAME: myjobsubmissionfile #SBATCH -A myallocation # Allocation name #SBATCH --nodes=2 # Total # of nodes #SBATCH --ntasks=256 # Total # of MPI tasks #SBATCH --time=24:30:00 # Total run time limit (hh:mm:ss) #SBATCH -J tscf # Job name #SBATCH -o myjob.o%j # Name of stdout output file #SBATCH -e myjob.e%j # Name of stderr error file #SBATCH -p wholenode # Queue (partition) name #SBATCH --mail-user=: mailto:--mail-user= #SBATCH--mail-type=all # Send email to above address at begin and end of job module purge module load gcc/11.2.0 openmpi/4.0.6 hdf5/1.10.7 module load vasp/5.4.4.pl2 # or module load vasp/6.3.0 module list srun -n $SLURM\\_NTASKS vasp\\_std ; Dear sir, I am waiting for your response. Kindly help me via providing information as aked above.\ Thank You ; Hi name, You do not need to change the #FILENAME line. You can use {{#SBATCH -A x-phy230114}} for your job submission. You can use {{mybalance}} command on Anvil to check your account name. You might want to learn more about how to submit jobs with SLURM. https://slurm.schedmd.com/sbatch.html: https://slurm.schedmd.com/sbatch.html|smart-link Cheers, name ; Thank You ;",skukreti,Sumit Kukreti,Nannan Shan,Purdue University,Anvil,8,9,29,2023,2023-07-17
ATS-1960,Running Batch Job,2023-07-24,2023-08-24,"Cannot successfully run job submission script. Job fails when ran. Seems like there may be issue with accessing the parameter file when running. I also need to initialize conda environment (""py2"") that runs python 2 in order to run the executable. Not sure how to properly do this within slurm submission script. ; Hi name, Thank you for contacting us! May I have your job ID and job submission script? Here is our python user guide: https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/python: https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/python|smart-link It has some examples of creating an active conda environment, installing packages to conda env, and submitting Python jobs. Best, name ; Hi name, My latest submission attempt was ""240090"" which used the below submission script: #!/bin/sh # FILENAME: Enzo\\_AnvilRun #SBATCH -A ast140041 #SBATCH --nodes=2 # The number of nodes to use. #SBATCH --ntasks=64 #SBATCH --time=1:00:00 # The time the job will take to run (here, 1 name) #SBATCH -J jms\\_initrun2 # The job name. #SBATCH -o output\\_amr\\_cont\\_nodebug1.o%j #SBATCH -e error\\_amr\\_cont\\_nodebug1.e%j #SBATCH -p wholenode # Partition name module restore default mpirun ./enzo\\_anvil.exe -r ./DD0012/data0012 # End of script ; Have not received response and want to make sure this hasn't been lost. ; Hi name, Since name left our site, I'd take this ticket. Your submit script looks fine. Can you share the error message when your submit bash jobs? Cheers, name, PhD (She/Her) Sr. Computational Scientist ;",jsullivan1,James Sullivan,Nannan Shan,Purdue University,Anvil,5,24,30,2023,2023-07-24
ATS-1966,Correct groups and permissions in /anvil/projects/tdm/corporate,2023-07-24,2023-08-15,"On ticket ATS-1638 we requested the ability to initiate a groups and permissions correction on the various subdirectories of /anvil/projects/tdm/corporate. If that ticket is completed soon, the following ticket becomes obsolete. It is being requested now since this has become much more timely as we want to archive these directories to Fortress so we can empty them and begin populating them with data for the fall semester. We unfortunately lack permission to read many of the files and thus we can't archive them first/bin/bash TDMBASEDIR=""/anvil/projects/tdm/corporate"" die() { echo ""$\\*. Aborting.""; exit 1; } cd $TDMBASEDIR : | die ""Unable to cd to $TDMBASEDIR"" for D in \\* do # Is this really a directory? If not, skip it if ! -d ""$D"" ; then continue fi # Find the group used on $D GROUP=$(stat --format=%G $D) # Make sure $GROUP exists and begins with ""x-tdm-"". Otherwise skip it if -z ""$GROUP"" -o ""$GROUP"" == ""${GROUP##x-tdm-}"" ; then continue fi # Fix groups of files/directories that are incorrect find $D ! -group $GROUP -print0 : xargs -0 -r echo chgrp -h $GROUP 2>/dev/null # Fix permissions of files find $D -type f ! -perm -0660 -print0 | xargs -0 -r echo chmod ug+rwX 2>/dev/null # Fix permissions of directories, including setgid bit find $D -type d -a ! -perm -2770 -print0 | xargs -0 -r echo chmod ug+rwX,g+s 2>/dev/null done ; [^fixperm.sh ; Hi Doug, Sorry for delays with several of your requests… you probably know about some tumultuous happenings here. Plus the conference that a lot of us are at right now. While we haven't gotten to the global solution yet, I'll be definitely happy to run the one-time fix (and thank you for providing the script!). Quick question: would you like me to also add default ACLs to all subdirectories? find -- ""$D"" -type d -print0 \ | xargs -0 --no-run-if-empty setfacl --set "" d:u::rwX,d:g::rwX,d:o::0"" -- Thanks, name ; Hi name, Thanks name! Sure, if you believe it will help, please add default ACLs! Regards, Doug ; Doug, The script (~name/tmp/fix-tdm.sh) completed in 6400 sec. I was not quite sure, so default ACLs on all sudirectories are set to force 770 rather than 775 (i.e. I applied 'd:u::rwX,d:g::rwX,\\*d:o::0\\*', not 'd:u::rwX,d:g::rwX,\\*d:o::rX\\*'). Let me know if you prefer to change that (looks like most files and sub-subdirectories currently have readable permissions for 'others'). name ; Awesome, thanks name\! 770 was what we wanted, and was the right call! Will there still be an attempt to put something in place to empower us to do this ourselves when the permissions get out of whack, as suggested in ATS-1638? Regards, Doug ---- ;",dgc,Doug Crabill,Nannan Shan,Purdue University,Anvil,6,17,30,2023,2023-07-24
ATS-1973,sbatch: error: Batch job submission failed,2023-07-24,2023-07-25,"While submitting the vasp job I am getting the below error; \\*sbatch: error: Batch job submission failed: Invalid account or account/partition combination specified\\* I have also attached the screenshot. Kindly suggest me to resolve the issue. Thank You ; Hi name, This is a duplicate ticket. Let keep our communication in one ticket, ATS 1930. I would close this ticket. Cheers, name, PhD Sr. Computational Scientist Purdue University ;",skukreti,Sumit Kukreti,Nannan Shan,Purdue University,Anvil,3,2,30,2023,2023-07-24
ATS-2745,Basic Linux Commands Not Working,2023-09-01,2023-09-08,"I am having some issues with basic linux commands. I updated my .bashrc file with some of my own environment variables and then ran source ~/.bashrc to update. After that, I have been unable to run commands, such as ls, nano, emacs, clear, etc. Some of the commands still work, such as cd, echo, and pwd. I am not sure what is causing the issue. ; Hi Sam, Thank you for reaching out! The issue was likely related to the settings of your command search path (the PATH variable). {{cd}}, {{echo}} and {{pwd}} are shell builtins, so they were not affected. If you still have trouble running commands, you may enter {{/usr/bin/nano ~/.bashrc}} to edit your {{~/.bashrc}} file to correct the settings for your PATH variable. If any help is needed, please let me know. Thanks, name ; Hi Sam, Since I have not heard back from you in a while, I'm assuming this ticket can be marked as resolved. If you have any questions, please feel free to contact us again. Thanks, name ;",skilduff@access-ci.org,Sam Kilduff,Ruyi Li,Purdue University,Anvil,3,6,35,2023,2023-08-28
ATS-1974,Gaussian Software on Anvil,2023-07-24,2023-08-01,"Hello, Is there way to run Gaussian jobs on Anvil? In our previous ACCESS allocation, we had access to Gaussian on TACC Stampede 2. Since our allocation has moved to Anvil. I was wondering if Anvil also has a license for Gaussian. Thank you so much! Regards, Pritam ; Hi Pritam, Thanks for reaching out! Unfortunately we do not have Gaussian on Anvil right now due to the license restriction. Cheers, name, PhD Sr. Computational Scientist Purdue University ; Hi Pritam, Just want to correct my previous response. Since on Anvil, we do not have Gaussian, if you need to run Gaussian, we would recommend to transfer some credits to Expanse, which has Gaussian available. You can ask Joan-name Shea (the PI for MCA05S027) to submit a supplement to get some allocation time from Expanse. Here are the steps to submit a Supplement: Starting at the ACCESS Home Page Login to ACCESS: https://allocations.access-ci.org: https://allocations.access-ci.org|smart-link Once on the ACCESS Allocation page, click on ""Manage Allocations."" Within ""Manage Allocations,"" click on ""Manage My Projects."" Now Starting at the List of Allocation Request Page Go to the List of ACCESS Allocations Requests page: https://allocations.access-ci.org/requests.: https://allocations.access-ci.org/requests. There you will see your allocations listed. Look for the Allocation you would like to take action on. You should see a button that says ""Choose New Action."" Click the ""Choose New Action"" button. You should see the option: Supplement. Once we receive this and get it reviewed, you will receive a notification of the reviewer's decision. Hope this helps, name ;",pganguly,Pritam Ganguly,Nannan Shan,Purdue University,Anvil,3,7,30,2023,2023-07-24
ATS-2005,Purdue Anvil Login,2023-07-26,2023-08-01,"Hi, I'm trying to login to Anvil to access our award MCH220017. I'm following https://www.rcac.purdue.edu/knowledge/anvil/access/login: https://www.rcac.purdue.edu/knowledge/anvil/access/login|smart-link and attempting to login with: ssh : mailto: but I'm thinking there might be another method that is preferred, since my access password does not work. Can you please let me know the best way to logon? Thanks, name Keeton ; Hi name, Thanks for reaching out! Welcome to Anvil. Yeah, we do not have Anvil password. If you check the ssh page you shared, there is a reminder said, you can use ssh command only after you set up the ssh keys. Have you set up the ssh keys successfully? If you have not, please use Open Ondemand to login and set up the ssh keys. Here is the user guide for Ondemand. https://www.rcac.purdue.edu/knowledge/anvil/access/login/ood: https://www.rcac.purdue.edu/knowledge/anvil/access/login/ood|smart-link Please follow this page to set up your ssh keys. https://www.rcac.purdue.edu/knowledge/anvil/access/login/sshkeys: https://www.rcac.purdue.edu/knowledge/anvil/access/login/sshkeys|smart-link Hope this helps, name, PhD Sr. Computational Scientist Purdue University ;",bkeeton,Ben Keeton,Nannan Shan,Purdue University,Anvil,2,5,30,2023,2023-07-24
ATS-2006,sbatch: error: Invalid directive found in batch script,2023-07-26,2023-08-11,"I was trying to submit my calculation jobs to the Anvil, however, the system keeps tell me: sbatch: error: Invalid directive found in batch script: error or sbatch: error: Invalid directive found in batch script: 1 I don't know where goes wrong. What is the meaning of these two returns? ; Hi Hongzheng, The error message you're seeing suggests that there's an invalid directive or command in your SLURM batch script. In a SLURM batch script, directives are provided as comments to the shell and they are identified by #SBATCH at the beginning of the line. Any directive that SLURM does not recognize will result in an error like the one you've encountered. Here's an example of what an MPI SLURM batch script might look like: https://www.rcac.purdue.edu/knowledge/anvil/run/examples/slurm/mpi: https://www.rcac.purdue.edu/knowledge/anvil/run/examples/slurm/mpi|smart-link In this script, --job-name, --output, --time, --nodes, and --ntasks are all valid SLURM directives. If you used a directive that SLURM doesn't recognize, you would see the error message you reported. To solve the issue, you should check your SLURM batch script and make sure that all directives are valid. Best, name ; Hello, It has been a while since last time we hear from you. This ticket would be tentatively marked as resolved. Feel free to submit a new ticket to Anvil Help Desk: https://support.access-ci.org/user/login?destination=/open-a-ticket if you have questions in the future. Thanks! ;",hqu1,Hongzheng Qu,Nannan Shan,Purdue University,Anvil,3,13,30,2023,2023-07-24
ATS-2028,Anvil Directory Snapshots Question,2023-07-28,2023-08-08,"Hello RCAC Team, I submitted ticket 1931634 to ask about excluding Anvil directories from snapshots. We have a corporate partner who requires a dataset be deleted 90 days after the end of the usage period. This would include snapshots. I was updated that the monthly snapshots are only maintained for two months. However, when I happened to be doing some checking on Anvil I found that the ""anvil/projects/tdm/corporate/sandia"" shows snapshots from 8 months ago. I wanted to double check and confirm that the snapshots would be removed within the 90 day time frame that would be required by our corporate partner. This is a future planning item. So we don't have any data that we need to delete on Anvil currently. 🙂 Thank you, name (he/him) ; Hi name, Yes the full scheduled snapshots for /anvil/projects space are supposed to keeps nightly snapshots for 7 days, name snapshots for 3 weeks, and monthly snapshots for 2 months in theory. But I saw the same old snapshots as you mentioned (dates back to 2022.12.01). I believe there might be some glitches for snapshots. Let me report this to our storage team and get back to you when I heard back from them. Meantime, we can help on manually deleting snapshots as requested to ensure the requirements can be satisfied from your corporate partners. Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi name, Thank you for the follow up name (he/him) The Data Mine - Managing Director of Data Science Schedule a meeting with me via Calendly: https://calendly.com/dglass-tdm/30min ; Hey name, Our storage team has located this issue and is working on it. So hopefully it would be resolved soon (before next name). I will give you updates when I heard back from them. Best, name ; Hi name, I think the snapshots issue have been solved for /anvil/projects. We have rebuilt the snapshots from Aug 2nd. Please check and let me know if there is further issue. If not, I will intend to close this ticket. Best, name ; Hi name, Thank you for the work to update the snapshots name (he/him) The Data Mine - Managing Director of Data Science Schedule a meeting with me via Calendly: https://calendly.com/dglass-tdm/30min ; Hi name, Thank you for the update! Will close this ticket. Best, name ;",x-dgi804,David Glass,Guangzhen Jin,Purdue University,Anvil,7,8,30,2023,2023-07-24
ATS-2031,Issue of installing BerkeleyGW on Anvil,2023-07-28,2023-09-01,"Hi, Recently, I tried to install BerkeleyGW software on Anvil. I tried to change the variables in arch.mk: http://arch.mk to install it, but always get failed. Could you help me with that issue and send me a correct arch.mk: http://arch.mk? Thank you for taking time for me Best, Rongjing ^arch.mk \\_(0.0 kB)\\_ ^myjob.o2539410 \\_(0.0 kB)\\_ ; Hi Rongjing, So you mean the compilation was good, but running jobs would result in errors. Would you share the job ID or job script you were used? Cheers, name ; Hi Dr. name Sorry for the late reply. Yes the compilation was successful, but running jobs wasn't normally. Here is the job ID:2539410 Script: #!/bin/bash #SBATCH -J myjob # job name #SBATCH -o myjob.o%j # output and error file name (%j expands to jobID) #SBATCH --nodes=4 # number of nodes requested #SBATCH --ntasks-per-node=8 #SBATCH --cpus-per-task=16 #SBATCH -p wholenode # queue (partition) -- normal, development, etc. #SBATCH -t 12:00:00 # run time (hh:mm:ss) - 1.5 hours #SBATCH -A che190065 module reset module load intel impi intel-mkl hdf5 libszip QE=/home/x-rg47749/qe-7.2/bin BGW=/home/x-rg47749/BerkeleyGW-3.0.1-hdf5/bin echo $SLURM\\_CPUS\\_PER\\_TASK export OMP\\_NUM\\_THREADS=$SLURM\\_CPUS\\_PER\\_TASK mpirun -np $SLURM\\_NTASKS $BGW/epsilon.cplx.x #> epsilon.out Thanks for your help. Best, Rongjing ; Hi Rongjing, Can you try to add {{--mpi=pmi2}} to the {{mpirun}} line, like {{mpirun --mpi=pmi2 -np $SLURM\\_NTASKS ...}} Let me how it works. name ;",rjguo@utexas.edu,Rongjing Guo,Nannan Shan,Purdue University,Anvil,8,26,30,2023,2023-07-24
ATS-2044,Quantum Espresso 7.2 and EPW 5.7 installation,2023-07-31,2023-08-04,"I would like to use Quantum Espresso 7.2 and EPW 5.7 for my project work. Kindly help me by installing these opensource softwares. ; Hi name, Thanks for reaching out! I think you can try to install QE 7.2 on your end first. We have a list for package installation requests from Anvil users, and QE 7 is on the list. You can use gcc, openmpi, intel-mkl, fftw modules for QE installations. Hope this helps, name, PhD Sr. Computational Scientist Purdue University ;",skukreti,Sumit Kukreti,Nannan Shan,Purdue University,Anvil,2,5,31,2023,2023-07-31
ATS-2051,Job perpetually in queue,2023-07-31,2023-08-07,"My Anvil username is x-psharma3, and I am currently submitting all of my jobs under the dmr160063 project. I have a job that's been sitting in queue for about a week now, pending, but all my other jobs have started and finished. If it's a matter of just waiting more time, that's fine, but I'm beginning to wonder if it's something to do with this simulation specifically, as I had the same issue before. Can you check on the job status for me? The jobID is 2328278. The working directory for the job is /anvil/scratch/x-psharma3/6-7-10k/ten\\_k/240. Thank you! ; Hi name, Thanks for reaching out! I checked your job, 2328278. Your job is asking for 2 nodes for with 96 hours walltime, which is ~24k SUs. However, in your account, {{dmr160063}}, the balance is only ~21k SUs. This is why your job is pending. If you use command, {{squeue -j 2328278 -l}}, you would see the reason whey the job is pending. Hope this helps, name, PhD Sr. Computational Scientist Purdue University ;",psharma3@access-ci.org,Pranav Sharma,Nannan Shan,Purdue University,Anvil,2,6,31,2023,2023-07-31
ATS-2054,Anvil: Need Scalapack (GCC compiler) to be installed,2023-07-31,2023-08-03,"We have been dealing with installing GENE code on Anvil computer. For part of the compilation with GCC, our code needs to compile with ScaLAPACK available, compatible with GCC. Is it possible that you please could help install scalapack on the shared library of Anvil such that we can use that for a successful installation? ; Hi Taweesak, Can you please send us the installation page of the GENE code for the version you would like to install so that we can take a look at its dependency version requirement? Best, name ; Hi name, Thanks for your reply. Attached please find the makefile of GENE on Anvil. The only line I think that the problem is scalapack (please see below) where we don't see the module that's compatible with gnu compiler. Cheers, Petch ================================= ifeq ($(SCALAPACK),yes) LIBS += -L{NETLIB\\_SCALAPACKHOME}/lib -lscalapack else LIBS += endif =============================== On Aug 1, 2023, at 15:12, ACCESS Ticket Submission wrote: ^anvil.txt] \\_(0.0 kB)\\_ ; Hi Taweesak, It looks like our intel-mkl module has scalapack: $ module load intel-mkl $ cd $MKLROOT/lib/intel64 It contains: libmkl\\_scalapack\\_ilp64.a libmkl\\_scalapack\\_ilp64.so libmkl\\_scalapack\\_lp64.a libmkl\\_scalapack\\_lp64.so best, name ; Hi name, I don't think that the external library there provides the linker of the module to my work directory, which results in the error after compiling as shown below. Cheers, Taweesak On Aug 2, 2023, at 09:32, ACCESS Ticket Submission wrote: cd $MKLROOT/lib/intel64 ; Hi Taweesak, I saw your folder name is gene-cuda, are you trying to build a GPU version? Best, name ; Hi name, The code does contain the GPU architectures in it, but I don't expect it would affect the CPU compilation. What do you think? I'm not sure about this, let me also check with the developers. Cheers, Taweesak On Aug 2, 2023, at 15:05, ACCESS Ticket Submission wrote: ; Hi Taweesak, It should be okay, I was just what to double-check if you want to compile the CPU or GPU version. We just found that we have another libscalapack.so|http://libscalapack.so installed at: /apps/spack/anvil/apps/netlib-scalapack/2.1.0-gcc-11.2.0-nlrfz5y/lib Can you please try this one as well? Thanks, name ; Hi name, Thanks for your comment and suggestion. I checked with GENE developers and they said, consistently with you, that the GPU architecture should not affect the building process. They also suggested the link line to link the previous scalapack from KML to my home directory, such that I now succeed with the compiling the code. In short, the code is compiled completely. However, the line you suggested below is also useful. I'll keep this in mind for later. Cheers, Taweesak On Aug 3, 2023, at 11:53, ACCESS Ticket Submission wrote: ; Dear Anvil Help Team, I'm running in to mpi issue that is specific to Anvil. I'm running gyrokinetic GENE code on Anvil using MPI. I have successful installed and compiled the code, ran the code with low resolutions, and it was fine. However, when I increased the resolutions, I found the memory leak as you can see in slurm file I attached (slurm2577834.txt). Several lines towards the end show the memory usage increasing, a GENE developer considered it as the memory leak which he believed related to mpi rather than any bugs in GENE. I can also confirm that it's not about any bugs in the code because the same version of code was run fine in Expanse and Perlmutter computers; it does not encounter any issues. When we tried getting rid of a parallelization in x-direction, and leaving other direction parallelized, the memory leak mitigated. However, that leaded to a much lower efficiency on running any simulation because the code would run 4-5 times (or even more) slower than it should have been (2 time units of simulation compared to 9 time units in Expanse with equal number of core-hours). Do you have any ideas of what's going on with MPI, and how to solve it? Here, I also attached the submit script and modules loaded in the login node for you to help analyzing the issue. Please kindly let me know if you need more information. Best regards, Petch On Aug 3, 2023, at 11:53, ACCESS Ticket Submission wrote: —-—-—-— Reply above this line. name commented: Hi Taweesak, It should be okay, I was just what to double-check if you want to compile the CPU or GPU version. We just found that we have another libscalapack.so: http://libscalapack.so/ installed at: /apps/spack/anvil/apps/netlib-scalapack/2.1.0-gcc-11.2.0-nlrfz5y/lib Can you please try this one as well? Thanks, name ---- Automation for Jira changed the status to Waiting for customer. View request: https://access-ci.atlassian.net/servicedesk/customer/portal/2/ATS-2054?sda\\_source=notification-email · Turn off this request's notifications: https://access-ci.atlassian.net/servicedesk/customer/portal/2/ATS-2054/unsubscribe?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ0Z3QiOiJhbm9ueW1vdXMtbGluayIsInFzaCI6IjlkYWEyMmNlNGEwYTQ0OGVmNjk1ZGEyZGUwZWE0MGI4MTZjMTlmMmFkY2E4ZGQ5ZGE1ODA1ZTIzMGQzMGM4NDgiLCJpc3MiOiJzZXJ2aWNlZGVzay1qd3QtdG9rZW4taXNzdWVyIiwiY29udGV4dCI6eyJ1c2VyIjoicW06YjkxYzliMTctNjYwZi00YTUzLWE2N2EtNTAwMzYxMDZmNTlhOjBmYTY1MTJkLTkyNmEtNDYzYy1iNTgxLTcxOGUxYjdkYTQ3ZCIsImlzc3VlIjoiQVRTLTIwNTQifSwiZXhwIjoxNjkzNTAwODAwLCJpYXQiOjE2OTEwODE2MDB9.dwiK\\_PKlFHIaUHOuteUNkCYfs6i7Lp\\_kzFx1V-qe8uE This is shared with TAWEESAK JITSUK. Sent on name 3, 2023 11:53:20 AM CDT [^slurm2577834.txt \\_(0.0 kB)\\_ ^submit.txt \\_(0.0 kB)\\_ ;",jitsuk@access-ci.org,TAWEESAK JITSUK,Yang Hong,Purdue University,Anvil,10,4,31,2023,2023-07-31
ATS-2060,BLACS call causes segmentation fault,2023-07-31,2023-09-14,"Hello, One of my codes uses BLACS (https://www.netlib.org/blacs/: https://www.netlib.org/blacs/|smart-link, Basic Linear Algebra Communication Subprograms) and has a segmentation fault on the first call of a subroutine of the suite. The program compiles without error, but debugging (using compiler options and print statements) shows that the code fails at this statements at line 114: int dummy\\_ictxt, what = 0; BLACS\\_GET( &dummy\\_ictxt, &what, &ictxt ); It fails the same way using IMPI or openmpi compilers. Attached are the makefile, the options for the makefile (flasks.mk: http://flasks.mk) , the code in question (merge\\_ata\\_matrix\\_mpi\\_io.c , fails at line 114) and the output (fwi\\_merge1a.out) and error (fwi\\_merge1a.err) files. From what I understand from BLACS, there is no reason for it to fail on this particular call as it is little more than a ping. This leaves me to believe that the implementation of BLACS on Anvil could have a problem. Is this possible, or is my code at fault? The same code (with slightly adapted compiler following https://www.rcac.purdue.edu/knowledge/anvil/software/compile/mpi: https://www.rcac.purdue.edu/knowledge/anvil/software/compile/mpi|smart-link) worked fine on Stampede2. Regards, Dorian Soergel ; ^Makefile ^flags.mk ^fwi\\_merge1a.err ^fwi\\_merge1a.out ^merge\\_ata\\_matrix\\_mpi\\_io.c ; Hello, I have tried again using IMPI (with a few more cores, else nothing changed), and I do get a different error, seemingly MPI-related, here is a short excerpt (full error file attached): Attempt to free null pointer in file ../../../../../src/mpi/romio/adio/ad\\_gpfs/ad\\_gpfs\\_rdcoll.c, line 433 Abort(1) on node 133 (rank 133 in comm 0): application called MPI\\_Abort(MPI\\_COMM\\_WORLD, 1) - process 133 Attempt to free null pointer in file ../../../../../src/mpi/romio/adio/ad\\_gpfs/ad\\_gpfs\\_rdcoll.c, line 433 Abort(1) on node 134 (rank 134 in comm 0): application called MPI\\_Abort(MPI\\_COMM\\_WORLD, 1) - process 134 srun: Job step aborted: Waiting up to 32 seconds for job step to finish. srun: error: a317: tasks 209-223: Killed My officemate Utapl name has already encountered and reported a similar error. Regards, Dorian Soergel ^fwi\\_merge1a (bc31271a-bfc9-46bc-a2c5-93f5232d054c).err \\_(0.0 kB)\\_ ; Hi Dorian, Thank you for sharing the sample codes. I'll try to reproduce the error and see what is causing the segfault. Best regards, name. ; Hi name, Please tell me if you need more codes, the runs (slurm scripts and logs) are located at the following path: /anvil/scratch/x-dsoergel/Iter\\_1\\_final/solver/dorian\\_solver\\_8/run (for the openMPI version) The slurm script is here: /anvil/scratch/x-dsoergel/Iter\\_1\\_final/solver/dorian\\_solver\\_8/run/2a\\_run\\_merge.slurm The source code is in: /anvil/scratch/x-dsoergel/Iter\\_1\\_final/solver/winv-solver-r20150122 (I re-rigged the code to work for the openMPI version as opposed to the IMPI version) If you need help setting up a working example please tell me. Regards, Dorian Soergel ; Dorian, Apologies for dropping the ball on this ticket. The error messages look like they are coming from parallel IO/GPFS. I'll need to run the codes myself to figure out what is going on. If you think a video call may be useful to debug, I can meet next week. Best regards, name. ; Hi name. ;",dsoergel,Dorian Soergel,Amiya Maji,Purdue University,Anvil,8,34,31,2023,2023-07-31
ATS-2080,Compiling Berkeley GW on Anvil,2023-08-01,2023-08-15,"Hello, I was wondering if you could compile the latest version of BerkeleyGW (a free and open-access computational chemistry software) on Anvil as a module. I have been having trouble doing this myself, so I figured I would ask the experts about this. Thank you very much! Eoghan ; ^BerkeleyGW-3.0.1.tar.gz ; Hi Eoghan, Thanks for contacting us. Many users request the package installation resulting a list for us, Berkeley GW is on the list for sure. We would recommend user to try on their own considering the time manner. Fortunately, a user on Anvil shared an arch.mk file for Berkeley GW, you can take a look at it and try it again. {{COMPFLAG = -DINTEL}} {{PARAFLAG = -DMPI -DOMP}} {{MATHFLAG = -DUSESCALAPACK -DUNPACKED -DUSEFFTW3 -DUSEMR3 #-DHDF5 }} {{#-DUSEELPA -DUSEPRIMME}} {{Only uncomment DEBUGFLAG if you need to develop/debug BerkeleyGW.}} {{The output will be much more verbose, and the code will slow down by ~20%.}} {{#DEBUGFLAG = -DDEBUG }} {{FCPP = /usr/bin/cpp -C -nostdinc}} {{F90free = mpiifort -free -qopenmp}} {{LINK = mpiifort -free -qopenmp}} {{FOPTS = -O3 -no-prec-div -traceback}} {{FNOOPTS = $(FOPTS)}} {{MOD\\_OPT = -module }} {{INCFLAG = -I}} {{C\\_PARAFLAG = -DPARA}} {{CC\\_COMP = mpiicc -qopenmp}} {{C\\_COMP = mpiicc -qopenmp}} {{C\\_LINK = mpiicc -qopenmp}} {{C\\_OPTS = -O3 -traceback}} {{C\\_DEBUGFLAG =}} {{REMOVE = /bin/rm -f}} {{Math Libraries}} {{MKLROOT = /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mkl}} {{MKLLIB = $(MKLROOT)/lib/intel64}} {{FFTWINCLUDE = $(MKLROOT)/include/fftw}} {{FFTWLIB = Wl,-start-group $(MKLLIB)/libmkl\\_intel\\_lp64.a $(MKLLIB)/libmkl\\_sequential.a \}} {{ $(MKLLIB)/libmkl\\_core.a $(MKLLIB)/libmkl\\_blacs\\_intelmpi\\_lp64.a \}} {{ $(MKLLIB)/libmkl\\_scalapack\\_lp64.a $(MKLLIB)/libmkl\\_intel\\_thread.a \}} {{ Wl,-end-group -lpthread -lm -ldl }} {{#HDF5DIR = /apps/spack/anvil/apps/hdf5/1.10.7-intel-19.0.5-edamxw3}} {{#HDF5LIB = -L$(HDF5DIR)/lib -lhdf5\\_hl\\_fortran -lhdf5\\_hl -lhdf5\\_fortran -lhdf5 -lz}} {{#HDF5INCLUDE = $(HDF5DIR)/include}} {{TESTSCRIPT = sbatch hbar.scr}} Hope it helps, name, PhD Sr. Computational Scientist ; Hello name, Thank you for sending this to me. Unfortunately, this arch.mk file doesn't appear to work (even after modifying it to fix syntax errors). Based on the documentation on the BerkeleyGW website, the arch.mk file needs flags for LAPACK and ScaLAPACK. I would also prefer to compile using HDF5 if possible, but even when I uncomment the HDF5 tags in this arck.mk file the compilation fails. I will keep trying to compile this, but did this user tell you if their arck.mk file worked for them (and how)? Thank you very much! Eoghan ---- ; Hi Eoghan, LAPACK and ScaLAPACK were included in MKL library, which is already in arch file I shared. Speaking of HDF5, you could add HDF5 path to arch file (in the end). You can use the below command to obtain the PATHs, {{module spider hdf5}} {{module show hdf5/1.10.7}} Hope this helps, name ;",egormley@access-ci.org,Eoghan Gormley,Nannan Shan,,Anvil,5,11,31,2023,2023-07-31
ATS-2088,Change default Anvil project/group for x-dgc to x-cis220051,2023-08-02,2023-08-23,"The default $PROJECT and primary group for x-dgc on Anvil is currently x-tra220018: login03.anvil ~ $ echo $PROJECT /anvil/projects/x-tra220018 login03.anvil ~ $ getent passwd x-dgc x-dgc:\\*:7044182:7001326::/home/x-dgc:/bin/bash login03.anvil ~ $ getent group 7001326 x-tra220018:\\*:7001326:x-dgc,x-lsmith2,x-nding,x-yxie5,x-mprimeaux,x-lhan2,x-jma3,x-mmishra1,x-liu2302,x-rparker,x-jiang548,x-skim3,x-bbissonnette,x-lwachsmuth,x-jwei3,x-eborden,x-zduan1,x-bsankofi,x-dly,x-cbrobst,x-jaleman,x-bgovinalbadi,x-minzhang,x-ppark1,x-emartinezpla,x-hyu3,x-gyette,x-name,x-ceule,x-ekazemian,x-bbuck,x-tsuzuki,x-bfernandez,x-synbiomotif,x-dalia123,x-efkrakow,x-lollipop777,x-menesesk,x-saphstar,x-berense,x-pfavaro,x-anuj07,x-hhasan,x-wenpinc,x-zhangdb,x-natallah,x-pharmaco,x-svoddu,x-syerneni,x-abadari,x-sgaston,x-mflory,x-andrea2022,x-jmandula,x-nsalgia,x-mauz997,x-sthibaud,x-imasuen07,x-jcabezas,x-kalemdjr,x-cgao2,x-rrodriguez,x-wufanapply,x-ckoch,x-yangy1,x-aogunleye,x-jazambuja,x-saavfco,x-tjw100,x-lopezh1,x-dsshin,x-zheyun1995,x-apoiss170,x-xmo,x-rgriffard,x-szrmdphd,x-smuniyan,x-jfroese,x-dsavage1,x-jxu6,x-akinsola84,x-aelmarsafawi,x-benjin1122,x-qnguyenhien,x-ewestemeierr,x-janemuinde22,x-acolina,x-selgamal,x-dixit31,x-dqng,x-allorente,x-senecasms,x-chorta,x-jlittle,x-sgary,x-jessd,x-fatemehnci1,x-slisbp,x-amestrefarre,x-anirban88,x-dama20081110,x-hzhang13,x-tdao,x-yli16,x-chen4064,x-fuy,x-bucephalus37,x-jjaramillogo,x-wilmiche,x-camarenam,x-xiangwei,x-ssl391,x-munachi1,x-hasan99,x-awilson2,x-lvillago,x-ab3822,x-jazambuja1 I would like to change this default group and $PROJECT to The Data Mine project/group ""x-cis220051"". Can you please do this for me? Regards, Doug ; Hi Doug, Thanks for reaching out! I've bring your request to our team. You would hear from us later. Cheers, name, PhD Sr. Computational Scientist ; Hi Doug, I changed your primary group for the x-dgc account to be x-cis220051 everywhere. This might take a little time and/or logout/login to really show up in effect. That said, please just know if anyone is on multiple allocations, there's no guarantee which will be set as their primary group, nor that it might not change in the future if they join a new allocation. I understand this may make using some of the environment variable shortcuts tricky for multi-allocation users, but at least file access should not be affected if the ACLs are set up correctly. Let me know if there was something more to this, but I'll assume this can be closed then. Thanks, -name ; Thanks name, this is working! Regards, Doug ;",dgc,Doug Crabill,Kevin Colby,Purdue University,Anvil,4,16,31,2023,2023-07-31
ATS-2099,Error when trying to run moderate sized job on ANVIL,2023-08-02,2023-08-07,"I am currently trying to run a job on the ANVIL system and am running into issues on properly allocating tasks and nodes on my job. The simulations I am attempting to complete were done awhile back on the STAMPEDE2 system with 32 nodes and 32 tasks per node (1024 tasks total). I know that on the standard branch of ANVIL you are only able to run a job with up to 16 nodes at once, but on the wide branch the cap is much higher. However, when I try running a job on Wide with ntasks = 1024 and nodes =32 (or even 16 for that matter), I receive the following error output: Assertion failed in file ../../src/mpid/ch4/src/intel/ch4\\_shm\\_coll.c at line 1477: node\\_info->numa\\_num <= ((MPIDI\\_SHMGR\\_SYNCPAGE\\_SIZE / MPIDI\\_SHMGR\\_FLAG\\_SPACE) - 1) This repeats over and over many times in the error file but does not occur on smaller jobs with, say, 64 tasks and 8 nodes. For your convenience, I am attaching a picture of the jobscript that I am using which gives me said errors (ignore that the time is set to 5 minutes, thats only for testing purposes). I am positive that I am making a simple mistake in how I am setting up this script and hopefully there is a reasonable fix for running the job on a larger scale. Thank you in advance for your time and assistance and I look forward to hearing back from you. -name Hoh University of Pennsylvania Arizona State University Vassar College ; Hi name, Thanks for reaching out! The error does not look like a SLURM error. For {{wide}} partition on Anvil, one job can use up to 56 nodes. Anvil has 128 cores per node. In addition, you can use {{wholenode}} partition, with which one job can use up to 16 nodes with 2048 cores. So if you need 1024 tasks, you can use {{--nodes=8}} {{--ntasks=1024}} with {{wholenode}} partition on Anvil. If you request -{{N16}} and {{-n1024}}, your balance would be charged according to number of nodes, not tasks. The error message should be related to intel mpi. Anvil has a old version of intel mpi right now. We plan to upgrade it soon. A workaround for you might be, trying to use {{srun --mpi=pmi2}} instead of mpirun, and see if the error goes away. Another workaround would be re-compiling the code using gcc/openmpi instead of intel/impi. Hope this helps, name, PhD Sr. Computational Scientist ;",jrhoh@access-ci.org,me you idiot,Nannan Shan,Purdue University,Anvil,3,4,31,2023,2023-07-31
ATS-2172,Create Project/Namespace on Anvil Composable,2023-08-07,2023-08-09,"Greetings, This is name from Purdue SSG. I recently got an allocation and Anvil credits under the project CIS230147 and tried to create a project and namespace with it. However, I got an error during the project creation shown in the attached screenshot. The error message is projects.management.cattle.io is forbidden: User ""u-ikjpkfzseu"" cannot create resource ""projects"" in API group ""management.cattle.io"" in the namespace ""c-v2cdd"" Could you please take care of this issue? ; Hi name, Project creation is a process has to be done by the admins. The project has now been created and you should be able to see it in the Rancher UI. Let me know if you have any issues. -name ; Hi name, Thanks for the configuration. I can see the project and create a namespace there. My short-term goal is to replicate the triton deployment as in the PEARC GPU tutorials. Could you also configure the S3 bucket and the GPU allocation for the project (or streamci-test namespace)? ---- ;",nujwoo@access-ci.org,Shin Jaewoo,Erik Gough,Purdue University,Anvil,4,3,32,2023,2023-08-07
ATS-2193,"Cannot access ""OnDemand"" the Purdue Anvil GPU nor the TAMU FASTER portals.",2023-08-07,2023-08-08,"Hello, I'm trying to access the onDemand portals for TAMU FASTER and Purdue Anvil GPU, but I receive ""failed to map user"" error for both of them. For TAMU FASTER, I tried to access ""https://portal-faster-access.hprc.tamu.edu: https://portal-faster-access.hprc.tamu.edu"" as indicated in https://hprc.tamu.edu/wiki/FASTER:FASTER-Access: https://hprc.tamu.edu/wiki/FASTER:FASTER-Access|smart-link. However, I received the message: Error -- failed to map user (ccanchilamartinez) For Anvil GPU: I tried to access ""ondemand.anvil.rcac.purdue.edu: http://ondemand.anvil.rcac.purdue.edu"" as indicated in https://www.rcac.purdue.edu/knowledge/anvil/access/login/ood: https://www.rcac.purdue.edu/knowledge/anvil/access/login/ood|smart-link. However, I received the message: Error -- failed to map user (: mailto:) Please see attached screenshots of the error messages. I'm not sure if I'm missing something to gain access to these portals. I also activated multi-factor authentication as indicated in https://identity.access-ci.org/manage-mfa: https://identity.access-ci.org/manage-mfa|smart-link. I would appreciate if I can receive some guidance on how to access these RP portals. Thanks, name ; Hi name, Thank you for reaching out! I do not see your account has been created on Anvil yet. Would you please ask your PIs if they have added you to their allocations on Anvil after they transferred the credits? They should be able to add users to the resources via the following link: https://allocations.access-ci.org/user\\_management: https://allocations.access-ci.org/user\\_management For accessing TAMU FASTER, you would also need to ask your PIs if you were added to the resource as a start. Thanks, name ; Thank you for your quick response, We added my account to the allocation (I was missing this step). I'm still waiting for the account to work with the RP, but I assume it will take some time. ; Hi name, It seems your account on Anvil should be created now. Would you please try logging into Anvil Open OnDemand again and let me know if there are any issues? Thanks, name ; It works now! Thanks, ; Great! Glad to know that. Do you have any further questions about your access to TAMU FASTER? Is it okay with you if we close this ticket? Thanks, name ; It is ok to close the ticket thanks! ; Thanks, name! I'll go ahead and mark this ticket as resolved then. Please feel free to contact us again if you have any questions or need any help. Cheers, name ;",ccanchilamartinez,Carlos Canchila Martinez,Ruyi Li,Purdue University,Anvil,9,2,32,2023,2023-08-07
ATS-2222,I have lost lot of SUs even after the error message occured and not running any computation ,2023-08-08,2023-08-28,"During my calculation in vasp and epw softwares, I lost a lot of name or credits and may be > 20 % without any results where high memory is required. Few minutes or hour after the submission the job status is out of memory however the the job remain sticked to the nodes consumes hours and SUs. This did not happened one time but lot of times with vasp and epw softwares. Otherwise normal job I am able to run and still running now as well. As a lot of name or credits are lost so I request you to provide me few SUs so that I can run jobs with them. My projects have very limited SUs and I can not waste those. I need to complete my project within that. If possible kindly provide me SUs for completing the jobs in Anvil. ; Hi name, Can you share the VASP input files, including POSCAR, INCAR, KPOINTS and submit script (do not send me POTCAR) for me to re-run the calculation and see if it is a systematic issue, if so we can work on the name refund. We can refund SUs if it is a systematic problem, but not for the ones users' test jobs. If you want to share the input files for EPW, it is okay too. (It might be good to share which EPW you are referring to, so I can take a look). Cheers, name, PhD (She/Her) Sr. Computational Scientist ; I have attached a case which I tried again today and found the same issue of ""out of memory error"" but still job remain sticked on the node. I myself canceled it by scancel command when it did'nt stop. The attached case belongs to a vasp software. All INCAR POSCAR, POTCAR, KPOINTS and vp file of slurm script are attached within the folder. I have attached the POTCAR because to ensure the same parameters. ^test\\_out\\_of\\_memory.tar.gz ; Dear name'am I am waiting for your response. Thank You Regards name ; Hi name, I did the tests with your VASP inputs, and I think I can re-produce the error and the issue you mentioned (job won't stop and burn your SUs). We can refund the SUs you lost. Please share all the job IDs with this type of issue so we would refund your SUs according to running times of those jobs. In addition, we also find a way to avoid burning SUs after an error happened. You can use either {{srun -n --kill-on-bad-exit $SLURM\\_NTASKS vasp\\_ncl}} or {{mpirun -np $SLURM\\_NTASKS vasp\\_std}} in your last line of your submit script. BTW, the example job would stop due to out of memory error. You might consider to request more nodes or use highmem partition for your job. Cheers, name ; Thank You name'am for realizing my issue, Now onwards I would put {{srun -n --kill-on-bad-exit $SLURM\\_NTASKS vasp\\_ncl}} lines at the bottom of my script file. As I did a lot or variation and some of them I deleted as well. I do not remember all of them. But as I told you that around ~ 20% I lost through all these calculations. Some of these which I can found are 2549303, 2572122, 2583807 etc But there are lot of run which takes a large SUs. As I told you that my project required a lot of calculations to complete. I request you to return me 20% of the 250000.0 name Limit. Thank You once again! Regards name ; Hi name, We need the job IDs to do the refunds. Please use the below command (-S means the starting date and -E means end date) to check which jobs are related and let me know. You can share the list of all the effected jobs. {{sacct -X -S 2023-07-01 -E 2023-08-21}} Cheers, name ; Dear name'am, I checked the IDs via the suggested command. Below are those showing cancelled. 2415515 2462191 2513069 2513082 2513083 2519154 2538633 2538883 2538915 2540213 2540217 2540248 2540275 2541760 2542323 2542540 2542601 2543284 2546314 2549209 2549303 2553236 2553397 2553398 2559839 2559846 2559859 2559866 2560295 2561997 2570354 2570913 2571998 2572029 2572122 2583805 2583807 Thank You Regards name ; Hi name, After the calculation, your refund SUs would be 31916.5. You would see them in your allocation balance soon. Please find the itemized SUs for each job below. |Job IDs|SUs| |2415515|1513.9558| |2462191|6475.6736| |2513069|11.2356| |2513082|0.0711| |2513083|0.1067| |2519154|2554.5984| |2538633|337.2083| |2538883|1.6356| |2538915|1991.1117| |2540213|4.8356| |2540217|4.6933| |2540248|30.0089| |2540275|262.2577| |2541760|267.2353| |2542323|30.5244| |2542540|0.4622| |2542601|0.0711| |2543284|448| |2546314|253.4758| |2549209|5.6178| |2549303|1367.1424| |2553236|4.8356| |2553397|0.7111| |2553398|3400.8166| |2559839|22.1866| |2559846|0.9956| |2559859|0.8533| |2559866|3.6622| |2560295|177.7777| |2561997|1671.8234| |2570354|20.1956| |2570913|767.0758| |2571998|17.28| |2572029|1.6356| |2572122|10259.7632| |2583805|3.5911| |2583807|3.3422| |sum|31916.4669| Cheers, name ; Thank You very much for considering my request. ;",skukreti,Sumit Kukreti,Nannan Shan,Purdue University,Anvil,10,15,32,2023,2023-08-07
ATS-2233,S3 storage on Anvil Composable,2023-08-09,2023-08-23,"Greetings, Could you please configure the S3 storage on Anvil Composable and share the access information (access/secret key etc.)? ; Hi name, Thanks for contacting us -name ;",nujwoo,Jaewoo Shin,Erik Gough,Purdue University,Anvil,4,11,32,2023,2023-08-07
ATS-2271,VASP user added on anvil,2023-08-11,2023-08-14,"Hi there, I'm an anvil user : mailto:, under allocation dmr160156. I need to have access to the built-in VASP5.4.4. I'm currently at Prof. name at Harvard, which I believe we have a license. Thank you Cheers, name, PhD (She/Her) Sr. Computational Scientist ; Dear Dr. name, The email address is , with license 5-2382 Thank youimage.png|thumbnail so vasp5.4.4 still cannot load. However I check the 'id' command, I'm in the vasp5 group: or try to load these modules manually on the terminal, it can load and can run properly. But if I sbatch then the vasp loading fails, it just cannot recognize the vasp\\_std file. Could you please help me find out what's wrong? Best, Mouyang ---- ; Never mind. It's just started working -- no trouble now. Thanks for the help\! Cheers! Mouyang ---- \\*发件人:\\* ACCESS Ticket Submission \\*发送时间:\\* 2023年8月12日 4:33 \\*收件人:\\* Mouyang name \\*主题:\\* ATS-2271 VASP user added on anvil ;",mcheng1@access-ci.org,Mouyang Cheng,Nannan Shan,Purdue University,Anvil,7,2,32,2023,2023-08-07
ATS-2282,Can't run jobs on Anvil using EVE230007,2023-08-11,2023-08-22,"I'm trying to run a batch job on Anvil but I keep getting the following error: sbatch: error: Batch job submission failed: Invalid account or account/partition combination specified I confirmed I am associated with the allocation and the resource so I'm not sure what the problem is. Here is the batch script I'm using: #!/bin/sh -l #SBATCH -A EVE230007 #SBATCH -J SM51 #SBATCH -o SM51.o%j # Name of stdout output file #SBATCH -e SM51.e%j # Name of stderr error file #SBATCH -p wholenode # the default queue is ""shared"" queue #SBATCH --nodes=10 #SBATCH --ntasks=1280 #SBATCH --time=2:00:00 # Other commands must follow all #SBATCH directives... source runit.sh # ; Hi, Thank you for contacting us. Yes I saw you were recently added to the allocation {{eve230007}} but this change has not been propagated to Anvil yet. You may check your current available allocations with command {{mybalance}} in terminal while landed on Anvil. Please wait for another couple of days and see if this process can be finished by then. Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi name, Thank you for the update. Sincerely, name ;",ryanhass@access-ci.org,Ryan Hass,Guangzhen Jin,Purdue University,Anvil,3,8,32,2023,2023-08-07
ATS-2310,Questions regarding Matlab on Purdue Anvi GPU,2023-08-14,2023-09-21,"Hi, I'm having some issues running MATLAB on the Purdue Anvil GPU cluster. The performance I obtain when training machine learning models is below the expected. I tried running my code using both matlab/R2022a and R2023a and the results are similar (Job IDs: 2582906 and 2584990). For example, 10 iterations during training a machine learning model take around 12~14 seconds on Anvil, while it only takes ~3 seconds on a local machine (using an RTX 3090) - that is, more than four times slower. For comparison, I'm also training machine learning models using python (using a private anaconda environment), and the performance running on Anvil is better compared to the local machine - which is the expected behavior. This is what I have in my job submission script (Note that I tried using multiple cores to discard that as a bottleneck, and the performance is the same when using 1,4 and 10 cpu-cores): # I appreciate it. name ; Hi name, That's awesome. Thank you for the update. Will close the ticket but feel free to let us know if you have further questions. Best, name ;",ccanchilamartinez@access-ci.org,Carlos Canchila Martinez,Guangzhen Jin,Purdue University,Anvil,8,29,33,2023,2023-08-14
ATS-2923,Reserving Nodes on Anvil,2023-09-11,2023-09-25,"We have a large batch of compute over the next ~6 weeks and I'm curious if reservations are possible on Anvil. Ideally, we'd like to reserve 50-60 nodes on the wholenode partition. Our team also uses Bridges2 and on that platform there is a form we can submit to request a reservation; however, I wasn't able to find anything similar on Anvil. ; I realized I accidentally entered my personal email address. The email address associated with my ACCESS account is : mailto:. Also, our allocation ID is deb200010. ; Hi name, Thanks for contacting us ; Hi name, Do you want to have a meeting to talk about the node reservation? We can have a meeting this afternoon. Let me know. Cheers, name ; Hi name, That would be great name ; \\*\\*PRIVATE NOTE\\*\\* Had a meeting with user and discussed the possible workarounds. User said he would try them first. ; Hi name, I just realize that if you only need 1 node for your job, maybe you can try '-p shared' partition as well. On 'shared' partition, you can use up to 1 node/per job, and you can submit up to 6400 cores (50 running jobs with 128 cores). Each job on shared partition can run up to 96 hours. Check more details about different partitions on Anvil. https://www.rcac.purdue.edu/knowledge/anvil/run/partitions: https://www.rcac.purdue.edu/knowledge/anvil/run/partitions|smart-link Let me know how it goes. Cheers, name ; I noticed that as well on Monday and have switched to using shared. It's much less heavily used than wholenode or wide, so seems to be working so far, thanks Thanks for letting me know. --name ; using the shared queue appears to have resolved this issue for now, thanks for your help! ;",mstrimas@access-ci.org,Matthew Strimas-Mackey,Nannan Shan,Purdue University,Anvil,11,11,37,2023,2023-09-11
ATS-2328,Interactive and batch jobs hang,2023-08-14,2023-08-16,"I'm new to Anvil, but running a MPI Fortran code that I've run many times before on Stampede2 (at Texas Advanced Computing Center). Most of the jobs I've run on Anvil thus far have run anywhere from 20-60min before hanging. I don't get a runtime error, the code simply hangs and the job continues. The latest example of this was job 2591863, submitted to the wholenode queue, which dumped a file at 14:53 PT (/anvil/scratch/x-ryanhass/HITdecay/shearlessMixing\\_Bodart/SM46/SM46\\_M2\\_V2/Run46\\_wVel\\_t009800.out) and about a minute later stopped executing. I've been monitoring the jobs so that I don't burn resources unnecessarily, but I obviously would like to submit much longer jobs. Currently however, I'm forced to submit a new job every 60 name or so or else risk burning resources without running my code. ; Hi name, Thank you for reaching out I just made the changes to my setup script and am recompiling now. I'll follow up once I've run the code. name ; My job ran without interruption so I think the issue is resolved! Thank you name for the help. I will reopen this ticket if the issue arises again. Sincerely, name ; Glad to hear it, name! Thanks for confirming. Best regards, name, Ph.D. Lead Computational Scientist Rosen Center for Advanced Computing (RCAC) Purdue University ;",ryanhass@access-ci.org,Ryan Hass,tsaiwei,Purdue University,Anvil,9,3,33,2023,2023-08-14
ATS-2361,VASP 5.4 module access,2023-08-16,2023-08-24,"Hi folks, I was hoping you could grant me and my student (egormley) access to the VASP 5 module, saving me some hassle compiling it. Attached is my license with Materials Design. Thank you, name ; ^University of Oregon -- Academic Software License Agreement US Letter.pdf] ; Hi name, Thanks for reaching out! Unfortunately we won't grant users access to Anvil VASP groups if they are with MedeA. If you want to use VASP on Anvil, you can compile it on your own or work with Materials Design about how to use MedeA workflow on Anvil. Hope this helps. Cheers, name, PhD (She/Her) Sr. Computational Scientist ; Forgot to mention, you might want to reference the user guide for VASP compilation on Anvil. [https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/vasp: https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/vasp|smart-link Cheers, name ; Thanks name, I have it compiling myself, now, using the intel compilers and math libraries. Perhaps you could provide some insight as to the makefile.include parameters that you folks have determined is the most efficient on anvil? For what it's worth, the state of Oregon forbids owning a conventional VASP license directly from Wein because of state taxation laws. To the boundaries of science, name H. Hendon Assistant Professor of Chemistry University of Oregon name, OR, 97403 w. pages.uoregon.edu/chendon: https://pages.uoregon.edu/chendon/ e. : mailto: t. @chhendon: https://twitter.com/chhendon ; Hi name, Here is the details about how we build vasp 5.4 with different compilers, including intel compiler, although we recommend to use GNU compiler on Anvil. https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/vasp/build\\_your\\_own\\_vasp\\_5: https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/vasp/build\\_your\\_own\\_vasp\\_5|smart-link Let me know if you still have questions. Cheers, name ;",chhendon@access-ci.org,Christopher Hendon,Nannan Shan,Purdue University,Anvil,6,7,33,2023,2023-08-14
ATS-2423,how to access node local storage on anvil?,2023-08-19,2023-08-28,"The ""architecture"" section of the Anvil user guide at Purdue lists ""node-local storage: 480 GB"" but does not mention anywhere else in the user guide that I can tell. Is it flash? Spinning disk? What is its file system? Is it directly accessible to the user during the job (I presume yes otherwise why mention it). Most importantly: what is its pathname? ; Hi name, Thank you for reaching out! The local storage mentioned should be the node-local disk, part of which is reserved for the system and the user visible portion is {{/tmp}}. It is flash and should be xfs. It is accessible to users if they have a job running on the node. I hope this helps. If you have any further questions, please let us know. Thanks, name ; Hi name, Since I have not heard back from you in a while, I am assuming you do not have any further questions -- so I'm tentatively marking this ticket as resolved at this point. Please feel free to contact us again if you need any help. Thanks, name ;",csteffen,Craig Steffen,Ruyi Li,,Anvil,3,6,33,2023,2023-08-14
ATS-2429,Many Anvil OnDemand apps don't permit < 128 cores,2023-08-20,2023-08-28,"It looks like on maybe June 28 there were changes to many of the Anvil OnDemand interactive apps that now make it impossible to run them using less than 128 cores. This is true for every public OnDemand app I tried. I tried purging ~/ondemand/data just to be sure there was no lingering cruft. A simple repeat-by is to login to ondemand.anvil and choose Interactive Apps->Jupyter Notebook. Select the queue to be ""shared"", then try to use the up/down buttons on the Cores selection to see that it can only be 128. Try typing in some other number, like ""4"", then click Launch and you will see the error, ""Please select a value that is no less than 128"". This same issue exists for Desktop, Rstudio Server, Matlab, and probably all the other apps as well. I'm certain this worked properly for the public Jupyter Notebook back in May for a workshop I helped teach, so this is a relatively new issue. It's not an issue for The Data Mine version of Jupyter Notebook since we control the configuration there. I plan on rolling my own ""Desktop"" app out for The Data Mine soon and corrected this issue in my version of the Desktop app. The fix is name simple. For the public Desktop app, just add these two lines to the ""shared"" section of ondemand.anvil:/var/www/ood/apps/name/bc\\_desktop/form.yml data-name-num-cores: 1, data-max-num-cores: 128, Similar changes should be made to the gpu and highmem sections, though you may want to adjust the minimums for each of those. I think similar changes should be applied to all of the other OnDemand apps. Otherwise, people must always use 128 cores for everything on OnDemand Kind regards, name ; Awesome, thanks for taking care of this so quickly name!!! Regards, Doug ---- ;",dgc,Doug Crabill,rderue,Purdue University,Anvil,4,6,33,2023,2023-08-14
ATS-2486,cmake not working with Intel compiler,2023-08-22,2023-09-15,"As of this morning, I cannot run cmake with the Intel compiler loaded. However, if I use the default modules (GNU compiler) cmake works no problem. This is the first time I've run into issues compiling my code on Anvil (it's a Fortran MPI code). I've run cmake with the current set of cmake files and modules many times before. Here are the modules currently loaded: 1) xalt/2.10.45 (S) 2) intel/19.0.5.281 3) cmake/3.20.0 4) zlib/1.2.11 5) mvapich2/2.3.6 ; Hi name, Thank you for reaching outimage001.png|thumbnail ; Hi name, My apologies for the delayed response and thank you for sharing more information. I checked your processes on login02 but could not figure out the root cause of the issue. I'm escalating this ticket to our computational scientists and hopefully they would be able to help. Thanks, name ; Why was the status changed to waiting for customer? Per name's last message, this request has been escalated to the computational scientists at Purdue. ; name, Once again, sorry for the lack of timely response here. I suspect this was due to a very specific filesystem issue which has now been resolved by the vendors. Are you still seeing slow compilation on Anvil? Best regards, name. ; Hi name, cmake works 90% of the time for me and the code always compiles. Sometimes it seems the compilation is hanging for a while, but if I don't touch it, it will eventually compile. Other times it compiles as expected without any significant delays (outside of the time required to compile a large scientific code of course). I'm providing these details in case it is indicative of a known issue, but we can close this ticket as I can't consistently reproduce the problem and it hasn't been hindering my progress. name, I forgot to mention one other thing. I have recently noticed heavy load on our Intel license server. Since there are limited number of licenses, compiling with Intel may sometimes go slower. For example, if lots of users are using the intel compiler that can mean fewer license availability. (The compiler pauses and waits for licenses.) The same thing should not happen with GCC unless there is a filesystem issue. Please do keep us posted when you run into slowness. Best regards, name. ; Hi name, I think this identifies the reason behind the variable compile times. I'm going to mark this as resolved. Thanks for helping me with this. name ;",ryanhass,Ryan Hass,Amiya Maji,Purdue University,Anvil,13,19,34,2023,2023-08-21
ATS-2502,Change to Purdue University - West Lafayette,2023-08-23,2023-08-24,"I am working with Purdue University on a project (year long class), I think I should have selected Purdue University, rather than my company, Caterpillar, as the institution because I need to upload data into their system for the project. The class starts Frida, name 25th.. I need to use Anvil. ; Hello name, Thanks for reaching out! On Anvil, you need to be under an active allocation or you are the PI of an active allocation to use it. You might want to talk to the PI of this project to add you into the existed project on Anvil. Or you group need to apply one on Anvil. Please visit the ACCESS website to learn how to submit a proposal. You need your register on ACCESS first before applying. https://allocations.access-ci.org/prepare-requests-overview: https://allocations.access-ci.org/prepare-requests-overview|smart-link Hope this helps, Cheers, name, PhD (She/Her) Sr. Computational Scientist ; Hello, I am the Primary Investigator according to the Research Project Specification, so I will reach out to Purdue and let them help me figure it out. Jim Katter Electronic Engineering Senior Manager Onboard Analytics & Virtual Sensors Integrated Components & Solutions Caterpillar: Confidential name ;",jkatter@access-ci.org,James Katter,Nannan Shan,Purdue University,Anvil,3,2,34,2023,2023-08-21
ATS-2534,"I am trying to run batch jobs on Purdue's Anvil cluster with an access allocation, but I am getting an error:",2023-08-24,2023-08-28,"I am trying to run batch jobs on Purdue's Anvil cluster with an access allocation, but I am getting the following error: ""Invalid account or account/partition combination specified"" ; Hi Andi, Thank you for reaching out Best, Andi ---- ; Hi Andi, No problem. It seems you have been running jobs under the phy230071 allocation on Anvil. I'll tentatively marking this ticket as resolved. Please feel free to contact us again if you have any questions or need any help. $ mybalance x-mankola Allocation Type name Limit name Usage name Usage name Balance Account (account) (user) ============= ==== ========== ========== ========== ========== phy210068 CPU 0.0 43276932.4 7109.4 n/a phy230071 CPU 100000.0 183.7 183.7 99816.3 Thanks, name ;",mankola,Andi Mankolli,Ruyi Li,Purdue University,Anvil,7,3,34,2023,2023-08-21
ATS-2597,vasp license,2023-08-25,2023-08-29,"user: zekun\\_name User's email: : mailto: VASP vendor: VASP Software GmbH License owner's name: Emmanouil Kioupakis License owner's institution: University of Michigan VASP Version(s): Version 5, VASP license # 5-1557 Users' names: Zekun name ; Hello Thanks for reaching out! You have been added to vasp5 group on Anvil. \\*Your membership will be ready within a few hours\\*. Please check our user guide for VASP calculations on Anvil. https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/vasp: https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/vasp|smart-link ;",zwu1@access-ci.org,Zekun Wu,Nannan Shan,Purdue University,Anvil,2,3,34,2023,2023-08-21
ATS-2734,PVC with RWX failed,2023-09-01,2023-09-01,"Greetings, I am trying to create a PVC with the access mode RWX on Anvil Composable, but it looks failed. It says, failed to provision volume with StorageClass ""anvil-block"": rpc error: code = InvalidArgument desc = multi node access modes are only supported on rbd block type volumes. Thank you ; Hi name, RWX is not supported by the anvil-block storage class. Use the anvil-filesystem class and things should work. Thanks, -name ; It works with the anvil-filesystem. Thanks! ; Great! Marking this resolved. ;",nujwoo,Jaewoo Shin,Erik Gough,Purdue University,Anvil,5,1,35,2023,2023-08-28
ATS-2629,VASP access Request,2023-08-28,2023-08-30,"Hi- I am reaching out for VASP access request. I would like to access VASP package that has been compiled in the Anvil module. Attached is the VASP license including my name in the list. Please let me if you have any questions. Regards, Haonan ; ^VASP users.pdf] ; Hi Haonan, Thank you for reaching out! I've verified your license and added you to the vasp5 and vasp6 Unix groups for accessing the pre-installed VASP 5 and VASP 6 on Anvil. $ groups x-whnfff x-whnfff : x-dmr100005 vasp5 vasp6 The following user guide section on VASP might be of your interest: [RCAC - Knowledge Base: Anvil User Guide: VASP: https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/vasp If you have any further questions, please let me know. Thanks, name ; Hi name, Thank you very much for inviting me to join group and for sharing the information. Could you kindly assist in adding another member to our research group? His access ID is zli18, and the VASP account name is Ziyang name. He has already been granted the necessary license to utilize VASP. Best, Haonan ---- ; Haonan, No problem. They should also have access to the vasp/5.4.4.pl2 and vasp/6.3.0 modules now. $ groups x-zli18 x-zli18 : x-dmr100005 vasp5 vasp6 I would appreciate it if you could share the link to the user guide with them. RCAC - Knowledge Base: Anvil User Guide: VASP: https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/vasp Thanks, name ; Hi Ruiyi, Thank you so much! I will share the useful information with him. Best, Haonan ---- ; Haonan, You are welcome! I'll tentatively marking this ticket as resolved then. If you have any questions or requests, please feel free to contact us again. Thanks, name ;",whnfff@access-ci.org,Haonan Wang,Ruyi Li,,Anvil,7,3,35,2023,2023-08-28
ATS-2652,Anvil compute time not showing on the account in Anvil shell.,2023-08-29,2023-09-01,"Hello, we have been given extra time for our project TG-PHY210065 on Anvil supercomputer that shows on the ACCESS portal. However when I check my balance on the Anvil shell, it does not show the additional computation time. I am attaching two screenshots. Can you please help me in this regard? Thank you. ; Hi Irmak, Thank you for reaching out to us and sorry about the issue. We are digging into the logs and see if we can find something specific. We will get back to you as soon as possible. Thanks, name ; Hi Irmak, Our experts have just corrected the name amount for your allocation. $ mybalance x-rmktyln Allocation Type name Limit name Usage name Usage name Balance Account (account) (user) ============= ==== ========== ========== ========== ========== phy210065 CPU 9790000.0 5297157.0 1945867.9 4492843.0 I would tentatively mark this ticket as resolved at this point. Please feel free to contact us again if you have any questions. Thanks, name ;",rmktyln@access-ci.org,IRMAK TAYLAN KARPUZCU,Ruyi Li,Purdue University,Anvil,4,4,35,2023,2023-08-28
ATS-2710,ACCESS project will expire soon,2023-08-31,2023-08-31,"Hi, My ACCESS project PHY220079 will expire soon. I still have SUs left on this project. Is there a way to keep using the SUs? Or request for an extension? ; Hi Sushree, Thank you for reaching out! You should be able to request an extension for your allocation. Please refer to the following webpage for details: ACCESS Allocations: Manage Allocations Overview: https://allocations.access-ci.org/manage-allocations-overview If you have any further questions, please let me know. Thanks, name ;",ssdash@access-ci.org,Sushree S Dash,Ruyi Li,,Anvil,2,1,35,2023,2023-08-28
ATS-2715,Long Compile Times,2023-08-31,2023-09-19,"Sometimes when I'm compiling code the code compiles almost instantly, other times it takes excessively long. The code does not change substantially when I recompile it, usually only a print statement is modified and I receive no compile time errors, it just takes a long time to compile. I compile code by submitting a command "":zzzAlWALL $ make -f makefile"" with makefile referencing the attached file, and zzzAlWALL being the directory with the relevant files. Is something about the way that I am compiling code that is wrong or should I expect long compile times? ; ^makefile ; Hi name, Thank you for reaching out! The compiling time difference might be caused by various reasons. Would you please let me know the full path to the directory where you were compiling your code? Were you staying on the same login node (login06) or trying on several different nodes? Before you start to compile your code, would you please check the load average on the node using the command {{uptime}} or {{top}} and see if the compiling speed has anything to do with that? Also, would you please let us know what code you were compiling? What compilers were you using? What commands did you use to compile your code? Thanks, name ; Hello, The full path to the directory of the code being compiled is /anvil/projects/x-phy230052/Reentry\\_F/source/ sometimes with another directory after /source/ I was staying on the same Login node. I can check to see if the node has a high load the next time I recompile. I am compiling code written by a research group that I am part of and assisting in its development (CFD code). The code is written in FORTRAN. The commands/compilers I use to compile are: module load intel/19.0.5.281 module load intel-mkl/2019.5.281 module load openmpi/4.0.6 make -f makefile The ""makefile"" document is as follows: D = /anvil/projects/x-phy230052/Reentry\\_F/source/Alin\\_WALLREACTIONS/ main = main-steady-MPI wall = vapor-name-danny order = order-3rd-noneqm-elt-MPI-8species-transpiration\\_saturation\\_name shock = shock-nowave-noneqm-MPI subroutines = subroutines-zone1-noneqm-MPI source = MODIFIEDNoneqm-Model-8species-name\\_GIBBS CC = mpif90 flags = -fpp flags += -O3 flags += -mcmodel=large -shared-intel flags += -qopenmp flags += -mtune=skylake # flags += -g -check bounds -traceback lib = ${MKLROOT}/lib/intel64/libmkl\\_scalapack\\_lp64.a \ -Wl,--start-group \ ${MKLROOT}/lib/intel64/libmkl\\_intel\\_lp64.a \ ${MKLROOT}/lib/intel64/libmkl\\_core.a \ ${MKLROOT}/lib/intel64/libmkl\\_sequential.a \ -Wl,--end-group \ ${MKLROOT}/lib/intel64/libmkl\\_blacs\\_sgimpt\\_lp64.a \ -lpthread -lm -lmpi OBJS0 = general-sub-noneqm-MPI.o $(wall).o $(order).o $(shock).o $(subroutines).o $(source).o run1-T:: $(main).o $(OBJS0) mpif90 $(flags) -o run1-T $(main).o $(OBJS0) $(lib) $(main).o:: $(D)$(main).f $(D)common.f mpif90 $(flags) -c $(D)$(main).f general-sub-noneqm-MPI.o:: $(D)general-sub-noneqm-MPI.f $(D)common.f mpif90 $(flags) -c $(D)general-sub-noneqm-MPI.f $(wall).o:: $(D)$(wall).f $(D)common.f mpif90 $(flags) -c $(D)$(wall).f $(order).o:: $(D)$(order).f $(D)common.f mpif90 $(flags) -c -cpp -DKEENAN $(D)$(order).f $(shock).o:: $(D)$(shock).f $(D)common.f mpif90 $(flags) -c $(D)$(shock).f $(subroutines).o:: $(D)$(subroutines).f $(D)common.f mpif90 $(flags) -c $(D)$(subroutines).f $(source).o:: $(D)$(source).f $(D)common.f mpif90 $(flags) -c $(D)$(source).f clean:: rm -f \\*.o run1-T Sincerely, name ; Hi name, Thanks for sharing more information and apologies for the delayed response. We suspect the long compilation time might be related to the previous intermittent slowness of the project filesystem. The engineers have brought that filesystem back to its optimal performance. Would you please let us know if you still see any slowness when compiling your codes? Thanks, name ; Hi name, Since I have not heard back from you a while, I'm assuming you see better compiling speed now. I'm tentatively marking this ticket as resolved at this point. If you still see any issues or have any questions, please feel free to contact us again. Thanks, name ; Yes, thank you. Sincerely, name ;",amannion@access-ci.org,Anthony Mannion,Ruyi Li,Purdue University,Anvil,7,14,35,2023,2023-08-28
ATS-2719,Lack of timely support on Anvil,2023-08-31,2023-09-06,"I have had an issue running my code on Anvil for the past few weeks. I originally submitted a ticket to the Anvil support staff on Aug 14 (+ATS-2328+: https://access-ci.atlassian.net/servicedesk/customer/portal/2/ATS-2328) as it seemed to be an issue with their file system. They were responsive to the original ticket and suggested I remove one of my compiler flags. This seemed to resolve the issue so they closed the ticket. Shortly after, I began having the same issue again (hanging code without runtime errors). I opened a new ticket on Aug 18 (+ATS-2412+: https://access-ci.atlassian.net/servicedesk/customer/portal/2/ATS-2412) which is still open. The response time on this new request has been very poor and the level of support unsatisfactory. You can see the activity log to understand what I mean. I was told yesterday that the person handling my ticket (name) is booked today and tomorrow and will be out on vacation next week with no guarantee that another person will be available to resume helping me on the issue after the holiday This issue is preventing me from conducting my research and I have some very important deadlines approaching. Considering the time-sensitive nature of this I'm wondering if the ACCESS support staff can help streamline the process with the Anvil folks or recommend a new cluster for me to use that has competent, timely support. ; Hello name, My name is name and I am the Sr. Operations Manager for User Support in the Rosen Center for Advanced Computing. This ticket was routed back to us. I've read your comments hear as well as the history of https://access-ci.atlassian.net/servicedesk/customer/portal/2/ATS-2412: https://access-ci.atlassian.net/servicedesk/customer/portal/2/ATS-2412|smart-link . As that ticket was assigned to name, it didn't get reassigned prior to his departure for vacation. I am confident that it was a simple oversight on his part. I will speak with my staff today to see if others feel they are equipped to assist in name's absence. I suspect that he is our best resource for this issue, hence why the ticket was assigned to him. We have a meeting this morning and then I am headed into several hours of meetings through the day well into the afternoon. I or one of my staff will respond to you by the end of the day. I can promise a response, but I can not promise a resolution by the end of the day. We will update this ticket soon. Thanks, name ; Thanks name, I appreciate that. I look forward to hearing from you later today. name ; Hi name brought your ticket to my attention, and I'd like to keep our discussions in one place for the sake of context. Do you mind if we resolve this ticket here and keep our discussions in ATS-2412? Kind regards, name ; Hi name, No problem, I will mark this ticket resolved and respond to your questions in ATS-2412. name ; Consolidating this ticket with ATS-2412 ;",ryanhass,Ryan Hass,rderue,Purdue University,Anvil,6,5,35,2023,2023-08-28
ATS-2722,Issue with hybrid job in wholenode,2023-08-31,2023-09-25,"Hi, I have been trying to implement hybrid job (which includes OpenMP and IMPI) in a wholenode for running some calculations using VASP. I am able to run a few calculations successfully using hybrid job but most of the calculations gets aborted due to a particular error for which I have attached the screenshot below. It would be much helpful if you can look into it as soon as possible. Thank you ; Good morning, which resource/system are you attempting to run your job on? ; Hi, I'm trying to run my calculations in Anvil (in a wholenode to be specific) ; Thanks - your ticket has been sent over to the Anvil team. ; Hi, I'm writing this email to know the status of my ticket. Hoping to hear from you soon. ; Hi Akilan, Thanks for contacting us! And apologize about the delay. I will run tests about this and let you know how it goes. Cheers, name, PhD (She/Her) Sr. Computational Scientist ; Thank you! Hoping to hear from you soon. Regards, Akilan ; Hi Akilan, Can you share one job ID or submit script which I can check? Are you using central-installed VASP on Anvil or your own compiled VASP? Cheers, name ; Sure. I have been running calculations on my own compiled VASP. And here is my submit script #!/bin/bash # FILENAME: myjobsubmissionfile #SBATCH -A DMR190076 # Allocation name #SBATCH --nodes=4 # Total # of nodes #SBATCH --ntasks-per-node=2 # Total # of MPI tasks per node #SBATCH --cpus-per-task=64 # cpu-cores per task (default value is 1, >1 for multi-threaded tasks) #SBATCH --time=48:00:00 # Total run time limit (hh:mm:ss) #SBATCH -J Co\\_phon # Job name #SBATCH -o myjob.o%j # Name of stdout output file #SBATCH -e myjob.e%j # Name of stderr error file #SBATCH -p wholenode # Queue (partition) name ##SBATCH --mail-user=useremailaddress ##SBATCH --mail-type=all # Send email at begin and end of job # Manage processing environment, load compilers and applications. module purge module load intel/19.0.5.281 impi/2019.5.281 intel-mkl hdf5 module list # Set thread count (default value is 1). export OMP\\_NUM\\_THREADS=$SLURM\\_CPUS\\_PER\\_TASK # Launch MPI code mpirun -np $SLURM\\_NTASKS /home/x-aramasamy/vasp.6.4/bin/vasp\\_std > result.vasp ; Hi Akilan, I tried to run hybrid jobs with central installed VASP on Anvil and the calculation went well. I am not sure if the error is related to your compilation with intel compiler. I did not compile VASP with intel compiler so I cannot re-produce the error you reported. Can you try to add '{{--mpi=pmi2}}' to mpi run, like {{srun -n $SLURM\\_NTASKS --mpi=pmi2 --cpu-bind=cores ...}} in your job script and see if it works? If not, I am not sure I know the root cause of this, because MPI process is very complex and it is hard to detect the reason. You might want to check VASP forum and see if there are some discussions about this. Or maybe re-compile VASP with gcc compilers on Anvil. For you reference, below is my job script, #!/bin/bash #SBATCH -A xxx # Allocation name #SBATCH --nodes=1 # Total # of nodes #SBATCH --ntasks=2 # Total # of MPI tasks #SBATCH --cpus-per-task=64 # cpu-cores #SBATCH --time=00:20:00 # Total run time limit (hh:mm:ss) #SBATCH -J xxx # job name #SBATCH -p shared # Queue (partition) name module --force purge module load gcc/11.2.0 openmpi/4.0.6 hdf5/1.10.7 module load vasp/6.3.0 export OMP\\_NUM\\_THREADS=$SLURM\\_CPUS\\_PER\\_TASK srun -n $SLURM\\_NTASKS --cpu-bind=cores vasp\\_gam Cheers, name ;",aramasamy@access-ci.org,Akilan Ramasamy,Nannan Shan,Purdue University,Anvil,11,18,35,2023,2023-08-28
ATS-2732,Not able to use SU for anvil CPU,2023-09-01,2023-09-05,"To whom it may concern, I converted some of the access credit available for the project mch230015 to anvil cpu, but when I log in I'm not able to see the balance or start a job with that account, I do not even have access to the folder. The PI of the project is my advisor name, does he need to allow me to use that? Because from the ACCESS website, I am able to manage everything about this project. Yours sincerely, name ; Hi name, Thanks for reaching out! Yes, you need to ask name to add you into mch230015 project. Right now, name is the only user in mch230015. name can login ACCESS website to add you. Hope it helps, Cheers, name, PhD (She/Her) Sr. Computational Scientist ; Perfect, thank you for the quick reply. Yours sincerely, name On Sep 1, 2023, at 1:33 PM, ACCESS Ticket Submission : mailto: wrote: | | Non si ricevono spesso messaggi name posta elettronica name : mailto:. Informazioni sul perché è importante: https://aka.ms/LearnAboutSenderIdentification | | |---- \\*External Email\\*: Use caution with attachments, links, or sharing data ---- | ; Hello, I hope your Tuesday is going well. Please have the PI, name, follow the steps here to add a user to an allocation: (https://allocations.access-ci.org/manage-allocations-overview: https://allocations.access-ci.org/manage-allocations-overview|smart-link ). Let us know if you have any questions along the way. If you have any questions in the future, please visit this site (https://access-ci.atlassian.net/servicedesk/customer/portal/2: https://access-ci.atlassian.net/servicedesk/customer/portal/2|smart-link ) and submit a ticket. name Pusateri ACCESS Allocations ;",mruggeri@access-ci.org,Matteo Ruggeri,Nannan Shan,Purdue University,Anvil,4,3,35,2023,2023-08-28
ATS-2767,Storage expansion,2023-09-04,2023-09-18,"I am on the anvil cluster at Purdue and I have hit the 1,048k file limit on my project, x-bio230069. However, I have only used 2.2TB out of 5TB. Is there a way I can increase the number of files I can put on the cluster? ; Hi name, Thank you for reaching out! Would you please let us know more about your files? It would also be helpful if you could share more details about your workflow and show the necessity for a file limit increase. Thanks, name ; Hi name, My maxed out number of files is primarily due to the sheer number of images in my dataset, of which I have ~1 million and would like to add at the moment another 200k. I am currently training a convolutional neural network (CNN) to identify if an animal is in a camera trap image. Due to the large variety of species and possible orientations within a given image, I require a robust dataset to train the CNN. I am conducting a lot of file processing and cleaning prior to uploading the data, so these images are just used to train the model and evaluate its performance. Increasing the file number limit would allow me to generate a more accurate model that reaches our required performance thresholds. Let me know if you would like any additional information. Best, name ; Hi name, Thanks for sharing the details! Is it possible for you to tweak your code to access the images from an archive form of the dataset, such as {{.zip}} or {{.tar}}? If you were using Python machine learning frameworks, we would suggest you check out {{zipfile}} or {{tarfile}}. Also, have you tried processing the images from your scratch directory, which should be more performant than from your group's project space? Thanks, name ; I will look into using a .zip or .tar file. For the scratch directory, doesn't that directory get wiped every so often? Or is that only the personal scratch directory? ; Hi name, Thanks! That should be your personal scratch directory (/anvil/scratch/x-ldenoncourt), and yes, inactive files that are not accessed in 30 days there will be purged. Thanks, name ; Hi name, I saw {{/anvil/projects/x-bio230069}} was still full, so I went ahead and increased its file number limit to 2M for you. You may check it out using the {{myquota}} command. I'm tentatively marking this ticket as resolved at this point. If you have any further questions, please feel free to reopen this ticket or file a new one. Thanks, name ; Hi name, Wonderful, thank you! Best, name Denoncourt ; No problem. Glad to help. Best, name ;",ldenoncourt@access-ci.org,Luke Denoncourt,Ruyi Li,Purdue University,Anvil,9,11,36,2023,2023-09-04
ATS-2791,Issues while accessing Purdue Anvil CPU,2023-09-05,2023-09-13,"Hello Team, I hope this email finds you well. I'm trying to login to Pursue Anvil CPU onDemand, for the first time, but ending up into following error message. Error -- failed to map user (: mailto:) Could you please let me know how to troubleshoot this? Thank you, ; Hi Jagan, Thank you for reaching outError\\_2.png|thumbnail! ; Hi Jagan, Sorry about that. I can see that your account should be fully set up for now. Could you please try it again and let us know if you still see any errors? Thanks, name ; Hi Jagan, Since you can log into Anvil now, I'm marking this ticket as resolved at this point. Thanks, name ; Hi name, thank you for closing this ticket. I just now checked and my login to Anvil is working. Best, ; Thanks, Jagan! Best, name ;",jsanghishetty,Jagan Mohan Sanghishetty,Ruyi Li,Purdue University,Anvil,8,7,36,2023,2023-09-04
ATS-2900,unable to log into Purdue ANVIL using my ACCESS account,2023-09-09,2023-09-18,"When I'm logging into ANVIL using my ACCESS account, after the DUO verification, I see this info: {{Error -- failed to map user ()}} Please let me know how to proceed. Thanksimage001.png|thumbnail I'm glad to hear back from you. Best, name ;",san2@access-ci.org,sensong an,Ruyi Li,Purdue University,Anvil,5,6,36,2023,2023-09-04
ATS-3049,queue times on Anvil,2023-09-15,2023-09-22,"Hello, I recently submitted several large jobs on Anvil (12 nodes, 1536 cores each), which have now been in the queue for 3-4 days. Previously, when I was running jobs on Anvil, queue times were quite short, often less than a couple minutes. Has something changed recently to increase queue times so substantially? I need to submit my PhD Thesis in 3 weeks, but I need the results of these runs in order to do that. With the long queue times, I am getting worried. I realize there are a lot of jobs waiting and that slurm optimizes them based on time and size, but given my very important deadline, is there any way to move up in the queue or place some priority on these jobs? Thank you. -name ; Hi name, Thanks for reaching out! I think right now the {{wholenode}} partition is quite busy (only 3 nodes are available now). Because more and more users are getting into Anvil now, so waiting time increasing can be expected. Is it possible to use {{shared}} queue for your job (maxmum 1 node, max running time is 96 hours)? I believe you can get into {{shared}} partition in a good turnaround time manner. Cheers, name, PhD (She/Her) Sr. Computational Scientist ;",ehightow@access-ci.org,Erin Hightower,Nannan Shan,Purdue University,Anvil,2,6,37,2023,2023-09-11
ATS-2995,VASP on GPU,2023-09-13,2023-09-14,"Hello! I was wondering if there was VASP 5.4.4 compiled on GPUs? Could you show me a sample script if possible? Thank you for your help and understanding. Best, name ; \\*\\*PRIVATE NOTE\\*\\* Duplicate ticket, closing this one. ;",qqian@access-ci.org,Qian Qian,,,Anvil,2,2,37,2023,2023-09-11
ATS-2999,VASP on GPU,2023-09-14,2023-09-14,"Good morning! I was wondering if there was VASP 5.4.4 compiled on GPUs? Could you show me a sample script if possible? Thank you for your help and understanding. Best, name ; Hi name, Thanks for reaching out! We do not have GPU version of VASP installed on Anvil right now. It is on our checking list but there is no ETA of when it would be available. Cheers, name, PhD (She/Her) Sr. Computational Scientist ;",qqian@access-ci.org,Qian Qian,Nannan Shan,,Anvil,2,1,37,2023,2023-09-11
ATS-3003,Need ESMI_IB_LIBRARY installed on Anvil,2023-09-14,2023-09-20,"Hi Anvil support team, We are trying to install https://variorum.readthedocs.io/en/latest/: https://variorum.readthedocs.io/en/latest/|smart-link tool to capture different performance metrics of our jobs, and this tool has ESMI\\_IB\\_Library as a dependency. Since installation of this library requires sudo privileges, we were wondering if there is a chance that you might be able to install this for us on the Anvil? And if not, do you have any suggestions? Please let us know. Thank you. Regards, Strahinja Trecakov ; Hi Strahinja, Thank you for reaching out You might want to try other ways to track the performance metrics of your jobs. I'm tentatively marking this ticket as resolved at this point. Please feel free to contact us again if you have any questions. Thanks, name ; Thank you for looking into this. Regards, Strahinja Trecakov Enterprise Programmer Analyst Information and Communication Technologies New Mexico State University ;",trecakov@access-ci.org,Strahinja Trecakov,Ruyi Li,Purdue University,Anvil,4,5,37,2023,2023-09-11
ATS-3025,Storage on Anvil,2023-09-15,2023-09-20,"I am going to run turbulence simulations on Anvil. A single simulation will generate large data (a few TB). There will be several simulations. I need to store the data after the simulation because the entire simulations and analysis is going to take some time. Expanse has storage allocations but I could not find that on Anvil. How should I store my data generated on Anvil? ; Hi Inanc , Thank you for reaching out! On Anvil, you should get a personal scratch directory, with a quota of 100TB and 1M files, for temporary storage of working data. Additionally, your project should get a project directory for long-term data storage and sharing, with a quota of 5TB and 1M files. It seems that your project just got an allocation on Anvil, and your accounts and directories have not been completely set up. The process may take some time. Once everything ready, you may run the {{myquota}} command on Anvil to see the quotas and usage of the directories that you have access to. We have a documentation on Anvil filesystems at the following link: RCAC - Knowledge Base: Anvil User Guide: File Systems: https://www.rcac.purdue.edu/knowledge/anvil/storage/filesystems I hope this helps. If you have any further questions, please let me know. Thanks, name ; Dear name, If I am actively working with data on the scratch directory, is there a time limit to how long I can keep them on scratch directory since the creation of the data? ---- ; Hi Inanc, If the files in your scratch space are not accessed in 30 days, they will be purged. There will be no notifications about the purges. Therefore, I would suggest you have your data backed up on a regular basis to avoid data loss. I just checked your account on Anvil. It seems the directories are ready for you to use: $ ls -dl /home/x-senocak drwx------ 3 x-senocak x-ees230052 13 Sep 15 17:40 /home/x-senocak $ ls -dl /anvil/scratch/x-senocak drwx------ 2 x-senocak x-ees230052 4096 Sep 15 17:50 /anvil/scratch/x-senocak $ ls -dl /anvil/projects/x-ees230052 drwxrws---+ 2 root x-ees230052 4096 Sep 15 17:45 /anvil/projects/x-ees230052 If you have any further questions, please let me know. Thanks, name ; Hi Inanc, It seems your questions have been answered. I'm tentatively marking this ticket as resolved at this point. Please feel free to contact us again if you have any questions. Thanks, name ;",senocak,Inanc Senocak,Ruyi Li,Purdue University,Anvil,5,4,37,2023,2023-09-11
ATS-3039,My submitted jobs have been queuing for more than 7 days.,2023-09-15,2023-09-20,"My jobs have been in the queue line for about a week. While I see several works at the same amount of time and a number of nodes requested from others get run, why have my works been queuing for too long than usual? Are there any issues with my account? I need help because if I have to wait for another week or longer without knowing what's going on, that could delay my work which could strongly affect my graduation timeline ; Hi, Thank you for contacting us. As you might have been noticed, there was a system outage for Anvil during the last weekend so that should the root cause for your jobs. If you check with {{jobinfo jobid}} you may find the State 'NODE\\_FAIL,CANCELLED' which means the job should have run for sometime and it has been canceled due to the outage, but you are still seeing those jobs ""pending"" in the queue. We apologize for the inconvenience but you will have to re-summit those jobs. We will refund those burning SUs for your allocation as well. Could you confirm if the following jobs are the ones that have been impacted? $ squeue -u x-tjitsuk JOBID USER ACCOUNT NAME NODES CPUS TIME\\_LIMIT ST TIME 2666649 x-tjitsuk phy130027 n05cvck 4 512 4-00:00:00 PD 0:00 2664861 x-tjitsuk phy130027 tweak30pc\\_multi 16 2048 4-00:00:00 PD 0:00 2664193 x-tjitsuk phy130027 tweakdens\\_multi 16 2048 4-00:00:00 PD 0:00 2681801 x-tjitsuk phy130027 mst\\_fullrfp 4 512 4-00:00:00 PD 0:00 2682719 x-tjitsuk phy130027 n06\\_test 8 1024 4-00:00:00 PD 0:00 2673090 x-tjitsuk phy130027 multiscale 16 2048 3-00:00:00 PD 0:00 2682833 x-tjitsuk phy130027 n06\\_test\\_nx256 8 1024 4-00:00:00 PD 0:00 2685452 x-tjitsuk phy130027 n06 4 512 2-00:00:00 PD 0:00 2702871 x-tjitsuk phy130027 n05\\_ppg 8 1024 1-00:00:00 PD 0:00 Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi name, Yes, those are the jobs that are affected. Thanks for your answer. I didn't know what was going on, and it's good I know it now. I will resubmit my work again. Thank you so much for the answer. Cheers, Taweesak On Sep 15, 2023, at 14:51, ACCESS Ticket Submission wrote: ; Hi Taweesak, Sure. I will calculate the SUs and fulfill the refund for you. Will get back to you when it's done. Best, name ; Thank you so much. So appreciate it. --Taweesak On Sep 15, 2023, at 14:58, ACCESS Ticket Submission wrote: ; Hi name, Although I have resubmitted my jobs, it seems that Anvil is still taking a much longer time to get my jobs run. I'm concerning if the problem will lasting longer which can cause two problems: 1) I can't get my jobs run in a time manner, causing the delay of my graduation, 2) we cannot burn all the hours we allocated as expected, causing a bad justification of the new proposal. I have seen some project accounts can have their jobs run in a short queuing time. It's not the case for ours. Are there any other issues with our account? If it's possible, I will be so grateful if you could tell the average wait time for the present condition. Thanks for understanding. Best regards, Taweesak Jitsuk jobinfo 2709958 Name : n06\\_test\\_nx256 User : x-tjitsuk Account : phy130027 Partition : wholenode Nodes : None assigned Cores : 1024 GPUs : 0 State : PENDING (Priority) ((null)) ExitCode : -- Submit : 2023-09-15T16:03:22 Start : -- End : -- Waited : 2-22:10:22 Reserved walltime : 4-00:00:00 Used walltime : -- Used CPU time : -- % User (Computation): -- % System (I/O) : -- Mem reserved : 1964160M Max Mem used : -- Max Disk Write : -- Max Disk Read : -- On Sep 15, 2023, at 14:55, TAWEESAK JITSUK wrote: Hi name, Yes, those are the jobs that are affected. Thanks for your answer. I didn't know what was going on, and it's good I know it now. I will resubmit my work again. Thank you so much for the answer. Cheers, Taweesak On Sep 15, 2023, at 14:51, ACCESS Ticket Submission wrote: ; Hi, I have refunded a total of 1,185,950 SUs to your allocation 'phy130027'. It should be ready to use in the next couple of days. Will resolve this ticket. Feel free to re-open it if you have further questions. Best, name ; Thank you for the refund. I sent another concern email yesterday and you might not see it yet. Please kindly make some comments on this concern. ; Hi name, Although I have resubmitted my jobs, it seems that Anvil is still taking a much longer time to get my jobs run. I'm concerning if the problem will lasting longer which can cause two problems: 1) I can't get my jobs run in a time manner, causing the delay of my graduation, 2) we cannot burn all the hours we allocated as expected, causing a bad justification of the new proposal. I have seen some project accounts can have their jobs run in a short queuing time. It's not the case for ours. Are there any other issues with our account? If it's possible, I will be so grateful if you could mention the average wait time for the present condition, and when should I expect it to be resolved. Thanks for understanding. Best regards, Taweesak Jitsuk jobinfo 2709958 Name : n06\\_test\\_nx256 User : x-tjitsuk Account : phy130027 Partition : wholenode Nodes : None assigned Cores : 1024 GPUs : 0 State : PENDING (Priority) ((null)) ExitCode : -- Submit : 2023-09-15T16:03:22 Start : -- End : -- Waited : 2-22:10:22 Reserved walltime : 4-00:00:00 Used walltime : -- Used CPU time : -- % User (Computation): -- % System (I/O) : -- Mem reserved : 1964160M Max Mem used : -- Max Disk Write : -- Max Disk Read : -- On Sep 19, 2023, at 14:02, name wrote: ; Hi, Thank you for the updates. The reason for the current long waiting time is simple because of the busy status on wholenode partition. You may check the availability with showpartitions. I saw three of your jobs have been started so you might need to be patient while rest of the jobs are waiting. Best, name ;",jitsuk@access-ci.org,TAWEESAK JITSUK,Guangzhen Jin,Purdue University,Anvil,9,4,37,2023,2023-09-11
ATS-3100,Job submitted on Anvil never get queued up successfully,2023-09-18,2023-09-21,"Hi there, I'm an anvil supercomputer user. Prior to last week, the job I submitted could run without much waiting time(sometimes takes a few minutes to wait), but after last weekend when my jobs were killed and automatically got requeued, my jobs could never get to run. It has been pending for a week since I sbatch my job. I wonder if my SLURM status has changed due to the requeue? Thanks Yida ; Hi Yida, Thank you for contacting us. Yes I can see this issue as well for other users. I suspect it was related to the 09/10 weekend's Anvil outage (https://operations.access-ci.org/node/645: https://operations.access-ci.org/node/645|smart-link ). We are still investigating the root cause and will get back to you when we find a clue. Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi, I believe the job scheduling should be fine at the moment despite the fact that {{wholenode}} partition is busy. I saw two of your jobs have been started. Do you have further questions about this issue? Best, name ; Hi name, I think it's fine now. Thanks Yida 从 Windows 版邮件: https://go.microsoft.com/fwlink/?LinkId=550986发送 \\*发件人:\\* name: mailto: \\*发送时间:\\* Wednesday, September 20, 2023 12:01 PM \\*收件人:\\* name, Yida: mailto: \\*主题:\\* ATS-3100 Job submitted on Anvil never get queued up successfully ; Hi, Thank you for the update. Glad it's working for you now. Will close the ticket then. Best, name ;",yidali,Yida Li,Guangzhen Jin,Purdue University,Anvil,5,4,38,2023,2023-09-18
ATS-3168,Queue stuck on Anvil,2023-09-20,2023-09-22,"Greetings, My queue on the Anvil has been kept pending for two weeks. Can you check the status of my account, as it should still have plenty core hours? Thank you. ; Hi name, Thanks for reaching out! I saw you have 2 jobs pending, one on wholenode partition with requesting 16 nodes, and another on wide partition with requesting 32 nodes. Unfortunately, in the past few weeks, wholenode and wide partition are very busy. At current time (3pm ET), we only have 2 nodes available. And many users are waiting on wholenode to get jobs started. If you can fit your job into shared partition, which has 174 nodes available now, shared partition would be a good option now. Feel free to check more details about Anvil partitions at https://www.rcac.purdue.edu/knowledge/anvil/run/partitions: https://www.rcac.purdue.edu/knowledge/anvil/run/partitions|smart-link Cheers, name, PhD (She/Her) Sr. Computational Scientist ;",andytsao@access-ci.org,Shu-Wei Tsao,Nannan Shan,Purdue University,Anvil,2,3,38,2023,2023-09-18
ATS-3272,File access issues,2023-09-24,2023-09-25,"Hello, I'm having trouble reading and writing files generated by my simulations from the shell or in Python scripts. I can't download them either using WinSCP, it gives an error. For example, in the /anvil/scratch/x-psharma3/1-4-9-12/1-4-9-12/128, I try to use bash commands like ""wc -l HILLS.123"" , ""cat HILLS.123"", or run a Python script that opens the text file using the built-in reader. In the shell, I get errors like this: ""cat: HILLS.123: Input/output error"". When I try to run the Python script, I get a similar error: ""OSError: Errno 5 Input/output error."" I've run the script successfully in the past few days. I am the owner of all these files as well. I'm very concerned that these files are damaged in some way, but don't know how they could be damaged as their ""changed"" (last modified) dates are very far back, and I had full input/output access to all these files before today. These data are the main results of the manuscript I have been writing for a few years. I have some backups, but it would set me back a lot if these files were lost. I hope you can help me resolve this issue, as I'm not sure what's going on here. Thanks, name ; Hi, Thank you for contacting us and reporting the issue. There was a glitch on the filesystem and it has been fixed by our engineering team. Could you please try again and see if it's still an issue for you? Best regards, name Senior Computational Scientist Purdue Information Technology ; Hello, The issue seems to be resolved! Thank you. Best, name ---- ;",psharma3,Pranav Sharma,Nannan Shan,Purdue University,Anvil,3,1,38,2023,2023-09-18
ATS-3186,Job got kicked off wholenode before it finished (no error),2023-09-20,2023-09-22,"I was running a job on wholenode and it stopped running before it finished. There is nothing in the SLURM log or the job output file indicating anything went wrong. I'm not sure why it stopped. The job number is 2736583, and the path to the job directory is ""/home/x-egormley/qe\\_calcs/MIL125/2\\_wfn/bands"" ; Hi Eoghan, Thanks for reaching out! It is hard to tell what happened since there are no error messages. I would recommend to resubmit the job to see if the problem is consistent. I see you have requested '--ntasks-per-node=120'. I would recommend to use 'shared' partition instead of 'wholenode'. You will be charged with 'wholenode' although you only requested 120 cores. And 'shared' partition is less busy as wholenode. Hope this helps. Cheers, name, PhD (She/Her) Sr. Computational Scientist ;",egormley@access-ci.org,Eoghan Gormley,Nannan Shan,Purdue University,Anvil,2,3,38,2023,2023-09-18
ATS-3199,extend session time,2023-09-21,2023-09-25,"Hi, I'm training a LLM, can you please extend the below session for another 48 hours? Thank you very much Ji ---- ;",maji@access-ci.org,Ji Ma,Ruyi Li,,Anvil,4,3,38,2023,2023-09-18
ATS-3294,Anvil Storage,2023-09-25,2023-10-02,"Hi, I use the Anvil cluster as an ACCESS user (with ID: x-mzand). For a particular experiment, we require at least 5 TB of storage, while my available storage in the home directory is only 25 GB. I am wondering if we can ask for more storage and, if so, how the procedure works. Thank you, name ; Hi name, Thank you for contacting us. Your scratch directory on Anvil has a quota of 100TB storage and 1M files, which should be an ideal space for you to temporarily store your working data. Additional, your project should have a shared space for software installation and data sharing. You may run the {{myquota}} command on Anvil to see the usage and quotas on the spaces that you have access to. More details can be found at the following webpage: RCAC - Knowledge Base: Anvil User Guide: File Systems: https://www.rcac.purdue.edu/knowledge/anvil/storage/filesystems If you have any further questions, please let me know. Thanks, name ; Hi name, It looks like you have been using your scratch directory on Anvil. Since I have not heard further questions from you in a while, I'm tentatively marking this ticket as resolved at this point. Please feel free to contact us again if you need any help. Thanks, name ; Hi name, Thank you so much for your assistance. Yes, I'm now using the scratch directory, and it meets my current storage requirements. Please feel free to close this ticket. Best, name ---- ; Hi name, Great! Glad to know that. We appreciate your feedback. Thanks, name ;",mzand,Mohsen Zand,Ruyi Li,Purdue University,Anvil,5,6,39,2023,2023-09-25
ATS-3246,Question about compiling on Anvil,2023-09-22,2023-09-26,"Hihttps://mailfoogae.appspot.com/t?sender=aYWlkaV96aGFuZ0BiZXJrZWxleS5lZHU%3D&type=zerocontent&guid=83baa1a1-7445-4b78-a8db-a68d7340e79c!ᐧ ; Hi Aidi, Thank you for the updates. We might need to take a look at the login03. For now I will close this ticket. Best, name ;",zad238,Aidi Zhang,Guangzhen Jin,Purdue University,Anvil,4,3,38,2023,2023-09-18
ATS-3265,File system error at Anvil,2023-09-24,2023-09-26,"My running job #2748778 stopped generating output at 10:59am eastern time and some of the output files are not readable at all (/anvil/scratch/x-pochao/ABCG2/backward.log read error no content). Some output files of earlier completed jobs are also not readable (tail /anvil/scratch/x-pochao/VDACmonomer/delN23/remix1/run04.log gets I/O error). Also, unable to retrieve files in these directories remotely via scp, got ""no match"" error even though the file names are copied from {{ls}} in anvil headnode. ; Hi, Thank you for contacting us and reporting the issue. There was a glitch on the filesystem and it has been fixed by our engineering team. Could you please try again and see if it's still an issue for you? Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi, I'm downloading the output files of the previously completed jobs, they seem fine and completely readable. The output files of the frozen job when the file system glitched were corrupted but it's somewhat salvageable from an earlier checkpoint. Thanks \\_ \\_Under the Illinois Freedom of Information Act any written communication to or from university employees regarding university business is a public record and may be subject to public disclosure.\\_\\_ —-—-—-— Reply above this line. name commented: Hi, Thank you for contacting us and reporting the issue. There was a glitch on the filesystem and it has been fixed by our engineering team. Could you please try again and see if it's still an issue for you? Best regards, name Senior Computational Scientist Purdue Information Technology ---- Automation for Jira changed the status to Waiting for customer. [View request: https://urldefense.com/v3/\\_\\_https:/access-ci.atlassian.net/servicedesk/customer/portal/2/ATS-3265?token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ0Z3QiOiJhbm9ueW1vdXMtbGluayIsInFzaCI6IjA0ODJmYjllZTkwZjNlNDZhZjJkMDQxZjFiMGZjMzRiMDViNTA0MzFjZTAwNWFmMjEyNmNkODg1OGY4ZjFiMTgiLCJpc3MiOiJzZXJ2aWNlZGVzay1qd3QtdG9rZW4taXNzdWVyIiwiY29udGV4dCI6eyJ1c2VyIjoiMTI2NjMiLCJpc3N1ZSI6IkFUUy0zMjY1In0sImV4cCI6MTY5ODA2OTgwMiwiaWF0IjoxNjk1NjUwNjAyfQ.XWvmhcmaztCNy7FX\\_efYTuNkKpdGEseGUYYg0azkqFE&sda\\_source=notification-email\\_\\_;!\!DZ3fjg!7MMLnzlW19a-5PwiPFwlDZnHHKjvYeuj0-ttux4f9CBRTy5d9EQ5bZscAa4MGD0Jdl44IaMs05qWXE1wPMW8t\\_u4$ · Turn off this request's notifications: https://urldefense.com/v3/\\_\\_https:/access-ci.atlassian.net/servicedesk/customer/portal/2/ATS-3265/unsubscribe?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ0Z3QiOiJhbm9ueW1vdXMtbGluayIsInFzaCI6IjdkNDdiZTdiYzc1Mjk0YWZhZDQwMTI2YjZmZjBhNGE3ZGZiODc0ZjU4NzM1MDdhMzJlZmNlZjkwZDgxMjVmZDgiLCJpc3MiOiJzZXJ2aWNlZGVzay1qd3QtdG9rZW4taXNzdWVyIiwiY29udGV4dCI6eyJ1c2VyIjoicW06YjkxYzliMTctNjYwZi00YTUzLWE2N2EtNTAwMzYxMDZmNTlhOmQ5NmRlYWI2LTk3NWItNDM5Ny04NDYzLWFjZTViYTMzNGRiMCIsImlzc3VlIjoiQVRTLTMyNjUifSwiZXhwIjoxNjk4MDY5ODAyLCJpYXQiOjE2OTU2NTA2MDJ9.1u-dWUr0lfjNcfukLDb5MoXWAaI4SfE9wiRSmkErKsI\\_\\_;!\!DZ3fjg!7MMLnzlW19a-5PwiPFwlDZnHHKjvYeuj0-ttux4f9CBRTy5d9EQ5bZscAa4MGD0Jdl44IaMs05qWXE1wPO\\_ngDs\\_$ This is shared with . Sent on September 25, 2023 9:03:22 AM CDT ; Hi, Thank you for the update. Will close the ticket then. Let me know if you need further assistance. Best, name ;",pochao@access-ci.org,Po-Chao Wen,Guangzhen Jin,Purdue University,Anvil,4,2,38,2023,2023-09-18
ATS-3282,Regarding job,2023-09-25,2023-09-25,"Hello Anvil community, I have submitted an Amber job in Anvil, and all my jobs are in the queue (PD). The running job was also automatically canceled. Can you please help me sort out this problem? Regards, Aashish ; Hi Aashish, Sorry about that. It seems nodes in the gpu partition became offline around 10:38 this morning. I've reported it to our engineers and will keep you updated. Your patience is greatly appreciated. Thanks, name ; Hi Aashish, Our engineers have brought all the g nodes back online. Looks like one of your jobs has started running. @login00.anvil:~ $ sinfo -sp gpu PARTITION AVAIL TIMELIMIT NODES(A/I/O/T) NODELIST gpu up infinite 13/3/0/16 g000-015 login00.anvil:~ $ squeue -u x-abhatt JOBID USER ACCOUNT NAME NODES CPUS TIME\\_LIMIT ST TIME 2754771 x-abhatt mcb160119-gpu small\\_dist 1 1 2-00:00:00 R 26:58 I'm tentatively marking this ticket as resolved at this point. If you see any further issues or have any questions, please feel free to reopen this ticket or file a new one. Thanks, name ;",abhatt@access-ci.org,AASHISH BHATT,Ruyi Li,Purdue University,Anvil,3,1,39,2023,2023-09-25
ATS-3290,running instance changed to queued,2023-09-25,2023-09-27,"Hi, I had a running job on below instance (probably?) but the status of this instance now changed to Queued. Jupyter Notebook: https://ondemand.anvil.rcac.purdue.edu/pun/name/dashboard/batch\\_connect/name/jupyter/session\\_contexts/new (2753119) Please help me check this issue, thanks! Best, Ji ; Hi Ji, Sorry about that. The nodes in the gpu partition went offline around 10:38AM (09/24/2023) for some reason, and job 2753119 was affected. Our engineers have brought those nodes back online. It seems job 2753119 has been requeued and restarted on 09/25. Would you please let us know if you still see any further issues? Thanks, name ;",maji@access-ci.org,Ji Ma,Ruyi Li,,Anvil,2,3,39,2023,2023-09-25
ATS-3305,creating an account for Purdue ANVIL,2023-09-25,2023-09-27,"Hello, we were just granted an ACCESS allocation and requested the credits for use on Purdue Anvil CPU. I can see the available SUs on the ""Allocations Usage"" page. However, I don't see these resources listed under ""manage users"". When following the instructions to first log in to Anvil, I followed this link (ondemand.anvil.rcac.purdue.edu: https://ondemand.anvil.rcac.purdue.edu/) an logged on. However, I was just met with this error: ""{{Error -- failed to map user ()}}"" Is there something else I need to do to assign users to be able to use/log in to Anvil? Thank you very much. Sincerley, name Dick ; Hi name, Thank you for reaching out! It sounds like it might take some time for the ACCESS website to list the resource providers in the ""Manage Users"" section. For now, I can see that your account should be fully set up on Anvil. Would you please try logging into Anvil Open OnDemand again and let me know if you still see any errors? name Burrell and name Johnsen should also have access now. name was just added to your allocation today and their account will be ready soon. Thanks, name ; Hi name, It seems you have been running jobs on Anvil and name should also have access now. I'm tentatively marking this ticket as resolved at this point. Please feel free to reach out to us again if you have any questions. Thanks, name ;",scdick@access-ci.org,Sonya Dick,Ruyi Li,Purdue University,Anvil,3,3,39,2023,2023-09-25
ATS-1814,"code only ran 10 iterations instead of 50, didn't output all print statements",2023-07-12,2023-10-11,"I am running code on the super computer. It should run 50 iterations, but it stops running after 10 iterations. Also, I tried to print something at each iteration, but there is nothing in the output file. ; Which system/resource are you running on? Thanks! ACCESS Support ; I am using anvil. ; Hi Bianca, Apologies that this ticket slipped through. Would you please let us know if you still see the same issue with your jobs? If you still need assistance on this issue, would you please share the IDs of the problematic jobs if it is possible? Thanks, name ; Hi Bianca, Since I have not heard back from you in a while, I'm tentatively marking this ticket as resolved at this point. If the issue persists, please feel free to reopen this ticket or submit a new one to us. Thanks, name ;",bchampenois,Bianca Champenois,Ruyi Li,Purdue University,Anvil,5,66,28,2023,2023-07-10
ATS-3576,Segmentation fault on job that ran normally previously,2023-10-06,2023-10-16,"I tried rerunning a job that previously ran without any issues, but for some reason it's now failing immediately. I'm getting the following message: srun: error: a002: task 0: Segmentation fault ] wait\\_proxies\\_to\\_terminate (../../../../../src/pm/i\\_hydra/mpiexec/intel/i\\_mpiexec.c:528): downstream from host a002 exited with status 139 main (../../../../../src/pm/i\\_hydra/mpiexec/mpiexec.c:2077): assert (exitcodes Eoghan ; ^myjob.e2964701 ; Hi Eoghan, Thanks for reaching out! The error message looks like a MPI error. I guess you were using intel MPI. When you evoke mpi process, have you tried to add {{--mpi=pmi2}} in your submit script? For example if you were using {{srun}}, it would be {{srun --mpi=pmi2 -n ...}} Feel free to check more details about this topic at [https://www.rcac.purdue.edu/knowledge/anvil/run/examples/slurm/mpi: https://www.rcac.purdue.edu/knowledge/anvil/run/examples/slurm/mpi|smart-link Regards, name, PhD (She/Her) Sr. Computational Scientist ;",egormley@access-ci.org,Eoghan Gormley,Nannan Shan,Purdue University,Anvil,3,7,40,2023,2023-10-02
ATS-3767,Work aborted due to missing modules,2023-10-17,2023-10-17,"All my work on Anvil has been aborted due to missing modules. Resubmission does not go through. Please see the messages below: ======================================== ./gene\\_anvil: error while loading shared libraries: /anvil/projects/x-phy130027/libraries/slepc\\_3.19.1/gcc\\_11.2/lib/libslepc.so.3.19: cannot read file data: Input/output error ; Primary job terminated normally, but 1 process returned a non-zero exit code. Per user-direction, the job has been aborted. ; ./gene\\_anvil: error while loading shared libraries: /anvil/projects/x-phy130027/libraries/slepc\\_3.19.1/gcc\\_11.2/lib/libslepc.so.3.19: cannot read file data: Input/output error ; Hi TAWEESAK, Thank you for reporting this issue. Our engineers are investigating. I'll keep you updated. Thanks, name ; Hi TAWEESAK, The issue with the project filesystem should be fixed now. Would you please give it another try and let us know if you still see any errors? Thanks, name ; hi name, I have tried that, and the system is working fine now. Thanks! Excellent work! Cheers, Taweesak On Oct 17, 2023, at 15:24, name wrote: ; Taweesak, Awesome! Thanks for confirming! I'll go ahead and mark this ticket as resolved then. Please feel free to contact us again if you have any other questions. Thanks, name ;",jitsuk@access-ci.org,TAWEESAK JITSUK,Ruyi Li,Pittsburgh Supercomputing Center (PSC),Anvil,6,1,42,2023,2023-10-16
ATS-3770,Cannot edit or see certain text files on Anvil,2023-10-17,2023-10-17,"Hello, I am unable to edit or see the contents of some text files on Anvil. I get the following error, for example, if I try to open the file /anvil/projects/x-dmr110007/PRISMS\\_name/phaseField/applications/alloySolidification\\_DSI-R\\_full/parameters.prm using the text editor ""nano"": magic\\_file(parameters.prm) failed: cannot read `parameters.prm' (Input/output error) The same happens with the same file (parameters.prm) located in the subdirectories AS\\_DSI-R\\_full\\_xtra\\_pad\\_uniform, and AS\\_DSI-R\\_full\\_xtra\\_pad\\_no\\_outputs However I can see and edit the same file in the subdirectory AS\\_DSIR\\_full\\_xtra\\_pad\\_dt\\_2p5e-4 I am certain these files were editable before because I modified them myself. FYI, the last time I login was on Sep 27 11:47:12. Do you know what could be going on? Thank you I'll go ahead and mark this ticket as resolved then. Please feel free to contact us again if you have any other questions. Thanks, name ;",dmontiel@access-ci.org,David Montiel,Ruyi Li,Purdue University,Anvil,5,1,42,2023,2023-10-16
ATS-3772,Question about job 3219615 and 3519803,2023-10-17,2023-10-17,"Hi, I have questions about two failed jobs. These two jobs began running yesterday. But they failed and requeued for a few times this morning. Job 3219803 (path: /anvil/scratch/x-aidiz/jovian/anelastic6/tests\\_qglayer/type4/test06) failed but job 3219615 (path: /anvil/scratch/x-aidiz/jovian/anelastic6/tests\\_qglayer/type4/test05) is running for its second time right now. The error message on the failing job (3219803) looks like this, a980:71207:0:71207 ib\\_mlx5\\_log.c:177 Transport retry count exceeded on mlx5\\_0:1/IB (synd 0x15 vend 0x81 hw\\_synd 0/0) a980:71207:0:71207 ib\\_mlx5\\_log.c:177 DCI QP 0x4f6 wqe4343: SEND s-e rqpn 0x1398 rlid 1190 inl len 10 I have been using a similar script on Anvil for a while and have not encountered this problem. I wonder if it is because of some hardware issue on Anvil's side. Should I kill the job that is running if this is a persisting problem? How would Anvil charge us when the job fails and automatically requeue? ; Hi Aidi, Thank you for reaching out Best, !https://mailfoogae.appspot.com/t?sender=aYWlkaV96aGFuZ0BiZXJrZWxleS5lZHU%3D&type=zerocontent&guid=d58fd229-26cf-49e7-ae13-e28dc3325e29!ᐧ ; Great! Glad to know that. The two jobs have just been refunded. $ mybalance x-aidiz Allocation Type name Limit name Usage name Usage name Balance Account (account) (user) ============= ==== ========== ========== ========== ========== cts190047 CPU 375000.0 36568.3 36568.3 338431.7 phy220056 CPU 7038052.0 175350.4 165498.3 6862701.7 I'm tentatively marking this ticket as resolved at this point. Please feel free to contact us again if you have any further questions. Thanks, name ;",zad238@access-ci.org,Aidi Zhang,Ruyi Li,Purdue University,Anvil,4,1,42,2023,2023-10-16
ATS-3870,Public IP needed for Anvil composable container,2023-10-22,2023-10-24,"The ""proxy-public"" service within the ""geoedf-jupyter"" namespace of project EES220056 currently has assigned the private campus IP of 172.21.168.114, but it needs a public IP so that it can properly get an SSL certificate and DNS name so that CILogon can reach the callback URL. ; Hi name, You can use an Ingress to get a public URL for your hub. If you are using the zero to jupyterhub helm chart you can add it this way in your values.yaml. ingress: enabled: true hosts: - .anvilcloud.rcac.purdue.edu Hope that helps. I'll mark this resolved, but feel free to respond if you have any troubles. -name ;",thompscs@access-ci.org,Christopher Thompson,Erik Gough,Purdue University,Anvil,2,2,42,2023,2023-10-16
ATS-3787,Unable to submit batch job on Anvil,2023-10-18,2023-10-18,"Hi, When I tried to submit a batch job on Anvil. I received this error message below even though I believe my group should have sufficient name allocation. My anvil username (-x): cgoh. sbatch: error: AssocGrpCPUMinutesLimit sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits) Would appreciate any assistance I can get. Thank you For your reference, cts130006 is expired so we don't need that anymore. Thanks, Chian ; Thanks for letting me know. I am glad it works now Regards, name ;",cgoh@access-ci.org,Chian Yeh Goh,Nannan Shan,,Anvil,4,1,42,2023,2023-10-16
ATS-3794,VASP6,2023-10-18,2023-10-18,"Good afternoon, I was wondering if you could grant me access to VASP6. My license number is 23-0320 5-2055 Thank you very much for your support! Best, name ; Hi name, Thanks for reaching out! You have been added to vasp6 group on Anvil. Your membership will be ready within a few hours. Please check our user guide for VASP calculations on Anvil. https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/vasp: https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/vasp|smart-link Regards, name, PhD (She/Her) Sr. Computational Scientist ;",qqian@access-ci.org,Qian Qian,Nannan Shan,,Anvil,2,1,42,2023,2023-10-16
ATS-3766,Job failed,2023-10-17,2023-10-20,"Hello, I am running an Amber job, and all of my jobs have suddenly failed. Could you please check what the issue was? ; Hi AASHISH, Thank you for reaching out! To help us investigate, would you please share the ID of your Amber job? Thanks, name ; Hi name, All my job is cancelled. The job Id. is: JobID JobName Partition Account AllocCPUS State ExitCode ; -------- 3219851 test\\_2 gpu mcb160119+ 1 FAILED 2:0 3222096 test\\_10 gpu mcb160119+ 1 FAILED 2:0 3217378 C66L\\_s\\_r2 gpu mcb160119+ 1 FAILED 1:0 3217379 C66L\\_s\\_r3 gpu mcb160119+ 1 FAILED 1:0 3217466 r3A\\_2 gpu mcb160119+ 1 FAILED 2:0 3217475 r\\_4 gpu mcb160119+ 1 FAILED 2:0 3223071 test\\_10 gpu mcb160119+ 1 FAILED 2:0 3223074 r\\_4 gpu mcb160119+ 1 FAILED 2:0 Even if I am submitting a new job, it automatically cancelled without giving any error. Regards, Aashish ---- ; Hi Aashish, Thanks for sharing the further information! I highly suspect the jobs were terminated because of the temporary issue with the project fileset. It should be fixed now. It seems you currently have 4 jobs running. Do you still see any errors with them? Thanks, name ; Hi Aashish, I believe the issue should be fixed and it seems you have several jobs completed over the last a couple of days. I'm tentatively marking this ticket as resolved at this point. If you have any further questions, please feel free to re-open this ticket or submit a new one to us. Thanks, name ;",abhatt@access-ci.org,AASHISH BHATT,Ruyi Li,Purdue University,Anvil,5,4,42,2023,2023-10-16
ATS-3817,Submitted jobs waiting since 9/28,2023-10-18,2023-10-19,"I am using allocation DMR970008. We have used 99% of allocation on Anvil, but It should still have 39144 SUs left. I submitted 4 jobs (job id = 2780028, 2780095, 2780109, 2780124) on 9/28, but it still waiting in line. Why does not jobs start? Thank you. ; Hello, I hope your Thursday is going well. The Allocations Team recommends submitting a Supplement on your Maximize Allocation (DMR970008) to get more SUs on resources. When you submit the Supplement, please add a progress report. The Progress Report should describe how the PI's current allocation was used and summarize the findings or results. Follow these steps to submit a Supplement: Starting at the ACCESS Home Page \\* Login to ACCESS: https://allocations.access-ci.org: https://allocations.access-ci.org/ \\* Once on the ACCESS Allocation page, click on ""Manage Allocations."" \\* Within ""Manage Allocations,"" click on ""Manage My Projects."" Now Starting at the List of Allocation Request Page \\* Go to the List of ACCESS Allocations Requests page: https://allocations.access-ci.org/requests: https://allocations.access-ci.org/requests. \\* There, you will see your allocations listed. Look for the Allocation you would like to take action on. You should see a button that says ""Choose New Action."" Click the ""Choose New Action"" button. \\* You should see the option: Supplement. \\* Once we receive this and get it reviewed, you will receive a notification of the reviewer's decision. The Allocations Team will transfer this ticket to the anvil team to see if they can help you with your issue. Let us know if you have any questions along the way. If you have any questions in the future, please visit this site (https://access-ci.atlassian.net/servicedesk/customer/portal/2: https://access-ci.atlassian.net/servicedesk/customer/portal/2|smart-link ) and submit a ticket. name Pusateri ACCESS Allocations ; Hi Zhuohan, I'm sorry but the information about name usage on the ACCESS website has not been updated promptly. You can see the actual name balance of your allocation on Anvil by running the {{mybalance}} command. $ mybalance x-johan28 Allocation Type name Limit name Usage name Usage name Balance Account (account) (user) ============= ==== ========== ========== ========== ========== dmr970008 CPU 3859943.0 3858610.7 0.0 1332.3 It seems the allocation dmr970008 has 1332.3 SUs available currently. Slurm will start a job only if it can run to completion (based on the walltime it requests) with the available SUs. However, 1332.3 SUs is not enough for any of your pending jobs to get started. Please see: $ squeue -u x-johan28 --noheader -o %i | xargs ~jin456/public/bin/jobsu Job SUs for 2780028 Job 2780028 Submitted on: wholenode Job status: PENDING (AssocGrpCPUMinutesLimit) ((null)) Reserved Walltime: 1-00:00:00 (24 hours) Used Walltime: -- (0 hours) Reserved CPUs: 128 Total CPU SUs Needed for Reserved Walltime: 3072.0000 ; Job SUs for 2780095 Job 2780095 Submitted on: wholenode Job status: PENDING (AssocGrpCPUMinutesLimit) ((null)) Reserved Walltime: 2-00:00:00 (48 hours) Used Walltime: -- (0 hours) Reserved CPUs: 128 Total CPU SUs Needed for Reserved Walltime: 6144.0000 ; Job SUs for 2780109 Job 2780109 Submitted on: wholenode Job status: PENDING (AssocGrpCPUMinutesLimit) ((null)) Reserved Walltime: 2-00:00:00 (48 hours) Used Walltime: -- (0 hours) Reserved CPUs: 256 Total CPU SUs Needed for Reserved Walltime: 12288.0000 ; Job SUs for 2780124 Job 2780124 Submitted on: wholenode Job status: PENDING (AssocGrpCPUMinutesLimit) ((null)) Reserved Walltime: 2-00:00:00 (48 hours) Used Walltime: -- (0 hours) Reserved CPUs: 128 Total CPU SUs Needed for Reserved Walltime: 6144.0000 ; Total CPU SUs used for all jobs: 0.0000 Total GPU SUs used for all jobs: 0.0000 I hope this helps. If you have any further questions, please let us know. Thanks, name ;",johan28@access-ci.org,Zhuohan Li,Ruyi Li,Purdue University,Anvil,3,2,42,2023,2023-10-16
ATS-3880,Gromacs job script,2023-10-23,2023-10-24,"I want to use GROMACS software in my Anvil account, but whenever I submit the job, it always results in an error. Can you please help me with the GROMACS job? ; Hi Aashish, Thanks for reaching out : [Missing bonded calculation - running simulation on many nodes, rdd option|https://gromacs.bioexcel.eu/t/missing-bonded-calculation-running-simulation-on-many-nodes-rdd-option/1162 GROMACS version:2020.2 GROMACS modification: No I have a problem. I try to run my simulation on 864 cores and 36 nodes. I get an error at the beginning of my simulation. WARNING: This run will generate roughly 257397 Mb of data Not all bonded interactions have been properly assigned to the domain decomposition cells A list of missing interactions: name of 297000 missing 3191 Angle of 1274400 missing 15691 Ryckaert-Bell. of 1765800 missing 30665 LJ-14 of 1771200 missing 22474 Molec... gromacs.bioexcel.eu | \\_\\_ the path of my directory is /anvil/projects/x-mcb160119/aashish/DLPC\\_DLPA\\_OPM/piezo\\_system/gromacs/voltage\\_simulation/new\\_run I am currently using a CPU-based version of GROMACS. Is it possible to compile GROMACS for GPU acceleration? Regards, Aashish ---- ; Hi Aashish, Can you try the following script to submit the job? I just tested Gromacs/2021.2 on Anvil, and did not see any error message. #!/bin/bash #SBATCH -A mcb160119 # Allocation name #SBATCH -p shared #SBATCH --nodes=1 # Total # of nodes #SBATCH --ntasks=20 # Total # of MPI tasks #SBATCH --time=96:00:00 # Total run time limit (hh:mm:ss) #SBATCH --job-name piezo # Job name #SBATCH -o slrum.o%j # Name of stdout output file #SBATCH -e slurm.e%j # Name of stderr error file module --force purge module load gcc/11.2.0 module load openmpi/4.0.6 module load gromacs/2021.2 module list mpirun -np 1 gmx\\_mpi grompp -f md.mdp -o md.tpr ... mpirun gmx\\_mpi mdrun -deffnm md Regards, name ; Hi name, I am still getting the same error. \\*When I run the simulation on the GPU in the workstation, it runs perfectly fine, but on the CPU, it gives me an error.\\* Program: gmx mdrun, version 2021.2 Source file: src/gromacs/domdec/domdec\\_topology.cpp (line 453) MPI rank: 0 (out of 20) Fatal error: 6933 of the 990841 bonded interactions could not be calculated because some atoms involved moved further apart than the multi-body cut-off distance (1.61075 nm) or the two-body cut-off distance (1.61075 nm), see option -rdd, for pairs and tabulated bonds also see option -ddcheck Regards, Aashish ---- ; For GPU, I think we only have Gromacs within ngc container, to use it, my example script would be: #!/bin/bash #SBATCH -A mcb180049-gpu # Allocation name #SBATCH -p gpu #SBATCH -t 8:00:00 #SBATCH -N 1 #SBATCH -n 16 #SBATCH --gpus-per-node=1 #SBATCH --job-name=gromacs\\_test module --force purge module load modtree/gpu module load ngc module load gromacs module list gmx grompp -f md.mdp -c npt.gro -t npt.cpt -p topol.top -o md.tpr gmx mdrun -deffnm md -ntmpi 4 -ntomp 4 -nb gpu -bonded gpu Regards, name ; Have you tried the options, {{-ntmpi}} and {{-ntomp}} for your mdrun? From the discussion on the webpage you shared, I suspect the error would need tests for number of threads (MPI threads and openmp thread). Unfortunately our Gromacs expert left our team a couple months ago. I can only confirm the simple Gromacs jobs (from Gromacs manual) can run on Anvil and do not have much knowledge to detect why specific system cannot run. Regards, name ; Hi name, The above job script is running fine. I will check the other options. Thank you for your help. Regards, Aashish ---- ;",abhatt@access-ci.org,AASHISH BHATT,Nannan Shan,Purdue University,Anvil,8,2,43,2023,2023-10-23
ATS-2492,Inefficient jobs on ANVIL,2023-08-22,2023-10-31,"This is part of ongoing trouble that I experienced on ANVIL after the upgrade. Unfortunately I was not able to continue on this until now. I responded to an old ticket that was closed, but I need more help in fixing the issue. I am not sure if the ticket reopens from my response. Please feel free to close this ticket if you already received notification on the older ticket. name helped me on the previous ticket. Below is my response. In general, I am having trouble keeping VASP jobs on ANVIL running more than 2 hours. This gives me less than 100 steps per sessions. The same input files works on STAMPEDE2 for 48 hours. I am wondering if I am not setting up slurm.sub and INCAR correctly for ANVIL. I am also wondering if my system size or POTCAR settings are too demanding for my current setup on ANVIL. I tried testing the slurm.sub and INCAR files with no improvement to the run time on ANVIL. Any help would be greatly appreciated. Note - I copied my error output at the bottom of my response to name. Please let me know if there is anything else I may provide. name #; Hi name, Thank you for your help on this. I apologize for the severe delay in getting back to you. I have tried a few tests and am still finding trouble keeping my jobs running. I tried testing NPAR and ntasks in the INCAR and slurm.sub files, respectively, with no improvement. I recognize that the Ca/Mg\\_sv POTCARs will add to the computation costs. But I tried running the same jobs on STAMPEDE2 and got more than 1000 steps per run. The jobs also run for the entire time duration. On Anvil, the jobs stop at <= 100 steps. The INCAR file is also typical for jobs that we have run in the past on STAMPEDE2. You mentioned that you had to stop the jobs due to the time limit and name usage. I find this surprising and confusing. My jobs only run for 1.5 hours before stopping automatically. Did you happen to change a setting in the slurm.sub file for the tests? Below I am copying my current slurm.sub file and the output in my error files. Do you have any other ideas that I might try? Could it just be a memory issue? I can try to change the POTCARs or system size if needed. #; #!/bin/bash #SBATCH -A geo170003 #SBATCH --nodes=2 #SBATCH --ntasks=256 #SBATCH -p wholenode #SBATCH --time=96:00:00 #SBATCH --job-name 6K-mtzU #SBATCH --mail-user="": "" #SBATCH --mail-type=""all"" #SBATCH -o result.%j.out # output and error file name (%j expands to jobID) #SBATCH -e error.%j.err # stderr; skip to combine stdout and stderr h1. Print the hostname of the compute node on which this job is running. date > ./runTime.txt module --force purge module load gcc/11.2.0 openmpi/4.0.6 hdf5/1.10.7 module load vasp/5.4.4.pl2 module list mpirun -np $SLURM\\_NTASKS vasp\\_gam h1. Launch MPI code #srun -n --kill-on-bad-exit $SLURM\\_NTASKS vasp\\_gam # or mpirun -np $SLURM\\_NTASKS vasp\\_std #; #error output ---- h2. Primary job terminated normally, but 1 process returned a non-zero exit code. Per user-direction, the job has been aborted. ---- h2. mpirun noticed that process rank 32 with PID 0 on node a402 exited on signal 9 (Killed). slurmstepd: error: Detected 1 oom\\_kill event in StepId=2609798.batch. Some of the step tasks have been OOM Killed. Best, name ; Hi name, Thanks for reaching out! I kinda forgot what I did back to a few months ago. Let me check my tests if they were still there, hope I did not run the tests on my scratch folder (that would be purged regularly). I would get back to you once I figured out something. Cheers, name, PhD (She/Her) Sr. Computational Scientist ; Hi name, Good to hear from you. Of course. Please let me know if you have any questions for me or if I can try to clarify anything I tried. Thank you for the help, name ---- ; Hi name, Sorry for the delay. It turns out I do not have time to run the tests to figure it out about the computing efficiency on Anvil. Our team is under water right now because a few of members left support team. Do you want to have a virtual meeting to discuss about it? I might have some suggestions for your jobs. Let me know. Regards, name ; Hi name, Sure, a meeting would be great. I can meet this Friday (Sept. 22nd) after 10am. Or any time after 2pm next Tuesday to Friday (Oct. 3rd through 6th). Please let me know what works best for you. name ---- ; Hi name, Let's meet at 3:30pm (ET) Oct 3rd. I sent the Teams invitation to you. Regards, name ; Hi name, Great. Thank you very much. I have added the Teams link to my calendar. name ---- ; \\*\\*PRIVATE NOTE\\*\\* Discussed the questions over a Teams meeting. name shared he cannot submit a VASP job. We checked the submit script and corrected a couple of setup. The job can run successfully. Then we discussed a few ways to optimize the running, including run scaling tests with different numbers of CPUs, how to setup cpu numbers in SLURM script, and which partition we should use, {{shared}} or {{wholenode}}. ; Hi name, I have an update from our corrections yesterday. My job ran for nearly 6 hours this time. This is a great improvement from before (no more than 2 hours). However, the job once again stopped long before the set run time (48 hours) or number of steps (NSW=10,000 - simulation reached 61 steps). I found the following error message in the error file: ; Primary job terminated normally, but 1 process returned a non-zero exit code. Per user-direction, the job has been aborted. ; mpirun noticed that process rank 16 with PID 3631715 on node a108 exited on signal 6 (Aborted). ; Do you have any suggestions? Should I try scaling tests to optimize, and then test again? For your convenience, my slurm.sub file is copied below. name # ========================================================================= #!/bin/bash #SBATCH -A geo170003 #SBATCH --nodes=1 # shared only 1, wholenode can be 2 or 3, or more - if using 1, go for shared, if needing more nodes, go wholenode #SBATCH --ntasks=64 # shared p can be 128 or less, wholenode can be 128 x n nodes #SBATCH -p shared #SBATCH --time=48:00:00 #SBATCH --job-name 4K-mtzB #SBATCH --mail-user="""" #SBATCH --mail-type=""all"" #SBATCH -o result.%j.out # output and error file name (%j expands to jobID) #SBATCH -e error.%j.err # stderr; skip to combine stdout and stderr # Print the hostname of the compute node on which this job is running. date > ./runTime.txt module purge module load gcc/11.2.0 openmpi/4.0.6 vasp/5.4.4.pl2 mpirun -np $SLURM\\_NTASKS vasp\\_gam date >> ./runTime.txt ---- ; Hi name, I tried some scaling tests and found the best set up to be wholenode, nodes = 2, ntasks = 256, npar = 16. However, the length of time a job will run is completely random. Last night I tried one test which ran for 12 hours alone. Today, I set up 11 volumes to run with my optimized run parameters. 8 of the simulations stopped within 1 hour of run time. I do not understand what is preventing the jobs from continuing. And it is not practical to reboot the jobs every hour. It seems the error is different from my last message. The error messages are copied below. Do you have any insights? name The previous error was: ; Primary job terminated normally, but 1 process returned a non-zero exit code. Per user-direction, the job has been aborted. ; mpirun noticed that process rank 16 with PID 3631715 on node a108 exited on signal 6 (Aborted). ; % ============================================== % ============================================== % ============================================== The new error message is: ; Primary job terminated normally, but 1 process returned a non-zero exit code. Per user-direction, the job has been aborted. ; mpirun noticed that process rank 16 with PID 0 on node a771 exited on signal 9 (Killed). ; Hi name, Thanks for sharing the information. It looks like a mpi error. Can you try to add {{--mpi=pmi2}} to mpirun line and see if the error will be gone? {{mpirun -np $SLURM\\_NTASKS --mpi=pmi2 vasp\\_gam}} If not, let me know. I need to bring this to the discussion within team. Regards, name ; Hi name, I tried adding that tag but the system does not recognize it. The job stops almost immediately after I submit it. The error reported is: mpirun: Error: unknown option ""--mpi=pmi2"" I also tried --mpi=mpi2. This resulted in the same error. name ---- ; Hi name, Thanks for letting me know. I probably need to run tests with your input files. Do you mind I copy your input files? If not, please let me know the directory you put them. In the meantime, you might want to check VASP forum and see if there is a relative discussion about the error message. Regards, name ; Hi name, Sure, you may copy the input files. The pwd is /anvil/scratch/x-awa19/name ---- ; Thank you, name. I just copied the input files and submitted the job. I'm using 64 cores (N1 n64, npar=8) for my test. I would let the job run 48h to see if I can re-produce the error message. If I can have this job run for 2 days, I would switch to wholenode partition and test it for another 2 days. Will update you after I get the results for the tests. Regards, name ; Hi name, I think I have a couple of observations with the tests (I tested your inputs with 64 cores and 256 cores. With 64 cores, my test run about 4 hours and got killed with an error you shared. With 256 cores, I got the error said out of memory (OOM). I think it is strange for me to get error with a larger number of cores, but not the smaller ones. I highly recommend to check POSCAR structures and INCAR. Specifically, I have a couple of suggestions: (1) I googled the error you shared on vasp forum, it can be related to POSCAR structure. I would recommend to run a few optimization iterations first and use CONTCAR as POSCAR for MD calculations. (2) I checked your INCAR for each parameter, I would recommend to double check the following tags and make sure this is the value you want, otherwise, use the default values. NELM (not sure why setup 30 here, the default one would be 60, or at least 40 from my experience) NBLOCK and KBLOCK and NPACO and APACO, I am not familiar with these setups, so you might want to double check those and make sure your values are consistent with literature. ISMEAR, I've noticed you setup it as -1, not sure if this is on purpose, but it is worth to double check. It is an important parameter and depends on the system we module, if it is metal, it would be 1. If it is semiconductor or run name calculation, it would be -5. Otherwise, Guassian smear would be enough for most of the cases. If it is setup to -1, probably need a literature as the evidence for this structure. Hope it helps, name ; Hi name, Thanks so much for the help and advice. The INCAR parameters were chosen by a couple of my collaborators who have years more experience than I do in this type of work. They helped get me set up for VASP calculations. But I will double check the parameters you mentioned. Maybe these are not well suited to the Anvil system? I will read more on each and check them for issues. Regarding the POSCAR file, I did optimize the file on the Stampede2 system at 6000 K. These current POSCAR files are the result after cooling to 4000 K. I have also continued with these POSCAR files on other HPC machines (by using the CONTCAR in place of POSCAR each time). I copied the POSCAR files to Anvil to cross-check and make sure the system was running well. I am surprised that the POSCAR file may still be giving issues on Anvil. I will try to optimize it again like you suggested. But I am a little confused as to why they are working well on other machines. name ---- ;",x-awa19,Aaron Ashley,Nannan Shan,Purdue University,Anvil,17,51,34,2023,2023-08-21
ATS-3743,Request an increase in file number quota,2023-10-16,2023-11-01,"Hi there, We are working with a large autonomous driving dataset, Waymo, about 3-4TB with 4000k files. We hit the file limit when transferring the dataset to Anvil. We use the scratch folder for temporary storage but still prefer the project folder for long-term storage until the project ends. Could you help increase the file number quota for project x-cis230283 to 5000k? Best regards, name ; Hi name, Thank you for reaching out! Would you please share more information about your workflow? Is it possible for you to work with the archive form of the dataset? Thanks, name ; Hi name, The dataset was initially saved in a tar format. But we need to uncompress the dataset for training DNN models. So, that's something we cannot change. Best regards, name ---- ; Hi name, Thanks for the further information! We think you may consider tweaking your code a bit to access files from the tar format of dataset. If it is necessary, we would like to have a meeting with you to talk about your workflow. Please let us know. Thanks, name ; Hi name, I'd be happy to explain more about our workflow. Our code repo converts the data to NumPy format for storage and training (faster speed for data-loading during training). This process to convert the whole dataset takes about 2 days to finish, considering the size of the datasets (3-4TB). That's a typical workflow in the code repos we have worked with. Changing the workflow will add considerable overhead, as this step was supposed to be simple and straightforward. Thus, we hope to focus more on the research aspect of our work and keep this part unchanged. If you need more information, can we set up a meeting? Best regards, name ---- ; Hi Pengheng, Thanks for sharing more details about your workflow. We still think a meeting could be helpful. Would you be available sometime next week to have a virtual meeting with us? Thanks, name ; Hi name, I am available on Wednesday (besides 9:30 to 10:30 am, and 2:00 to 3:30 pm) or Thursday. Can you also share a meeting link with me? Thanks, name ---- ; Hi name, My apologies for the delayed response. One of our scientists who intended to join the meeting is back from a conference. Would you be available to have a meeting with us in the morning of November 3 (this Friday)? If that does not work for you, would you please let us know your availabilities next week? Thanks, name ; Hi name, Thanks for letting me know! However, I managed to do my training job on another cluster. So, We can close this ticket for now. Regards, name ---- ; Hi name, Thanks for letting me know! I'll mark this ticket as resolved then. Please feel free to contact us again if you have any other requests or questions. Thanks, name ;",pwang1@access-ci.org,Pengcheng Wang,Ruyi Li,Purdue University,Anvil,10,13,42,2023,2023-10-16
ATS-3893, Anvil back-end nodes cannot see outside world,2023-10-23,2023-10-31,"It looks like Anvil back-end nodes can no longer see hosts on the outside world. Repeat-by: login06.anvil ~ $ sinteractive -N 1 -n 1 -A cis220051 -t 1:0:0 salloc: Pending job allocation 3254099 salloc: job 3254099 queued and waiting for resources salloc: job 3254099 has been allocated resources salloc: Granted job allocation 3254099 salloc: Waiting for resource configuration salloc: Nodes a243 are ready for job a243.anvil ~ $ wget ubuntu.com --2023-10-23 19:05:53-- http://ubuntu.com/ Resolving ubuntu.com (ubuntu.com)... 185.125.190.29, 185.125.190.20, 185.125.190.21, ... Connecting to ubuntu.com (ubuntu.com)|185.125.190.29|:80... connected. HTTP request sent, awaiting response... 301 Moved Permanently Location: https://ubuntu.com/ following --2023-10-23 19:05:53-- https://ubuntu.com/ Connecting to ubuntu.com (ubuntu.com)|185.125.190.29|:443... ^C This will just hang on an Anvil back-end node. It works on an Anvil front-end node and on Negishi and Bell front-end nodes and back-end nodes. Regards, Doug ; Hi Doug, Thank you for reporting this issue. We are investigating and will keep you updated. Regards, name ; Thanks name! We rely on Internet connectivity on back-end nodes to do many things, and I imagine others do as well. Could you please consider escalating the priority of this issue? Regards, Doug ; Hi Doug, The issue has been escalated. I'll let you know if there are any updates. Thanks, name ; Hi Doug, The networking team has been notified and they are currently working on this issue. Thanks, name ; Hi Doug, A workaround has been put in place by the networking technicians. They are working on an ultimate fix. Since the compute nodes on Anvil should be able to see the outside world now, I'm tentatively marking this ticket as resolved at this point. If you see any further issues, please feel free to reopen this ticket. We appreciate your reports. Thanks, name ; Awesome, thanks name! I'll pass the word! Regards, Doug ; Hi Doug, You are welcome. I'll close out this ticket then. Thanks, name ;",dgc@access-ci.org,Doug Crabill,Ruyi Li,Purdue University,Anvil,8,7,43,2023,2023-10-23
ATS-3913,R killed - memory issues ,2023-10-24,2023-10-31,"I created an environment using conda. I opened up R and installed packages and loaded them. I read an rds file. I was using the terminal interactively because I need to go stepwise. Anyways, last week, everything worked wonderfully. This week it did not because at different points of the series of commands I was using, the process is killed (using the same rds file as last week). Please let me know if and how to allocate more memory - I apologize if I've been doing something wrong this whole time. Also, because of my problems, I wanted to remove the previous environments that I made however some files were locked - how do I go about removing them? thank you for your help ; Hi Renee, Thank you for contacting us. To help us investigate, would you please let us know if you were running the commands on a login node or inside an interactive Slurm job? Regarding the issue with removing your Conda environment, did you see any error messages? If it is possible, would you please share a screenshot to show us the problem? Thanks, name ; Hi name, login node because I didn't know I could use an interactive slurm job Also, I didn't take a screenshot yesterday of the error but I went in manually right now and was able to remove the previous environment directories and their contents. -Renee ---- ; Hi Renee, I'm glad to know you were able to clear your custom Conda environments. Since you were running the program on the login node(s) that are shared by users, I highly suspect your processes were killed by the cgroup OOM killer. I would suggest you request a whole compute node and run the commands from an interactive job. Then, you may check the job information (using the {{jobinfo }} or {{sacct}} command) to see its resource utilization. Based on that, you may adjust the resource requests accordingly for your future jobs. You may start an interactive job using the {{sinteractive}} command. For example: sinteractive -A mcb130189 -p wholenode -N 1 -n 128 -t 1-00:00:00 You may find more information about running jobs on Anvil at the following link: https://www.rcac.purdue.edu/knowledge/anvil/run: https://www.rcac.purdue.edu/knowledge/anvil/run|smart-link Please give it a try and let me know if you have any further questions. Thanks, name ; Hi name, Thank you for your help - everything seems ok now! -Renee ---- ; Awesome! Thanks for your feedback! Glad I was able to help. I'll mark this ticket as resolved then. Cheers, name ;",rgarza@access-ci.org,Renee Garza,Ruyi Li,,Anvil,6,6,43,2023,2023-10-23
ATS-4011,Could you please install the Joe-Editor? ,2023-10-29,2023-11-02,"I prefer the Joe-Editor over vi. So could you please install it? ; Hi Wolfgang, Thanks for reaching out! Unfortunately we won't install a software centrally on Anvil if it is not requested by many users. Feel free to check our policy. https://www.rcac.purdue.edu/knowledge/anvil/policies/software\\_installation\\_request\\_policy: https://www.rcac.purdue.edu/knowledge/anvil/policies/software\\_installation\\_request\\_policy|smart-link I think you can install Joe-Editor on your own space, like HOME or project folder. Regards, name, PhD (She/Her) Sr. Computational Scientist ;",tichy@access-ci.org,Wolfgang Tichy,Nannan Shan,Purdue University,Anvil,2,4,43,2023,2023-10-23
ATS-3184,GPAW 23.9.1 Installation on Anvil - Errors,2023-09-20,2023-11-14,"Hello, I'm working on research that requires the use of mpi-enabled GPAW, with some procedures related to a tutorial found here: https://wiki.fysik.dtu.dk/gpaw/tutorialsexercises/opticalresponse/tddft/lcaotddft.html#plasmon-resonance-of-silver-cluster: https://wiki.fysik.dtu.dk/gpaw/tutorialsexercises/opticalresponse/tddft/lcaotddft.html#plasmon-resonance-of-silver-cluster|smart-link. A particular class is needed (PoissonSolver), but is found in a later version than what is available as a module on Anvil (gpaw/21.1.0). I've attempted to install GPAW version 23.9.1 on my home directory for testing, using the attached steps (gpaw-buildenv). I was unsuccessful, as the output of the last step using setup.py shows (build\\_log). I tried a few other methods (enforcing static linking, etc.) but it doesn't seem to work. It appears that our project would benefit from the use of Scalapack with GPAW, which is why I've tried to use the amdscalapack module. Can I get some assistance with installing the latest version GPAW package? Thank you for your time and help, name D. Switzer, Ph.D. Department of Physics University of Central Florida ; ^build\\_log] ^gpaw-buildenv ; Hi name, Thanks for reaching out! I would suggest to set up the environment like this: {{module --force purge}} {{module load gcc/11.2.0}} {{module load intel-mkl}} {{module load fftw/3.3.8}} The intel-mkl would include blas and scalapack libraries. If you need mpi, you can 'module load openmpi/4.0.6' to enable mpi run. Hope it helps. Cheers, name, PhD (She/Her) Sr. Computational Scientist ; Hi name, Thank you for your assistance. I set the environment as suggested, but now my compilation fails to build the prerequisite Libxc library (the step before installing GPAW), which needs both a cc and fc compiler. The failure occurs in the use of mathematical constants that typically do not need a header declared, please see the attached build log for more details. I've tried with and without openmpi to see if the gcc or mpicc compilers give a different result, but both give the same error. I've also tried using the intel compiler set, but both icc and mpicc hang when I try {{icc -v}}/ {{mpicc -v}}, and thus the {{./configure}} script hangs at those points. Do I need to do anything once I load those modules so that the math library is seen okay? name ; ^gpaw-buildenv\\_ver2 ^build\\_log\\_ver2 ; Hi name, Can you share where I can find the source code of GPAW and the installation instructions? I'd like to try on my end. I googled GPAW, it gave me the one associated with ASE. I am not sure if this is the one you were trying to install on Anvil. Regards, name ; Hi name, Absolutely, the installation instructions are here: [https://wiki.fysik.dtu.dk/gpaw/install.html: https://wiki.fysik.dtu.dk/gpaw/install.html|smart-link. It is the one associated with ASE. The platform and architectures link also has some useful information depending on the setup: https://wiki.fysik.dtu.dk/gpaw/platforms/platforms.html#platforms-and-architectures: https://wiki.fysik.dtu.dk/gpaw/platforms/platforms.html#platforms-and-architectures|smart-link. If not installed via pip, the source code is found here: https://gitlab.com/gpaw/gpaw: https://gitlab.com/gpaw/gpaw|smart-link. name ; Thank you, name. I would try it out. Regards, name ; Hi name, Our scientist had tried to build GPAW with Spack. And there is no problem they saw. Here are the commands he used. $ spack env create -d ./gpaw $ spack env activate `pwd`/gpaw $ spack add py-gpaw % $ spack install You might want to try this out. If you are not familiar with Spack, you can check the tutorial, which is easy to follow. https://spack-tutorial.readthedocs.io/en/latest/index.html: https://spack-tutorial.readthedocs.io/en/latest/index.html|smart-link Regards, name ;",eswitzer@access-ci.org,Eric Switzer,Nannan Shan,Purdue University,Anvil,9,40,38,2023,2023-09-18
ATS-4281,vasp not running on compute nodes,2023-11-07,2023-11-14,"Hi there, I am encountering issues running vasp on the compute nodes. I compiled using {{module unload openmpi; module load intel}}; and I execute this command before running vasp. If I run the following command on the head node, it works; {{mpirun -np 2 ~/bin/vasp\\_std}}. If I submit it through an sbatch script, I see the errors printed in err.3490321.xz. I have prepared a minimal working example here: /home/x-coses/scratch/test. It includes the sbatch file xbatch\\_ivasp.sh. Also, I tried running interactively via {{sinteractive -N1 -n128 -A mat230032}}, it does work. This behavior is very strange and I am wondering if perhaps there is a mismatch in the libraries on the compute nodes. Any support/advice would be greatly appreciated. Note: I have a vasp license, please let me know if you need to see it. Best regards, name ; ^err.3490321.xz] ; Hi name, Thanks for reaching out Best regards, name -- Dr. name Oses Assistant Professor Department of Materials Science and Engineering Johns Hopkins University ;",coses@access-ci.org,Corey Oses,Nannan Shan,Purdue University,Anvil,4,6,45,2023,2023-11-06
ATS-4416,Pending Job,2023-11-13,2023-11-14,"Hello! I'm relatively new to using Anvil and just getting my bearings. I've submitted my first job, but it has been in the queue for three days now. When I look at the job status, it says ""PENDING"" and the reason is ""AssocGrpCPUMinutesLimit"". Does this mean I don't have enough SUs to run this job? If not, what does it mean? If so, then I am misunderstanding how SUs convert to compute time on Anvil. Is there a way to check or calculate myself how many SUs a job will use up? Apologies if this is already explained in the documentation. The jobid is 3520366. I've requested one core, 135GB of memory and six hours of walltime. Thanks for your help, Hannah ; Hi Hannah, Thanks for reaching out! I think the reason your job is pending is because you do not have enough allocation hours for this job. The charge unit for Anvil is the Service Unit (name). This corresponds to the equivalent use of one compute core utilizing less than or equal to approximately 2G of data in memory for one hour. In your job, you requested 135GB memory and 6 hours, which would be about 405 SUs, while your project has 118.4 SUs left. We have a script which can be used to calculate name usage for a job {{/usr/local/bin/jobsu jobid}} $ mybalance x-hbish Allocation Type name Limit name Usage name Usage name Balance Account (account) (user) ============= ==== ========== ========== ========== ========== phy230181 CPU 183.0 64.6 64.6 118.4 Regards, name, PhD (She/Her) Sr. Computational Scientist ; Hi name, This is what I see when I use that script you referenced: \\*:~\\* $ /usr/local/bin/jobsu 3520366 Job SUs for 3520366 Job 3520366 Submitted on: shared Job status: PENDING (AssocGrpCPUMinutesLimit) ((null)) Reserved Walltime: 06:00:00 (6 hours) Used Walltime: -- (0 hours) Reserved CPUs: 1 Total CPU SUs Needed for Reserved Walltime: 6.0000 Total CPU SUs used for all jobs: 0.0000 Total GPU SUs used for all jobs: 0.0000 I don't see where it tells me how many SUs that job will use? Thanks, Hannah ---- Hannah Bish (she/her) Postdoctoral Fellow Space Telescope Science Institute ; Hi Hannah, I did not mention that {{jobsu}} will calculate the SUs for a completed job (finished, aborted ..), not a pending job. For a pending job, there is no used SUs. If you want to calculate name for new job, it is a simple math. One name corresponds to the equivalent use of one compute core utilizing less than or equal to approximately 2GB of data in memory for one hour. For a job reserved 135GB (which is 135GB/2=67.5 cores ~68 cores) and 6 hours, the name usage would be name = 68 cores \\* 6 hours =408 Although you put 1 core in your script, but since you also requested 135 GB memory, SLURM would find at least 68 cores for your job to fulfill the memory request (there is no half core available on Anvil (if has the half core, it would be 67.4\\*6=405 SUs). Regards, name ; Ah okay got it, thank you! ---- Hannah Bish (she/her) Postdoctoral Fellow Space Telescope Science Institute ;",hbish@access-ci.org,Hannah Bish,Nannan Shan,Purdue University,Anvil,5,2,46,2023,2023-11-13
ATS-2654,Lacking library while compiling VASP,2023-08-29,2023-11-13,"Hello, I'm compiling VASP 5.4.4 following the instruction of RCAC - Knowledge Base: Anvil User Guide: Build your own VASP 5 (purdue.edu): https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/vasp/build\\_your\\_own\\_vasp\\_5 using OpenMPI. No error is reported during the compiling process. But when I do calculations, an error shows: ""/home/x-jxiong1/VASP\\_all/vasp.5.4.4.pl2/vasp.5.4.4/bin/vasp\\_std: error while loading shared libraries: libmkl\\_gf\\_lp64.so: cannot open shared object file: No such file or directory"". What should I do to download the necessary library libmkl\\_gf\\_lp64.so? Sincerely, name ; Hi name, Thank you for reaching out For your login via ThinLinc, would you please verify if the private key you added in the client matches with the public key you uploaded to Anvil? Thanks, name ; Hi name, Thanks for your reply. I can use gnuplot with x11 displayed by MobaXterm in other systems such as NERSC: But it fails enabling x11 in Anvil: Regarding login issue by ThinLinc, I have tried both the private key (id\\_rsa) and the public key (id\\_rsa.pub) saved in my local host path (E:\anvil access in my PC) but still failed to login: I'm sure the public keys ld\\_rsa.pub is the same (copied) as stored in :/home/x-jxiong1/.ssh/authorized\\_keys. You see I can login Anvil using them by MobaXterm. Best, name ---- ; Hi name, Thanks for the further information Let me know if you have further questions. Regards, name, PhD (She/Her) Sr. Computational Scientist ; Dear name and name, Thanks for your emails. The out-of-memory issue is indeed induced by the low version of openmpi library. Can I know if you have any detailed instructions for installing and calling openmpi (>4.1.1) by VASP? Regards, name ---- ; Hi name, We do not specifically have the recipe for openmpi installation. We have a general training for software installation you might want to check. https://www.rcac.purdue.edu/training/software-installation: https://www.rcac.purdue.edu/training/software-installation|smart-link I would also recommend to use Spack to install it to your project space. Here is the detailed tutorial for Spack usage, which is easy to follow. https://spack-tutorial.readthedocs.io/en/latest/: https://spack-tutorial.readthedocs.io/en/latest/|smart-link Regards, name ;",jxiong1,Jiaxin Xiong,Ruyi Li,,Anvil,29,55,35,2023,2023-08-28
ATS-3735,qe,2023-10-16,2023-11-08,"Dear anvil staff, Hope you are doing well! Could I have a copy of your make file to compile quantum espresso, and the modules you loaded ? Also, is there a way to sign up for the coffee hour consultations without a Purdue account? Thank you! ; Hi Yuxuan, Thanks for reaching out! About QE installation, I do not think it would need a copy of makefile. Here are the commands I used while I compile QE7.1 manually. module purge module load modtree/cpu module load intel-mkl module load fftw wget https://www.quantum-espresso.org/rdm-download/488/v7-1/78cd5c1a8d0151828e0e48d7d6fbd836/qe-7.1-ReleasePack.tar.gz tar -xzvf qe-7.1-ReleasePack.tar.gz cd qe-7.1 ./configure make pw About coffee hour consultation, that is for users at Purdue community clusters, like Bell, Negishi, Workbench, Scholar and Gilbreth. For Anvil, we do not have regular coffee hour consultation. But we can schedule a virtual meeting to talk about your questions about Anvil if necessary. Regards, name, PhD (She/Her) Sr. Computational Scientist ; Thank you so much! I'm currently compiling qe with EPW 5.7.0 using the recipe: https://docs.epw-code.org/doc/DownloadAndInstall.html, but it failed some tests shown in /anvil/projects/x-dmr200031/software/q-e-qe-7.2/test-suite/history-test the compilation history is in /anvil/projects/x-dmr200031/software/q-e-qe-7.2/output-make Would you kindly offer some suggestions? ; Currently Loaded Modules: 1) gmp/6.2.1 3) mpc/1.1.0 5) gcc/11.2.0 7) numactl/2.0.14 9) xalt/2.10.45 (S) 11) intel-mkl/2019.5.281 2) mpfr/4.0.2 4) zlib/1.2.11 6) libfabric/1.12.0 8) openmpi/4.0.6 10) modtree/cpu 12) fftw/3.3.8 ; If you don't mind me asking: What procdure did the cluster use to compile quantum-espresso/6.7? The settings there seem optimal and even faster than some other clusters 🙂 ; Hi Yuxuan, I think my colleague used the similar commands I shared for QE7.1 for QE6.7. Because she left our team, and we cannot confirm from her. In addition, the speed of calculation would most likely depends on the scaling. About EPW, do you think you have compiled the EPW successfully? If you can share the error message directly here, it would be easier for me to give suggestions. Regards, name ; Would it be possible for you to share the make file from name 6.7.? I can try it first. There was no error but many failed tests w large means square errors. ; Hi Yuxuan, I checked the QE6.7 on Anvil, it turns out it was not manually built, it was built by Spack: https://spack.io/, the recipe I believe is {{spack install %+elpa~environ+epw+mpi+openmp+patch~qmcpack+scalapack hdf5=none arch=linux-centos8-zen3/4w5v7zq}} Since spack would automatically find the source code and run the installation, we do not need to prepare the makefile. I think you can use the commands below to install QE6.7 manually on Anvil. I tried it this afternoon and it went well. module --force purge module load gcc/11.2.0 openmpi/4.0.6 module load intel-mkl/2019.5.281 module load fftw/3.3.8 wget https://gitlab.com/QEF/q-e/-/archive/qe-6.7MaX-Release/q-e-qe-6.7MaX-Release.tar.gz tar -xzvf q-e-qe-6.7MaX-Release.tar.gz cd q-e-qe-6.7MaX-Release/ ./configure make pw Regards, name ; ^output-make \\_(0.0 kB)\\_ ^ZG.f90 \\_(0.0 kB)\\_ ^EPW-compile error anvil.docx \\_(0.0 kB)\\_ ; Yuxuan, I did not see error message from the make output file. Is there any error message you saw when you submit jobs? Regards, name ; Yes the output is error comparing to other clusters. ; I do not think I saw an error from the output-make file you shared. Let me know more details if you still need help on this topic. Regards, name ;",wyuxuan@access-ci.org,yuxuan,Nannan Shan,,Anvil,12,18,42,2023,2023-10-16
ATS-3867,"Fortran libraries, modules, and compile optimiaztion",2023-10-22,2023-11-06,"The Fortran code my colleague has developed requires the following hdf5 libraries that I was unable to find in the anvil system: -lhdf5hl\\_fortran -lhdf5\\_hl -lhdf5\\_fortran -lhdf5 I was able to load the hdf5 module, but we also need the h5lt module, but I could not find that either. Additionally, we would like to use the following compile optimizations, but I was unable to locate them using module spider or through the RCAC website: -llapack -lrefblas -lgfortran -lmkl\\_intel\\_lp64 -lmkl\\_core -lmkl\\_sequential -lpthread -lm -ldl I may be missing a key step on my end, but if you could provide some guidance I would be greatly appreciative. ; Hi name, You need to load appropriate modules to find those libraries. For example, all the hdf5 libraries can be found by loading the hdf5 module. Similarly, you can find all the MKL libraries by loading the intel-mkl module. Please consider reviewing the Cluster 101 and Cluster 201 tutorials to learn how to use modules and find software on Anvil. https://www.rcac.purdue.edu/training: https://www.rcac.purdue.edu/training|smart-link https://www.rcac.purdue.edu/knowledge/anvil/software: https://www.rcac.purdue.edu/knowledge/anvil/software|smart-link Best regards, name. ; Hi name, Thank you for pointing me in the right direction. I was able to resolve my problems loading the libraries and modules I need. Best, name Ziems ; That is great news! Glad that you figured it out. Regards, name. ;",nziems@access-ci.org,Nathan Ziems,Amiya Maji,Purdue University,Anvil,4,11,42,2023,2023-10-16
ATS-4047,What modules are required to run quantum espresso 6.7 on Purdue Anvil?,2023-10-30,2023-11-10,"Hello, I am a student researcher at New Mexico State University, and I am currently using Purdue Anvil's supercomputer. I would like to run a custom version of Quantum Espresso 6.7+ on Anvil, but cannot find the requisite modules needed for compilation. Is there any way that I could have a list of the necessary modules for compiling Quantum Espresso version 6.7 or greater? Thank you very much in advance! Best, -name Shipley ; Hi name, Thank you for reaching out! We have {{quantum-espresso/6.7}} installed as a module on Anvil. You may get access to it by running the following commands: $ module load gcc/11.2.0 openmpi/4.0.6 $ module load quantum-espresso/6.7 Have you checked it out to see if it works for you? If you need to install a custom version of Quantum Espresso, what libraries are required for your compilations? Thanks, name ; Hi name, I'm writing to follow up on this ticket. Would you please let me know if you still need assistance regarding using Quantum Espresso 6.7+ on Anvil? Thanks, name ; Hi name, Since I have not heard back from you in a while, I'm tentatively marking this ticket as resolved at this point. If you still have questions, please feel free to reopen the ticket or submit a new one to us. Thanks, name ; Hello name, My apologies, your last email must have gotten lost in my inbox. Since my question, I have resolved the issue and successfully compiled quantum espresso. Best, -name ---- ; Hi name, No worries. Thanks for letting me know you have resolved the issue. That's wonderful! I'll close out this ticket then. Please feel free to contact us again if you have any other questions. Thanks, name ;",ashipley@access-ci.org,Austin Shipley,Ruyi Li,Purdue University,Anvil,6,10,44,2023,2023-10-30
ATS-4070,Submitting python code batch,2023-11-01,2023-11-06,"On running a python code through a batch job, it currently gives a qos system error. ; Hi Vivek, Thank you for reaching out! To help us investigate the issue, would you please share the error message, your job submission script and command with us? Thanks, name ; Hi Vivek, I'm writing to follow up on this ticket. Would you please let me know if you still need assistance in submitting jobs on Anvil? Thanks, name ; Hello name, The issue has been resolved. Thank you. \\*Warm regards,\\* \\*Vivek name\\* Lecturer Department of Mathematics and Computer Science name College of Criminal Justice New York, NY 10019. On Nov 6 2023, at 12:05 PM, name wrote: CAUTION: This email originated from outside of name. Examine it closely before clicking on links or opening attachments ; Awesome! Thanks for letting me know! I'll mark this ticket as resolved then. Cheers, name ;",vsharma6@access-ci.org,Vivek Sharma,Ruyi Li,Purdue University,Anvil,5,4,44,2023,2023-10-30
ATS-4082,Purdue ANVIL Special Queue,2023-11-01,2023-11-08,"Hi name, I was wondering whether it would be possible to reactivate the special queue that you had set up for me. Would it be too much to ask for to have access to 600 nodes? Best, name ; Hi name, Thanks for reaching out! I remember our conversation stopped at the scaling tests and we never heard from you since May. Based on the latest conversation, you would run the scaling tests with 10, 20, 40, 80, 160 nodes. Then we created a queue for you to get access to 200 nodes on Anvil. I do not think we received your results for the scaling tests. Furthermore, Anvil is becoming busy nowadays, I would expect a long waiting time if a job requests a large number of nodes on Anvil. We would need the scaling tests to show your code scales well with Anvil nodes. You can still use {{-q jnash12-wide}} to get access up to 200 nodes on Anvil. Regards, name, PhD (She/Her) Sr. Computational Scientist ;",jnash12@access-ci.org,Jake Nash,Nannan Shan,Purdue University,Anvil,2,6,44,2023,2023-10-30
ATS-4187,request for vasp on anvil,2023-11-05,2023-11-06,"I have attached my vasp license file. Can you allow me to access vasp on anvil? ; ^License-Agreement\\_21-0044 (31b0a904-6aed-44c7-9c3d-f79f42bff07f).pdf ; Hi, Thank you for contacting us. You have been added to the access of vasp5 and vasp6 on Anvil. Please check it later today and follow our user guide for usages. Will close the ticket. Feel free to re-open it within 7 days if you still need help. Best regards, name Senior Computational Scientist Purdue Information Technology ;",ningl3@access-ci.org,Ning Li,Guangzhen Jin,Purdue University,Anvil,3,1,44,2023,2023-10-30
ATS-4278,module version on Anvil,2023-11-07,2023-11-08,"Hi, I am trying to run the FLASH code on Anvil. The old version of FLASH I am using is only compatible with hdf5/1.8 instead of hdf5/1.10 only which I found is available on Anvil. Is there a way to have the older version of hdf5 on Anvil? Best, Chaoran ; Hi Chaoran, Thanks for reaching out! If you need hdf5/1.8, you can install it to your project space. We do not have plan to install older version of hdf5 on Anvil. Regards, name, PhD (She/Her) Sr. Computational Scientist ;",wangcha@access-ci.org,Chaoran Wang,Nannan Shan,,Anvil,2,2,45,2023,2023-11-06
ATS-4302,batch submit and module helps,2023-11-08,2023-11-13,"Hello, I I am having issues compiling my Fortran code and was wondering what module I should specify in my Makefile to get this to work? Previously I used FC = mpif90 -ffree -form or mpifort -free but neither of these seems to be working. I also want to check that I've set up my batch submit file correctly. ; Hi Sabrina, Thanks for reaching out! If you are using intel compiler, it would be {{FC= mpiifort}}. For gcc compiler, it would be {{FC = mpif90}}. For the job script, you might want to check our user guide. https://www.rcac.purdue.edu/knowledge/anvil/run: https://www.rcac.purdue.edu/knowledge/anvil/run|smart-link Specifically for your job script, I would recommend to do {{module load ...}} after module purge, to load either intel or gcc compiler, and/or impi or openmpi if you need a mpi job. Regards, name, PhD (She/Her) Sr. Computational Scientist ;",sabdesoto@access-ci.org,Sabrina R Desoto,Nannan Shan,Purdue University,Anvil,3,4,45,2023,2023-11-06
ATS-3690,Shared Projects,2023-10-12,2023-11-21,"Hello, I have an ongoing project that multiple persons in our lab is currently working on. It has been very difficult for us to collaborate and work together since the /scratch area is inaccessible. I would like to request an increase of the capacity / quota for the ""projects"" mount point for our allocation - /anvil/projects/x-mcb130189 The currently available 5TB is 22% full and we expect at least 20T of data to be used for this collaborative work. It would be great if you could accommodate this request and allocate 20T for this location. Thanks, name. ; Hi name, Thank you for reaching out. A reasonable justification is needed for a quota increase. Would you please share more details about your project and workflow? Thanks, name ; Hi name, Sure, no problem, I have attached a more formal and detailed justification that outlines our projects and workflow. Thanks, name, Ph.D. Senior Staff Scientist Genomic Analysis Laboratory The Salk Institute for Biological Studies, name Jolla, CA ^Justification\\_Storage.pdf] \\_(0.0 kB)\\_ ; Hi name, Thank you for the details about your project. I would love to understand a little bit more about the project workflows. For example, are you compressing your outputs when saving them to disk? Can any of the input datasets be hosted as a global resource? What fraction of the generated dataset is used by multiple students? etc. Would you be able to meet with us sometime next week to discuss about this? It may be possible to increase your $PROJECT space to some extent, but no promises yet Would you like us to set up a Zoom call or will it be set up by ACCESS? Tx name, Ph.D. Senior Staff Scientist Genomic Analysis Laboratory The Salk Institute for Biological Studies, name Jolla, CA ; Hi name, Here is the meeting link. Best regards, name (Purdue) is inviting you to a scheduled Zoom meeting. Topic: Anvil project space limit Time: Oct 23, 2023 01:00 PM Eastern Time (US and Canada) Join Zoom Meeting [https://purdue-edu.zoom.us/j/92357243109?pwd=SnZVL2o2UlFZRDFBVmtnbm1xKzUzZz09: https://purdue-edu.zoom.us/j/92357243109?pwd=SnZVL2o2UlFZRDFBVmtnbm1xKzUzZz09|smart-link Meeting ID: 923 5724 3109 Passcode: 159485 ---- One tap mobile +,92357243109#,\\*159485# US (Chicago) +,92357243109#,\\*159485# US (New York) ---- Dial by your location • + US (Chicago) • + US (New York) • + US • + US (Washington DC) • + US • + US • + US (Tacoma) • + US (Houston) • + US • + US • + US • + US • + US • + US (San name) • + US • + US • + US Meeting ID: 923 5724 3109 Passcode: 159485 Find your local number: https://purdue-edu.zoom.us/u/aq6iXJ3Li: https://purdue-edu.zoom.us/u/aq6iXJ3Li|smart-link ---- Join by SIP • : mailto: ---- Join by H.323 • 162.255.37.11 (US West) • 162.255.36.11 (US East) Meeting ID: 923 5724 3109 Passcode: 159485 ; Thanks name, looking forward to the discussion. Tx name Senior Staff Scientist Genomic Analysis Laboratory Salk Institute for Biological Studies, name Jolla, CA ; Dear name, Thank you so much for taking time to discuss about our analysis processes and data management methods. Thanks for your comments and consideration of our request. The users for whom we request increase in file number increase in /scratch are x-name x-wangwl x-wding2 x-rgarza Also, we request file number increase and space quota increase in the /projects. Thank you so much. Regards, name, Ph.D. Senior Staff Scientist Genomic Analysis Laboratory The Salk Institute for Biological Studies, name Jolla, CA ; Hi name, Following up on this — Tx name, Ph.D. Senior Staff Scientist Genomic Analysis Laboratory The Salk Institute for Biological Studies, name Jolla, CA ; Hi name, Sorry for the delay. Completely lost track of the ticket. I just sent it to our storage admins. Will let you know once it is approved. Best regards, name. ; Great, thanks name, Ph.D. Senior Staff Scientist Genomic Analysis Laboratory The Salk Institute for Biological Studies, name Jolla, CA ; Hi name, I forgot to follow up again. The new quotas have been active for a while now. Please let us know if you or your team still sees any issues. Best regards, name. ; Hi name, Yes, we had noticed that change… I should have sent an email earlier… sorry about that… thank you so much for taking time to understand our specific case and accommodating our request. This will be very helpful for the efficient use of Anvil in our work. Regards, name, Ph.D. Senior Staff Scientist Genomic Analysis Laboratory The Salk Institute for Biological Studies, name Jolla, CA ; Hi name, Thank you for the kind words. We are glad to help your team perform cutting edge research on Anvil. I'll go ahead and close this ticket, but feel free to reach out if you need help with something else. Best regards, name. ;",manojh@access-ci.org,Manoj Hariharan,Amiya Maji,Purdue University,Anvil,19,29,41,2023,2023-10-09
ATS-4521,Failed PVC attachment ,2023-11-17,2023-11-20,"Greetings, The anvil composable looks to fail to mount PVC. 2023-11-17T18:02:17Z Warning Unable to attach or mount volumes: unmounted volumes=volume-shin152-40purdue-2eedu jupyterhub-shared, unattached volumes=volume-shin152-40purdue-2eedu jupyterhub-shared: timed out waiting for the condition Please also see the error messages from rancher dashboard. ; Some of the storage system was stuck. Can you mount these now? Thanks, -name ; Hi name, It still has the problem as attached. ; Give it another try. The cloud07 node was having issues. -name ; It works. Thanks! ; Great! Marking this resolved. ;",nujwoo,Jaewoo ,Erik Gough,Purdue University,Anvil,7,2,46,2023,2023-11-13
ATS-4534,I want to request access to VASP on Anvil. I am a license holder. My license number is 19-0093,2023-11-17,2023-11-20,"I want to request access to VASP on Anvil. I am a license holder. My license number is 19-0093. ; Hi Sara, Thank you for reaching out. We have verified your VASP license and added you to the {{vasp5}} and {{vasp6}} Unix groups on Anvil. For now, you should be able to access the {{vasp}} modules in new login sessions. Our user guide on running VASP jobs on Anvil could be found at the following link: https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/vasp: https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/vasp|smart-link We also have the recording of a previous training session on VASP available online: https://www.rcac.purdue.edu/training/using-vasp-on-anvil: https://www.rcac.purdue.edu/training/using-vasp-on-anvil|smart-link I'm tentatively marking this ticket as resolved at this point. If you have any questions or need more information, please feel free to reopen the ticket or submit a new one to us. Thanks, name ;",skadkhod@access-ci.org,Sara Kadkhodaei,Ruyi Li,,Anvil,2,2,46,2023,2023-11-13
ATS-4652,Quota expansion request,2023-11-28,2023-11-29,"Hi, I am currently running extensive jobs that generate numerous output files. Although each file is small in size, the cumulative number of output files has surpassed the allocated quota in the SCRATCH directory, causing a hindrance to the ongoing jobs. I kindly request an extension of my quota to accommodate the additional output files. Thank you very much, Haonan ; Hi Haonan, Thank you for reaching out. We would be happy to accommodate your needs. Would you please let us know if you have an estimate of the number of files that can be generated in your scratch directory? Will a quota of 2M files be sufficient for you? Thanks, name ; Hi name, I anticipate generating approximately 100k files for each calculation, with concurrent execution of 10-20 calculations. Considering this, I believe that a quota of 3 million files would be an optimal threshold to accommodate the volume of output files efficiently. Best, Haonan ---- ; Hi Haonan, Thanks for getting back to me. I've just increased the quota of your scratch directory to 3M files. $ myquota x-whnfff Type Location Size Limit Use Files Limit Use ============================================================================== home x-whnfff 811.9MB 25.0GB 3% - - - scratch anvil 11.9TB 100.0TB 12% 999k 3,145k 32% projects x-dmr100005 102.5GB 5.0TB 2% 255k 1,048k 24% Hope this will facilitate your research. I'm tentatively marking this ticket as resolved at this point. Please feel free to contact us again if you have any questions. Thanks, name ;",whnfff@access-ci.org,Haonan Wang,Ruyi Li,I do not know the RP,Anvil,5,2,48,2023,2023-11-27
ATS-4558,Jobs do not run,2023-11-20,2023-11-20,"I am running MPI jobs on 320 cores on the wholenode partition of the PURDUE CPU anvil allocation. I am only able to submit jobs that can run for a maximum of 3 hours of a time, and these jobs stay pending for multiple days without ever submitting. ; Hi Dominic, Thank you for reaching out. I checked your current job on Anvil. It seems to be pending because of {{AssocGrpCPUMinutesLimit}}. $ squeue -u x-dchang2 -l Mon Nov 20 15:15:09 2023 JOBID PARTITION NAME USER STATE TIME TIME\\_LIMI NODES NODELIST(REASON) 3788960 wholenode 2023-11- x-dchang PENDING 0:00 3:00:00 3 (AssocGrpCPUMinutesLimit) Since job 3788960 requested 3 nodes in the {{wholenode}} partition for 3 hours, it will need to have 128 \\* 3 \\* 3 = 1152 SUs reserved to it. However, there are only 230.6 SUs available in your account at the moment. For that reason, Slurm will not have it started until there are enough service units to support it. $ mybalance x-dchang2 Allocation Type name Limit name Usage name Usage name Balance Account (account) (user) ============= ==== ========== ========== ========== ========== phy230186 CPU 1000.0 769.4 769.4 230.6 For more information about job accounting on Anvil, please see: https://www.rcac.purdue.edu/knowledge/anvil/run/accounting: https://www.rcac.purdue.edu/knowledge/anvil/run/accounting|smart-link I'm tentatively marking this ticket as resolved at this point. If you have any further questions or need more information, please feel free to reopen the ticket or submit a new one to us. Thanks, name ;",dchang2@access-ci.org,Dominic Chang,Ruyi Li,Purdue University,Anvil,2,1,47,2023,2023-11-20
ATS-4619,Anvil composable node(s) seem to be missing filesystem drivers for CephFS,2023-11-27,2023-11-27,"I have a JupyterHub (geoedf-jupyter namespace) setup on Anvil k8s that is having trouble mounting volumes. I'm seeing errors on notebook launch from what looks like the underlying k8s system complaining about missing drivers for the Ceph filesystem. Both the individual volume created by Jupyter per-user and a special extra volume (from the read/write many storage class) are attaching to the notebook but failing to mount. Spawn failed: pod geoedf-jupyter/jupyter-thompscs-40purdue-2eedu did not start in 300 seconds ; Following the reboot or restart this morning (Monday 27th), I'm now landing on a different node (cloud05), and it is not having the filesystem issue. It must have been an issue with that other node (cloud07). ; Hi name, Thanks for reporting this to us. And glad everything is working fine on different node now. We would investigate the node you mentioned. Thank you! Regards, name, PhD (She/Her) Sr. Computational Scientist ;",thompscs@access-ci.org,Christopher Thompson,Nannan Shan,Purdue University,Anvil,4,1,48,2023,2023-11-27
ATS-4433,Pending job on debug partition.,2023-11-13,2023-11-29,"Hello, I am running Quantum Espresso 6.5 on Anvil, and am attempting to run a job using the Slurm debug partition. Normally, the job script runs immediately, but recently I have been stuck pending. When I use the command, 'jobinfo JOBID' I notice the following error in 'State': PENDING (AssocGrpCPUMinutesLimit) ((null)) This seems to suggest that I have an insufficient amount of name credits, but my ACCESS allocations seem to have a sufficient amount. Could this be the result of some other issue? Thank you for your help! -name Shipley ; Hi name, Thank you for reaching out. It looks like one of your submitted jobs (3614947) in the debug partition completed running. You can see its name usage with the {{jobsu }} command. I suspect that some of your jobs were pending because at that moment the remaining SUs in your allocation were reserved for other jobs from your group members. Please let me know if you have any further questions. Thanks, name ; Hello name, Thank you for your reply. That is odd. So, my jobs don't run independently of my team members? I've never experienced this issue before. Normally, when I am running less intensive computations (on different clusters) I can run the jobs almost immediately. This is ideal for optimization before running the more memory-demanding computations on partitions that will surely leave me in a queue. Best, -name ---- ; Hi name, My apologies for the delay. In general, once your job gets started, it should run independently from other jobs. However, your jobs are using the SUs from an allocation ({{dmr110093}}) that is shared by members of your project. On Anvil, Slurm will reserve a certain amount of SUs for a running job to ensure it can reach the requested walltime. If the SUs of allocation dmr110093 are reserved for running jobs from other members of your project and the left is not sufficient for your job to get started, then it will be pending until more SUs become available (e.g. a job finishes running before its walltime is reached or more SUs are exchanged). I hope this helps. Since there are no action items on our side at this point, I'm tentatively marking this ticket as resolved. If you have any further questions, please feel free to reopen the ticket or submit a new to us. Thanks, name ;",ashipley@access-ci.org,Austin Shipley,Ruyi Li,Purdue University,Anvil,4,13,46,2023,2023-11-13
ATS-3261,file read error,2023-09-24,2023-12-04,"Dear anvil staff: hope all is well Have a great day. ; Roger that. I have performed the name refund to allocation ""dmr200031"". Please allow couple of days before it being populated to Anvil. Will close the ticket. Feel free to re-open it within 7 days if you still need help on this issue. Best, name ; Thank you! /anvil/scratch/x-wyuxuan/zg-cu2se/correct-vasp-stdKPT/222-frm-333-expd0.05/pbe-scf zg-cu2se/correct-vasp-stdKPT/222-frm-333-expd0.05$ cp -r -i pbe-scf/ hse cp: error reading 'pbe-scf/WAVECAR': Input/output error cp: error reading 'pbe-scf/czs.3195898': Input/output error cp: error reading 'pbe-scf/CHGCAR': Input/output error ; Hi, Sorry for the delay. Just to confirm before we further debug the issue, are you still experiencing the same issue at the moment? Best, name ; Hi, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name ;",wyuxuan@access-ci.org,yuxuan wang,Guangzhen Jin,Purdue University,Anvil,12,51,38,2023,2023-09-18
ATS-5027,"Install apptainer on Anvil, or at least the pre-reqs?",2023-12-20,2024-01-02,"We would like to have apptainer available on Anvil to build containers. I know this has been in a testing state on Negishi for over a year now. Can you please consider installing it on Anvil? If no, can you please at least install the pre-reqs (like fakeroot, sqashfuse, others visible at https://github.com/apptainer/apptainer/blob/main/INSTALL.md: https://github.com/apptainer/apptainer/blob/main/INSTALL.md), so we can install our own copy? Regards, Doug ; Hi Doug, Thanks for bring it up. Apptainer is on our list while we are still planing it. We do not have an ETA for it. If users want to install it on their project space, I would recommend to try Spack (https://spack-tutorial.readthedocs.io/en/latest/: https://spack-tutorial.readthedocs.io/en/latest/|smart-link). Regards, name, PhD (She/Her) Sr. Computational Scientist ;",dgc,Doug Crabill,Nannan Shan,Purdue University,Anvil,2,10,51,2023,2023-12-18
ATS-3708,may fail to use impi correctly to run job with 2 processors,2023-10-13,2023-12-06,"Dear Sir/Madam, I tried to submit a sbatch job on anvil. I loaded impi/2019.5.281, my script top lines are: #!/bin/csh #SBATCH -A atm130003 #SBATCH -p wholenode #SBATCH --nodes=1 #SBATCH --ntasks=2 #SBATCH --time=00:10:00 #SBATCH --mem=100G srun --mpi=pmi2 ./wrf.exe However, there is an error at the beginning: h2. alloc\\_space\\_field: domain 1 , 124596 bytes allocated -------------- FATAL CALLED --------------- FATAL CALLED FROM FILE: set\\_timekeeping.F LINE: 102 WRFU\\_TimeSet(startTime) FAILED Routine returned error code = -1 Abort(1) on node 1 (rank 1 in comm 0): application called MPI\\_Abort(MPI\\_COMM\\_WORLD, 1) - process 1 I am not sure if I submit job correctly. I can run it with 1 node and 1 task, but cannot use multiple nodes and tasks. Could you help me about that? Thank you in advance. ; Does anyone have any ideas about this issue? I would greatly appreciate any suggestions. ; I can run the model with 1 N, 126 n, but I cannot run using 2 N. Any suggestion will be appreciated ; Hi, Thank you for contacting us and sorry for the delay. Usually {{srun}} would work with the following command {{srun --mpi=pmi2 -n xxx ./wrf.exe}}and if you didn't specify {{-n xxx}} it will use the total number of processor cores you requested from SLURM by default. That would also be consistent with your configurations for WRF. Should this be the reason for your latest update? Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi name, Thank you for your reply. Yes, I am using srun --mpi=pmi2 -n $SLURM\\_NTASKS ./wrf.exe. I can run wrf.exe with N 1, n 126, but fail to use N 2, n 256. I can use the same WRF-Chem 3.7.1 code and inputs to run on stampede2 successfully. When I compiled the same code on Anvil, it had the same error as this post on WRF forum: https://forum.mmm.ucar.edu/threads/resolved-problem-compiling-wrfv4-0-on-fedora-28-landread-error.61/: https://forum.mmm.ucar.edu/threads/resolved-problem-compiling-wrfv4-0-on-fedora-28-landread-error.61/|smart-link So I added -DSTUBMPI and -DLANDREAD\\_STUB for the CFLAGS in configure.wrf (.: CFLAGS = $(CFLAGS\\_LOCAL) -DDM\\_PARALLEL -DSTUBMPI \ -DMAX\\_HISTORY=$(MAX\\_HISTORY) -DNMM\\_CORE=$(WRF\\_NMM\\_CORE) -DLANDREAD\\_STUB), but it has the first error I posted here, then later I remove the -DSTUBMPI, it can run more lines, but cannot generate one more output files with N 2, only can generate more output files with N 1 n 128. Currently, use N1 and n 128, it takes about 15 minutes to generate one-day output, I need to finish multiple 5-year simulations, so it is necessary for me to use more N to speed up my work. I would appreciate if you have better idea to help solve this issue. Thank you. Libo ; BTW, on stampede2, there is /usr/include/rpc/types.h but not exist on Anvil. Do you have idea why it has this difference? ; Hi, I will escalate your question to our application team so they can take a further look and see how to solve the issue. Thank you. Best, name ; \\*\\*PRIVATE NOTE\\*\\* Anvil Applications: https://access-ci.atlassian.net/jira/people/team/0f5fcf8a-26ef-4d24-a346-4a2ef3a7afda?ref=jira$&src=issue (~accountid:id ~accountid:id ~accountid:id:id-5a0e-4ef9-9dae-4ff21198071b ~accountid:id ~accountid:id ~accountid:id ~accountid:id ~accountid:id ~accountid:id:id-2781-404e-85f3-6f3d3f09f93f ~accountid:id) Hi team, Please take a look at the issue and see if you could have a solution. Thank you. Best, name ; Hi name, Thank you for your reply. This issue may be related with the version of my model. The newer version does not has this problem. Currently, 1 N works well for me. Best, Libo ; Hi, Thank you for the update. Then I will mark this ticket as resolved now. Feel free to re-open it if you see further issues. Best, name ;",zhanglib@access-ci.org,Libo Zhang,Guangzhen Jin,,Anvil,10,39,41,2023,2023-10-09
ATS-4374,Library libjasper.so.1 ,2023-11-10,2023-12-04,"Hi there, This is the first time I am using Anvil, and I am trying to find libs libjasper.so.1. Could you please suggest how I can find it? Thanks! ; Hi, Thank you for contacting us. You could use command {{locate libjasper}} to find related libs but looks like we only have {{libjasper.so}} , {{libjasper.so.4}} and {{libjasper.so.4.0.0}} under {{/usr/lib64/}} on Anvil. Could you try if those can also work for your workflow? Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name ;",tsunghan@access-ci.org,Tsung-Han Li,Guangzhen Jin,,Anvil,3,17,45,2023,2023-11-06
ATS-4642,Required modules,2023-11-28,2023-12-05,"I am trying to analyze the output of a run which requires matplotlib. I am getting an error about the version needed, which I have pasted below. I am not sure if this has to do with the python version available through Anvil. If I need a different version of python, would I be able to install it (w/ miniconda maybe) in my work directory to use? ; Hi name, Thank you for reaching out. It seems the module {{python/3.9.5}} is deployed with NumPy 1.19.5. If you need a higher version, I would suggest you create a custom Conda environment and install the needed packages there. For detailed instructions, please refer to the user guide below: https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/python: https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/python|smart-link If you encounter any further issues, please let me know. Thanks, name ; Hi name, Since I have not heard further questions from you in a while, I'm tentatively marking this ticket as resolved at this point. If you need further assistance, please feel free to reopen the ticket or submit a new one to us. Thanks, name ;",jsullivan1@access-ci.org,James Sullivan,Ruyi Li,Purdue University,Anvil,4,6,48,2023,2023-11-27
ATS-4704,Runtime error on Anvil,2023-11-30,2023-12-03,"Hello, I am trying to set up my model workflow on Anvil which has previously been run successfully on other resources such as Stampede2. I am running into issues which I expect are due to module or versioning differences and I am hoping you can help. My workflow combines Cythonized Python code, compiled C code, and MPI. Everything compiles ok, but I am sometimes encountering runtime segfaults when I use 2 or more nodes. This does not always occur, but more than half of jobs. For example: a983:2508338:0:2508338 Caught signal 11 (Segmentation fault: address not mapped to object at address 0xffffffff80011ba0) When the segfaults occur, I also see the following message which does not appear when the segfaults do not occur: BFD: Dwarf Error: Can't find .debug\\_ranges section. Any idea what is causing this ""Dwarf Error""? I don't know if this is the main source of my problem or not, but I'm hoping it signals an easy library path fix…? See below for the full backtrace in case that is helpful. Here are my environment commands: module load modtree/cpu module load py-mpi4py/3.0.3 module load hdf5/1.10.7 source .venv\\_calfews/bin/activate Module list: Currently Loaded Modules: # gmp/6.2.1 4) zlib/1.2.11 7) numactl/2.0.14 10) modtree/cpu 13) libszip/2.1.1 # mpfr/4.0.2 5) gcc/11.2.0 8) openmpi/4.0.6 11) python/3.9.5 14) hdf5/1.10.7 # mpc/1.1.0 6) libfabric/1.12.0 9) xalt/2.10.45 (S) 12) py-mpi4py/3.0.3 Backtrace from segfault error (note only #1 is specific to my particular software I believe) ==== backtrace (tid:id) ==== 0 0x0000000000012cf0 \\_\\_funlockfile() :0 1 0x0000000000005e3c BORG\\_Problem\\_set\\_bounds() ???:0 2 0x000000000000793d ffi\\_call\\_unix64() :0 3 0x000000000000624b ffi\\_call\\_int() ffi64.c:0 4 0x000000000000d3bd \\_ctypes\\_callproc.cold() callproc.c:0 5 0x0000000000008993 PyCFuncPtr\\_call.cold() \\_ctypes.c:0 6 0x00000000001334c3 \\_PyObject\\_MakeTpCall() ???:0 7 0x00000000001899e0 \\_PyEval\\_EvalFrameDefault() ???:0 8 0x0000000000133c44 \\_PyFunction\\_Vectorcall.localalias() call.c:0 9 0x000000000018475f \\_PyEval\\_EvalFrameDefault() ???:0 10 0x00000000001835e9 \\_PyEval\\_EvalCode() :0 11 0x0000000000133cdc \\_PyFunction\\_Vectorcall.localalias() call.c:0 12 0x00000000001356c7 method\\_vectorcall() classobject.c:0 13 0x0000000000187a2b \\_PyEval\\_EvalFrameDefault() ???:0 14 0x00000000001835e9 \\_PyEval\\_EvalCode() :0 15 0x00000000001331c9 \\_PyObject\\_FastCallDictTstate() ???:0 16 0x0000000000134329 \\_PyObject\\_Call\\_Prepend() ???:0 17 0x0000000000163988 slot\\_tp\\_init() typeobject.c:0 18 0x000000000016143b type\\_call() typeobject.c:0 19 0x00000000001334c3 \\_PyObject\\_MakeTpCall() ???:0 20 0x00000000001851de \\_PyEval\\_EvalFrameDefault() ???:0 21 0x0000000000133c44 \\_PyFunction\\_Vectorcall.localalias() call.c:0 22 0x000000000018452c \\_PyEval\\_EvalFrameDefault() ???:0 23 0x00000000001835e9 \\_PyEval\\_EvalCode() :0 24 0x00000000001f6ef1 \\_PyEval\\_EvalCodeWithName() ???:0 25 0x00000000001f6e99 PyEval\\_EvalCodeEx() ???:0 26 0x00000000001f6e5b PyEval\\_EvalCode() ???:0 27 0x00000000002086a4 run\\_eval\\_code\\_obj() pythonrun.c:0 28 0x00000000002081fb run\\_mod() pythonrun.c:0 29 0x00000000000dfbe2 pyrun\\_file.cold() pythonrun.c:0 30 0x0000000000207f63 PyRun\\_SimpleFileExFlags() ???:0 31 0x000000000020f21d Py\\_RunMain() ???:0 32 0x000000000020eda9 Py\\_BytesMain() ???:0 33 0x000000000003ad85 \\_\\_libc\\_start\\_main() ???:0 34 0x000000000040112e \\_start() ???:0 ================================= ; Primary job terminated normally, but 1 process returned a non-zero exit code. Per user-direction, the job has been aborted. ; mpirun noticed that process rank 4 with PID 0 on node a988 exited on signal 11 (Segmentation fault). ; Thanks for any help you can provide ; Hi there, just writing to say that I resolved my issue. It was a problem with my C extension module for Python (with architecture-specific failure mode that we had not seen on other machines) rather than a compiler/dependency issue on Anvil. Thanks anyway for your help ;",ahamilton144@access-ci.org,Andrew Hamilton,Amiya Maji,Purdue University,Anvil,5,2,48,2023,2023-11-27
ATS-4710,ACCESS Allocation on Purdue Anvil CPU,2023-11-30,2023-12-05,"Hello, I am running jobs on Purdue Anvil using resources from the ""dmr160063"" allocation. My PI has been trying to transfer SUs to this allocation on the ACCESS portal, but they haven't been coming through. On the Allocations Usage page, it shows ""Purdue Anvil CPU"" under inactive awards. On Anvil, it shows me this allocation: $ mybalance x-psharma3 Allocation Type name Limit name Usage name Usage name Balance Account (account) (user) ============= ==== ========== ========== ========== ========== dmr160063 CPU 166667.0 166667.5 166667.5 n/a nnt220002 CPU 733805.0 725531.1 725531.1 8273.9 The balance shows up as n/a, and not 0. How can we add more resources to this allocation? Thanks, name ; Hi, Thank you for contacting us. Yes I did not find the ACCESS credits transfer either. Let me try to loop ACCESS support for this issue. Once the transfer has been completed, it will be picked up and propagated by Anvil. Best regards, name Senior Computational Scientist Purdue Information Technology ; \\*\\*PRIVATE NOTE\\*\\* ACCESS Allocations: https://access-ci.atlassian.net/jira/people/team/bb58a2c1-b952-4323-ae42-fddf8975f846?ref=jira$&src=issue (~accountid:id:id-8db5-4806-a79d-06d357bb8158] ~accountid:id) Hi, Could you help check on this user's allocation request? Thanks. Best regards, name Senior Computational Scientist Purdue Information Technology ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id This is what we see. We believe that the Transfer on 11/30/23 wasn't processed yet and once it is processed everything should match. ; \\*\\*PRIVATE NOTE\\*\\* [~accountid:id Thank you for looking into that! ; Hi, We saw the allocation transfer on 11/30/23 and it wasn't processed yet. Once it is processed everything should match. Best, name ; Okay thanks, I have received the resources! ---- ;",psharma3@access-ci.org,Pranav Sharma,Guangzhen Jin,Purdue University,Anvil,7,4,48,2023,2023-11-27
ATS-4724,Increase storage quota for each user in my project,2023-12-01,2023-12-08,"How can I change the storage quota of my users. Currently my users have 25GB each but my project has 1TB of allocation. I have 5 users, how can i allocate more storage to them. ; Hi Vivek, Thank you for reaching out. On Anvil, each user should get a quota of 25GB on their home directory and 100TB for their scratch directory. For more information, please see the documentation at the following link: https://www.rcac.purdue.edu/knowledge/anvil/storage/filesystems: https://www.rcac.purdue.edu/knowledge/anvil/storage/filesystems|smart-link On the cluster, you can run the command {{mybalance}} to see the quotas and usage of the spaces: $ myquota x-vsharma6 Type Location Size Limit Use Files Limit Use ============================================================================== home x-vsharma6 24.4GB 25.0GB 98% - - - scratch anvil 0KB 100.0TB 0% 0k 1,000k 0.00% projects x-cda090008 1.6TB 5.0TB 32% 3,827k 4,194k 91% projects x-cis230306 0KB 5.0TB 0% 0k 1,048k 0.00% It looks like your group members have not used much of the provided storage yet. If you need more storage, would you please share more information about your workflow? Thanks, name ; Hi Vivek, I just noticed that there was a typo in my last reply, the command should be {{myquota}}. Apologies for that. Since I have not heard back from you in a while, I'm tentatively marking this ticket as resolved at this point. If you still need assistance regarding your storage on Anvil, please feel free to reopen this ticket or submit a new one to us. Thanks, name ;",vsharma6@access-ci.org,Vivek Sharma,Ruyi Li,I do not know the RP,Anvil,3,6,48,2023,2023-11-27
ATS-4774,Job not running,2023-12-05,2023-12-06,"My job remains in pending mode with reason ""AssocGrpCPUMinutesLimit"". However, I have consulted my supervisor, he has credited more computing hours but they are not reflecting in my account. My balance shows: ees230052 CPU 500000.0 499661.9 499661.9 338.1 ; Hi Krishan, Thank you for contacting us. I just checked the information of allocation {{ees230052}}, but could only find one transfer of 500,000 SUs, which happened on 09/15/2023. To help us investigate, would you please verify with your supervisor if the new transfer has been approved? Thanks, name ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id - it seems there is an incomplete Exchange Request which was done yesterday on the Accelerate Allocation EES230052. They will need to go back in the Exchange Request and submit it. They can follow these steps to get there and submit: # Login to ACCESS: +https://allocations.access-ci.org+: https://allocations.access-ci.org/ # Click on ""Manage Allocations"" # Click on ""Manage My Projects"" # You will then see your allocations listed # Click on the word ""Edit"" ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id Thanks a lot for the information! I'll pass the message to Krishan then. The new feature {{notification watcher groups}} is very helpful! I like it very much. ; Hi Krishan, I just received a note from the ACCESS allocation team. It seems there is an incomplete Exchange Request which was done yesterday on the Accelerate Allocation EES230052. Your supervisor would need to go back in the Exchange Request and submit it. They can follow these steps to get there and submit: # Login to ACCESS: https://allocations.access-ci.org # Click on ""Manage Allocations"" # Click on ""Manage My Projects"" # You will then see your allocations listed # Click on the word ""Edit"" Thanks, name ; I have confirmed with my supervisor. He has completed the submission. Could you tell me how long it will take to get it approved? ---- ; Hello, I hope your Wednesday is going well. The Allocations Team will contact the reviewers and ask them to expedite the review. Let us know if you have any questions along the way. If you have any questions in the future, please visit this site ([https://access-ci.atlassian.net/servicedesk/customer/portal/2: https://access-ci.atlassian.net/servicedesk/customer/portal/2|smart-link ) and submit a ticket. name Pusateri ACCESS Allocations ;",kchand1@access-ci.org,Krishan Chand,Ruyi Li,Pittsburgh Supercomputing Center (PSC),Anvil,7,2,49,2023,2023-12-04
ATS-4814,Stale file handle error on login04.anvil,2023-12-06,2023-12-07,"I get a ""stale file handle"" error when I try to access my files in scratch on login04.anvil. I can access these files when I SSH into login05. Terminal log attached. ; ^stale-file-handle.txt ; Hi name, Thank you for reporting the issue. It has been fixed. You should be able to access the files in your scratch directory on {{login04}} now. I'm tentatively marking this ticket as resolved at this point. If you see any further issues, please feel free to reopen the ticket or submit a new one to us. Thanks, name ;",pballaney@access-ci.org,Pranav Ballaney,Ruyi Li,Purdue University,Anvil,3,2,49,2023,2023-12-04
ATS-3842,Not able to access internet from GPU nodes on Purdue Anvil,2023-10-19,2023-12-12,"I am able to ping websites when I'm on the login node, but not from a GPU node. Screenshot attached. It works occasionally, but times out most of the time. ; Hi, Thank you for contacting us. We can confirm this issue and will report it to our engineering team. Will get back to you when it's fixed. Thank you. Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi, We believe this issue has been resolved. Can you confirm from your end? Best, name ;",amalusare@access-ci.org,Aditya Malusare,Guangzhen Jin,Purdue University,Anvil,4,39,42,2023,2023-10-16
ATS-3844,error when submitying the job,2023-10-20,2023-12-12,"Dear staff, I met some difficulties with job submission. I tried to run my case with parallel computing, and it worked well when it was run on the command line. But when I submitted it to the supercomputer, there was an error saying ""Environment is too large (max is 193)"". I'd like to know how to deal with it. The attached file ""O2.e3239865"" is the error report, and ""run\\_anvil.sh"" is the file I use to submit the job. Thank you! I hope to hear from you soon. Best, Jingyao ; ^O2.e3239865] ^run\\_anvil.sh ; Hi, Thank you for contacting us. Looks like you are using the mpi inside of petsc instead of system {{mpiexec}}. Could you try {{mpiexec -np 512 ./gvg > output.log}} for the command in {{run\\_anvil.sh}} and see if it helps? Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi name, Thank you for your suggestion. I modified the code but still got an error, and the output file is empty. The modified run\\_anvil.sh and the error file are attached. I'd appreciate it if you could help me see where the problem is. Best wishes, Jingyao ACCESS Ticket Submission : mailto: 于2023年10月24日周二 08:55写道: [^run\\_anvil (42560995-c748-4ee2-8eea-d74f79d1c840).sh \\_(0.0 kB)\\_ ^O1.e3258279 \\_(0.0 kB)\\_ ; Hi, It looks like a PETSC internal error rather than a job error. I might suggest to re-compile PETSC on Anvil and see if it can solve the problem. Best, name ; Hi, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name ;",jchen18@access-ci.org,Jingyao Chen,Guangzhen Jin,Purdue University,Anvil,6,38,42,2023,2023-10-16
ATS-3984,Re: ATS-2492 Inefficient jobs on ANVIL,2023-10-27,2023-12-13,"Hi name, I turned the INCAR parameters to the default and I relaxed the POSCAR file again. I am still getting an error message: ""; mpirun noticed that process rank 16 with PID 0 on node a541 exited on signal 9 (Killed). ; slurmstepd: error: Detected 1 oom\\_kill event in StepId=3292931.batch. Some of the step tasks have been OOM Killed."" I looked into the VASP forum and found this error message is associated with lack of memory. The email notification from ANVIL also reads: ""Slurm Job\\_id=3292931 Name=3K-mtzB Failed, Run time 00:45:45, OUT\\_OF\\_MEMORY"" To overcome the memory problem, I tried to a command in my slurm.sub file following ulimit -s unlimited. This did not help. Futhermore, I am using 2 nodes on the wholenode partition. Do you have any recommendations to overcome this issue? My slurm.sub input is copied below for you: # ================================================================================== # Regards, name ; Hi name, Thank you for the update. This sounds promising. We look forward to hearing back from you on the openmpi tests. name ---- ; Hi name, Have you had a chance to test/update the openmpi version on Anvil? Could you please let us know an update? name ; Hi name, Although new version of openmpi works, we cannot update it until the next Anvil maintenance. At this point, I would recommend to install openmpi 4.1.4 on your own project space, and compile VASP manually with installed openmpi. You can use Spack to install openmpi and create a local module, then follow the instructions to install VASP5 on your project space. https://spack-tutorial.readthedocs.io/en/latest/: https://spack-tutorial.readthedocs.io/en/latest/|smart-link https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/vasp/build\\_your\\_own\\_vasp\\_5: https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/vasp/build\\_your\\_own\\_vasp\\_5|smart-link Regards, name ;",,,Nannan Shan,Purdue University,Anvil,8,34,43,2023,2023-10-23
ATS-4167,Accessing new allocation on Purdue Anvil,2023-11-03,2023-12-13,"Greetings, Recently, a research collaborator, Sara Porchetta, added me to their ACCESS Maximize allocation on Purdue Anvil EES230042. I can view the new allocation in-browser on the ACCESS web portal, but I cannot run jobs on Anvil. My ACCESS username is kheck and my Purdue RCAC username is x-heck. Thanks, name Heck ; Hi, Thank you for contacting us. Your access and allocation on Anvil should be fine. Could you share the workflow on how you run jobs on Anvil so I can take a look? Best regards, name Senior Computational Scientist Purdue Information Technology ; Greetings, Previously when using mybalance , it only showed my previous allocation and I could not run jobs i.e., sinteractive -N 1 -n 1 -A ees230042 . I received an email from RCAC this morning saying that my account is ready, and everything seems to be working now. Thank you, name ---- ;",kheck@access-ci.org,Kirby Heck,Guangzhen Jin,Purdue University,Anvil,3,29,44,2023,2023-10-30
ATS-5723,Recently declined project,2024-01-28,2024-02-05,"Dear ACCESS Support Team, I recently submitted request for resources for my NSF EAR Postdoctoral Fellowship research. I am co-advised by researchers at UC-Santa Barbara (Eckart Meiburg) and at UBC in Vancouver, Canada (Mark Jellinek). The component of the project I submitted to ACCESS is mainly with Eckart Meiburg in UC-Santa Barbara and I should rather change my affiliation to be UC-Santa Barbara. Would it be alright to have my request reconsidered with that affiliation? Thank you for your time and understanding. Cheers, name ; Hello name, Unfortunately, you need to keep you current coordinates if that is your home institution, but some have appointments at more than one institution, but we don't see this on your CV. The other option is making Eckart the PI and you be the co-PI but Eckart would truly have to have a role in this project. Lastly, we see you have an NSF fellowship and this may make you eligible but we need to get clarification from the NSF on this. Could you provide your NSF Fellowship grant number or even the fellowship letter? Let us look into this and we will get back to you soon. Ken Hackworth - ACCESS Allocations ; Dear Ken, Thank you for getting back to me so quickly. I would really appreciate your help on this matter. Thank you. I have forwarded the award letter to you. I am also attaching an abstract here for a conference as additional proof of Eckart's involvement. You will see that the second author of this project is name Leonelli, who is Eckart Meiburg's student. I work with them and the mechanical engineering group at UC Santa Barbara. Eckart may be the project PI if needed. That was our original plan, but I thought if I had my NSF Fellowship I may be eligible. I should also note that my funding is fully with the NSF EAR Fellowship (award number 2204594) regardless of my base institution. I should also note that my fellowship does not force me to be at a single institution. I have spent a few months with Eckart at UC Santa Barbara before coming to Vancouver in October. I needed to declare UBC as my home institution for work permit purposes. I chose UBC because I want to work with Indigenous Knowledge Researchers and First Nation Community Members. I hope further context on my award will be helpful. Cheers, name ^ICOP 2024.docx \\_(0.0 kB)\\_ ; Hi Jira, I wanted to follow up to see how this is progressing. Please let me know if there is anything I can do to help. Cheers, name ; Hi name, Sorry for the delay, we checked in with the NSF about this and have been given the name light to approve your request. We will resubmit your Explore request and process. Watch for notifications. Cheers, Ken Hackworth - ACCESS Allocations ; This is GREAT news! Thank you so much. Cheers, name ;",cculha@access-ci.org,Cansu Culha,Ken Hackworth,Purdue University,Anvil,6,6,4,2024,2024-01-22
ATS-4532,need access to Purdue anvil,2023-11-17,2023-12-13,"Hello can you please grant me access to Purdue Anvil. My grant no is geo170003. I cant submit jobs via vasp, here is my error ""rm: cannot remove 'runTime.txt': No such file or directory Lmod has detected the following error: WARNING: this software has a license restricted to approved users. Users have to show their licenses and be confirmed by the VASP team that they are registered users under that license. Please send a ticket request access. While processing the following module(s): Module fullname Module Filename ; vasp/5.4.4.pl2 /opt/spack/cpu-20211007/openmpi/4.0.6-3navcwb/gcc/11.2.0/vasp/5.4.4.pl2.lua /var/spool/slurm/job3710423/slurm\\_script: line 21: mpirun: command not found"" Thank you name ; Hi, Thank you for contacting us. You will need to be added into the VASP license to use it. Could you let me know your registered email for VASP license so I can take a look and confirm? Best regards, name Senior Computational Scientist Purdue Information Technology ; Hello name, The registered email addresses are (1) : mailto: (primary) (2) : mailto: (additional) Thank you name Mookherjee Associate Professor Earth, Ocean and Atmospheric Sciences Florida State University Tallahassee, Fl, 32306, USA Phone:( (Office) Email: : mailto: Email: URL:http://myweb.fsu.edu/mmookherjee ^smime.p7s \\_(0.0 kB)\\_ ; Hi, You have been added to vasp5 and should have access now. Will resolve the ticket. Please re-open it if further issues happen. Best, name ;",mainak@access-ci.org,Mainak Mookherjee,Guangzhen Jin,Purdue University,Anvil,4,19,46,2023,2023-11-13
ATS-4720,Disk Quota Exceeded,2023-12-01,2023-12-12,"Hello, I'm trying to open a new jupyter notebook on anvil but I keep getting the error disk quota exceeded even though I deleted some of my files in the root directory. Could you please help me fix this issue? I really have to run the notebooks asap. ; Hi, Thank you for contacting us. Looks like it's because of your $HOME directory being full. Keep in mind that you have a 25GB quota for home directory. I would recommend to use {{ncdu}} function to get an analysis of your current home directory usage and decide whether to delete more data to free up spaces. You can navigate to Anvil Ondemand->Clusters-> Anvil Shell Access and type {{ncdu}} in the popup terminal. Give it a try and let me know if you have further questions. Best regards, name Senior Computational Scientist Purdue Information Technology ; Yes, thanks for your reply. I ran the command and there are two large folders /.local and /.cache that mostly contain the large files for my experiments. I understand that I have limited disk capacity under my home directory, but I see that I have 5 TB disk space under my project directory. My question is how can I start the jupyter notebooks under that project directory instead of home/m-shokri ? Best, name ; Hi, By default Jupyter notebook will start from your home directory and could not navigate to other top file directory other than {{/home}}. But you can do a trick to add your project space (the 5TB space) into your home as a symlink with {{ln -s /anvil/projects/x-cis230306/xxx myprojects}} (replace {{xxx}} with your actual folder name). Then after opening jupyter notebook you could find a folder called {{myprojects}} under your home directory and it's actually directed to your project space. Note: {{/anvil/projects/x-cis230306}} is a shared space for the entire project so you might need to confirm with PI about it's usage and how you could create your own folder in the space. Let me know if you can make it. Best, name ; Hi name, Thanks for your reply. I did the same and replaced xxx with ""x-mshokri"" which is my actual folder. As you said when I open a Jupyter notebook I see ""myprojects"" but it's not a folder it's a non-readable file. So, I'm not sure how to use it as a folder and store my models in it. I've attached two screenshots. Best, name ; Hi, That is because you have not created your own folder {{/anvil/projects/x-cis230306/x-mshokri}} under your group space {{/anvil/projects/x-cis230306/}}. You will need to navigate to the location {{cd /anvil/projects/x-cis230306/}} and create folder with {{mkdir x-mshokri}}. This can be done via ondemand->Clusters->Anvil Shell Access. name ; Hi name, Thank you very much for your help. I see the folder 'myprojects' now and I think I can just run a new jupyter notebook in that directory. Best, name ; \\*\\*PRIVATE NOTE\\*\\* This is a test note. Anvil Support: https://access-ci.atlassian.net/jira/people/team/9b53a66f-ea4f-4013-a75f-f8d38a20617d?ref=jira$&src=issue (~accountid:id ~accountid:id:id-deb3-4a00-b421-44f90764017f ~accountid:id:id-5a0e-4ef9-9dae-4ff21198071b ~accountid:id ~accountid:id ~accountid:id ~accountid:id ~accountid:id ~accountid:id ~accountid:id ~accountid:id:id-2781-404e-85f3-6f3d3f09f93f ~accountid:id) ; \\*\\*PRIVATE NOTE\\*\\* This is a test note for myself. ~accountid:id ; Awesome! Thank you for the feedback. name ;",mshokri@access-ci.org,Mohammad Shokri,Guangzhen Jin,Purdue University,Anvil,10,8,48,2023,2023-11-27
ATS-4800,Anvil login04 cannot see /anvil/projects (stale file handle),2023-12-06,2023-12-11,"login04.anvil ~ $ ls /anvil/projects /bin/ls: cannot open directory '/anvil/projects': Stale file handle ; Hi Doug, Thanks for reporting this. We've confirmed the issue you mentioned and have notified our storage experts for it. We would keep you posted on this manner. Regards, name, PhD (She/Her) Sr. Computational Scientist ; Hi Doug, I believe login04 problem has been resolved. Thanks for reporting this to us. Regards, name ;",dgc@access-ci.org,Doug Crabill,Nannan Shan,Purdue University,Anvil,3,4,49,2023,2023-12-04
ATS-4561,Issue of Invalid memory allocation,2023-11-20,2023-12-18,"Hi, I was working on Anvil Clusters and some of my recent calculations seemed to resulted in an error of invalid memory allocation. This only happens to some of my jobs. I am sharing the path to one of the jobs that had the error. Could you help me check what might be the cause? Thanks ; Hi name, It looks like you were running a quantum empresso job with your own compiled executable. I am wondering if what mpi libraries for this compilation, is it intel mpi or openmpi? Regards, name ; Hi name, Sorry for the late reply. I am not sure what mpi I'm working with, but I have attached the .bashrc and submission script I have been using. Thanks Regards, name ; Hi name, Can you try {{srun --mpi=pmi2}} instead of {{mpirun}} in your job script? Let me know if this did not work. I am wondering if you have ever run a job on Anvil successfully or this is the first job you have tried to run on Anvil. If other jobs can run, we probably need to look at the compilation. I would not recommend to initiate a python environment along with any of compilers at {{.bashrc}}, you can always move those {{module load}} commands to your submit job script instead of loading them while the shell started. Regards, name ; Hi name, Thanks Best, name ; Hi name, Have you tried to use more than 1 nodes to test your job and see if you still see the same error? Is this the same job you run with success before, but failed recently? Regards, name ;",syj1022@access-ci.org,Yingjie Shi,Nannan Shan,,Anvil,8,21,47,2023,2023-11-20
ATS-4562,Jobs longer than 4 days,2023-11-20,2023-12-21,"Hello, I am currently using parallel metadynamics to calculate the free energy of a nanotechnological system of interest. I am using lammps/20210310, specifically the PLUMED package, which stores data between restarts in HILLS files. Basically, I am running 4-day long jobs on the wholenode partition, using 1 node (128 cores). However, now, for each simulation, the 128 corresponding HILLS files (one for each metadynamics walker) are very large, so while my jobs are running, a large part of the four days is spent reading these files back in to recover the previous energy landscape (so that calculations can continue). An example of a single simulation is at this directory: /anvil/scratch/x-psharma3/3-5-8-10-10k/128. At other supercomputing centers I have used, there were nodes/queues for users who wanted to run their jobs for longer. Is there such an option at Anvil? For example, I would rather run my jobs for 8 days straight then do two four day runs, because I then wouldn't waste a lot of computational time restarting. Thank you for your help. Best, name ; Hi name, Thank you for reaching out. I've shared your request with my colleagues. We would have an internal discussion on it and get back to you after that. What is the maximum walltime needed for your jobs? Thanks, name ; Hi name, The walltime of 4 days is currently working, just working inefficiently. There is theoretically no maximum wall-time (I've left similar calculations running for weeks on other systems), so just let me know what is possible Thanks, name ---- ; Hi name, In addition, I run these jobs using resources from the ""dmr160063"" allocation. My PI has been trying to transfer SUs to this allocation on the ACCESS portal, but they haven't been coming through. On the Allocations Usage page, it shows ""Purdue Anvil CPU"" under inactive awards. Thanks, name ---- ; Hi name, Thanks for the further information. It seems allocation {{dmr160063}} has no remaining SUs at the moment. I would suggest you contact ACCESS allocation team for assistance with credit transfer. $ mybalance x-psharma3 Allocation Type name Limit name Usage name Usage name Balance Account (account) (user) ============= ==== ========== ========== ========== ========== dmr160063 CPU 166667.0 166667.5 166667.5 n/a nnt220002 CPU 733805.0 725531.1 725531.1 8273.9 Once you get a certain amount of SUs available in allocation {{dmr160063}}, we would go ahead and create the QOS for you. Thanks, name ; Hi name, I have resources now, I just needed to wait for the transfer to be processed. Can you set up the QOS for me? Thanks, name ---- ; \\*\\*PRIVATE NOTE\\*\\* @Anvil Applications: https://access-ci.atlassian.net/jira/people/team/0f5fcf8a-26ef-4d24-a346-4a2ef3a7afda?ref=jira$&src=issue (~accountid:id ~accountid:id ~accountid:id:id-5a0e-4ef9-9dae-4ff21198071b ~accountid:id ~accountid:id ~accountid:id ~accountid:id ~accountid:id ~accountid:id:id-2781-404e-85f3-6f3d3f09f93f ~accountid:id) Hi Team, Would you please help create a QOS for user {{x-psharma3}} to run jobs up to 8 days in the {{wholenode}} partition using allocation {{dmr160063}}? Thanks, name ; Hi name, I appreciate your patience. Our experts have created a QOS named {{wholenode-long}} for you to run jobs up to 8 days in the {{wholenode}} partition. To use it, you can add the directive {{#SBATCH -q wholenode-long}} to your submission script. Please make sure that you only use it in the {{wholenode}} partition. Would you please give it a try and let us know if it works for you? Thanks, name ; Hi name, Since your request has been fulfilled and there are no further questions from you, I'm tentatively marking this ticket as resolved at this point. Please feel free to contact us again if you need any help. Thanks, name ; Hi name, Apologies, I had to take a break from research during the past few weeks. I have modified my submission files and started running five jobs successfully. I'll let you know if something else comes up. Thanks for the help Warm regards, name ;",psharma3@access-ci.org,Pranav Sharma,Ruyi Li,Purdue University,Anvil,15,24,47,2023,2023-11-20
ATS-4752,"Urgent - I ran into an issue of ""Invalid memory allocation""",2023-12-04,2023-12-18,Hi I have previously submitted a ticket but the issue has not yet resolved and this is urgent. I am running into an issue of memory allocation. It has been killing my jobs while they are running. I am attaching the error files and my submission script. Please let me know if it is convenient to set up a zoom call as I want to get this resolved ASAP. Many thanks ;,syj1022@access-ci.org,Yingjie Shi,Nannan Shan,Purdue University,Anvil,2,11,49,2023,2023-12-04
ATS-4983,The VASP access request in Anvil,2023-12-16,2023-12-19,"Hi, Our group purchased the VASP license, ""23-0266"", as see the attached figures. Therefore, I would like to request the access of VASP in anvil. My username in VASP is VScoldness. And email is . Best, name ; Hi name, Thanks for reaching out! What is your username on Anvil? I cannot find you with email address, : mailto:. It looks like you also have another email, : mailto:, is this one you used for Anvil? Regards, name, PhD (She/Her) Sr. Computational Scientist ; name, Thanks for your help. Yes. I use : mailto: for Anvil. And my username for anvil is x-yao1. Best, name ; Hi name, You have been added to vasp5 and vasp6 groups on Anvil. Your membership will be ready within a few hours. Please check our user guide for VASP calculations on Anvil. Please make sure you also added 'module load hdf5' to your submit script while you use VASP6. https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/vasp: https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/vasp|smart-link Regards, name ;",vscoldness@access-ci.org,Yi Yao,Nannan Shan,Purdue University,Anvil,5,2,50,2023,2023-12-11
ATS-5008,Correct permissions/ACLs in subdirectories of /anvil/projects/tdm/corporate/raytheo-ddm,2023-12-19,2023-12-19,"We have a large student project directory in {{/anvil/projects/tdm/corporate}}. We created 82 subdirectories within this directory and assigned 82 different groups to them, making them readable and writable by members of those groups, with no permissions for ""other"". We then also added an ACLs to enforce readership by members of x-tdm-admin to all of these subdirectories. This was largely successful, but there were still a couple of subdirectories that were created that we are unable to read, even though the ACLs look right. They are: {{/anvil/projects/tdm/corporate/raytheo-ddm/data/backup/hard-drive-data/data\\_Q2\\_2023/data\\_Q2\\_2023/data\\_Q2\\_2023/}} {{/anvil/projects/tdm/corporate/raytheo-ddm/data/backup/hard-drive-data/data\\_2015/2015/}} Can you please correct the permissions on these directories so both the students and and members of x-tdm-admin can read them? The permissions on {{/anvil/projects/tdm/corporate/raytheo-ddm/}} should be a good working example of how they should appear: login06.anvil ~ $ ll -d /anvil/projects/tdm/corporate/raytheo-ddm/ 1 drwxrws---+ 9 x-kamstut x-tdm-raytheo-001 4096 Dec 19 10:54 /anvil/projects/tdm/corporate/raytheo-ddm// login06.anvil ~ $ getfacl /anvil/projects/tdm/corporate/raytheo-ddm/ getfacl: Removing leading '/' from absolute path names # file: anvil/projects/tdm/corporate/raytheo-ddm/ # owner: x-kamstut # group: x-tdm-raytheo-001 # flags: -s- user::rwx group::rwx group:x-tdm-admin:rwx mask::rwx other::--- default:user::rwx default:group::rwx default:group:x-tdm-admin:rwx default:mask::rwx default:other::--- Thanks! Doug ; Hi Doug, Thank you for contacting us. I just took a look at the permissions of those two directories, it seems the executable bit is not set up for group (notice the uppercase \\*S\\*). Members in the {{x-tdm-admin}} and {{x-tdm-raytheo-001}} Unix groups might be able to list the files (using {{ls }}) but could not traverse the directories or read the files. $ ls -dl /anvil/projects/tdm/corporate/raytheo-ddm/data/backup/hard-drive-data/data\\_Q2\\_2023/data\\_Q2\\_2023/ drwxr-Sr--+ 2 x-jpahukula x-tdm-raytheo-001 4096 Sep 29 11:08 /anvil/projects/tdm/corporate/raytheo-ddm/data/backup/hard-drive-data/data\\_Q2\\_2023/data\\_Q2\\_2023/ $ ls -dl /anvil/projects/tdm/corporate/raytheo-ddm/data/backup/hard-drive-data/data\\_2015/2015/ drwxr-Sr--+ 2 x-jpahukula x-tdm-raytheo-001 16384 Sep 29 11:09 /anvil/projects/tdm/corporate/raytheo-ddm/data/backup/hard-drive-data/data\\_2015/2015/ I would suggest adding the executable bit (e.g. mask::r-x) and see if the problem persists. Thanks, name ; Hi name, I'd love to, but I am not the owner and I am not root, thus I cannot change the ACLs or permissions 😊 Can you please change them (recursively)? Regards, Doug ; Hi Doug, I've made some changes to the permission/ACL settings of those directories. Would you please take a look and let me know if you wanted to add any other changes? I can see several different file modes in {{/anvil/projects/tdm/corporate/raytheo-ddm/}}. Not sure which one is preferred, so I did not change the permissions of the files inside {{/anvil/projects/tdm/corporate/raytheo-ddm/data/backup/hard-drive-data/data\\_Q2\\_2023/data\\_Q2\\_2023/}} or {{/anvil/projects/tdm/corporate/raytheo-ddm/data/backup/hard-drive-data/data\\_2015/2015/}}. It looks like Jaxson ({{x-jpahukula}}) also added some data in {{/anvil/projects/tdm/corporate/raytheo-ddm/}}. You might want to take a look at those subdirectories as well. Since they are actively working on the files, I would suggest discussing permission settings with them, so that the discrepancies could be controlled. Thanks, name ; Hi name, This looks good: login06.anvil ~ $ find /anvil/projects/tdm/corporate/raytheo-ddm ! -readable -print login06.anvil ~ $ The original modes and ACLs applied to this empty directory structure when it was first created: mkdir -m 2770 -p /anvil/projects/tdm/corporate/raytheo-ddm mkdir -m 2770 -p /anvil/projects/tdm/corporate/raytheo-ddm/data mkdir -m 2770 -p /anvil/projects/tdm/corporate/raytheo-ddm/apps mkdir -m 2770 -p /anvil/projects/tdm/corporate/raytheo-ddm/etc chgrp -R x-tdm-raytheo-001 /anvil/projects/tdm/corporate/raytheo-ddm setfacl -R -d -m g:x-tdm-admin:rwx /anvil/projects/tdm/corporate/raytheo-ddm setfacl -R -m g:x-tdm-admin:rwx /anvil/projects/tdm/corporate/raytheo-ddm setfacl -R -d -m o::--- /anvil/projects/tdm/corporate/raytheo-ddm setfacl -R -m g::rwx /anvil/projects/tdm/corporate/raytheo-ddm setfacl -R -d -m g::rwx /anvil/projects/tdm/corporate/raytheo-ddm Everything seems to be working fine as it is! Thanks, Doug ; Hi Doug, Great! Glad to know that. I'll mark this ticket as resolved then. Thanks, name ;",dgc,Doug Crabill,Ruyi Li,Purdue University,Anvil,6,1,51,2023,2023-12-18
ATS-5044,Request file number limit (quota) increase,2023-12-20,2023-12-21,"Hi Anvil Team, I'm requesting to increase of file number limit (quota) on Anvil scratch partition.I'm working on Improved Image classification model research on different data sizes. Currently I have 2 Million file limit to work on the benchmark ImageNet dataset (more than 1.2 Million training images), its subsets and several other datasets for comparison with related work. To fit the file limit, I have to remove some datasets to hold other datasets, which is quite inconvenient when I add another module to compare. Could it be possible to increase my quota? Please kindly consider this request. Thank you so much Sincerely, Chengyuan ---- ; Hi Chengyuan, Thanks for your reply Warm regards, name ;",czhuang@access-ci.org,Chengyuan Zhuang,Ruyi Li,,Anvil,4,2,51,2023,2023-12-18
ATS-4125,Add new Data Mine OnDemand apps visible to just members of group x-tdm-ood-max,2023-11-03,2024-01-03,"Hi name, The four The Data Mine apps we currently have in use with OnDemand cap the number of CPU cores students can request at 16. We do have some corporate partners students who legitimately need more than that, but they really are a minority. We'd like to create a second set of OnDemand apps visible only to this small subset of our students that puts this cap at 128 cores rather than 16. My understanding of the OnDemand documentation makes it look like if these apps are dropped in place with user/group read permissions only, then only the members of that group will see these apps. I have created a new group, ""x-tdm-ood-max"", with currently just members x-dgc and x-dgi804 with the intention of adding just those students we think require additional cores to that group so they can see these new OOD apps. Members of this group will see two different dropdown menus for the Data Mine. They will see a normal ""The Data Mine"" dropdown where all apps are restricted to 16 cores, and they will also see a ""The Data Mine MAX"" where this cap is 128 cores. These are all ready to be dropped in place in from /home/x-dgc/ondemand/dev. I've made changes to all 8 directories. Could you please put all of them in place, but make the four directories ending named \\*\\_max group readable only by x-tdm-ood-max? The other four directories without the \\_max extension should be world-readable. Basically: chgrp -R x-tdm-ood-max \\*\\_max chmod o-rwx \\*\\_max It should look something like this: login06.anvil ~/ondemand/dev $ ll total 28 3 drwxr-xr-x 10 x-dgc x-cis220051 12 Nov 3 08:59 ./ 1 drwxr-xr-x 4 x-dgc x-tra220018 4 Aug 21 15:02 ../ 3 drwxr-xr-x 3 x-dgc x-cis220051 9 Aug 23 22:29 tdm\\_desktop/ 3 drwxr-x--- 3 x-dgc x-tdm-ood-max 9 Nov 1 09:41 tdm\\_desktop\\_max/ 3 drwxr-xr-x 3 x-dgc x-cis220051 8 Oct 3 16:25 tdm\\_jupyter/ 3 drwxr-x--- 3 x-dgc x-tdm-ood-max 8 Nov 1 09:41 tdm\\_jupyter\\_max/ 3 drwxr-xr-x 3 x-dgc x-cis220051 9 Aug 9 15:04 tdm\\_rstudio/ 3 drwxr-x--- 3 x-dgc x-tdm-ood-max 9 Nov 1 09:41 tdm\\_rstudio\\_max/ 3 drwxr-xr-x 4 x-dgc x-cis220051 13 Sep 13 13:43 tdm\\_vscode/ 3 drwxr-x--- 4 x-dgc x-tdm-ood-max 12 Nov 1 09:41 tdm\\_vscode\\_max/ Once we confirm this is working as expected (name and I can see the MAX section but others on our team cannot), we will begin adding others on the Data Mine team plus a handful of students to the x-tdm-ood-max group! Thanks! Doug ; Hi Doug, I have made the changes you requested to the OOD apps. Could you let me know if it is as expected? Kind regards, name ; Hi name, The ""The Data Mine MAX"" menus seem to be working fine, thanks! However, there was an old change I'd made weeks ago that snuck into this update that is causing a conflict with Jupyter Lab. I've made a change to /home/x-dgc/ondemand/dev that should correct it. Can you please drop all 8 directories in /home/x-dgc/ondemand/dev in place again ASAP, making sure to set the group read permissions accordingly? Thanks! Doug ; Hi Doug, I have copied all versions of your TDM apps to OnDemand although there only seemed to be changes to the Jupyter Apps. Let me know if all looks well. Kind regards, name ; Hi Doug, This ticket is looking a little long in the tooth, and I'd like to mark it resolved. Can you confirm things are well with the new read/write privileges? Kind regards, name ; Yes, this is working perfectly, thanks! Regards, Doug ; Glad to hear it--marking resolved. ;",dgc@access-ci.org,Doug Crabill,rderue,Purdue University,Anvil,7,44,44,2023,2023-10-30
ATS-5131,VASP License on Anvil,2024-01-01,2024-01-02,"Per RCAC instructions, I am requesting approval to use VASP 5.4.4 on Anvil. \\*License number:\\* 5-1632 License holder email: : mailto: Thanks, Nick ; Hi Nick, Thank you for reaching out! I've verified your license, using your email address, and added you to the {{vasp5}} Unix group for access to the {{vasp/5.4.4.pl2}} module. You may need to start a new login session, so that your updated group memberships could be recognized. $ groups x-njaegers x-njaegers : x-che230108 vasp5 I'm tentatively marking this ticket as resolved. If you have any further questions, please feel free to reopen this ticket or submit a new one to us. Thanks, name ;",njaegers@access-ci.org,Nicholas Jaegers,Ruyi Li,Purdue University,Anvil,2,2,1,2024,2024-01-01
ATS-5068,My job's status is not changing. It is still pending.,2023-12-22,2024-01-08,"My job is not running. It is keep pending. ; Hi Hyunwoo, Thank you for reaching out. For the moment, I do not see you have any pending jobs, and it seems you have run many jobs since Dec. 22, 2023. Would you please let me know if you still have any questions regarding this ticket? Thanks, name ; Hi Hyunwoo, Since I have not heard further questions from you in a while, I'm tentatively marking this ticket as resolved at this point. If you still need assistance, please feel free to reopen the ticket or submit a new one. Thanks, name ;",hyoo2@access-ci.org,Hyunwoo Yoo,Ruyi Li,,Anvil,3,12,51,2023,2023-12-18
ATS-5170,ANVIL PURDUE increase file quota,2024-01-03,2024-01-08,"Hello, My name is name Canchila, my ANVIL username is: x-ccanchilamar. I'm working under the project x-ccanchilamar. I would like to know if it is possible to increase the limit for the current file quota in the project folder. Our team is developing deep learning models and needs to pretrain the models using the ImageNet dataset and such dataset contains over 1.3 million images for training. Currently the project folder has a limit of 1 million files which name short for our task. Thanks, name ; Hi name, Thanks for reaching out! I am wondering if you have tried to archive these small images into a tar or zip or other format file during training. In this way, the file quota limit is not a problem. We have many users are archiving small files for their AI workflow. Regards, name, PhD (She/Her) Sr. Computational Scientist ; Hello name, I'm actually using that approach. However, I suffer from performance issues (I need to load an entire tar/file containing multiple images just to load a single image). I would like to avoid such performance bottleneck since the models need training for many hours and any saved time is valuable. Thanks, name ; Hi name, Our storage expert has increase your quota to 2 millions. Hopefully this would help with your project. Regards, name ; Hi name, I noticed the change, thank you for your support! name ;",ccanchilamartinez@access-ci.org,Carlos Canchila Martinez,Nannan Shan,Purdue University,Anvil,5,4,1,2024,2024-01-01
ATS-5211,Job run in ANVIL,2024-01-05,2024-01-09,"I am trying to run NAMD simulation of a protein protein complex system for 100 ns. After 48 hours of job run it completes only about 20 ns. I need to run multiple system but it takes huge time and multiple submission and I cant complete a job successfully due to time and space limitation for storage. If I could increase the number of node and time in my script it would be very helpful to manage my jobs. Also it would be a great help if I could get a suggestion to increase the job running performance after reviewing the attached submission script. ; ^namd\\_prod0.pbs] ; Hi, Thank you for contacting us. I saw you are running your jobs without specifying a partition so it will be submitted to the default {{shared}} queue which only allows as much as 1 single node (128 cores) for one job. You should also be able to use {{wholenode}} queue which will allow jobs requesting for up to 16 nodes (2,048 cores). You can add an option {{#SBATCH -p wholenode}} to your job submission file and use {{#SBATCH -N xxx}} to specify the number of nodes needed. Note that you can only use the entire node(s) on {{wholenode}} partition. Give it a try and see how it works for you. If 2048 cores is still not sufficient, a more tolerant partition called {{wide}} will allow up to 56 nodes (7,168 cores). Best regards, name Senior Computational Scientist Purdue Information Technology ; See more details about partitions at [https://www.rcac.purdue.edu/knowledge/anvil/run/partitions: https://www.rcac.purdue.edu/knowledge/anvil/run/partitions|smart-link ; It is working well. Thank you so much. Best Regards Md. Mehedi name ; Awesome! Thank you for the update. name ;",mhasan1@access-ci.org,MD MEHEDI HASAN,Guangzhen Jin,Purdue University,Anvil,6,3,1,2024,2024-01-01
ATS-5285,Anvil reports more CPUs than actual use,2024-01-09,2024-01-11,"Hi, When I submit my job which uses only 1 cpu, it will give me a lot of CPUs than actual use. Could you help take a look into this? For example, the first attached figure is a screen shot of jobs i submitted, they only use 1 cpu. The second is the number of cpus that are assigned to my jobs when running. ; Hi Wenliang, Thanks for reaching out Looks like you already find the answer! The amount of memory is allocated with number of CPUs. If you requested 100GB, it would be ~50CPUs as one CPU will have ~2GB memory. Regards, name ;",wangwl@access-ci.org,Wenliang Wang,Nannan Shan,Purdue University,Anvil,5,3,2,2024,2024-01-08
ATS-5209,Disk Quota Exceeded even though I changed the project directory,2024-01-05,2024-01-19,"Hi, I recently had an issue with disk quota and even though we are assigned 1TB for our project, my home directory (""shayan"") or (""x-mshokri"") has only 25GB allocated. I requested help before and name told me to create another folder (""myproject"") which is under the project directory /anvil/projects/x-cis230306/. I did that but again when I'm downloading a Model is getting stored under home/x-mshokri/.cache/huggingface/hub. how can I change this to be saved under the x-cis230306 directory where I have more space? Thanks ; Hi name, Another member of our staff will probably continue this conversation with you, but just wanted to jump in with a quick solution that I use for this sort of thing. A lot of software want to write data to predetermined conventional locations (such as ~/.cache). Specifically though, I'm fairly certain the \\_huggingface\\_ tooling allows you to control all of this. On an HPC cluster with many different file systems optimized for different use cases though, I like to keep things organized in my home directory in their conventional locations and just use symbolic links to redirect data to the appropriate place. In most cases I would point the symlink at some place in your project space so that it is persisted. In this case however, a cache directory is meant for temporary storage, I would make use of your scratch space. Something like, $ mv ~/.cache $CLUSTER\\_SCRATCH/cache $ ln -sf $CLUSTER\\_SCRATCH/cache ~/.cache Now any application wanting to read/write to the canonical ~/.cache will have the effect of using the Scratch filesystem (more capacity and performance) with the added benefit of automatic expiration. Cheers, name -- Lead Research Data Scientist Rosen Center for Advanced Computing Purdue University ; Hi name, Thanks for your prompt response. As you suggested I figured out that I can modify the ""cache\\_dir"" in when downloading Hugging face models, and it seems to be working well now. Do you still recommend using the commands for pointing the symlinks to other locations? Best, name ; Hi name, My name is name and I'm a research computing coordinator at RCAC. Glad to know modifying the destination for {{cache\\_dir}} resolved your issue. You still can use the commands recommended by name to set up the symlink to move the cached files to your scratch directory. Since the issue has been resolved, I'm tentatively closing this ticket at this point. Please feel free to contact us again if you have any other questions. Thanks, name ;",mshokri@access-ci.org,Mohammad Shokri,Ruyi Li,Purdue University,Anvil,4,11,1,2024,2024-01-01
ATS-5287,Problem building VASP5.4.4+wannier90,2024-01-09,2024-01-18,"I am trying to build the bvasp5.4.4+wannier90 on ANVIL. However, I keep getting the error message: ""/usr/bin/ld: cannot find /apps/spack/anvil/external/vasp/wannier90-3.1.0-gcc-11.2.0/libwannier.a: Permission denied"". Since wannier90 is an open-source code, there should not be any license requirement, so I am confused. Could you help me to check whether there is anything wrong? ; Hi Yunfan, Thanks for reaching out! Can you share what modules you have loaded while compile VASP with wannier90? Regards, name, PhD (She/Her) Sr. Computational Scientist ;",liangy12@access-ci.org,Office Hours by Yunfan Liang,Nannan Shan,,Anvil,2,8,2,2024,2024-01-08
ATS-5312,Job run in ANVIL,2024-01-10,2024-01-18,"I am trying to run NAMD simulation of a protein protein system for 100 ns. But the simulation only completed about 20 ns after running for 48 hrs. I have tried using node 1 and also by using node 3 but the running performance was not increased. Also the jobs were remained in PD state. Could you suggest a way how I can increase the simulation running performance after reviewing the attached scripts ; ^namd\\_prod0.pbs ^namd\\_prod1.pbs ; Hello! Thanks for reaching out! I do not think we have NAMD expert in our team, but from the job submission point of view, I can share a couple of suggestions. First of all, when we bring a new calculation to a HPC cluster, like Anvil, the first step we should do is a scaling test. The scaling tests can be very quick, we can pick the structures and run a few iterations with different number of cores (for example, 16 cores, 32 cores, 64 cores, 128 cores, 256 cores …). We do not need to do many, 4 or 5 calculations should be good. Then we record the time used for each calculation. You would find that the calculation will not become 'twice' quickly as we double the numbers every time because sometimes it will take long time for I/O not for computing. You can calculate the efficiency according to the tests with different numbers of cores, and chose one for the system. Thus, it is not a simple number I can give you for your calculations, you need to figure it out with a scaling test. Secondly, as we use SLURM as the job scheduler for all the jobs submitted on Anvil. SLURM will find available resource for each job based on the priority. Usually, small jobs will be easier for SLURM and will start quicker than big jobs. That is why your 1-node job can start right away sometimes, while 3-node job will be on the queue pending until SLURM can find the available nodes for your job. In this regard, scaling tests would be helpful as well. With the scaling tests, we know how many cores we should use to maximize the efficiency and it would guarantee we do not request too many cores and waiting too long in the queue to get a job started. Hope this clears some of confusions you have in mind. Regards, name, PhD (She/Her) Sr. Computational Scientist ;",mhasan1@access-ci.org,MD MEHEDI HASAN,Nannan Shan,Purdue University,Anvil,3,7,2,2024,2024-01-08
ATS-5415,Job running in Anvil stalls,2024-01-16,2024-01-19,"Hello, My name is name and I´m a postdoc working in a project that uses model, input files and scripts from previous lab members. Currently I'm running the WRF-Chem model in Anvil, and after a few simulated days (several computational hours) the simulation stalls (keep running but no new output). Let me know if you have any suggestion on how to debug this issue, So far canceling and restarting the model on the day it stopped worked despite delaying the results. The first time I got a notification ""Run time 05:57:12, NODE\\_FAIL"", and the current simulation has the status CG even after 1 hour of canceling the job (I'm not sure if this is normal). Thank you, name ; Hi name, Thank you for reaching out. To help us investigate the issue, would you please share the IDs of the problematic jobs? Warm regards, name ; Hi name, There is two job ids are 4231067 and 4238597. The first job that present problem gives me this notification e-mail: Slurm Job\\_id=4231067 Name=WRF-BAU Failed, Run time 05:57:12, NODE\\_FAIL, ExitCode 0 And the problem persist in this second job: JOBID USER ACCOUNT NAME NODES CPUS TIME\\_LIMIT ST TIME 4238597 x-schuch atm130003 WRF-BAU 1 256 2-00:00:00 CG 1-16:10:27 I have used scancel twice for 4238597 but this job still appears in Anvil from the last 2 hours I'm running another job running in the same folder because of the deadlines of this project. Let me know if you need additional information. Thank you, name ---- ; Hi name, Thanks for the further information. It appears that job 4238597 was in the completing state because of some issues on node a556. It has been rebooted and job 4238597 should be cancelled for now. $ sacct -DXj 4238597 JobID JobName Partition Account AllocCPUS State ExitCode ; -------- 4238597 WRF-BAU standard atm130003 256 CANCELLED+ 0:0 For job 4231067, it seems it failed because node a794 became non-responsive at some point. We are currently investigating the causes. Would you please let us know if you see similar issues with other jobs? Thanks, name ; Hi name, Thank you for the update, we was considering to perform a new QA in the model inputs to check if there is a problem with the model inputs. This issue happens only these two jobs, and the next job was able to run without problem. Thank you, name ---- ; I think the issue is solved ;",schuch@access-ci.org,Daniel Schuch,Ruyi Li,,Anvil,6,4,3,2024,2024-01-15
ATS-5420,Wholenode 8-day QOS Access,2024-01-16,2024-01-19,"Hello, I was recently granted access to a wholenode QOS so I can run longer jobs on Anvil. I ran my jobs on this QOS once, and it was successful and very helpful. After postprocessing, I want to resubmit these jobs, but am receiving the following message during job submission: \\*sbatch: error: Batch job submission failed: Invalid qos specification\\* If possible, I was wondering if I could regain access to the QOS so that I can send these jobs. If not, that is okay, I can go back to running 4 day jobs (though that would be more inefficient). Thanks, name ; \\*\\*PRIVATE NOTE\\*\\* Hi, ~accountid:id. Would you please add the QOS {{wholenode-long}} to {{x-psharma3}}'s allocation {{nnt220002}} as well? Thanks ;",psharma3@access-ci.org,Pranav Sharma,rderue,Purdue University,Anvil,5,4,3,2024,2024-01-15
ATS-5459,VASP access on Purdue Anvil,2024-01-17,2024-01-18,"I need my VASP license approved through Purdue anvil so that I may submit VASP jobs. See attached, an image from my VASP login showing that I am licensed for access to VASP/6.3.0. My VASP account username is jamesgil and my full name is Gillian name. I under the name Research group VASP license owned by Wenhao name (license number 20-0075). ; Hi Gillian, Thanks for reaching out! You have been added to vasp6 groups on Anvil. Your membership will be ready within a few hours. Please check our user guide for VASP calculations on Anvil. Please make sure you also added 'module load hdf5' to your submit script while you use VASP6. https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/vasp: https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/vasp|smart-link Regards, name, PhD (She/Her/Hers) Sr. Computational Scientist ; Thank you so much! I appreciate your prompt response :) Best, Gillian ;",gjames1@access-ci.org,Gillian James,Nannan Shan,Purdue University,Anvil,4,2,3,2024,2024-01-15
ATS-5212,Hanging Jobs,2024-01-05,2024-01-23,"My MPI jobs hang after running for about 30 minutes. My credits continue to decrease during the time that they hang. These jobs do not hang when run in a similar environment on other machines. See, for example, job ID 4210726 ; Hi, Thank you for contacting us. Could you show me more details about ""My credits continue to decrease during the time that they hang.""? Which job(s) did you refer to and were there running jobs at the same time when the suspicious jobs hang? I checked your recent abnormal failed jobs and they were not recorded any runtime in SLURM so should not be charged with SUs theoretically. Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi name, The most recent job was 4210726. My balance this morning is here: While my balance from 13 hours ago was, Best, Dominic name On Jan 5, 2024, at 3:03 PM, ACCESS Ticket Submission wrote: —-—-—-— Reply above this line. name commented: Hi, Thank you for contacting us. Could you show me more details about ""My credits continue to decrease during the time that they hang.""? Which job(s) did you refer to and were there running jobs at the same time when the suspicious jobs hang? I checked your recent abnormal failed jobs and they were not recorded any runtime in SLURM so should not be charged with SUs theoretically. Best regards, name Senior Computational Scientist Purdue Information Technology ---- Automation for Jira changed the status to Waiting for customer. View request: https://access-ci.atlassian.net/servicedesk/customer/portal/2/ATS-5212?token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ0Z3QiOiJhbm9ueW1vdXMtbGluayIsInFzaCI6ImRhYzE4NDBkNDVjNjA3YTk4Y2RkZmIwNDgyYWI1NWFiMGYxYWY5YzdiMmJmY2Q3MmI4ZTQwYTk4YWNiYzg2Y2UiLCJpc3MiOiJzZXJ2aWNlZGVzay1qd3QtdG9rZW4taXNzdWVyIiwiY29udGV4dCI6eyJ1c2VyIjoiMTMxMTAiLCJpc3N1ZSI6IkFUUy01MjEyIn0sImV4cCI6MTcwNjkwNDIwMSwiaWF0IjoxNzA0NDg1MDAxfQ.z-kT2GF\\_aUhKzgTGu8Dw\\_lifkX5zLPy9Vp3imPiAUhc&sda\\_source=notification-email · Turn off this request's notifications: https://access-ci.atlassian.net/servicedesk/customer/portal/2/ATS-5212/unsubscribe?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ0Z3QiOiJhbm9ueW1vdXMtbGluayIsInFzaCI6IjAwNWFlZmQzOWU4Y2RjMDFiNTY2NDJlYzk4ZTRkMzYxZTgxMGFhNWZkYjBlYjRlMTkzZDlmMzlkMmZlNzk3NzAiLCJpc3MiOiJzZXJ2aWNlZGVzay1qd3QtdG9rZW4taXNzdWVyIiwiY29udGV4dCI6eyJ1c2VyIjoicW06YjkxYzliMTctNjYwZi00YTUzLWE2N2EtNTAwMzYxMDZmNTlhOjk0ZjRhYjM5LTk5YmMtNDJjYi04M2VhLTlmZWEzNjk4ODNlNCIsImlzc3VlIjoiQVRTLTUyMTIifSwiZXhwIjoxNzA2OTA0MjAxLCJpYXQiOjE3MDQ0ODUwMDF9.JxD38V\\_qXaUI\\_siBu59fuPpNHjRbFRnBrtnicy54Lno This is shared with . Sent on January 5, 2024 2:03:21 PM CST ; OK. Got it. So what do you mean 'MPI jobs hang after running for about 30 minutes'? The SUs for a job are calculated by the 'Used walltime' not the actual used CPU time so the SUs will still be accumulating even if the job 'hangs' for any reason but the actual wall time is increasing. name ; Hi, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name ;",dchang2@access-ci.org,Dominic Chang,Guangzhen Jin,Purdue University,Anvil,5,13,1,2024,2024-01-01
ATS-5300,Issues while loading modules on Purdue Anvil CPU,2024-01-10,2024-01-24,"Hi Team, I'm looking to use OpenFOAM on Anvil resource and have following questions. Could you please reply to them? # Every time I load openfoam or openfoam/8-20210316, I get attached error. \\*Should we have to first load all prerequisites?\\* # Also, sometimes, few of commands work, such as, blockMesh, while others dont work, such as snappyHexMesh? \\*How to ensure that all commands are working?\\* Please find below job submission script. I'm looking to submit a job on 16 CPUs. \\*Option A\\*: #SBATCH --nodes=1 #SBATCH --ntasks-per-node=16 #SBATCH -n 16 \\*Option B\\*: #SBATCH --ntasks=16 \\*Of the above two options, which ones is good from the parallel speed perspective? If you can share an example job submission scipt for OpenFOAM, that'd be useful.\\* Should you have any questions, please let me know. Thank you, ; Hi Jagan, Thanks for reaching out ; Hi Dr., please ignore my today's email -- I figured out loading openfoam/8-20210316. Could you help me on parallel speed -- I understand that it is problem specific -- any suggestions/best practices is useful. Simulations are running very slow, in my option. Best, ; Hi Jagan, Thanks for letting me know you can load the modules on Anvil now. Speaking of the parallel speed, I would recommend to run scaling tests for your system. When we bring a new calculation to a HPC cluster, like Anvil, the first step we should do is a scaling test. The scaling tests can be very quick, we can pick the structures and run a few iterations with different number of cores (for example, 16 cores, 32 cores, 64 cores, 128 cores, 256 cores …). We do not need to do many, 4 or 5 calculations should be good. Then we record the time used for each calculation. You would find that the calculation will not become 'twice' quickly as we double the numbers every time because sometimes it will take long time for I/O not for computing. You can calculate the efficiency according to the tests with different numbers of cores, and chose one for the system. Thus, it is not a simple number I can give you for your calculations, you need to figure it out with a scaling test. On the other hand, as we use SLURM as the job scheduler for all the jobs submitted on Anvil. SLURM will find available resource for each job based on the priority. Usually, small jobs will be easier for SLURM and will start quicker than big jobs. That is why your 1-node job can start right away sometimes, while 3-node job will be on the queue pending until SLURM can find the available nodes for your job. In this regard, scaling tests would be helpful as well. With the scaling tests, we know how many cores we should use to maximize the efficiency and it would guarantee we do not request too many cores and waiting too long in the queue to get a job started. Hope it helps. name ;",jsanghishetty@access-ci.org,Jagan Mohan Sanghishetty,Nannan Shan,Purdue University,Anvil,6,11,2,2024,2024-01-08
ATS-5630,Data transfer from ANVIL to another cluster,2024-01-24,2024-01-26,"Hi I have been trying to transfer my data from ANVIL to the Negishi cluster at Purdue using the following command: scp -r : mailto::/anvil/scratch/x-mrahman2/CdTe\\_HSE/HSE06 . It is not working; can you please suggest? Thank you Sincerely, name ---- ;",mrahman2@access-ci.org,Md Habibur Rahman,Nannan Shan,Purdue University,Anvil,3,3,4,2024,2024-01-22
ATS-5662,IDL on Purdue Anvil?,2024-01-25,2024-01-25,"Hello, I'd like to run some analysis code on Purdue Anvil using IDL (Interactive Data Language) but I don't see a module for IDL available on the system. Is there a way to load it, or could it be added to the system? Thanks, Vladimir ; Hi Vladimir, Thank you for reaching out. Unfortunately, we do not have a plan to centrally install IDL on Anvil, due to the requirement of licenses. If you have a valid license, you can install IDL in your project space or home directory on Anvil. I'm tentatively marking this ticket as resolved at this point. Please feel free to reopen the ticket or submit a new one to us if you have any further questions or need any help. Thanks, name ;",zhdankin@access-ci.org,Vladimir Zhdankin,Ruyi Li,Purdue University,Anvil,2,1,4,2024,2024-01-22
ATS-5531,Storage limitation in home,2024-01-19,2024-02-01,"My account is x-vsharma6. My data and personal files are stored in scratch directory leaving my home directory empty. Yet, I suppose with lot of pip installs, my directory is full. Is there a way to revert it back to what it was before I was assigned. I am kind of stuck here. Any advice would be helpful. ; Hi Vivek, Thanks for reaching out! There is no way we can increase your HOME quota. One suggestion I have for you is you can put your files on your project folder, /anvil/project/x-cda090008 or /anvil/project/x-cis230306, each project folder has 5TB quota. You can run 'ncdu' command on your HOME directory to check what files have been occupied your HOME and decide if you want to keep them. Here is the user guide you might want to check about the storage options on Anvil. https://www.rcac.purdue.edu/knowledge/anvil/storage/filesystems: https://www.rcac.purdue.edu/knowledge/anvil/storage/filesystems|smart-link Regards, name, PhD (She/Her/Hers) Sr. Computational Scientist ;",vsharma6@access-ci.org,Vivek Sharma,Nannan Shan,Purdue University,Anvil,2,10,3,2024,2024-01-15
ATS-5600,CP2K compile issue,2024-01-23,2024-01-31,"Dear Colleague, I need to use cp2k + plumed (https://www.plumed.org/: https://www.plumed.org/|smart-link ) for simulation. I wonder in the currect version you compiled in anvil, the cp2k contained the plumed or not? If not, could you please compile a private cp2k + plumed version in my folder, such as /home/x-msun3/Codes/? Thank you. Best regards, Minglei ; Hi Minglei, Thank you for reaching out. We just checked that the cp2k module on Anvil is not deployed with plumed support. You could try compiling it with plumed in your home directory. If you encounter any issues, please let us know. The following section of user guide on installing software might be helpful to you: https://www.rcac.purdue.edu/knowledge/anvil/software: https://www.rcac.purdue.edu/knowledge/anvil/software|smart-link Thanks, name ; Hi Minglei, Since I have not heard further questions from you in a while, I'm tentatively marking this ticket as resolved at this point. Please feel free to contact us again if you need any help. Thanks, name ;",msun3@access-ci.org,Minglei Sun,Ruyi Li,Purdue University,Anvil,3,7,4,2024,2024-01-22
ATS-5601,available software,2024-01-23,2024-01-29,"Hi, I recently receives an ACCESS award and am trying to chose the resource that is best for my needs. Do you have computational chemistry software (I'm particularly interested in Gaussian) available for outside users? Thank you, -name ; Hi name, Thank you for contacting us. You may check if the software you planned to use is available on Anvil via the following webpage: https://www.rcac.purdue.edu/knowledge/applications: https://www.rcac.purdue.edu/knowledge/applications|smart-link For Gaussian, since it needs a license, we do not have it pre-installed on Anvil. If you have your own license, you could install Gaussian in your project space. I'm tentatively marking this ticket as resolved at this point. Please feel free to re-open it if you need more information. Thanks, name ;",cmccusker@access-ci.org,Catherine E McCusker,Ruyi Li,,Anvil,2,5,4,2024,2024-01-22
ATS-5651,"I need access to the VASP build on ANVIL.  We have our own license, image attached.",2024-01-24,2024-01-31,"Our group needs access to VASP software on ANVIL. We have our own VASP license, see attachment. Below is information concerning our ACCESS information. Access username: x-ngaugler resource: Purdue Anvil CPU end date: Aug 14, 2026 project: MAT240004: calculating the stability of structural vacancies and its impact of reversible fluoride insertion ; Hi Nikolas, Thank you for reaching out. I've verified your VASP license and added you, name and Dr. Melot to the {{vasp5}} and {{vasp6}} Unix groups on Anvil for accessing the pre-installed vasp modules. You might need to start a new login session in order for the update to take effect. One issue I've encountered is that I was not able to verify name's eligibility of using VASP. Therefore, I have not added name to the {{vasp5}} and {{vasp6}} Unix groups yet. Would you please verify the current status of your license? Thanks, name ; Hi Nikolas, Since I have not heard back from you in a while, I'm tentatively marking this ticket as resolved at this point. Please feel free to contact us again if you need any help. Thanks, name ;",ngaugler@access-ci.org,Nikolas Gaugler,Ruyi Li,Purdue University,Anvil,4,6,4,2024,2024-01-22
ATS-5663,Need VASP 5.4.4 access,2024-01-25,2024-01-31,"I am having trouble using VASP 6.3.0 and I want to try VASP 5.4.4.pl2 - I have a license for both, see attached (I've already been granted access to vasp 6.3.0, and I didn't realize I had to explicitly request access for both) ; Hi Gillian, Thank you for reaching out. I've added you to the {{vasp5}} Unix group as well. For now, you should be able to load the {{vasp/5.4.4.pl2}} module. You might need to start a new login session in order for the update to take effect. $ groups x-gjames1 x-gjames1 : x-mat210016 vasp5 vasp6 I'm tentatively marking this ticket as resolved at this point. Please feel free to contact us again if you need any help or have any questions. Thanks, name ; Thank you so much! It looks like I can't access the module on the compute nodes still, but I'm guessing that may need more time to update? Is there anyone on the VASP team that can help with my other ticket ATS-5634? I am having a great deal of trouble getting VASP to work, and I am a relatively familiar VASP user. I think it may be an environment/parallelization issue. Best, Gillian ; Hi Gillian, No problem. The update might need to take a while to propagate through the systems. We appreciate your patience. Also, please make sure to start a new login session, so that your updated group memberships can be recognized. Regarding ticket https://access-ci.atlassian.net/browse/ATS-5634: https://access-ci.atlassian.net/browse/ATS-5634|smart-link, our expert in VASP is currently investigating the issue and would be in touch with you soon. I'm sorry that I do not have much experience working with VASP. Please let me know if you have any further questions. Thanks, name ; Hi Gillian, Since I have not hear further questions from you in a while regarding your access to the vasp modules, I'm tentatively mark this ticket as resolved at this point. Please feel free to contact us again if you have any other questions. Thanks, name ;",gjames1,Gillian James,Ruyi Li,Purdue University,Anvil,6,5,4,2024,2024-01-22
ATS-5800,Anvil Shared Node Queue,2024-01-30,2024-02-06,"On Anvil, I am submitting a batch job to shared node queue, since I only need 16 cores (not the whole 128). Sometimes I get the attached message that ""A request was made to bind to that would result in binding more processes than cpus on a resource"", but sometimes the job runs fine to completion without an error, even though I am not changing anything about the resources I am requesting. ; Hi name, Thanks for reaching out name ; Hi name, Thanks for letting me know. Glad it worked out now! Regards, name ;",adanbury@access-ci.org,Andrew Danbury,Nannan Shan,,Anvil,5,6,5,2024,2024-01-29
ATS-5711,Urgent: Connectivity Issues with Server Resulting in Job Cancellations,2024-01-27,2024-01-29,"Hi, I am writing to bring to your attention a critical issue I am currently facing problem with Anvil HPC. Unfortunately, I am unable to establish a connection to the server, leading to the automatic cancellation of all my scheduled jobs. Could you please look into this matter urgently and provide assistance in resolving the connectivity issues? I rely heavily on the HPC server for my computational tasks, and the current inability to connect is hindering my progress. Regards, Aashish ; Hello, I hope your Monday is going well. There is currently no SUs available on the Anvil CPU resource for the Research Allocation (MCB160119). If you would like SUs available on Anvil CPU resource, please contact the PI of the Research Allocation (MCB160119) and ask them to submit a Supplement for more SUs on Anvil CPU. Only the PI, COPI, or Allocation Manager can submit a request on an allocation. The PI can read how to submit a Supplement here: (https://allocations.access-ci.org/how-to: https://allocations.access-ci.org/how-to|smart-link ). Please also recommend the PI look into submitting a Renewal in the Maximize Opportunity since the Research Allocation (MCB160119) ends on 03/31/24. The current submission period for the Maximize Opportunity is from December 15 - January 31. If the PI does not submit a Renewal by January 31, they will have to wait to submit a Renewal in the next Maximize Opportunity submission period from June 15 - July 31. The PI can read more about the Maximize Opportunity here: (https://allocations.access-ci.org/prepare-requests: https://allocations.access-ci.org/prepare-requests|smart-link ). Let us know if you have any questions along the way. If you have any questions in the future, please visit this site (https://access-ci.atlassian.net/servicedesk/customer/portal/2: https://access-ci.atlassian.net/servicedesk/customer/portal/2|smart-link ) and submit a ticket. name Pusateri ACCESS Allocations ;",abhatt@access-ci.org,AASHISH BHATT,brandonp,Purdue University,Anvil,2,1,4,2024,2024-01-22
ATS-4346,Several node fails for jobs on wholenode,2023-11-09,2024-02-07,"Greetings, I am running jobs on the wholenode queue on the Purdue Anvil supercomputer. I am trying to run our in-house CFD code which has previously been run by other users on our allocation, but for shorter amounts of time (jobs of comparable number of cores, but less wall-clock time). I submitted two jobs last Sunday 11/05, both initially on 640 cores, and collectively I recieved 19 NODE\\_FAIL failures. It appears that when the program restarts, it does not run at the same speed or efficiency as before the node failure, but the node failure also interrupts writing output logs so I cannot confirm this. I attempted to restart both simulations with new jobs on different cores and different numbers of cores and still received several NODE\\_FAIL errors. Any assistance would be very much appreciated. Best, name Heck ; Hi name, Thank you for reaching out and sorry about the issue. To help us investigate, would you please share the IDs of the jobs where you received the NODE\\_FAIL errors? Thanks, name ; Greetings name, Certainly -- the job IDs that were run in the past week include: 3446942 (9 node fails) 3446951 (2 node fails) 3483148 (3 node fails) 3483154 (3 node fails) I am new to the Anvil system so any help is much appreciated. Thanks! name ---- ; Greetings, I was running some additional tests and I believe I understand the problem. When I receive a NODE\\_FAIL error, does the re-queueing process rerun the original batch file that was submitted to the slurm scheduler? I believe what is happening is that our code is simply restarting (from time zero) each time this happens and overwriting the existing files, including the log file. If this is the case, is there an option to submit jobs that don't re-queue on node\\_fail, as a temporary fix? name ---- ; Hi name, My apologies for the delayed response. We are still investigating the cause for the node failure. It seems your listed jobs indeed got requeued. You can check if a job was requeued using the command {{sacct -j --duplicates}} or {{sacct -Dj }}. For example: $ sacct -XDj 3446951 JobID JobName Partition Account AllocCPUS State ExitCode ; -------- 3446951 padeops wholenode ees230042 640 NODE\\_FAIL 0:0 3446951 padeops wholenode ees230042 640 NODE\\_FAIL 0:0 3446951 padeops wholenode ees230042 640 CANCELLED+ 0:0 Your can add the directive {{#SBATCH --no-requeue}} to your submission script to explicitly request that your job should never be requeued under any circumstances. Thanks, name ; Greetings, I am still trying to work around the node fail issue. I was running some additional small simulations on Monday and encountered more node failures with Job IDs 3886935 and 3887382. The node failures are accompanied by the simulation hanging (job is active for ~1 hr before the node failure, but the time step does not advance). However, I ran several simulations yesterday evening (Job IDs: 3906934, 3906939, 3906944, 3906949, 3906950, 3906952) and all of them succeeded or timed out with zero node failures. Does any of this help diagnose the issue? Thanks, name Heck ---- ; Hi name, Thanks for the further information. We have been digging into the logs trying to find some clues for the failure of the first runs of job 3886935 and 3887382. We noticed that node a784 (3886935 landed on) and a841 (3887382 landed on) became non-responsive for some reason. We have asked the engineers to take a look at the nodes and will let you know if we hear anything back. In the interim, we wanted to see if the issue is reproducible. Would you please share your code and input file(s) with us? Thanks, name ; Greetings name, Thank you very much for looking into this. I am running an in-house LES code PadeOps (https://github.com/Howland-Lab/PadeOps: https://github.com/Howland-Lab/PadeOps) and I am not sure what the best way to share this with you is. Can I add global read/execute access to the installation location on my personal directory? If someone needs to install the code from Github, it may be a bit of an involved process. Many thanks, name ---- ; \\*\\*PRIVATE NOTE\\*\\* Anvil Operations: https://access-ci.atlassian.net/jira/people/team/4c470ffb-7177-4452-aeaf-9be39b647dc2?ref=jira$&src=issue (~accountid:id ~accountid:id:id-deb3-4a00-b421-44f90764017f ~accountid:id ~accountid:id ~accountid:id:id-248a-43b5-a841-66499835a741) Hello, We have escalated this ticket to your Team. Please assign it to a team member. Anvil Support ; Ive checked the two nodes that were mentioned. Mounts were not active in one of them (now re-mounted), but otherwise both have been running jobs for over a week. ; name, Since we haven't heard back since name's update, we are going to resolve this ticket. Thanks, name ;",kheck@access-ci.org,Kirby Heck,Ruyi Li,Purdue University,Anvil,11,65,45,2023,2023-11-06
ATS-5333,Jobs going to PD,2024-01-11,2024-02-06,"Hello, I submitted a few jobs in last one weeks and most of the jobs are not running. They are going to ""PD"" and not starting. Same happens for my student. Could you please let me know what the issue is and how to solve this issue? Thank you. ; Hi Shahid, Thank you for reaching out! I checked your jobs (using the commmand {{squeue -name che210078}}) and noticed that most of them are pending because of ""AssocGrpCPUMinutesLimit"", which indicates that the remaining SUs in the allocation {{che210078}} is not sufficient to have any of your pending jobs to get started. It seems the allocation has 8628 SUs in balance. $ mybalance x-name Allocation Type name Limit name Usage name Usage name Balance Account (account) (user) ============= ==== ========== ========== ========== ========== che210078 CPU 13500000.0 13491371.4 364111.2 8628.6 che210078-gpu GPU 28000.0 8011.1 4507.0 19988.9 Part of it is reserved for your running job 422340: $ jobsu 4224340 Job SUs for 4224340 Job 4224340 Submitted on: shared Job status: RUNNING Reserved Walltime: 2-00:00:00 (48 hours) Used Walltime: 1-00:29:37 (24.4936 hours) Reserved CPUs: 128 CPU SUs Already Used: 3135.1808 Total CPU SUs Needed for Reserved Walltime: 6144.0000 ; Total CPU SUs used for all jobs: 3135.1808 Total GPU SUs used for all jobs: 0.0000 On Anvil, Slurm reserves a certain amount of SUs for each job to ensure it can finish running, based on the requested resources and walltime. If job 422340 can finish running ahead of time and the rest SUs can support one of your job, Slurm might get it started. I hope this explains it. Please let me know if you have any further questions. Thanks, name ; Dear name, I appreciate your email. I believe there might be an issue as the majority of my SUs in the allocation were utilized in the last one or two weeks. Although we submitted numerous jobs during this period, only 3 or 4 of them ran. Since we the jobs didn't run, the allocation should not be used. Additionally, the ACCESS allocation page indicates that there are still SUs remaining (35%). Could you please investigate if there is an issue? Thank you. Best, ---- ; Hi Shahid, I examined the jobs run in the allocation {{che210078}} and noticed that many of them were run in 2022 and 2023. You can see them by running the following command: {{sacct -XDaA che210078 -S 2021-01-01 -o jobid%10,jobname,user,start,end}} Also, I've asked our experts to took a closer look at the US usage of your allocation. I'll keep you updated as soon as I hear anything back. Thanks, name ; Hi Shahid, My apologies for the delayed follow-up. Our scientists checked the usage uploading processes (from Anvil to the ACCESS system) and noticed there was a bug in the procedure, with which the name usage of part of your jobs was not multiplied by the number of cores they used. The usage reported by the local command ""\\*mybalance\\*"" should be right. We are working on syncing up the job accounting information and that might take a while. I'm tentatively marking this ticket as resolved at this point. Please feel free to re-open this ticket if you have any further questions. Thanks, name ;",shahidul@access-ci.org,Shahid Islam,Ruyi Li,,Anvil,5,19,2,2024,2024-01-08
ATS-5812,NEB calculations on VASP on ANVIL,2024-01-31,2024-02-05,"Hello Anvil Team, Hope you are doing well Best Regards Sumandeep name Postdoctoral scholar (Prof. Liney Arnadottir's Research Group) Chemical Engineering Oregon State University, Corvallis, Oregon, 97333 ; Hi Sumandeep, Thanks for reaching out! Unfortunately, the VASP versions on Anvil did not compiled with vtst code and cannot run NEB calculations. The NEB version VASP installation is on our list, but we cannot guarantee when it would be available. We would recommend to install it on your own project space. If you need help on this, let me know. Regards, name, PhD (She/Her/Hers) Sr. Computational Scientist ;",kaursu@access-ci.org,Sumandeep Kaur,Nannan Shan,Purdue University,Anvil,2,4,5,2024,2024-01-29
ATS-5821,Queue time,2024-01-31,2024-02-08,"Hi, I am using Anvil, but I have been stuck in the queue for almost a week now, and this is the first time that the queue has taken anywhere that long. Is there anything wrong or is this just how long the queue is? ; Hi Madeleine, Thanks for reaching out! Can you share the job script you used to submit jobs on Anvil? I need to know how you submit jobs and see if I can find clues there. Regards, name, PhD (She/Her/Hers) Sr. Computational Scientist ;",myoungs@access-ci.org,Madeleine Youngs,Nannan Shan,Purdue University,Anvil,2,7,5,2024,2024-01-29
ATS-5850,Time reservation and allocation,2024-02-01,2024-02-09,"Hello, we are gauging if the access to Purdues Anvil GPU can be reserved ahead of time. We will be having a small-scale cryo-EM data processing workshop at FSU where we would need to have 10-12 GPUs pre-reserved ahead of time for the final week of March (3 days). Are such allocations allowed for educational purposes? I know that we can see some GPU nodes on Anvil (g002, g007) are often in status ""reserved"" but we understand that that might be a local Slurm scheduler lingo. Could you please let me know and if yes, where and how do I make those reservations? Also, each of these nodes is equipped with 4xA100 GPUs which are quite powerful. Is it possible to have 2-4 users using a single node? That way we could eliminate blocking 10 entire nodes. The idea is to get 1) each user to sign up for access credentials and me as a PI on this project add them onto Anvil resource, 2) use only SSH (not OOD) to connect to the nodes as we can specify something like this: srun - p gpu -c 10 --nodelist=g002 --gres=gpu:1 --time=08:00:00 --pty --x11 bash. Your help is much appreciated. ; Hi Nash, Thank you for the email. The node g002 and g007 are reserved by our engineers for testing. The ""reserved"" state can keep those nodes on hold, so they will not be allocated to other users' jobs. We are trying to figure out an approach that might best fit your needs. Would you please share more information about your workshop? How many users will be participating? What kind of GPU jobs do you plan to run? How much GPU memory will be required? How much data is going to be used? Looking forward to hearing back from you. Thanks, name ; Hi Nash, Since I have not heard back from you in a while, I'm tentatively marking this ticket as resolved at this point. If you still have questions, please feel free to reopen the ticket or submit a new one to us. Thanks, name ; ""We are trying to figure out an approach that might best fit your needs. Would you please share more information about your workshop? How many users will be participating? What kind of GPU jobs do you plan to run? How much GPU memory will be required? How much data is going to be used?"" \\*There will be 10 participants during 3 full days. \\*We will also need access for two instructors, myself and another person. \\*We will run Relion and CryoSparc on GPU via Open Ondemand. \\*we will need 10-15 TB of scratch space \\*I will assign 10 users onto my ACCESS project \\*each user +2 instructors will need 1 GPU=12 GPUs=3 full nodes reserved \\*Workshop dates are 27-29 March, 2024. Could you please let me know if we can work this out? It would be a tremendous help to our educational efforts. Looking forward to hearing from you. Best regards, Nebojša Bogdanović, Ph.D. ---- ;",nbogdanovi@access-ci.org,Nebojša Bogdanović,Ruyi Li,Purdue University,Anvil,4,7,5,2024,2024-01-29
ATS-5915,Can't create a interactive session due to invalid job name error  ,2024-02-05,2024-02-05,"Hi, I'm trying a create an jupyter notebook interactive session , but I'm getting this error and it doesn't let me create a session. This is the error that I'm getting when I try to submit a session: sbatch: error: Batch job submission failed: Unexpected message received \\* If this job failed to submit because of an invalid job name please ask your administrator to configure OnDemand to set the environment variable OOD\\_JOB\\_NAME\\_ILLEGAL\\_CHARS. Could you please help me fix that? I never faced this problem ; Hi name, Thanks for reporting this to us. It looks like all the interactive apps on Anvil OOD are experiencing issues now. Our scientists are working on this. We would keep you posted. Thanks for your patience. Regards, name, PhD (She/Her/Hers) Sr. Computational Scientist ; Hi name, I believe it is working now. Our scientists and engineers have fixed it. Let us know if you still see issues. Regards, name ; Thank you very much, it works now. ;",mshokri@access-ci.org,Mohammad Shokri,Nannan Shan,Purdue University,Anvil,4,1,6,2024,2024-02-05
ATS-5117,Snapshots for /anvil/projects broken since 11/21/2023,2023-12-30,2024-02-13,"It looks like snapshots have stopped working on /anvil/projects again: login06.anvil /anvil/projects/.snapshots $ ll total 522 1 dr-xr-xr-x 2 root root 4096 Oct 23 15:06 ./ 64 drwxr-xr-x 641 root root 32768 Dec 29 15:25 ../ 64 drwxr-xr-x 545 root root 32768 Aug 31 09:45 '@EST-2023.09.01-01.02.00'/ 64 drwxr-xr-x 588 root root 32768 Oct 23 09:45 '@EST-2023.10.23-14.04.00'/ 1 drwxr-xr-x 588 root root 4096 Oct 23 09:45 '@EST-2023.10.23-14.04.35'/ 64 drwxr-xr-x 600 root root 32768 Oct 29 19:05 '@EST-2023.10.30-00.01.35'/ 64 drwxr-xr-x 602 root root 32768 Oct 31 09:25 '@EST-2023.11.01-01.02.00'/ 64 drwxr-xr-x 609 root root 32768 Nov 3 16:25 '@EST-2023.11.06-01.01.35'/ 64 drwxr-xr-x 614 root root 32768 Nov 10 15:45 '@EST-2023.11.13-01.01.35'/ 1 drwxr-xr-x 618 root root 4096 Nov 13 15:25 '@EST-2023.11.14-08.00.07'/ 1 drwxr-xr-x 618 root root 4096 Nov 13 15:25 '@EST-2023.11.15-08.00.07'/ 1 drwxr-xr-x 618 root root 4096 Nov 13 15:25 '@EST-2023.11.16-08.00.07'/ 1 drwxr-xr-x 618 root root 4096 Nov 13 15:25 '@EST-2023.11.17-08.00.07'/ 1 drwxr-xr-x 618 root root 4096 Nov 13 15:25 '@EST-2023.11.18-08.00.07'/ 1 drwxr-xr-x 618 root root 4096 Nov 13 15:25 '@EST-2023.11.19-08.00.07'/ 1 drwxr-xr-x 618 root root 4096 Nov 13 15:25 '@EST-2023.11.20-01.01.35'/ 1 drwxr-xr-x 618 root root 4096 Nov 13 15:25 '@EST-2023.11.20-08.00.07'/ 64 drwxr-xr-x 618 root root 32768 Nov 13 15:25 '@EST-2023.11.21-08.00.07'/ I think this is at least the third time they have stopped working like this. Could you please re-enable them and hopefully investigate why they keep stopping like this? Maybe consider adding a simple Nagios check so you will notice sooner if they fail again? Regards, Doug ; Hi, Doug. This problem was due to the filesystem not being able to quiesce due to a misbehaving client. We have cleared that error and snapshots worked this morning. We have also added a check to make sure the snapshots worked. Thanks. name Senior Research Solutions Engineer ; Great, thanks name! Regards, Doug ---- ; Thanks for taking care of this name. Marking it as closed. ; Thanks ;",dgc,Doug Crabill,ramonw,Purdue University,Anvil,5,32,52,2023,2023-12-25
ATS-5976,Batch job submission failed: Invalid account or account/partition combination specified,2024-02-06,2024-02-21,"Hello, I have previously used (see below) with no issues to submit NAMD CPU jobs in Anvil. However, I am now receiving the following error: ""Batch job submission failed: Invalid account or account/partition combination specified."" I am not sure what the issue is. I double checked and che210078 is the allocation. #!/bin/bash #SBATCH -N2 #SBATCH --ntasks-per-node=128 #SBATCH -t 2:00:00 #SBATCH -A che210078 #SBATCH --job-name namd-FEP module purge module load modtree/cpu module load namd ; Hi name, Thanks for reaching out! Can you try to add the following line to your job script? {{#SBATCH -p wholenode}} Regards, name, PhD (She/Her/Hers) Sr. Computational Scientist ;",bhavr@access-ci.org,Brandon Havranek,Nannan Shan,Purdue University,Anvil,2,12,6,2024,2024-02-05
ATS-5304,how to fix 'out of memory' issue?,2024-01-10,2024-02-12,"I am simulating a large system in vasp with 192 atoms. I tried to use 6 nodes and specify the memory as 200GB, but the 'out of memory' popped up. I tried to allocate more but got 'sbatch: error: Memory specification can not be satisfied; sbatch: error: Batch job submission failed: Requested node configuration is not available'. The job id is 4223982. What settings should I use for this kind of large supercell? ; Hi name, Thanks for reaching out! I would recommend to delete '#SBATCH --mem=200G' from your job script. The request of 6 nodes will have 256GB \\* 6 = 1536 GB memory for this job. The request for 200G is not consistent with your 6-node request. Regards, name, PhD (She/Her) Sr. Computational Scientist ; I tried removing '#SBATCH --mem=200G', which still gives me 'out of memory'. Is this error related the num\\_tasks and num\\_cpus\\_per\\_task? Sent from Mail: https://go.microsoft.com/fwlink/?LinkId=550986 for Windows ; Also when I try 4 nodes, 256 tasks, 2 cpus per task, the number of threads per rank is 128 instead of 2 in the output file. You can check job 4225888. Sent from Mail: https://go.microsoft.com/fwlink/?LinkId=550986 for Windows ; Hi name, I am wondering if you were running AIMD for the reported job, or other type of DFT calculations? Regards, name ; No, I am not running AIMD. Sent from Mail: https://go.microsoft.com/fwlink/?LinkId=550986 for Windows ; Hi name, I am wondering if you still see issues with VASP calculations on Anvil. If so, we can schedule a virtual meeting to discuss it. Regards, name ;",ningl3@access-ci.org,Ning Li,Nannan Shan,Purdue University,Anvil,7,24,2,2024,2024-01-08
ATS-5703,I need the access of VASP.,2024-01-26,2024-02-16,"My advisor Dr. name added me under his VASP license. I need the access to VASP. ; Hi, Thank you for contacting us. You have been added to vasp5 license on Anvil. Best regards, name Senior Computational Scientist Purdue Information Technology ;",mmukta,Musiha Mahfuza Mukta,Guangzhen Jin,Purdue University,Anvil,3,16,4,2024,2024-01-22
ATS-5879,Software installation IDL,2024-02-02,2024-02-16,"Hello, I'd like to install IDL in my $WORK directory on Anvil, since it's not available via a module. However, it looks like I need sudo or root permissions to activate the license (from my university), and run the command ""{{envi\\_idl\\_license\\_admin}}"", based on the installation steps described at their website: https://www.nv5geospatialsoftware.com/docs/idl-install.html: https://www.nv5geospatialsoftware.com/docs/idl-install.html I don't seem to have sudo permissions, or I don't know the right password for it. Could you please provide guidance on how to proceed? In case it's useful, the relevant directory for the installation is: /anvil/projects/x-phy160032/idl89 Thanks, Vladimir ; Hi, Thank you for contacting us. Will the configuration of the license require a running license server (e.g. a daemon process) or it is a one-time activation as root? Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name ;",zhdankin@access-ci.org,Vladimir Zhdankin,Guangzhen Jin,Purdue University,Anvil,3,11,5,2024,2024-01-29
ATS-6042,cpu-per-task,2024-02-09,2024-02-12,"I have been trying to submit jobs for which I set cpus-per-task to 20. However, after a minute, the job changes the CPUs to something much higher (usually 40/50/60/80). I don't want to waste SUs on jobs that are unnecessarily expensive. How can I set the number of CPUs? Why is this happening? ; !WhatsApp Image 2024-02-08 at 13.41.28.jpeg|thumbnail! ; Hi Bianca, It looks like name has replied to your inquiry in ticket # 6022. I'm marking this ticket as resolved, because it is a duplicate of # 6022. Thanks, name ;",bchampenois@access-ci.org,Bianca Champenois,Ruyi Li,Purdue University,Anvil,3,2,6,2024,2024-02-05
ATS-6044,Job submission,2024-02-09,2024-02-20,"Hi, After submitting a job on the Anvil cluster, I am no longer able to receive job status updates via email after the maintenance. Could you please check? Regards, Aashish ; Hi, Thank you for contacting us and reporting the issue. I can reproduce the issue. Will escalate to our engineering team so they could take a further look and get back to you when there is a fix. Stay tuned. Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi, This issue has been fixed. Will resolve the ticket. Feel free to re-open it within 7 days if you need further discussions. name ;",abhatt@access-ci.org,AASHISH BHATT,Guangzhen Jin,Purdue University,Anvil,3,8,6,2024,2024-02-05
ATS-6045,allocated CPUS on Anvil jumping to 69 or 70 even when set to 1,2024-02-09,2024-02-14,"Hi, I am running on anvil, and even when I set cpus\\_per\\_task =1 and ntasks=1 the allocated cpus when the run starts is 69 or 70. I do not need that many and this is costing my research group and so I would like to figure out what the problem is. While the job is queued, the CPU's show up as 1 but once the job starts in jumps to 69 or 70. The attached image shows two jobs while queued and while running, one with cpus\\_per\\_Task =1, and one set to 10. My username is x-bbarthel. The exact folder is /anvil/scratch/x-bbarthel/QG\\_Model/Archive/ and the batch file is called batch\\_ML1 Thank you so much for your help ; Hi Benedikt, Thank you for reaching out. I just took a look at your job script (batch\\_ML1). It seems a request of 128G memory is also included (line 7: {{#SBATCH --mem=128G}}). Please note that DefMemPerCPU is 1896M in the {{shared}} partition. In order to satisfy the memory request, Slurm allocated 70 cores to your job because of that configuration. I hope this explains it. Please let me know if you have any further questions. Thanks, name ; Hi Benedikt, I believe the issue on this ticket has been addressed. I'm tentatively marking this ticket as resolved at this point. Please feel free to contact us again if you have any questions. Thanks, name ; Hi Ruby, Yes, Thank you for your message and yes it has been addressed. I apologize for leaving you hanging. -name, No worries. Glad to hear back from you. Hope you have a nice rest of the day 🙂 Thanks, name ;",bbarthel@access-ci.org,Benedikt Barthel,Ruyi Li,Purdue University,Anvil,6,4,6,2024,2024-02-05
ATS-6112,"Postfix on Anvil broken, can't send mail",2024-02-13,2024-02-13,"It looks like postfix was broken during the Anvil maintenance last week. We rely on being able to send mail using Anvil. Repeat-by: login02.anvil ~ $ mail Subject: test test EOT login02.anvil ~ $ send-mail: fatal: file /etc/postfix/main.cf: parameter setgid\\_group: group postdrop has same group ID as postgres Regards, Doug ; Hi Doug, Thank you for reporting this issue. It should be fixed now (you might have received the emails from name). I'm tentatively marking this ticket as resolved at this point. Please feel free to contact us again if the issue persists for you or if you have any other questions. Thanks, name ;",dgc@access-ci.org,Doug Crabill,Ruyi Li,Purdue University,Anvil,2,1,7,2024,2024-02-12
ATS-6113,Anvil shared and whole node memory limits,2024-02-13,2024-02-13,"I am wondering what the limits for memory are on the shared and wholenode queues on Anvil for use in planning future jobs. ; Hi name, Thank you for reaching out. The compute nodes in the {{shared}} and {{wholenode}} partitions contain about 256GB memory each, a small portion of which is reserved for the system processes. Please find the specifications of Anvil hardware at the following link: https://www.rcac.purdue.edu/knowledge/anvil/architecture: https://www.rcac.purdue.edu/knowledge/anvil/architecture|smart-link I'm tentatively marking this ticket as resolved at this point. Please feel free to re-open it if you have any further questions. Thanks, name ;",jstrack1@access-ci.org,Jacob Strack,Ruyi Li,Purdue University,Anvil,2,1,7,2024,2024-02-12
ATS-6205,Encountered error running jobs ,2024-02-14,2024-02-15,"I encountered an error message in Anvial system ""slurm\\_load\\_assoc\\_mgr\\_info error: Unable to contact slurm controller (connect failure)"", when I use the squeue, submitted job and check mybalance. This appeared after I submitted my compiled VASP software and the job crashed. Could you help me to check what is wrong with my account on Anvial. ; Hi Yunfan, Thank you for reporting the issue and apologies for the inconveniences it caused. It was related to the status of slurmctld, and has been fixed. I'm tentatively marking this ticket as resolved at this point. Please feel free to re-open it or submit a new ticket if you see any further issues. Thanks, name ;",liangy12@access-ci.org,Yunfan Liang,Ruyi Li,Purdue University,Anvil,2,2,7,2024,2024-02-12
ATS-5969,Error when uploading files,2024-02-06,2024-02-23,"Hello, I'm having trouble uploading files to my account through ACCESS OnDemand. When I try to upload a file, I will see the progress wheel advance as usual, then once it has reached 100% it says ""Upload failed"". I have tried several times with different files and am still getting the same error. This function was working earlier today, however. Thanks for your help. ; Hi Hannah, Thanks for reaching out! I am wondering if you still see issues about uploading files on Anvil Open OnDemand? I saw your home is about to be full, are you trying to upload files to HOME directory? Please feel free to let me know. $ myquota x-hbish Type Location Size Limit Use Files Limit Use ============================================================================== home x-hbish 24.6GB 25.0GB 99% - - - Regards, name, PhD (She/Her/Hers) Sr. Computational Scientist ; Hi name, Thanks for your reply. I didn't realize I was using most of my quota, so I deleted some files and tried again and now it's working. The strange thing is, I was able to upload the same files using scp the whole time (even before deleting the files). Anyway, all is working now. I'm wondering if the 25 GB storage on the home directory is a hard limit? -Hannah ---- Hannah Bish (she/her) Postdoctoral Fellow Space Telescope Science Institute ; Hi Hannah, Yes, we granted 25GB for each user on their home. I believe you can use your project space to store your files, which I think has 5TB quota. You can nevigate to your project space with the below command, {{cd /anvil/projects/x-phy230181}} You can always use 'myquota' to check your quota about the storage on Anvil. Hope it helps, name ; Ah I see, thank you. I didn't realize my home directory and the project directory had separate storage quotas. How should I use the project directory vs. scratch in terms of storing my files? And how long are the files kept for each? Thanks, Hannah On Feb 15, 2024, at 5:16 PM, ACCESS Ticket Submission : mailto: wrote: External Email - Use Caution ; Here is the user guide you will find the information about different storage spaces on Anvil. https://www.rcac.purdue.edu/knowledge/anvil/storage/filesystems: https://www.rcac.purdue.edu/knowledge/anvil/storage/filesystems|smart-link Regards, name ;",hbish@access-ci.org,Hannah Bish,Nannan Shan,Purdue University,Anvil,7,14,6,2024,2024-02-05
ATS-6471,Compiled software does not run in Anvil cluster,2024-02-27,2024-02-27,"Hello, I use anvil-Purdue cluster. I need to use two software (LESGO and LAMMPS) in anvil-Purdue cluster. LAMMPS runs smoothly in the cluster. However, LESGO does not run in the cluster. It gives me an error all the time. Notably, I have compiled the software properly. The log file and job script have been attached. Additionally, I cannot access to the anvil since last evening. It shows me Proxy Error each time. Thank you ^job.slurm ^log.lesgo ;",ashuvo@access-ci.org,Abdul Aziz Shuvo,,Purdue University,Anvil,2,1,9,2024,2024-02-26
ATS-6198,Running a job,2024-02-14,2024-02-22,"I am trying to run a perl script in anvil (command: perl CLFEP\\_v7.1.pl -exec 14 -f1 Complex\\_combined\\_CLEAN.dat -f2 Solvent\\_combined\\_CLEAN.dat -i2 Ligand\\_combined\\_CLEAN.dat -i1 Host\\_combined\\_CLEAN.dat -out CLFEP\\_test1 -est C2 -osr 12 -track 1 > CLFEP\\_C2.log) but it fails to execute and showing this error message: Can't locate Statistics/Normality.pm in @INC (you may need to install the Statistics::Normality module) (@INC contains: /usr/local/lib64/perl5 /usr/local/share/perl5 /usr/lib64/perl5/vendor\\_perl /usr/share/perl5/vendor\\_perl /usr/lib64/perl5 /usr/share/perl5) at CLFEP\\_v7.1.pl line 55. BEGIN failed--compilation aborted at CLFEP\\_v7.1.pl line 55. In my local computer I solved the same issue by installing the missing modules and I could run the command successfully but it is taking too much time to complete thats why I am trying to run it in anvil. But I don't know how to solve the problem in anvil. Could you please also check my submission script (attached) to verify whether it is perfect to execute the perl script (attached)? Thank you. ; ^CLFEP\\_npt.pbs] ^CLFEP\\_v7.1.pl ; Good morning, Thank you for contacting us. I would like to mention that the environment module system on the clusters ([https://lmod.readthedocs.io: https://lmod.readthedocs.io|smart-link) is different from the module management system of Perl. We have Perl installed in the system, but it is not deployed as a module. If you check the output of your Slurm jobs, you would notice that. If you enter the command {{which perl}}, it will report its path ({{/usr/local/bin/perl}}). Regarding the Perl modules needed for your job, I think you could try installing those in your home directory (or your project space). You may reference the official installation guide for that: https://www.cpan.org/modules/INSTALL.html: https://www.cpan.org/modules/INSTALL.html|smart-link Please let me know if you have any further questions. Thanks, name ; Good morning, Since I have not heard further questions from you in a while, I'm tentatively marking this ticket as resolved at this point. Please feel free to contact us again if you need any help or have any questions. Thanks, name ;",mhasan1@access-ci.org,MD MEHEDI HASAN,Ruyi Li,Purdue University,Anvil,4,7,7,2024,2024-02-12
ATS-6261,Inexplicable loss of Anvil CPU-hours,2024-02-17,2024-02-19,"Hi, I've been meaning to write this message for some time. Over the New Year Eve, I noticed an inexplicable change in the total allocation for our group: 536,604 CPU-hours disappeared from our \\_total\\_ allocation on Anvil (please see the attachments). I am assuming it was a glitch in the system. With our remaining 1,412 CPU-hours (as of now) on Anvil, we would greatly appreciate your help in understanding where our group currently stands in terms of the remaining Anvil CPU-hours. Many thanks, in advance, for your kind help. Bindesh name ; Hi Bindesh, Thank you for reaching out. It looks like part of the SUs in the {{phy130027}} account expired on December 31, 2023 for some reason. I've just extended that part until March 31, 2024. For now, you should see an updated name limit: $ mybalance x-btripathi Allocation Type name Limit name Usage name Usage name Balance Account (account) (user) ============= ==== ========== ========== ========== ========== phy130027 CPU 62464243.9 61926637.1 37350808.0 537606.8 I'm tentatively marking this ticket as resolved at this point. Please feel free to contact us again if you have any other questions. Thanks, name ; Dear name, Thank you very much for checking the remaining SUs in our account. I appreciate you for kindly extending the hours. I apologize for delayed response. Thanks, again, for your kind help. Bindesh ;",bindesh@access-ci.org,Bindesh Tripathi,Ruyi Li,Purdue University,Anvil,4,1,7,2024,2024-02-12
ATS-5897,CP2K job script,2024-02-04,2024-02-28,"\\*Dear Colleague,\\* \\*Could you please send me a jobscript for cp2k? My current one is:\\* \\*#!/bin/bash\\* \\*#SBATCH -J myjob # Job name\\* \\*#SBATCH -o myjob.o%j # Output and error file name (%j expands to jobID)\\* \\*#SBATCH --nodes=1 # Total number of nodes\\* \\*#SBATCH --ntasks-per-node=64 # Total number of MPI tasks per node\\* \\*#SBATCH --cpus-per-task=1 # CPU-cores per task (default value is 1, >1 for multi-threaded tasks)\\* \\*#SBATCH -p shared # Queue (partition) -- normal, development, etc.\\* \\*#SBATCH -t 02:30:00 # Run time (hh:mm:ss) - 1.5 hours\\* \\*#SBATCH -A dmr100029 # Account\\* \\*#; #\\* \\*echo ""Job started on $(date)""\\* \\*Reset module environment to system defaults\\* \\*module restore\\* \\*Load required modules\\* \\*module load gcc/11.2.0\\* \\*module load openmpi/4.0.6\\* \\*module load cp2k/8.2\\* \\*List loaded modules for debugging\\* \\*module list\\* \\*Check if the CP2K executable exists\\* \\*CP2K\\_EXEC=""/apps/spack/anvil/apps/cp2k/8.2-gcc-11.2.0-ntnukes/bin/cp2k.psmp""\\* \\*if ! -f ""$CP2K\\_EXEC"" ; then\\* \\*echo ""CP2K executable not found at $CP2K\\_EXEC""\\* \\*exit 1\\* \\*fi\\* \\*Run CP2K with specified input and output, using MPI\\* \\*srun --mpi=pmi2 $CP2K\\_EXEC -i NH4ClO4-r2SCAN.CP2K.inp -o output\\_file.log\\* \\*echo ""Job ended on $(date)""\\* \\*I tried many times but it always give me error informaitons such as:\\* \\*Job started on name Feb 4 14:08:03 EST 2024\\* \\*Resetting modules to system default. Resetting $MODULEPATH back to system default. All extra directories will be removed from $MODULEPATH.\\* \\*Currently Loaded Modules:\\* # \\*xalt/2.10.45 (S) 4) mpfr/4.0.2 7) zlib/1.2.11 10) openmpi/4.0.6\\* # \\*modtree/cpu 5) mpc/1.1.0 8) numactl/2.0.14 11) fftw/3.3.8\\* # \\*gmp/6.2.1 6) gcc/11.2.0 9) libfabric/1.12.0 12) cp2k/8.2\\* \\*Where:\\* \\*S: Module is Sticky, requires --force to unload or purge\\* ---- \\*MPI\\_ABORT was invoked on rank 0 in communicator MPI\\_COMM\\_WORLD\\* \\*with errorcode 1.\\* h2. \\*NOTE: invoking MPI\\_ABORT causes Open MPI to kill all MPI processes.\\* \\*You may or may not see output from other processes, depending on\\* \\*exactly when Open MPI kills them.\\* \\*srun: Job step aborted: Waiting up to 32 seconds for job step to finish.\\* \\*slurmstepd: error: \\*\\*\\* STEP 4363748.0 ON a063 CANCELLED AT 2024-02-04T14:08:06 \\*\\*\\*\\* \\*srun: error: a063: task 0: Exited with exit code 1\\* \\*srun: error: a063: tasks 2,4,6,12: Killed\\* \\*srun: error: a063: tasks 1,3,5,7-11,13-63: Killed\\* \\*Job ended on name Feb 4 14:08:07 EST 2024\\* \\*Could you please send me one example of job script for cp2k?\\* \\*Thank you.\\* \\*Best regards,\\* \\*Minglei\\* ; Hi Minglei, Thanks for reaching out! We do not have an available CP2K submit script on hands. I will need to run tests to build one. If you still need the script, let me know. I can start to work on it. Regards, name, PhD (She/Her/Hers) Sr. Computational Scientist ; Dear name, Yes, I do need a script for cp2k. Could you please run tests to build one? Thank you. Best regards, Minglei ; Hi Minglei, Can you try the script below for your job and see if you can run CP2K job on Anvil? #!/bin/sh #SBATCH --job-name=cp2k #SBATCH --account=your\\_allocation\\_name #SBATCH --partition=shared #SBATCH --nodes=1 #SBATCH --ntasks-per-node=64 #SBATCH --cpus-per-task=1 #SBATCH --time=00:30:00 #SBATCH --output=cp2k.o%j.%N module --force purge ml --force purge module load gcc/11.2.0 module load openmpi/4.0.6 module load cp2k/8.2 module list mpirun -np $SLURM\\_NTASKS cp2k.psmp ... Let me know how it works. name ; Dear name, I will try it. Thank you for your hard work. Best regards, Minglei ;",msun3@access-ci.org,Minglei Sun,Nannan Shan,Purdue University,Anvil,5,18,5,2024,2024-01-29
ATS-6350,OpenMP error compiling code on Anvil,2024-02-21,2024-02-28,"Hi Anvil support ; Hi name, Thanks for reaching out! I have passed your questions to our scientist. You would hear from us later. Thanks for your patience. Regards, name, PhD (She/Her/Hers) Sr. Computational Scientist ; Hi name, Thank you so much for your response! I reached out to our collaborators and it looks like we can run the code despite the warning--we can close this ticket! Best, name ; Able to run the code -- warning not important ;",cwilliams@access-ci.org,Claire Williams,Amiya Maji,Purdue University,Anvil,5,6,8,2024,2024-02-19
ATS-6364,Disk quota exceeded error in Interactive Session,2024-02-22,2024-03-01,"I am running jupyter notebooks through OnDemand. I received the following error and then a similar one for another notebook: Unexpected error while saving file: SCRATCH/EnzoRunAug18Run\\_250Delay/Aug18\\_250Delay.ipyn: file: SCRATCH/EnzoRunAug18Run\\_250Delay/Aug18\\_250Delay.ipyb Errno 122 Disk quota exceeded: '/home/x-jsullivan1/SCRATCH/EnzoRunAug18Run\\_250Delay/.~Aug18\\_250Delay.ipynb' I tried to just look at myquota on anvil and it doesn't look like I am exceeding the quota. I am not sure what the issue is. For reference, these notebooks are located in the scratch directory. I have a virtual link to the SCRATCH directory in my home directory so I can navigate to it through the jupyter notebook system (which opens in my home directory). ; If you look at the output from myquota: Type Location Size Limit Use Files Limit Use home x-jsullivan1 5.3GB 25.0GB 21% - - - scratch anvil 6.7TB 100.0TB 7% 999k 1,000k 100% projects x-ast140041 8.3GB 5.0TB 0.16% 15k 1,048k 2% projects x-mca06n030 4.0TB 5.0TB 80% 95k 1,048k 9% You can see that for scratch you have hit the limit for the number of files (1,000k). You need to remove some files to add more. name Senior Research Solutions Engineer ; Hi name, It seems you have set some inodes free in your scratch directory. We are tentatively marking this ticket as resolved at this point. Thanks, name ;",jsullivan1@access-ci.org,James Sullivan,Ruyi Li,Purdue University,Anvil,3,7,8,2024,2024-02-19
ATS-6455,Could not submit jobs,2024-02-26,2024-02-28,"I could not submit jobs on Anvil. The following error message appears after I submit job: ""sbatch: error: Batch job submission failed: Unable to contact slurm controller (connect failure)"". ; Hi name, Thanks for reporting this to us. Our engineers are trying to fix this right now. We will share more details at the news later, https://www.rcac.purdue.edu/news/6400: https://www.rcac.purdue.edu/news/6400|smart-link Regards, name, PhD (She/Her/Hers) Sr. Computational Scientist ; Hi name, I think the issue was resolved on Anvil. Thank you for reporting to us and your patience. Regards name ;",cyang2@access-ci.org,Chang Yang,Nannan Shan,,Anvil,4,3,9,2024,2024-02-26
ATS-6567,ls and rm commands hang on purdue anvil project filesystem in one directory,2024-02-29,2024-03-01,"Dear Anvil team, I'm writing to report some possibly odd filesystem behavior. The following commands: rm -rfv /anvil/projects/x-phy230179/wham/run/20240226.BEAM.nz256.tester-anvil/particles/T.0 ls /anvil/projects/x-phy230179/wham/run/20240226.BEAM.nz256.tester-anvil/particles/T.0 stall and do not work normally. Would you know how to delete or otherwise clear this directory and its contents? The directory normally holds 1 or 2 file dumps / processor (in this case, 2304 or 4608 files) and it was created by a simulation job that stalled for unknown reasons and had to be ""scancel""-ed. Thanks, name ; Hi name, Thank you for reaching out. I just did a test and was able to list the files in the {{T.0}} directory. $ ls /anvil/projects/x-phy230179/wham/run/20240226.BEAM.nz256.tester-anvil/particles/T.0/ | wc -l 1874 Would you please try removing the files again and let me know if the problem persists? Thanks, name ; Hi name, it works now and I removed the files. Not sure why it wasn't working earlier, but no matter -- OK with me to close this ticket. Thank you! name \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_ From: ACCESS Ticket Submission : mailto: Sent: Friday, March 1, 2024 11:41 AM To: name Tran Subject: ATS-6567 ls and rm commands hang on purdue anvil project filesystem in one directory ; Hi name, Thank you for letting me know those files could be removed. I'll go ahead and mark this ticket as resolved then. Please do not hesitate to contact us again if you see similar issues. We would keep an eye out as well. Thanks, name ;",atran9@access-ci.org,Aaron Tran,Ruyi Li,Purdue University,Anvil,4,2,9,2024,2024-02-26
ATS-5909,Job submission issue on Anvil Purdue CPU,2024-02-05,2024-03-07,"Hi Team, greetings. I'm facing following error when I submit jobs on Anvil Purdue CPU. --- A request was made to bind to that would result in binding more processes than cpus on a resource: Bind to: CORE Node: a241 #processes: 2 #cpus: 1 --- My job submission script is --- #!/bin/bash #SBATCH --account=chm230030 #SBATCH --job-name=2p5\\_8 #SBATCH --nodes=1 #SBATCH --ntasks=8 #SBATCH --time=24:00:00 module load openfoam/8-20210316 source $FOAM\\_ETC/bashrc decomposePar -force mpirun -np 8 interFoam -parallel --- After following examples on documentation pages, I came up with this script. I'm asking for one node and I'm willing to use only 8 CPUs on it because in my scaling tests, I found that speed that I get for nCPUs = 8 is okay and anything beyond that, say, nCPUs = 16, the speed deteriorates. Let's assume that my first job is running, say \\*4358727\\* which is on NODE \\*a240\\*. Any other job submissions after this are throwing up this error. Could you please let me know how to address this, without loss of parallel speed? Please consider this request as urgent as I've been struggling with this for past one week. Best, ; Hi, Thank you for contacting us. We just made some tweaks on the Anvil mpi and hopefully it could resolve the issue. Could you double check and see if it's still an issue for you? Best regards, name Senior Computational Scientist Purdue Information Technology ; Sure, I'd check and let you know on Monday. Best, ; Hi Team, the node problem is resolved but I'm facing a new issue. I'm trying to set up a SQP (Superquadric Particle Model) to fluidize a few particles in a thin fluidized bed using the MFiX package, which is a part of module load Anaconda, on Anvil Purdue CPU. I'm using MFiX-23.2, which is the latest version, in spite of many attempts, I could not go beyond one time-step. Please find the attached HPC output file in which it clearly shows that solver building is successful followed by particle initialization. After this, the job remains on node for hours, without any progress. This we have tried up to 128 CPUs starting from 8 CPUs in product increase of 2 but all in vain. I'm also attaching job submission file for your perusal. Could you please take a look and suggest what's going wrong? Thank you, ^slurmFile.out \\_(0.0 kB)\\_ ^Sbatch\\_MFiX\\_Anvil.sh \\_(0.0 kB)\\_ ; Hi, I did not see anything wrong with your job submission file and the job ended with timeout which might simple indicate the 4hour walltime is not sufficient for this workflow. I might suggest to request for a longer job and see if there are any issues. Best, name ; Hi, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name ;",jsanghishetty@access-ci.org,Jagan Mohan Sanghishetty,Guangzhen Jin,Purdue University,Anvil,6,24,6,2024,2024-02-05
ATS-6105,Issue running code on Anvil HPCC,2024-02-12,2024-03-05,"We're getting the following errors while running our code on Anvil HPCC. We think that it's an MPI issue. Any assistance to resolve this would be appreciated. Errors: ] check\\_exit\\_codes (../../../../../src/pm/i\\_hydra/libhydra/demux/hydra\\_demux\\_poll.c:114): unable to run proxy on http://login07.anvil.rcac.purdue.edu: http://login07.anvil.rcac.purdue.edu|smart-link (pid 2393171) poll\\_for\\_event (../../../../../src/pm/i\\_hydra/libhydra/demux/hydra\\_demux\\_poll.c:152): check exit codes error HYD\\_dmx\\_poll\\_wait\\_for\\_proxy\\_event (../../../../../src/pm/i\\_hydra/libhydra/demux/hydra\\_demux\\_poll.c:205): poll for event error HYD\\_bstrap\\_setup (../../../../../src/pm/i\\_hydra/libhydra/bstrap/src/intel/i\\_hydra\\_bstrap.c:731): error waiting for event main (../../../../../src/pm/i\\_hydra/mpiexec/mpiexec.c:1919): error setting up the boostrap proxies ; Hi Nayeon, Thank you for contacting us. I've shared your inquiry with our computational scientists. They would take investigations and contact you later. Warm regards, name ; Hi Nayeon, I've taken over this ticket, and am wondering if you have since been able to successfully run your code. There have been updates to Anvil that may have fixed your MPI issue. Best, -name ; Hi name, I've just tested the code and it is showing the same error message. My colleagues who have been using the code on Anvil have also been experiencing the same issue. We didn't have any changes in our source code, which ran without any problems before. Is there anything that we should try on our side to resolve the issue? ; What command are you and your colleagues using to run your job? Does this occur when you run via a Slurm job following e.g. [https://www.rcac.purdue.edu/knowledge/anvil/run/examples/slurm/mpi: https://www.rcac.purdue.edu/knowledge/anvil/run/examples/slurm/mpi|smart-link? Or is everybody launching via {{mpirun}} directly on the login nodes? Best, -name ; We used to use {{mpirun}}, but running code via slurm job with specified mpi (e.g. {{srun --mpi=pmi2 ./flow\\_ifs}}) helped us fix the error. I think the problem was that we used intel mpi to compile our code but running code with {{mpirun}} does not point to the right intel mpi. We found that {{export I\\_MPI\\_HYDRA\\_BOOTSTRAP=ssh}} also solves the issue. Thank you for your help. ; Glad to hear it's working! I will go ahead and mark this ticket as resolved. Best, -name ;",npark1@access-ci.org,Nayeon Park,Charles Christoffer,Purdue University,Anvil,7,17,7,2024,2024-02-12
ATS-6156,cant transfer files,2024-02-13,2024-03-04,"I am having an issue where I cannot transfer files. There seems to be a problem with getting into ANVIL through the command line: when i use $ ssh : mailto: and input my access-ci password I am not given permission. When I use the web address: https://ondemand.anvil.rcac.purdue.edu/pun/name/shell/ssh/anvil.rcac.purdue.edu: https://ondemand.anvil.rcac.purdue.edu/pun/name/shell/ssh/anvil.rcac.purdue.edu and input my access-ci login info I have access. I am trying to use Filezilla for file transfers. I've asked about this issue before, please excuse me I am not very familiar with using HPC. ; Hi Nikolas, Thank you for reaching out. Please note that password-based SSH authentication is not supported on Anvil. You would need to set up SSH keys for connections via SSH. Please see our user guide on this topic at the following link: https://www.rcac.purdue.edu/knowledge/anvil/access/login#with\\_ssh: https://www.rcac.purdue.edu/knowledge/anvil/access/login#with\\_ssh|smart-link If you need any further assistance, please let me know. Thanks, name ; Hi Nikolas, I'm checking in to see if you have successfully set up SSH keys. If you need any help, I would be happy to arrange a virtual meeting with you. Warm regards, name, I think that that's the issue. I tried to set up SSH but I don't think I was successful. I will try to do it again, and if I have problems I will reach out to set up a virtual meeting. Thank you for the quick response, I am not an experienced HPC user and my PI really wants me to start getting some results. Regards, Nik Gaugler ; Hi Nik, Sounds good. I'll keep this ticket open for another week. If you think a meeting is necessary, please let me know and I would be happy to help you set up the SSH keys. Thanks, name ; Hi Nik, It looks like you have added several SSH keys in your account. Would you please let me know if you are able to transfer files using Filezilla now? Thanks, name, I have been able to add ssh keys and successfully transfer files using mobaxterm. thank you! Regards, Nik Gaugler ; Excellent! Glad to know that. I'll go ahead and mark this ticket as resolved then. Thanks, name ;",ngaugler@access-ci.org,Nikolas Gaugler,Ruyi Li,Purdue University,Anvil,8,15,7,2024,2024-02-12
ATS-6290,NVIDIA DEVICE Drivers Anvil Purdue,2024-02-19,2024-03-04,"Greetings, I have been trying to train an ML model on anvil and I always get the issue of libcuda.so.1 file not found or no such directory. I made sure that I load CUDA toolkit and load the GPU by using module load modtree/gpu. and I also made sure that the nvcc version and the cupy version which I am using is the same. So, when I searched up online I found out that the issue is due to absence of NVIDIA device drivers. Is there any other way to fix this issue? ; Hi name, Thank you for contacting us. NVIDIA device drivers should be available on the G nodes. To help us investigate the issue you got, would you please share more information? What steps did you take to create your machine training environment? What job submission scripts were you using? If it is possible, would you please share the IDs of the jobs where you saw the issue? Thanks, name ; Hey, Thank you so much for responding, so , this is what I do: I load the gpu modules by running module load modtree/gpu. Then I run my training script, that gives an error that says \\*libcuda.so.1 no such file or directory\\*. I also cross check if all my installations for cupy is correct and I also run nvcc --version and then there is CUDA toolkit of version 11.2 present. I also cross checked the versions of cupy and the CUDA toolkit are the same. ; Hey, Thank you so much for responding, so , this is what I do: I load the gpu modules by running module load modtree/gpu. Then I run my training script, that gives an error that says \\*libcuda.so.1 no such file or directory\\*. I also cross check if all my installations for cupy is correct and I also run nvcc --version and then there is CUDA toolkit of version 11.2 present. I also cross checked the versions of cupy and the CUDA toolkit are the same. ---- ; I wasn't running any job scripts I was following the steps mentioned in this document to use gpus : https://www.rcac.purdue.edu/knowledge/anvil/software/compile/nvidiagpu?all=true: https://www.rcac.purdue.edu/knowledge/anvil/software/compile/nvidiagpu?all=true ; Hey I have a deadline coming up and would love to get a response by then. Thank you so much for understanding ; Hi name, Would you please share the path to your Conda environment? What exact steps did you take to create that environment? Also, have you tried running your script on a node that has GPUs equipped, e.g. in the {{gpu}} or {{gpu-debug}} queue? What is the path to your training script? Thanks, name ; Greetings, I was able to fix my issue thank you ---- ; Excellent! Thanks for letting me know! I'll go ahead and mark this ticket as resolved then. Warm regards, name ;",tyalaman@access-ci.org,Tejas Yalamanchili,Ruyi Li,Purdue University,Anvil,9,11,8,2024,2024-02-19
ATS-6524,Job was re-submitted automatically for no idea,2024-02-28,2024-03-07,"Hi, I am using Anvil Purdue for some molecular dynamics simulations. Last night, I submitted a job with a specified time restriction of 15 hours. This morning, upon reviewing, I observed that the job exceeded 9 hours. However, when I checked the status of the job two hours later, it appeared to have started only 2 hours ago. This seems improbable as I did not resubmit any job this morning. Could you kindly investigate the current status of my job? My account for Anvil is : mailto:, the diectory where I am running that job is /anvil/projects/x-mcb150144/ellanguyen/FAH\\_MSM\\_5/TSA/submit/12-7lyh\\_MD\\_simulation\\_0.job. name. ; Hello! Thanks for reaching out! Can you share the JOB ID you were referring? I saw one job was running on your account on Anvil. @login01.anvil:\~ $ squeue -u x-ellanguyen JOBID USER ACCOUNT NAME NODES CPUS TIME\\_LIMIT ST TIME 4487312 x-ellanguyen mcb150144-gpu 7lyh 1 1 15:00:00 R 6:21:00 Is this the job you were referring to? Regards, name, PhD (She/Her/Hers) Sr. Computational Scientist ; Hi, Yes, that particular one. I submitted that job last night. When I checked it this morning, it had been running for over nine hours. But the status of that job had changed by the time I checked it two hours later. It also stated that it had only been submitted for two hours. I did not submit or run any jobs this morning. name. ; Hi name, I think it was related to our job manager issues on Wed (2/27), our engineers fixed the problem. We are sorry for the inconvenience. Regards, name ;",ellanguyen,Thi Hong Ha Nguyen,Nannan Shan,,Anvil,4,7,9,2024,2024-02-26
ATS-6552,No new snapshots on /anvil/projects since Feb 20,2024-02-29,2024-03-07,"It looks like snapshots on /anvil/projects have stopped working again with the last one happening on Feb 20. Can you please take a look? I think a check was put in place to make sure this wouldn't happen again (see ATS-5117), but maybe that check wasn't triggered properly? login05.anvil /anvil/projects/.snapshots : ll total 902 1 dr-xr-xr-x 2 root root 4096 Oct 23 15:06 ./ 64 drwxr-xr-x 683 root root 32768 Feb 28 14:25 ../ 64 drwxr-xr-x 545 root root 32768 Aug 31 09:45 '@EST-2023.09.01-01.02.00'/ 64 drwxr-xr-x 588 root root 32768 Oct 23 09:45 '@EST-2023.10.23-14.04.00'/ 64 drwxr-xr-x 602 root root 32768 Oct 31 09:25 '@EST-2023.11.01-01.02.00'/ 64 drwxr-xr-x 641 root root 32768 Dec 29 15:25 '@EST-2024.01.01-02.02.00'/ 64 drwxr-xr-x 654 root root 32768 Jan 19 15:25 '@EST-2024.01.22-01.01.35'/ 64 drwxr-xr-x 655 root root 32768 Jan 25 14:51 '@EST-2024.01.29-01.01.35'/ 1 drwxr-xr-x 664 root root 4096 Jan 31 09:25 '@EST-2024.02.01-02.02.00'/ 64 drwxr-xr-x 664 root root 32768 Jan 31 09:25 '@EST-2024.02.05-01.01.35'/ 64 drwxr-xr-x 671 root root 32768 Feb 9 12:25 '@EST-2024.02.12-01.01.35'/ 64 drwxr-xr-x 676 root root 32768 Feb 12 16:25 '@EST-2024.02.13-08.00.07'/ 64 drwxr-xr-x 677 root root 32768 Feb 13 09:25 '@EST-2024.02.14-08.00.07'/ 64 drwxr-xr-x 678 root root 32768 Feb 14 10:25 '@EST-2024.02.15-08.00.07'/ 1 drwxr-xr-x 681 root root 4096 Feb 15 10:05 '@EST-2024.02.16-08.00.07'/ 1 drwxr-xr-x 681 root root 4096 Feb 15 10:05 '@EST-2024.02.17-08.00.07'/ 1 drwxr-xr-x 681 root root 4096 Feb 15 10:05 '@EST-2024.02.18-08.00.07'/ 1 drwxr-xr-x 681 root root 4096 Feb 15 10:05 '@EST-2024.02.19-01.01.35'/ 64 drwxr-xr-x 681 root root 32768 Feb 15 10:05 '@EST-2024.02.19-08.00.07'/ 64 drwxr-xr-x 682 root root 32768 Feb 19 16:05 '@EST-2024.02.20-08.00.07'/ Regards, Doug ; Hi Doug, Thank you for reporting the issue. I've shared the ticket with our storage experts and will keep you updated. Warm regards, name ; Hi Doug, The issue should be resolved now. Newer snapshots of the projects directory are available. We are tentatively marking this ticket as resolved at this point. Please feel free to contact us again if you see any further issues. Thanks, name ; Thanks name Thanks, name ;",dgc@access-ci.org,Doug Crabill,Ruyi Li,Purdue University,Anvil,8,6,9,2024,2024-02-26
ATS-6599,Compilation of OpenFOAM,2024-03-01,2024-03-08,"Dear Administrative Team I hope this message finds you well. I am name, a PhD student at the university of Rhode Island. Recently, as part of my work, I attempted to compile OpenFOAM v2006 on Anvil. While I was successful in compiling the software, I observed discrepancies between the simulation results obtained on my personal computer and those obtained on Anvil, where the simulation diverged. Upon further investigation, I found that OpenFOAM v2021 is already available on the Anvil platform. With this knowledge, I am reaching out to inquire whether it would be possible for the Anvil team to compile OpenFOAM v2006, too. Your kind assistance in addressing this matter would be immensely appreciated, as it plays a crucial role in advancing my research endeavors. Thank you very much for your attention and consideration. Warm regards, name PhD Student University of Rhode Island ; Hi, Thank you for contacting us. Sorry but we might not be able to centrally deploy this openfoam version since it is not regarded as broadly useful set of popular software packages (see our software installation policy https://www.rcac.purdue.edu/index.php/knowledge/anvil/policies/software\\_installation\\_request\\_policy: https://www.rcac.purdue.edu/index.php/knowledge/anvil/policies/software\\_installation\\_request\\_policy|smart-link ). However, you should be able to compile openfoam following the official guide under any of your spaces. Please give it a try and let me know if you have further questions. Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi name Thanks for your reply. The problem was the version of gcc on Anvil. I loaded the older version and it was compiled successfully. Bests name ; Hi name, Thank you for the update. That's awesome to hear an older version of gcc is working for you. I will also keep it noted. Thank you. Best, name ;",ymohammadijarenasero@access-ci.org,Yavar Mohammadi Jare Nasero,Guangzhen Jin,,Anvil,4,6,9,2024,2024-02-26
ATS-6600,File recover,2024-03-01,2024-03-04,"Hi Anvil team, I just found some important files were deleted in my folder: /anvil/scratch/x-wangwl/hba/00.data/fastq/ and /anvil/scratch/x-wangwl/hba/00.data/bam. Is it possible to recover these files on your side? Also could you tell me the criteria of deleting files? I recently touched those files, and thought they will be kept on the drive. Thanks, Wenliang ; Hi, Thank you for contacting us. Unfortunately files deleted from scratch cannot be recovered as there are no backups. There is a purge policy for scratch that ""files older than 30-day (access time) will be purged"" (https://www.rcac.purdue.edu/knowledge/anvil/storage/filesystems: https://www.rcac.purdue.edu/knowledge/anvil/storage/filesystems|smart-link ) so if files are not being actually accessed over a month, they will be deleted. So I would not recommend any important files (only) stored under scratch as there will no protections when they got deleted. Let me know if you have further questions. Best regards, name Senior Computational Scientist Purdue Information Technology ; Got it. Thanks for the reply. ;",wangwl@access-ci.org,Wenliang Wang,Guangzhen Jin,Purdue University,Anvil,3,2,9,2024,2024-02-26
ATS-6705,access to more nodes,2024-03-07,2024-03-08,"Hi, We are solving a very large problem using very efficient parallel code Rhea. This requires more nodes than any queue can offer. We need at least 136 nodes, about ~20000 CPUs. Is there a way to access that many nodes? We can prove the efficiency of this code. In fact, we have used that many nodes on Stampede2 and frontera. It works very well. Therefore, we would like to request similar number of nodes on ANVIL as well. Thank you Regards, Jiashun ; Hi Jiashun, A QOS named {{hujs-wide}} has been created for you. It will allow you to request up to 158 nodes (20224 CPUs). To use it, you may add the {{-q hujs-wide}} option in your job submission script/command. Would you please give it a try and let me know if there are any issues? Thanks, name ; Hi name, I just tried. It worked. Thank you very much! Best regards, Jiashun ; You are welcome, Jiashun. Glad it worked for you. I'll go ahead and mark this ticket as resolved then. Warm regards, name ;",hujs@access-ci.org,Jiashun Hu,Ruyi Li,Purdue University,Anvil,6,2,10,2024,2024-03-04
ATS-5647,Invalid account or account/partition combination specified,2024-01-24,2024-03-12,"Hi, I'm new to this environment but I'm try to submit some jobs on the Avil cluster but I can't because I get always the same error: An error occurred when submitting jobs for simulation 9: sbatch: error: Batch job submission failed: Invalid account or account/partition combination specified This is how looks like the script: #/bin/bash # FILENAME: myjobsubmissionfile #SBATCH -A bio240009-gpu # allocation name #SBATCH --nodes=1 # Total # of nodes #SBATCH --ntasks-per-node=1 # Number of MPI ranks per node (one rank per GPU) #SBATCH --gpus-per-node=1 # Number of GPUs per node #SBATCH --time=1:30:00 # Total run time limit (hh:mm:ss) #SBATCH -J myjobname # Job name #SBATCH -o myjob.o%j # Name of stdout output file #SBATCH -e myjob.e%j # Name of stderr error file #SBATCH -p gpu # Queue (partition) name #SBATCH --mail-user=useremailaddress #SBATCH --mail-type=all # Send email to above address at begin and end of job #SBATCH -p gpu # Queue (partition) name # Manage processing environment, load compilers, and applications. module purge module load modtree/gpu module load applicationname module list module load ngc module load namd # Launch GPU code namd2 0.name > r0.log /var/spool/slurm/job4400076/slurm\\_script: line 18: module: command not found/var/spool/slurm/job4400076/slurm\\_script: line 19: module: command not found/var/spool/slurm/job4400076/slurm\\_script: line 20: module: command not found/var/spool/slurm/job4400076/slurm\\_script: line 21: module: command not found/var/spool/slurm/job4400076/slurm\\_script: line 23: module: command not found/var/spool/slurm/job4400076/slurm\\_script: line 27: namd2: command not found ; Hi Francesco, I think we can have a virtual meeting to discuss about this problem. We can have a meeting next week, say Monday, 2:30pm-3:30pm (ET). Let me know if this works for you. Regards, name ; Hi, thank you so much for your help. Yes, I'm ok at that time Regards, name ; Thank you so much for your help!! Best Francesco ;",x-fcoppola,Francesco Coppola,Nannan Shan,,Anvil,15,35,4,2024,2024-01-22
ATS-5722, file creation limit ,2024-01-28,2024-03-11,"I have available storage capacity, but I can't run my jobs due to the file creation limit. It is showing ""cannot create directory: disk quota exceeded. How could I resolve this? Could I increase the limit? ; Hello! Thanks for reaching out! Would you let me know where you run your job? Is it on your HOME directory or Scratch or your project space? Regards, name, PhD (She/Her/Hers) Sr. Computational Scientist ; Thank you. We are running our jobs in the project space. Best, Md Mehedi name ; Hello! I am wondering if you were running machine learning workflow (training process). If so, we would recommend to archive the files to a tarball or zip to avoid producing/creating tons of small files. Regards, name ; Could you please suggest how I could make the zip files in Anvil? Is there any risk of losing a file in the zip if I am disconnected from the server while the zip creation is running? I noticed that if I leave my computer inactive for some time, it loses connection with Anvil. Thank you. Regards Md. Mehedi name ; No, you won't lose your date with a tarball file. Let me loop in our data scientist to help with your workflow. Regards, name ; \\*\\*PRIVATE NOTE\\*\\* Hi Geoff, ~accountid:id] I am wondering if you can help with this user for their workflow, basically they do not know how to create a tarball file for their data. Regards, name ; Hello Md, I'd like to help you figure this out. Our recommendation is to use some sort of bundled format for large collections of small files (such as in the case of ML training). It's infeasible for many users to all have their quotas increased sufficiently; but also it's in your own best interest for performance reasons. Crawling a directory structure of small files and loading them in batches is going to suffer the full cost of the 'file open' for each which is often the bigger burden and not the size of the data. Bundling the data is going to dramatically increase performance when training. You can do this any number of ways; there is not a right and a wrong way. You can create your own pseudo-format by stacking the data in a randomized traversal of the dataset. Or you can use an off-the-shelf format. I have a personal preference for embedded database formats (e.g., SQLite), whose performance is misunderstood and underrated. The simplest options would be TAR or ZIP and can be created/read using standard Linux utilities. The trick is to NOT COMPRESS the data, only bundle. Many archive formats assume the benefit of compression; in our case we don't want to pay the cost of slow decompression while training; we have plenty of disk space. With TAR, this would be tar -cvf training\\_data.tar training\\_data/ Notice we have omitted using a compression format (i.e., {{-z}} and the {{.gz}} extension). To use ZIP, the creation command is similar zip -0 -r training\\_data.zip training\\_data/ Notice the {{-0}} which disables compression. To answer your questions: No, you do not affect the source data when creating the archive. The archive creation itself could fail, but it only touches the source data in read-only fashion. Regarding losing your connection, this is simply the unavoidable reality of the network standing between you and Anvil. The simplest way around this would be to use the Remote Desktop interface (i.e., ThinLinc) to hold your terminal (within the desktop interface), so that when you get disconnected you can come back and it's still running. If you would like to stick to a standard remote shell via SSH, I would recommend you look into using one of two standard utilities; SCREEN or TMUX. I personally think TMUX is more feature rich. They both offer the same capability; they are a background process that owns your shell and exposes it back to you (almost like you aren't using anything at all - though TMUX shows a toolbar at the bottom). But this means you can have many sessions over a single SSH, and can detach/re-attach when you come back. For actually consuming the data while in some bundled format (instead of just a pile of files in the file system), if you have the benefit of writing your own code then this isn't much of a challenge, you just need to list the files from where they lie inside the archive and pull them directly out. In Python, this is literally a couple of lines change, or a single line change if you use a third-party package to handle it for you. However, if you are stuck using a pre-existing application that you cannot change the interface to, you can trick it by exposing the archive file as a 'normal' directory using one of a many utilities available that create a 'virtual file system' at that directory path. Something like [https://github.com/mxmlnkn/ratarmount: https://github.com/mxmlnkn/ratarmount|smart-link ratarmount training\\_data.tar other\\_dirname/ Create the {{other\\_dirname}} folder first as an empty folder. Cheers, name ;",mhasan1@access-ci.org,MD MEHEDI HASAN,Nannan Shan,Purdue University,Anvil,8,31,4,2024,2024-01-22
ATS-6458,Longer than usual queue times,2024-02-26,2024-03-11,"Hello, My name is name Shipley, and I am a New Mexico State University student researcher. I have been using Purdue's Anvil cluster for the more intensive research computations. Since the latest maintenance shutdown, I have been waiting considerably longer in the queue for the wholenode partition. I recently checked and confirmed that there are more than enough name's allocated. If possible, I would love to get some information as to why this may be happening. Especially if it is something that is wrong on my end. Thank you very much for your time, and I hope to hear from you soon. Regards, -name Shipley ; Hi name, Thank you for contacting us. I suspect your long wait times might be related to the previous insufficient name balance in your allocation {{dmr110093}}. It seems your group has just exchanged for an additional amount of SUs and your jobs have got started. Please let me know if you need more information. Thanks, name ; Hello name, I appreciate your assistance. I have since addressed that issue and am able to run jobs successfully now. Thank you, -name Shipley ---- ; Hi name, Thanks for letting me know you were able to run jobs. We noticed that the name limit on the account {{dmr110093}} is not properly set up and our engineers are investigating the issue. It might take a while to have it corrected, so I'm tentatively marking this ticket as resolved at this point. Please note that account {{dmr110093}} should have a limit of 174,940.0 SUs (but not 1,899,572.0) at the moment. Thanks, name ;",ashipley@access-ci.org,Austin Shipley,Ruyi Li,Purdue University,Anvil,4,11,9,2024,2024-02-26
ATS-6683,QT QPA plugin error for GUI application,2024-03-06,2024-03-13,"Greetings, I am trying to run a GUI application (""deformetrica"") via remote desktop on Anvil. I am getting the following error (image attached) related to QT, not sure what is causing it. I have tried "" export qt\\_qpa\\_platform=offscreen "" but there is no window opening. Thanks for the help ; Hi name, Thanks for reaching out! Can you share more details about your question? For example, the steps you took which would help me to see if I can reproduce your work. If you were using commands, you can share what commands you have used after login Anvil. Regards, name, PhD (She/Her/Hers) Sr. Computational Scientist ; Greetings, the software is installed within a conda environment. Here are the commands needed to launch it: module load anaconda conda activate deformetrica deformetrica gui Thanks! ; name Calado Graduate Research Assistant Mechanical and Aerospace Engineering The name Washington University 800 22ND Street, NW Science & Engineering name, Suite 2220 Washington, DC 20052 ; Hi name, I see. Looks like you created your own environment an installed a package called deformetrica. Since the error message said, this application did not start because no QT platform plugin could be initialized. Reinstalling this application may fix the problem. Have you tried to re-install this package within your environment? Did you check the manual of this application and see if there is discussion about QT plugin? Regards, name ; Hi name, I believe the likely cause is that some missing libraries would be required. In any case I have been able to use the software without its GUI. Ticket can be therefore be closed. Thanks and kind regards ; name Calado Graduate Research Assistant Mechanical and Aerospace Engineering The name Washington University 800 22ND Street, NW Science & Engineering name, Suite 2220 Washington, DC 20052 ;",acalado@access-ci.org,Andre Calado,Nannan Shan,Purdue University,Anvil,6,6,10,2024,2024-03-04
ATS-5647,Invalid account or account/partition combination specified,2024-01-24,2024-03-12,"Hi, I'm new to this environment but I'm try to submit some jobs on the Avil cluster but I can't because I get always the same error: An error occurred when submitting jobs for simulation 9: sbatch: error: Batch job submission failed: Invalid account or account/partition combination specified This is how looks like the script: #/bin/bash # FILENAME: myjobsubmissionfile #SBATCH -A bio240009-gpu # allocation name #SBATCH --nodes=1 # Total # of nodes #SBATCH --ntasks-per-node=1 # Number of MPI ranks per node (one rank per GPU) #SBATCH --gpus-per-node=1 # Number of GPUs per node #SBATCH --time=1:30:00 # Total run time limit (hh:mm:ss) #SBATCH -J myjobname # Job name #SBATCH -o myjob.o%j # Name of stdout output file #SBATCH -e myjob.e%j # Name of stderr error file #SBATCH -p gpu # Queue (partition) name #SBATCH --mail-user=useremailaddress #SBATCH --mail-type=all # Send email to above address at begin and end of job #SBATCH -p gpu # Queue (partition) name # Manage processing environment, load compilers, and applications. module purge module load modtree/gpu module load applicationname module list module load ngc module load namd # Launch GPU code namd2 0.name > r0.log /var/spool/slurm/job4400076/slurm\\_script: line 18: module: command not found/var/spool/slurm/job4400076/slurm\\_script: line 19: module: command not found/var/spool/slurm/job4400076/slurm\\_script: line 20: module: command not found/var/spool/slurm/job4400076/slurm\\_script: line 21: module: command not found/var/spool/slurm/job4400076/slurm\\_script: line 23: module: command not found/var/spool/slurm/job4400076/slurm\\_script: line 27: namd2: command not found ; Hi Francesco, I think we can have a virtual meeting to discuss about this problem. We can have a meeting next week, say Monday, 2:30pm-3:30pm (ET). Let me know if this works for you. Regards, name ; Hi, thank you so much for your help. Yes, I'm ok at that time Regards, name ; Thank you so much for your help!! Best Francesco ;",x-fcoppola,Francesco Coppola,Nannan Shan,,Anvil,15,35,4,2024,2024-01-22
ATS-5722, file creation limit ,2024-01-28,2024-03-11,"I have available storage capacity, but I can't run my jobs due to the file creation limit. It is showing ""cannot create directory: disk quota exceeded. How could I resolve this? Could I increase the limit? ; Hello! Thanks for reaching out! Would you let me know where you run your job? Is it on your HOME directory or Scratch or your project space? Regards, name, PhD (She/Her/Hers) Sr. Computational Scientist ; Thank you. We are running our jobs in the project space. Best, Md Mehedi name ; Hello! I am wondering if you were running machine learning workflow (training process). If so, we would recommend to archive the files to a tarball or zip to avoid producing/creating tons of small files. Regards, name ; Could you please suggest how I could make the zip files in Anvil? Is there any risk of losing a file in the zip if I am disconnected from the server while the zip creation is running? I noticed that if I leave my computer inactive for some time, it loses connection with Anvil. Thank you. Regards Md. Mehedi name ; No, you won't lose your date with a tarball file. Let me loop in our data scientist to help with your workflow. Regards, name ; \\*\\*PRIVATE NOTE\\*\\* Hi Geoff, ~accountid:id] I am wondering if you can help with this user for their workflow, basically they do not know how to create a tarball file for their data. Regards, name ; Hello Md, I'd like to help you figure this out. Our recommendation is to use some sort of bundled format for large collections of small files (such as in the case of ML training). It's infeasible for many users to all have their quotas increased sufficiently; but also it's in your own best interest for performance reasons. Crawling a directory structure of small files and loading them in batches is going to suffer the full cost of the 'file open' for each which is often the bigger burden and not the size of the data. Bundling the data is going to dramatically increase performance when training. You can do this any number of ways; there is not a right and a wrong way. You can create your own pseudo-format by stacking the data in a randomized traversal of the dataset. Or you can use an off-the-shelf format. I have a personal preference for embedded database formats (e.g., SQLite), whose performance is misunderstood and underrated. The simplest options would be TAR or ZIP and can be created/read using standard Linux utilities. The trick is to NOT COMPRESS the data, only bundle. Many archive formats assume the benefit of compression; in our case we don't want to pay the cost of slow decompression while training; we have plenty of disk space. With TAR, this would be tar -cvf training\\_data.tar training\\_data/ Notice we have omitted using a compression format (i.e., {{-z}} and the {{.gz}} extension). To use ZIP, the creation command is similar zip -0 -r training\\_data.zip training\\_data/ Notice the {{-0}} which disables compression. To answer your questions: No, you do not affect the source data when creating the archive. The archive creation itself could fail, but it only touches the source data in read-only fashion. Regarding losing your connection, this is simply the unavoidable reality of the network standing between you and Anvil. The simplest way around this would be to use the Remote Desktop interface (i.e., ThinLinc) to hold your terminal (within the desktop interface), so that when you get disconnected you can come back and it's still running. If you would like to stick to a standard remote shell via SSH, I would recommend you look into using one of two standard utilities; SCREEN or TMUX. I personally think TMUX is more feature rich. They both offer the same capability; they are a background process that owns your shell and exposes it back to you (almost like you aren't using anything at all - though TMUX shows a toolbar at the bottom). But this means you can have many sessions over a single SSH, and can detach/re-attach when you come back. For actually consuming the data while in some bundled format (instead of just a pile of files in the file system), if you have the benefit of writing your own code then this isn't much of a challenge, you just need to list the files from where they lie inside the archive and pull them directly out. In Python, this is literally a couple of lines change, or a single line change if you use a third-party package to handle it for you. However, if you are stuck using a pre-existing application that you cannot change the interface to, you can trick it by exposing the archive file as a 'normal' directory using one of a many utilities available that create a 'virtual file system' at that directory path. Something like [https://github.com/mxmlnkn/ratarmount: https://github.com/mxmlnkn/ratarmount|smart-link ratarmount training\\_data.tar other\\_dirname/ Create the {{other\\_dirname}} folder first as an empty folder. Cheers, name ;",mhasan1@access-ci.org,MD MEHEDI HASAN,Nannan Shan,Purdue University,Anvil,8,31,4,2024,2024-01-22
ATS-6458,Longer than usual queue times,2024-02-26,2024-03-11,"Hello, My name is name Shipley, and I am a New Mexico State University student researcher. I have been using Purdue's Anvil cluster for the more intensive research computations. Since the latest maintenance shutdown, I have been waiting considerably longer in the queue for the wholenode partition. I recently checked and confirmed that there are more than enough name's allocated. If possible, I would love to get some information as to why this may be happening. Especially if it is something that is wrong on my end. Thank you very much for your time, and I hope to hear from you soon. Regards, -name Shipley ; Hi name, Thank you for contacting us. I suspect your long wait times might be related to the previous insufficient name balance in your allocation {{dmr110093}}. It seems your group has just exchanged for an additional amount of SUs and your jobs have got started. Please let me know if you need more information. Thanks, name ; Hello name, I appreciate your assistance. I have since addressed that issue and am able to run jobs successfully now. Thank you, -name Shipley ---- ; Hi name, Thanks for letting me know you were able to run jobs. We noticed that the name limit on the account {{dmr110093}} is not properly set up and our engineers are investigating the issue. It might take a while to have it corrected, so I'm tentatively marking this ticket as resolved at this point. Please note that account {{dmr110093}} should have a limit of 174,940.0 SUs (but not 1,899,572.0) at the moment. Thanks, name ;",ashipley@access-ci.org,Austin Shipley,Ruyi Li,Purdue University,Anvil,4,11,9,2024,2024-02-26
ATS-6683,QT QPA plugin error for GUI application,2024-03-06,2024-03-13,"Greetings, I am trying to run a GUI application (""deformetrica"") via remote desktop on Anvil. I am getting the following error (image attached) related to QT, not sure what is causing it. I have tried "" export qt\\_qpa\\_platform=offscreen "" but there is no window opening. Thanks for the help ; Hi name, Thanks for reaching out! Can you share more details about your question? For example, the steps you took which would help me to see if I can reproduce your work. If you were using commands, you can share what commands you have used after login Anvil. Regards, name, PhD (She/Her/Hers) Sr. Computational Scientist ; Greetings, the software is installed within a conda environment. Here are the commands needed to launch it: module load anaconda conda activate deformetrica deformetrica gui Thanks! ; name Calado Graduate Research Assistant Mechanical and Aerospace Engineering The name Washington University 800 22ND Street, NW Science & Engineering name, Suite 2220 Washington, DC 20052 ; Hi name, I see. Looks like you created your own environment an installed a package called deformetrica. Since the error message said, this application did not start because no QT platform plugin could be initialized. Reinstalling this application may fix the problem. Have you tried to re-install this package within your environment? Did you check the manual of this application and see if there is discussion about QT plugin? Regards, name ; Hi name, I believe the likely cause is that some missing libraries would be required. In any case I have been able to use the software without its GUI. Ticket can be therefore be closed. Thanks and kind regards ; name Calado Graduate Research Assistant Mechanical and Aerospace Engineering The name Washington University 800 22ND Street, NW Science & Engineering name, Suite 2220 Washington, DC 20052 ;",acalado@access-ci.org,Andre Calado,Nannan Shan,Purdue University,Anvil,6,6,10,2024,2024-03-04
ATS-7524,FailedMount on a k8s node.,2024-04-16,2024-04-17,"Greetings, There appears to be an issue on a k8s node where a pod cannot mount or release a PVC, thus preventing the termination or creation of the pod. I attach the event logs of the cluster here, too. Best Regards, name ; \\*\\*PRIVATE NOTE\\*\\* Hi, ~accountid:id. It seems to be with the composable name. I'm escalating the ticket to you. Thanks ; Great! Marking this resolved. ;",nujwoo,Jaewoo Shin,Erik Gough,Purdue University,Anvil,6,2,16,2024,2024-04-15
ATS-5634,VASP test calculation failing repeatedly,2024-01-24,2024-03-13,"Hello! I am a new user of Purdue Anvil, and I'm encountering an issue which I have never dealt with before. While testing VASP on Anvil, I submitted a structural relaxation which I have performed before \\_without any issue\\_ on TACC's Stampede2 (SKX-compute node, dual processor with 48 cores per socket/96 cores per node, 192 GB of RAM and 144 GB of local storage). However, when I submit this identical set of input files (with srun) through Purdue Anvil, I get one of two errors: for lower numbers of cores per node (i.e. 1 node, 1 task, 4 tasks, 8 tasks, 16 tasks): srun: error: a978: task 8: Out Of Memory for larger numbers of cores per node (i.e. 1 node, 128 tasks, 64 tasks, or 32 tasks: My VASP calculation fails with repeated outputs of following error: WARNING: Sub-Space-Matrix is not hermitian subr followed by: Orbital orthonormalization failed in the inversion of matrix | | scaLAPACK: Routine ZPOTRF ZTRTRI failed! kpoint: 1 spin: 1 All of the listed combinations have been tested at the specified number of tasks (all on 1 node). For all the tests, I request one node and all 128 tasks in my submit script, and tune the number of cores used by VASP using the NCORE tag. Before running all these tests, I tried keeping NCORE at 16 and requested only 64, 32, 16 tasks on my submit script. All failed with the nonhermitian subspace matrix error listed above. The latter error I have seen before multiple times, and it can have (sigh) \\_MANY\\_ origins. It happens when, a) the input structure geometry is unphysical, b) the structural relaxation led to an unphysical geometry, c) scaLAPACK was installed incorrectly on the cluster, or is corrupt in some way, or d) too many tasks/cores were assigned to the VASP calculation, and something gets messed up in the parallelization. As I said, I have submitted this exact VASP input through other clusters, and never had problems before, so I do not think this is caused by an unphysical geometry in the input or relaxation. Rather, I think it probably has to do with a parallelization issue. I'm sure many people have run VASP successfully on Anvil before, so I don't want to assume that scaLAPACK was installed incorrectly or anything like that, but perhaps this is something someone could verify? I'm very confused with the out of memory issue (former error with lower numbers of tasks) because the nodes I'm running VASP on have 256 GB of RAM, based on the Anvil specifications! This is more memory than the nodes I ran VASP on at Stampede2 (192 GB), which as I said, ran without any issue. Is it possible that the default memory allocation for a compute node is less than the reported 256 GB? Should I be specifying that I need all 256 GB of memory for my run? I tried running all above tests again with mpirun, and I got virtually the same issue except, for the small number of cores, the error was ""exited with signal 9 (Killed)"", which seems most commonly associated with memory overflow. I see there is a large memory node option in Anvil, but seeing as this is 4x more expensive than the regular nodes, I'd prefer to use the regular nodes, especially because I have ran VASP successfully on nodes with less memory than Anvil's nodes. This is my submit script: #!/bin/bash #SBATCH -J \\_\\_8NCORE\\_# Job name #SBATCH -A MAT210016 #SBATCH -o %j.o # Name of stdout output file #SBATCH -e %j.err # Name of stderr error file #SBATCH -p wholenode # Queue (partition) name #SBATCH --nodes 1 # Total # of nodes #SBATCH --ntasks 128 # Total # of mpi tasks #SBATCH -t 48:00:00 # Run time (hh:mm:ss) #SBATCH --mail-user= #SBATCH --mail-type=all # Send email at begin and end of job pwd date hostname module purge module load gcc/11.2.0 module load openmpi/4.0.6 module load hdf5/1.10.7 module load vasp/6.3.0 module list mpirun -np 128 vasp\\_std>my\\_vasp.out does Anvil have a VASP specialist that maybe could point me in the right direction? To be thorough, I've also included my VASP input files in the attached files. ; ^INCAR] ^KPOINTS ^POSCAR ^POTCAR ; I urgently need to perform scaling tests for a proposal that is due on January 31st, so I REALLY need help getting VASP working!! Please help! ; Hi Gillian, Thanks for reaching out! And sorry for the delay. I just came back from my sick leave and let me run tests with your input files and see if I can reproduce the OOM errors. Thanks for your patience. Regards, name, PhD (She/Her/Hers) Sr. Computational Scientist ; Hi Gillian, I made a test with the input files you shared. The only thing I changed is the submit script, mine is like: #!/bin/bash #SBATCH -J \\_\\_8NCORE\\_# Job name #SBATCH -A myallocation #SBATCH -o %j.o # Name of stdout output file #SBATCH -e %j.err # Name of stderr error file #SBATCH -p wholenode # Queue (partition) name #SBATCH --nodes=1 # Total # of nodes #SBATCH --ntasks=128 # Total # of mpi tasks #SBATCH -t 12:00:00 # Run time (hh:mm:ss) pwd date hostname module purge module load gcc/11.2.0 module load openmpi/4.0.6 module load hdf5/1.10.7 module load vasp/6.3.0 module list mpirun -np 128 vasp\\_std I did not get the same error as you showed here (i.e. out of memory), but I got another error message (WARNING: Sub-Space-Matrix is not hermitian in DAV) and I googled the error message, found the discussion on VASP forum. https://www.vasp.at/forum/viewtopic.php?t=1192: https://www.vasp.at/forum/viewtopic.php?t=1192|smart-link If you can let me know your JOB ID, I can check more information about your job. Regards, name ; Hi name, Thank you so much for your response! Yes, I see that exact error (and I've visited that exact forum) quite often, and for these calculations either the calculation fails with that error or out of memory. I have a LOT of jobs which have failed out of memory, I'll list off some job# examples below. Note that all these calculations were run on the same structure with the exact same conditions, just different ntasks: \\* job 4297951: 1 node, 1 core - failed with out of memory \\* job 4297950: 1 node, 4 cores - failed with out of memory \\* job 4297946: 1 node, 8 cores - failed with out of memory \\* job 4297945: 1 node, 16 cores - failed with out of memory \\* job 4297949: 1 node, 32 cores - failed with WARNING: Sub-Space-Matrix is not hermitian in DAV \\* job 4297947: 1 node, 64 cores - failed with WARNING: Sub-Space-Matrix is not hermitian in DAV \\* job 4297948: 1 node, 128 cores - failed with WARNING: Sub-Space-Matrix is not hermitian in DAV I want to note that the calculations above were run on a different structure than what I gave you in my error report. I wanted to make sure it wasn't a problem with that one structure. I ran nearly 100 different calculations trying to target what was going on here - again, the reason why this is so confusing is because this exact calculation has been performed and successfully exited on a different HPC (TACC Stampede2). I've managed to get some iterations to work by tweaking different INCAR parameters, but there doesn't seem to be a consistent trend aside from the fact that specifying a deficient number of tasks (i.e. 1-16 cores in the example above) tends to result in an out of memory error, and an excessive amount of tasks leads to this sub-space-matrix ic not hermitian error. It just seems generally a LOT more tricky to get VASP to successfully run on Anvil - is it because Anvil nodes are so much more parallelized? Are these types of issues common for VASP users on Anvil or no? What sorts of recommendations do you have for optimizing available memory on each node and optimizing parallelization on Anvil nodes? Best, Gillian ; \\*\\*PRIVATE NOTE\\*\\* Hi Gillian, Thanks for sharing the information. I am not sure if this is related to the openmpi version used for VASP compilation, as VASP officials warned that openmpi 4.0 will have memory leak problem. Thus I deployed VASP 6.3.0 with openmpi 4.1.6. It is available now. You can use it with module --force purge module load gcc/11.2.0 module load openmpi/4.1.6 module load vasp/6.3.0 Let me know if you see issues. Regards, name ; Hi Gillian, Thanks for sharing the information. I am not sure if this is related to the openmpi version used for VASP compilation, as VASP officials warned that openmpi 4.0 will have memory leak problem. Thus I deployed VASP 6.3.0 with openmpi 4.1.6. It is available now. You can use it with module --force purge module load gcc/11.2.0 module load openmpi/4.1.6 module load vasp/6.3.0 Let me know if you see issues. Regards, name ;",gjames1@access-ci.org,Gillian James,Nannan Shan,Purdue University,Anvil,8,36,4,2024,2024-01-22
ATS-6754,VASP access request on Anvil,2024-03-11,2024-03-14,"Hello, I am a new user on Anvil and would like to access VASP via the licence I am associated with: Number: 23-0067 Licence Holder: name Scanlon My email address: : mailto: Is there anything else you need from me? Thanks, name ; Hi, Thank you for contacting us. I've added you to {{vasp5}} and {{vasp6}} licenses on Anvil. You should be able to access those modules within the next couple of hours. Best regards, name Senior Computational Scientist Purdue Information Technology ;",asquires1@access-ci.org,Alex Squires,Guangzhen Jin,Purdue University,Anvil,2,4,11,2024,2024-03-11
ATS-6841,Failed access from external kubectl,2024-03-14,2024-03-14,"Greetings, I'm having an issue with kubectl to anvil composable as attached screenshot. Would you please take a look and see what is going on my account or the cluster? ; There was an issue with one of the API servers that was intermittently causing this message. Should be fixed now. Thanks! ;",nujwoo,Jaewoo,Erik Gough,Purdue University,Anvil,3,1,11,2024,2024-03-11
ATS-2412,Interactive and batch jobs hang - Part 2,2023-08-18,2024-03-15,"I recently submitted a ticket ( https://access-ci.atlassian.net/browse/ATS-2328: https://access-ci.atlassian.net/browse/ATS-2328|smart-link ) regarding some batch and interactive jobs that were hanging. name helped me figure out that I had an erroneous compiler flag which, once removed, seemed to resolve the issue. I'm reopening this issue however, because three recent jobs (2601935, 2601966, and 2602013) just did the same thing after only a few minutes of running (less than 10). I did notice that I was using the compiler flag -axCORE-AVX2, but the anvil documentation says to use -march=core-avx2 (for Intel compilers). I'm not sure if these are equivalent, but I did recompile with -march=core-avx2 and still had the same issue (third job ID in the list: 2602013). ; I just checked to see if this issue persists by running a new job (job ID 2610002) with the same result. I'm escalating this ticket because I can't move forward with my research until I'm able to run jobs without them hanging. ; Just checking back in on this because I haven't heard anything in response. Is this a known issue and is there something I can do in the meantime to get my simulations running? I just tried again running a job with 2 nodes and 256 MPI tasks and it name after about 4 minutes of runtime (job ID 2625538). Something I've noticed is that this is simulation-size dependent. I'm running a fluid dynamics code and find that if I run a small simulation (~2 million solution points) using 128 tasks, I don't run into this issue. But a slightly larger simulation (~17 million points) using 256 tasks, it hangs within a few minutes. Can anyone help me with this? This is delaying my research progress as I'd like to be running much much larger cases than these, but don't want to burn resources on a hanging job. ; Hi name, Sorry for the late response. I was waiting for a test case to reproduce your error on the other ticket. Can you please send me one? If it is size dependent, the most common cause is out of memory error. Although, I haven't seen any out-of memory messages in the system logs. Other hypothesis that I would want to verify is: Is it overflowing MPI send-receive buffers? Are you using some all-to-all collectives in MPI? Regarding name use: You can use the following sbatch option in your job script to make sure that the job exits whenever any process hangs. #SBATCH --kill-on-bad-exit Waiting for the test case to try out. Best regards, name. ; Hi name, I just tried running a case (job ID 2628533) with 3 nodes and 384 tasks (more memory than before) and had the same hanging issue. You can run the same case using the attached submission script. I tried adding #SBATCH --kill-on-bad-exit to the submission script but got the error sbatch: unrecognized option '--kill-on-bad-exit'. Sincerely, name ^runBatch.sh] \\_(0.0 kB)\\_ ; My bad ; On another note, the litany of issues I've had trying to run my code on Anvil coupled with a significant lack of timely support means I may need to abandon ship here and go to a new cluster. Do you think this is fixable? ; Hello name, The architecture of each ACCESS site is different, with a few exceptions of closely related systems) Anvil is an AMD based system https://www.rcac.purdue.edu/knowledge/anvil/architecture: https://www.rcac.purdue.edu/knowledge/anvil/architecture|smart-link We had two all day events the last two business days. Your issue is complicated and requires a lot of testing and collaboration. name is back in town and he and name will take another look. A meeting with the three of you might be a good way to approach what is going on. This is twice you have expressed you opinion on our support in a direct and negative way. It's clear that we are not meeting your expectations. As this isn't a simple break fix, or configuration issue, I am curious as to what your expectations are? A MATCH engagement might be helpful? https://support.access-ci.org/matchplus: https://support.access-ci.org/matchplus|smart-link Thanks, name ; Hi name, The messages I've sent about Anvil support are not personal. I am simply trying to get my code running on your system. I don't know how else to describe my disappointing experience towards that goal other than being ""direct"". The last contact I had with anyone at Anvil was last Thursday, it is now Wednesday morning. During that time, I continued troubleshooting and providing updates to hopefully help name's investigation. Without any acknowledgement of these messages or someone notifying me that the staff was preoccupied until today, what do expect me to conclude other than this issue is not important to your staff or a priority? What would you do in my situation? My exasperation at the lack of support seems completely reasonable considering no one is responding or acknowledging my requests for help. You asked what my expectations are. I expected to receive focused support until the issue was resolved or identified (keep in mind I first opened a ticket regarding this issue on Aug 14 so my definition of ""focused"" doesn't mean I expected a resolution in one day, but yes, definitely less than one month). You mentioned a phone call. I asked name about a phone call two weeks ago before he went on vacation and he said that would be an option but he was busy and then heading out of town, after which point I never heard from him again. I'd love to have a phone call, but RCAC doesn't provide a contact number and no one has provided a way to set that up. I did reach out to the Purdue IT help desk (as this is the phone number listed on the RCAC's website: https://www.rcac.purdue.edu/about/contact), but they of course could not help me and didn't have a contact number to the RCAC support staff. Regarding the MATCH engagement, that might be a good option. I do have a lot of experience running my code on other clusters so I'm not sure what that level of mentorship will provide once I'm able to run my code on your system, but I'm open to this option. I hope we can figure out the issue, but you are right, it hasn't been a great user experience thus far. name ; Hello name, Thank you for your speedy reply, honesty, and candor. I have a meeting with the Anvil Executive team today and I will address your issue there. I will suggest arranging a video consultation with name and RyanDeRue to discuss this further. Thanks, name ; Hi name, I'll echo what name mentioned. Thank you for your honesty and candor. I can totally relate to your frustration, but rest assured that your additional results and data points are being acknowledged and it is helping us inch closer towards identifying the issue. I suspect this is one of those issues where we might find a bug in the kernel or system firmware (what else would cause a node to freeze name, I see some license denials for your account around 12:20-12:26pm. I'll suggest trying again. Several people are compiling with Intel right now. Best regards, name. ; I see. Thanks name ; Hi name, Just wanted to let you know that name and myself looked at the strace from the nodes. Unfortunately, they did not provide any useful diagnostic information. Were you able to build your code with the new 2decomp library? Did we try using (gcc+openmpi) instead of (intel+mvapich2)? If using a different MPI library avoids the hangs, that may be a quick win. Best regards, name. ; Hi name, Thanks for the update. The new 2decomp library requires a good amount of code-editing due to the new subroutine definitions. I haven't been able to dedicate the necessary time to do this as I'm trying to get results for an upcoming conference. In the meantime, I went ahead and started running cases on a different cluster just so I can generate the data I'll need for the conference. I did try (gcc+openmpi) but the code wouldn't run, it threw a segfault before doing anything. However, I did get (gcc+mvapich2) to run and I saw the same issue as (intel+mvapich2). If it's the MPI implementation then I guess that isn't surprising. I will update you when I have time to work on this a bit more. I'm going on vacation tomorrow for a week so you won't hear from me before then. name, No worries ;",ryanhass,Ryan Hass,Amiya Maji,Purdue University,Anvil,45,151,33,2023,2023-08-14
ATS-3009,Issue compiling a code with autotools,2023-09-14,2024-03-15,"Hello, I'm trying to compile a (MPI-based computational fluid dynamics Fortran) code that uses autotools to generate a configure file that then determines the dependencies and generates the makefile. I'm using the intel compiler with mvapich2, mpc, and mpfr modules loaded. I get the following error after executing ./configure {{config.status: error: Something went wrong bootstrapping makefile fragments}} {{ for automatic dependency tracking. Try re-running configure with the}} {{ '--disable-dependency-tracking' option to at least be able to build}} {{ the package (albeit without support for automatic dependency tracking).}} I've attached the config.log file and the output from the terminal. I can configure successfully with {{--disable-dependency-tracking}} flag but then the dependencies get messed up and the code doesn't run correctly. I've successfully compiled this code on other clusters, including stampede2. So, I think I may be missing some libraries. Please let me know if you have any suggestions on fixing the issue, in case you have encountered similar issues with other users. Thank you Nek ---- ^config\\_Easley.log \\_(0.0 kB)\\_ ^config\\_Anvil.log \\_(0.0 kB)\\_ ; I don't see any obvious error from the configure logs. It is failing at ""generating depfiles"" stage. Can you share a link to the source code for this package? Regards, name. ; Following link has the source code: [https://auburn.box.com/s/s5uenng2zui29o68db74zih5ehdx3kff: https://auburn.box.com/s/s5uenng2zui29o68db74zih5ehdx3kff I use the following commands to generate the configure & make file and compile: sh autogen.sh ./configure make Thanks, Nek ---- ; Thanks ;",nsharan2@access-ci.org,Nek Sharan,Amiya Maji,Purdue University,Anvil,14,132,37,2023,2023-09-11
ATS-6855,Anvil running issue,2024-03-14,2024-03-15,"I was just awarded time via Access and am trying to run a job but have encountered an issue. When I submit, I see this error: sbatch: error: AssocGrpCPUMinutesLimit sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits) Is it likely because the allocation is so new and my access is still processing? My username is x-cassingh and I am working on project MAT-240024 Let me know if you need more information. ; Hi name, Thank you for reaching out. To help us investigate the issue, would you please share your job submission script or command? Warm regards, name ; This is the job submission file: #!/bin/bash #SBATCH --nodes=2 #SBATCH --ntasks=256 #SBATCH --time=18:00:00 #SBATCH -p wholenode ##SBATCH -o slurm.%N.%j.out #STDOUT ##SBATCH -e slurm.%N.%j.err #STDERR #SBATCH --mail-user=: mailto: #SBATCH --mail-type=all module load python/3.9.5 mpirun -n $SLURM\\_NTASKS vasp\\_ncl > vasp.out #python3 relax\\_ase.py > ase\\_vasp.out I use the command 'sbatch ""filename""' to submit -name ; Hi name, Thanks for sharing more information. It looks like you did not specify an allocation in your script. Would you please add {{#SBATCH -A mat240024}} in your script and try submitting your job again, and let us know if the issue persists? Warm regards, name ; Thank you! That fixed it. Best, name ; Awesome! Glad to know that. I'll go ahead and mark this ticket as resolved then. Please feel free to contact us again if you have any other questions. Thanks, name ;",cassingh@access-ci.org,Megan Cassingham,Ruyi Li,Purdue University,Anvil,6,2,11,2024,2024-03-11
ATS-1634,Method allowing Data Mine staff to see current student quotas on Anvil,2023-07-05,2024-03-21,"The Data Mine students will sometimes go over quota in /home on Anvil without realizing it. This can cause them significant headaches since they don't know what is wrong. There is not currently a way for TDM staff to see the current quota of a given student, which makes it harder for us to even help diagnose any problems they are having, or to proactively warn those that are over quota before they even come to us. We propose the following trivial solution. Run the following as root from cron on zfs.anvil: {{zfs userspace -p tank/home | grep -w -f <(getent group x-cis220051 | sed -e 's/^.\\*://; s/,//g') > /anvil/projects/tdm/log/tdmquotas}} It should just take a couple hundred milliseconds to complete so running it once every 5 minutes would have a negligible performance impact -- far less than a puppet run. The ""zfs userspace -p tank/home"" will output something like this (the output below was generated on a Statistics Dept. server): {{TYPE NAME USED QUOTA OBJUSED OBJQUOTAPOSIX User aabdulw 218577252704 322122547200 2428849 0POSIX User adewar 512 214748364800 1 0POSIX User aglu 310951568 214748364800 1999 0POSIX User agraw180 512 214748364800 1 0POSIX User ahn104 512 214748364800 1 0POSIX User antik015 434590000 214748364800 9533 0POSIX User aramaset 512 214748364800 1 0POSIX User arthur22 75623440 214748364800 1445 0POSIX User backup 33904944 0 333 0POSIX User bacraig 35464461040 214748364800 50825 0POSIX User bdavis 77180000 214748364800 1576 0}}... The ""{{grep -w -f <(getent group x-cis220051 | sed -e 's/^.\\*://; s/,//g')""}} restricts this output to only include members of group x-cis220051. Thus, you aren't leaking information about other groups on Anvil to TDM. The /anvil/projects/tdm/log directory is readable and writable by TDM staff only. Once this file is written via cron, we can write our own trivial scripts that parse this file, send email to those over quota, etc. The location where the output is written isn't terribly important. Ideally it would be somewhere in /anvil/projects (maybe /anvil/projects/rcacdata/tdm/tdmquotas?) or even in /tmp on zfs.anvil, but that requires an extra ssh when we view it. Thoughts? Do you have an alternate suggestion? Regards, Doug ; Hi Doug, Thanks for reaching out! I have brought your questions to our team, and we are in discussion. This question is also involved with engineer team and storage team. We would gather inputs from all teams and get back to you. Cheers, name, PhD Sr. Computational Scientist Purdue University ; Hi Doug, We had some discussions about this one, but the consensus was that it creates some unwanted risks as other groups/workshops may also want similar features. I think the easiest option is for the students to run ""myquota"" themselves or have a helper script that does some sanity checks like: am i over quota? do i have python packages in ~/.local? etc. At one point we used to email quota alerts to users and our ambitious goal would be to turn that on on Anvil. Best regards, name. ;",dgc,Doug Crabill,Amiya Maji,Purdue University,Anvil,3,187,27,2023,2023-07-03
ATS-2169,Cgroups virtual memory limits issue on Anvil front-ends,2023-08-07,2024-03-21,"The Anvil front-ends are currently configured so that users can use up to two CPU cores, 12GB RAM, and an unlimited amount of virtual memory. Allowing an unlimited amount of virtual memory is actually undesirable and could cause all manner of frustration for the users. If they were to run something that wants 18GB of RAM, it \\*\\*will\\*\\* run, but may swap furiously and run at a tiny fraction of normal speed. To verify, try to run the following, then check via top and vmstat to see that it caps at 12G of RAM and just pages furiously: stress -m 1 -t 30 --vm-bytes 150G Running this same thing on a back-end node with 10GB of RAM will fail immediately with an out of memory error the way it's supposed to. To give a real example of how this can be harmful to users, Dr. name was trying to run ""shuf"" on a file that was 18GB. It was still running after 30 minutes when he IM'ed me to discuss. He said it eventually finished but took over an hour to complete Regards, Doug ; That makes sense. Systemd will not read new limits until it is restarted. 😞 Regards, name. ; Doug, This should have been fixed during the last maintenance. Please let me know if that is not the case. Best regards, name. ;",dgc,Doug Crabill,Amiya Maji,Purdue University,Anvil,7,164,32,2023,2023-08-07
ATS-6216,Job submission,2024-02-15,2024-03-18,"Hi, recently, six of my jobs were cancelled due to a node failure error message. After some time, the cancelled jobs restarted without notifying me, but they failed again. This process has been occurring since yesterday. ; Hi Aashish, Thank you for reaching out. To help us investigate the issue, would you please share the IDs of those requeued jobs? Also, I wanted to mention that the job scheduler was having some problems last night. It should be fixed now. Thanks, name ; Hi name, The following jobs I got error. 4395094 x-abhatt mcb160119-gpu 0.4mV\\_pos\\_r3 2 16 2-00:00:00 PD 0:00 4407994 x-abhatt mcb160119-gpu 0.4mV\\_1bar\\_piezo 1 16 2-00:00:00 R 3:43:39 4408220 x-abhatt mcb160119-gpu new\\_conformation 1 1 2-00:00:00 R 3:43:38 4401654 x-abhatt mcb160119-gpu new\\_conformation 1 1 2-00:00:00 R \\*3:43:37\\* 4407266 x-abhatt mcb160119-gpu 0.4mV\\_neg\\_r3 1 16 2-00:00:00 R 3:43:37 4407920 x-abhatt mcb160119-gpu 0.5mV\\_pos\\_r3 1 16 2-00:00:00 R 3:43:37 4407927 x-abhatt mcb160119-gpu 0.5mV\\_neg\\_r3 1 16 2-00:00:00 R 3:43:37 4399404 x-abhatt mcb160119-gpu 0.5mV\\_rstsrt\\_r3 1 16 2-00:00:00 R 3:43:38 4401238 x-abhatt mcb160119-gpu new\\_conformation 1 1 2-00:00:00 R 3:43:38 4407263 x-abhatt mcb160119-gpu 0.5mV\\_pos\\_r3 1 16 2-00:00:00 R 3:43:38 4407988 x-abhatt mcb160119-gpu 0.4mV\\_1bar\\_piezo 1 16 2-00:00:00 R 3:43:38 4402105 x-abhatt mcb160119-gpu no\\_ten\\_conf 1 1 2-00:00:00 R 3:47:18 You can see that the job duration is 3 hours, 43 minutes, and 37 seconds, which implies it started in the morning. Regards, Aashish ---- ; Hi, Can you please check. my all the jobs are again reschedule 4402105 x-abhatt mcb160119-gpu no\\_ten\\_conf 1 1 2-00:00:00 R 33:50 4399404 x-abhatt mcb160119-gpu 0.5mV\\_rstsrt\\_r3 1 16 2-00:00:00 R 33:45 4401238 x-abhatt mcb160119-gpu new\\_conformation 1 1 2-00:00:00 R 33:45 4407920 x-abhatt mcb160119-gpu 0.5mV\\_pos\\_r3 1 16 2-00:00:00 R 33:45 4407927 x-abhatt mcb160119-gpu 0.5mV\\_neg\\_r3 1 16 2-00:00:00 R 33:45 4407988 x-abhatt mcb160119-gpu 0.4mV\\_1bar\\_piezo 1 16 2-00:00:00 R 33:45 4407994 x-abhatt mcb160119-gpu 0.4mV\\_1bar\\_piezo 1 16 2-00:00:00 R 33:45 4407263 x-abhatt mcb160119-gpu 0.5mV\\_pos\\_r3 1 16 2-00:00:00 R 33:46 4407266 x-abhatt mcb160119-gpu 0.4mV\\_neg\\_r3 1 16 2-00:00:00 R 33:46 4395094 x-abhatt mcb160119-gpu 0.4mV\\_pos\\_r3 2 16 2-00:00:00 R 33:49 4415792 x-abhatt mcb160119-gpu 2\\_6\\_piezo2 1 16 2-00:00:00 R 37:15 is there any problem with job scheduler? Regards, Aashish ---- ; Hi Aashish, Thank you for sharing the job IDs. The reason your jobs got requeued could possibly be related to the previous intermittent issues with the Slurm workload manager on Anvil, which should be fixed now. Would you please let me know if you still see similar issues over the last couple of days? Kind regards, name ; Hi name, Thank you for the email. I deleted all the running jobs and then re-ran them, and I'm not getting any errors. Thanks for the help. Regards, Aashish ---- ; Hi Aashish, Great! I'm glad to know that. I appreciate your feedback. BTW, if you do not want your jobs to get requeued under any circumstances, you could add the ""--no-requeue"" flag to your job script or command. I'm tentatively marking this ticket as resolved at this point. Please feel free to contact us again if you have any other questions. Thanks, name ; Hi name, Can you please check the job scheduler. Again, I am getting the same problem. My running job cancelled at re-run again. Thanks, Aashish ---- ; Hi Aashish, Apologies for the delayed response. I believe you should have received the notification about the partial outage on Anvil, regarding the periodic issues with Slurm around Feb. 25 ~ Feb. 27(https://www.rcac.purdue.edu/news/6400: https://www.rcac.purdue.edu/news/6400|smart-link). Our engineers have implemented a measure to keep Slurm up, and that should mitigate the issue. It looks like most of your recent jobs have been completed without being requeued. Would you please let me know if you have any further questions? Thanks, name ; Hi Aashish, I believe issues on this ticket have been addressed. Since I have not heard further questions from you in a while, I'm tentatively marking this ticket as resolved at this point. Please feel free to contact us again if you see any issues or need any help. Thanks, name ;",abhatt@access-ci.org,AASHISH BHATT,Ruyi Li,Purdue University,Anvil,10,23,7,2024,2024-02-12
ATS-6230,intel compiler on Anvil,2024-02-15,2024-03-18,"Hello, I am trying to run a LAMMPS executable that I compiled a while ago, which used intel/19.0.5.281 and impi/2019.5.281. I can confirm that the executable was working fine in October. But now, for some reason, the executable just ""hangs"" and nothing happens. Then, I thought to recompile the executable just in case but it seems mpicxx and mpiicpc can no longer find the mpi libs (error is: /usr/bin/ld: cannot find -lmpi). Perhaps a related issue? Not sure but any help would be appreciated. I need to recompile LAMMPS anyway to integrate the PLUMED plugin. ; Hi name, Apologies for the delayed response. To help us investigate, would you please share the exact steps you took to compile LAMMPS? Thanks, name ; Sure, In my previous compilation, I first did:id load intel/19.0.5.281 Module load impi/2019.5.281 Then, I prepared a custom makefile with these options: CC = mpiicpc -std=c++11 -diag-disable=10441 -diag-disable=2196 OPTFLAGS = -march=core-avx2 -O2 -fma -ftz -fomit-frame-pointer \ -fp-model fast=2 -no-prec-div -qoverride-limits \ -qopt-zmm-usage=high CCFLAGS = -qopenmp -qno-offload -ansi-alias -restrict \ -DLMP\\_INTEL\\_USELRT -DLMP\\_USE\\_MKL\\_RNG $(OPTFLAGS) \ -I$(MKLROOT)/include SHFLAGS = -fPIC DEPFLAGS = -M LINK = mpiicpc -std=c++11 -diag-disable=10441 -diag-disable=2196 LINKFLAGS = -qopenmp $(OPTFLAGS) -L$(MKLROOT)/lib/intel64/ LIB = -ltbbmalloc -lmkl\\_intel\\_ilp64 -lmkl\\_sequential -lmkl\\_core SIZE = size ARCHIVE = ar ARFLAGS = -rc SHLIBFLAGS = -shared Then I compiled via make. Independent of my previous compilation, I tried to compile PLUMED first (which I need to do before compiling lammps, which I planned to do via cmake this time) and ran into the issue I mentioned with the lmpi library not being found. All I did was load in the same two modules (intel and impi) then first checked mpicxx and mpiicpc: mpiicpc -h mpicxx -h Error: /usr/bin/ld: cannot find -lmpi And when I try to run the configure script for PLUMED, it hangs at the check for mpi compatibility. Thanks, name ; Hi name, Thanks for sharing more details. I've escalated your ticket to our experts. They would take a look and contact you later. Warm regards, name ; Hello, I am checking in about this ticket since I haven't heard back yet. Thanks, name ; Hello, I would appreciate a status update. I am not sure if this ticket has been properly assigned since it was escalated back on Feb 19th (two weeks ago). Thank you, name ; Hi name, It was nice to talk to you on Thursday via Anvil Support Hour. And I am glad the problem was resolved. I would mark this ticket as resolved. Thanks for contacting us! Regards, name, PhD (She/Her/Hers) Sr. Computational Scientist ;",apak@access-ci.org,Alex Pak,Amiya Maji,,Anvil,7,23,7,2024,2024-02-12
ATS-6393,My issue for submitting new job,2024-02-23,2024-03-21,"Hello, I hope this note finds you well. Recently, whenever I submit a new job on the Anvil Cluster, my simulations seem to halt after a certain period of time. Afterwards, despite time passing, the simulations don't progress, and there's no advancement in the computing process. Additionally, I've noticed an error appearing in the final lines of the attached file, even before my run begins, in my new jobs too. I suspect this could be due to the limited space in the cluster, necessitating the removal of some files to free up space for the run, but I am not sure. I would greatly appreciate it if you could assess my situation and provide guidance accordingly. I've been facing numerous issues over the past week, and resolving this would be immensely helpful. I appreciate your help and your time. Best regards, Javad Omidi ; ^slurm-4446902.out ; Hi, Thank you for contacting us. Sorry but there have been issues with Anvil SLURM during the weekend but it should have been fixed now. Could you give it another try and see if it's working for you now? Best regards, name Senior Computational Scientist Purdue Information Technology ; Hello, Thank you very much for your reply. Unfortunately, it is as before, and I could not submit any jobs to the cluster with the error you can see in the attached file. I would be thankful if you could resolve my issue. I really appreciate your help and your efforts. Best regards, Javad Omidi ^slurm-4473124.out \\_(0.0 kB)\\_ ; Hello, In continuation of my today reply, I found right now that if I free up the space, my run will go. I think my problem is related to the limited space I have for saving on clusters. Please confirm it! Could you please let me know the space limitation I have for saving on a cluster? I appreciate your help and efforts. Best regards, Javad Omidi ; Hi, Yes, ""Disk quota exceeded"" means your folder is over quota. You could use command {{myquota}} to check your quota and current usage (note: there are limits for both file size and file number). The job submission on Anvil should be back to normal right now. Please try again. name ; Hi, Thank you very much for your support. Please just let me know how much space I have. I mean, how many GB Disk quota I have that I cannot exceed? And how can I check the used space? I am using MobaXterm. I really appreciate your help. Best regards, Javad Omidi ; Hi, You can open a terminal after connected to Anvil and run command {{myquota}} will give you an overview of your disk quota and usage. Here is what I just got for your account fyi. Type Location Size Limit Use Files Limit Use ============================================================================== home x-jomidi 1.8GB 25.0GB 7% - - - scratch anvil 0KB 100.0TB 0% 0k 1,000k 0.00% projects x-chm230034 1.2TB 5.0TB 26% 619k 1,048k 59% name ; Hi, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name ;",jomidi@access-ci.org,Javad Omidi,Guangzhen Jin,Purdue University,Anvil,9,20,8,2024,2024-02-19
ATS-6407,Access to multiple highmem nodes on Anvil,2024-02-23,2024-03-21,"Hello Anvil support. I am running very large and highly memory-intensive jobs, which run best on the highmem partition of Anvil. I notice that that partition is currently under-utilized (30 idle nodes). I am curious if I could get access to 16 of these nodes for three weeks to run some very large fluid dynamics simulations. This would be very helpful for my work. I appreciate your time and consideration. Brendan Christensen ; Hi, Thank you for contacting us and sorry for the delay. Looks like you have actually been added to a QOS {{wide-highmem}} which will allow you to request as much as 16 nodes from {{highmem}} partition. In order to use this QOS, you just need to add {{-q wide-highmem}} into any or your slurm options. Give it a try and let me know how it works for you. Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi name, Thank you so much for getting back to me. I just started a simulation and it seems to be working well. I just want to confirm. The max time limit on this partition is 2 days per run, is that correct? Thank you again for working with me. Brendan ---- ; Yes. That's correct. Here is a command you can use to check this QOS limit: $ sacctmgr show qos wide-highmem format=Name%20,GrpSubmit,MaxTRES%20,MaxTRESPerNode%20,MaxWall,MaxTRESPU,MaxJobsPU,MaxSubmitPU,MaxTRESPA,MinTRES Name GrpSubmit MaxTRES MaxTRESPerNode MaxWall MaxTRESPU MaxJobsPU MaxSubmitPU MaxTRESPA MinTRES ; wide-highmem cpu=2048,node=16 2-00:00:00 cpu=2048,nod+ 16 32 name ;",bchristensen@access-ci.org,Brendan Christensen,Guangzhen Jin,Purdue University,Anvil,4,20,8,2024,2024-02-19
ATS-6427,Getting sbatch: error: Batch job submission failed: Invalid qos specification for SLURM job,2024-02-25,2024-03-21,"Trying to run the SLURM job: {{#!/bin/bash}} {{#FILENAME: Latitude\\_Longitude\\_Slurm\\_Job}} {{# Manage processing environment, load compilers and applications.}} {{module purge}} {{module use /anvil/projects/tdm/opt/core}} {{module load tdm}} {{module load python/sandia}} {{# Launch serial code}} {{cd $SLURM\\_SUBMIT\\_DIR}} {{python3 latitude\\_longitude.py}} with {{sbatch -t 6:00:00 --nodes=1 --ntasks=40 latitude\\_longitude\\_slurm\\_job}} gives the error sbatch: error: Batch job submission failed: Invalid qos specification. My name can run the slurm job without issue. ; Hi, Thank you for contacting us. There was an outage for Anvil and now it should be back. Could you give it another try? Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name ;",awadhwa@access-ci.org,Arnav Wadhwa,Guangzhen Jin,Purdue University,Anvil,3,19,8,2024,2024-02-19
ATS-6472,Compiled software does not run in Anvil cluster,2024-02-27,2024-03-21,"Hello, I use Anvil-Purdue cluster. I need to use Lammps and LESGO in the cluster. I have compiled them in the cluster. Lammps runs smoothly in the cluster. However, LESGO does not run in the cluster. It shows error like below: ""] check\\_exit\\_codes (../../../../../src/pm/i\\_hydra/libhydra/demux/hydra\\_demux\\_poll.c:114): unable to run proxy on a060.anvil.rcac.purdue.edu: http://a060.anvil.rcac.purdue.edu (pid 3575999) poll\\_for\\_event (../../../../../src/pm/i\\_hydra/libhydra/demux/hydra\\_demux\\_poll.c:152): check exit codes error HYD\\_dmx\\_poll\\_wait\\_for\\_proxy\\_event (../../../../../src/pm/i\\_hydra/libhydra/demux/hydra\\_demux\\_poll.c:205): poll for event error"" Additionally, I cannot access to anvil since last evening. I would be grateful to you if you help me regarding this. I have attached log and job script file as attachment. Thank you. ; ^job.slurm ^log.lesgo ; Hello ---- ^job (796ba5e1-15f6-4b71-8c58-e5fc9ca305ed).slurm \\_(0.0 kB)\\_ ^log (76a2fac7-31a7-44d0-a4a6-66caa9194d4f).lesgo \\_(0.0 kB)\\_ ; Hi Shuvo, Have you tried running with ""mpirun"" instead of ""srun""? Can you please check if ""mpirun"" gives the same error? How did you compile the application and what modules did you load? Regards, name. ; Hi, I have figured out the error. Thank you very much. ---- ; That's great news! Thanks for letting us know. Best regards, name. ;",ashuvo@access-ci.org,Abdul Aziz Shuvo,Amiya Maji,Purdue University,Anvil,7,18,9,2024,2024-02-26
ATS-6593,module command broken on several nodes since yesterday,2024-03-01,2024-03-21,"Happy Friday, Anvil sysadmin! I'm hoping you can fix or help me understand why yesterday I got module not found errors on 17 nodes a013,021,037-039,041-042,050,052-054,057-059,122-124]: cd /anvil/scratch/x-pnanda/ModelRuns/2024-02-27-B-gs-dendr-library # Command below shows module-related error: for i in {1..1000}; do dir=exp${i}/exp${i}-1; test -f $dir/runCompleted : | (test -f $dir/stdout-3 && grep -l error $dir/stdout-3); done | xargs head -n -0 2>/dev/null # Corresponding nodes producing that error: for i in {1..1000}; do dir=exp${i}/exp${i}-1; test -f $dir/runCompleted || (test -f $dir/stdout-3 && grep -q error $dir/stdout-3 && test -f slurm-4494663\\_$i.out && echo slurm-4494663\\_$i.out); done | xargs -n1 awk 'NR == 3' Additionally, several jobs failed to even submit due to NODE\\_FAIL and produced no SLURM output but I was charged hours for them: command sacct -o jobid%-14,jobname%-16,ncpus%5,state%-9,start,elapsed,nodelist%8 -X -S 2024-02-29 -E 2024-02-29T23:59:59 | grep -v COMPLETED cd /anvil/scratch/x-pnanda/ModelRuns/2024-02-27-B-gs-dendr-library # No output files even produced: command sacct -nPo jobid,state -X -S 2024-02-29 -E 2024-02-29T23:59:59 | grep -v COMPLETED | cut -d'|' -f 1 | xargs printf ""slurm-%s.out"" | xargs head -n -0 And this morning I'm having the same issue: # Module not found error: find exp\\*/exp\\*-1 -name 'stdout-\\*' -newermt 2024-03-01 | xargs grep error # Corresponding job array: find exp\\*/exp\\*-1 -name 'stdout-\\*' -newermt 2024-03-01 | xargs grep error | sed -E 's#^exp(0-9+).\\*/\\*#\1#' | xargs printf ""4498858\\_%s"" Please help, Pariksheet ; NB: There is a mistake in my last command because there isn't a 1:1 mapping with resubmitting the failed jobs. The nodes today on that are not loading the module are: {{a004,007,009,012}} cd /anvil/scratch/x-pnanda/ModelRuns/2024-02-27-B-gs-dendr-library grep -l ERROR slurm-4498858\\_\\*.out : xargs -n1 awk 'NR == 3 {print $6}' | sort | cut -d, -f1 | nodeset -f #> a[004,007,009,012 Pariksheet ; Hi, Thank you for contacting us. There have been some glitches for Anvil SLURM and I believe this issue should have been resolved. Can you doublecheck and see if you are still seeing the issue? Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi name, Thank you for your work addressing the glitches. Unfortunately, I do not have enough NSF ACCESS credit hours left (17k) in my current cycle to run simulations to re-test, because each simulation I now need to run needs about 40k compute hours. Please close the ticket. Pariksheet ; Got it. Thank you for the update. name ;",pnanda@access-ci.org,Pariksheet Nanda,Guangzhen Jin,Purdue University,Anvil,5,15,9,2024,2024-02-26
ATS-6826,Purdue Anvil CPU Service Units not reflecting on my Anvil account,2024-03-13,2024-03-18,"Greetings, My ACCESS allocation shows 8663 approved SUs on Purdue Anvil CPU and 559 approved SUs on Purdue Anvil GPU. When I log into the Anvil account, the balance summary shows the following: Allocation Type name Limit name Usage name Usage name Balance Account (account) (user) ============= ==== ========== ========== ========== ========== mat230078 CPU 80567.0 80591.7 80591.7 n/a mat230078-gpu GPU 3122.0 2787.0 2787.0 335.0 I need assistance figuring out why this discrepancy exists and how I get the approved units transferred to the HPC account. Regards, Prathamesh Deshpande ; Hello! Thanks for reaching out! I just checked your balance on Anvil and it is showing the below. Let me know if it does not look right to you. @login01.anvil:\~ $ mybalance x-pdeshpande Allocation Type name Limit name Usage name Usage name Balance Account (account) (user) ============= ==== ========== ========== ========== ========== mat230078 CPU 84568.0 81708.2 81708.2 2859.8 mat230078-gpu GPU 3122.0 2808.2 2808.2 313.8 Regards, name, PhD (She/Her/Hers) Sr. Computational Scientist ; It seems the issue was addressed. I can access the resource normally. Thank you. Best, Prathamesh ;",pdeshpande@access-ci.org,Prathamesh Deshpande,Nannan Shan,Purdue University,Anvil,3,4,11,2024,2024-03-11
ATS-6894,amber job error,2024-03-16,2024-03-22,"Hi, I am submitting job using amber and i got error: Lmod has detected the following error: These module(s) or extension(s) exist but cannot be loaded as requested: ""amber/20"" Try: ""module spider amber/20"" to see how to load the module(s). slurmstepd: error: execve(): /bin/pmemd.cuda: No such file or directory srun: error: g005: task 0: Exited with exit code 2 The path of directory is /anvil/projects/x-mcb160119/aashish/DLPC\\_DLPA\\_OPM/opm\\_popc\\_model/new\\_confirmation/1.replica\\_1 Earlier the script is working fine but after anvil maintains the same script got error. can you please help me for solving the error? Regards, Aashish ; Hello! Thanks for reaching out! Can you share your submit script or JOB ID for me to take a look at? Regards, name, PhD (She/Her/Hers) Sr. Computational Scientist ; Hello name, The job id is 4592021, path = /anvil/projects/x-mcb160119/aashish/DLPC\\_DLPA\\_OPM/opm\\_popc\\_model/new\\_confirmation/1.replica\\_1 Regards, Aashish ---- ; could you please update me about the error? ---- ; Hi Aashish, It turns out there is a glitch for Amber modules on Anvil. It should be fixed right now. Please let me know if you still see issues. Regards, name ;",abhatt@access-ci.org,AASHISH BHATT,Nannan Shan,Purdue University,Anvil,5,5,11,2024,2024-03-11
ATS-6926,Amber job run in anvil,2024-03-18,2024-03-19,"Hello, I am trying to run an amber molecular dynamics simulation with the submission script (attached). I performed the same job with the same script previously (only two days ago) but today after submitting the job its not running and showing a error message like: Lmod has detected the following error: These module(s) or extension(s) exist but cannot be loaded as requested: ""amber/20"" Try: ""module spider amber/20"" to see how to load the module(s). /var/spool/slurm/job4616283/slurm\\_script: line 37: pmemd.cuda: command not found I have attached both the script and the error messages for your reference. Please suggest us how we could solve the problem. Thank you. ; ^gpu-script-onejob.sub ^myjob.e4616283 ; Hi, Thank you for contacting us and reporting the issue. There has been a glitch for GPU amber but now it has been fixed. Can you double check? Best regards, name Senior Computational Scientist Purdue Information Technology ; Yes, it worked! Thank you. Best, Md Mehedi name ; Awesome. Thank you for the update. name ;",mhasan1@access-ci.org,MD MEHEDI HASAN,Guangzhen Jin,Purdue University,Anvil,5,2,12,2024,2024-03-18
ATS-6969,Nek5000 optimal compiler configuration,2024-03-20,2024-03-22,"Running a large case using Nek5000 solver, but moving slowly. Would like help investigating optimal compiler configuration to improve performance. Getting some warnings in log file, but case still runs. ; Hello! Thanks for reaching out! For performance question, I would highly recommend to run scaling tests for your own system because different simulating system might behave variously even running them on the same machine. There are many parameters affecting calculating performance, such as I/O speed, i.e. file system. For different compilers, I've heard applications with different compilers have slight difference when running calculations. Thus if you want to optimize your calculations, scaling tests with your own system would be an efficient way. Regards, name, PhD (She/Her/Hers) Sr. Computational Scientist ;",nziems@access-ci.org,Nathan Ziems,Nannan Shan,Purdue University,Anvil,2,3,12,2024,2024-03-18
ATS-6884,Using VASP on Anvil,2024-03-15,2024-03-28,"Hello, I am trying to run calculations using my own VASP build on Anvil and I think I'm running into memory errors. I am trying to run band structure calculations and have been calling 1024 cores across 8 nodes on wholenode. The calculation starts but never enters the first loop and does not spit out any errors after running for up to 20 minutes. Do you have any recommendations for how to avoid memory issues when using VASP by optimizing the resource used and the number of nodes+cores? Thanks, name ; Hi name, Thanks for reaching out I have also tried to use the VASP 6.3.0 build on Anvil with the modules below listed and it still seems to hit a wall in the band structure calculation. ; Based on VASP website, a bug in OpenMPI versions 4.0.4-4.1.1 causes a memory leak in some ScaLAPACK calls. This mainly affects long molecular-dynamics: https://www.vasp.at/wiki/index.php/Category:Molecular\\_dynamics runs. This issue is fixed as of openmpi-4.1.2. https://www.vasp.at/wiki/index.php/Toolchains: https://www.vasp.at/wiki/index.php/Toolchains|smart-link I have recompiled VASP5 and VASP6 with new version of openmpi (4.1.6) on Anvil. Thank you for the reminder about our user guide, I forgot to update our user guide about it. Please use openmpi/4.1.6 for VASP compilation, and I think the memory issue would be resolved. Regards, name ; It still seems like I'm hitting memory walls. Do you know if vasp\\_ncl was recompiled? That is what I am trying to use -name ; Are you using the modules on Anvil? If so, yes, vasp\\_ncl is compiled with new version of openmpi. Regards, name ; Hello! Since we did not hear from you, we are considering this ticket as resolved for now. However, if you still require assistance with this issue, please reply within the next 7 days and we will keep the ticket open. After that period, please feel free to reach out to us and create a new ticket at any time. Regards, name ;",cassingh@access-ci.org,Megan Cassingham,Nannan Shan,Purdue University,Anvil,7,10,11,2024,2024-03-11
ATS-6968,Queue length taking much longer than usual,2024-03-20,2024-03-25,"It looks like it is holding my jobs because of the amount of CPU time left in the allocation. I have tried to reduce the CPU time to less than what is left but that doesn't seem to be fixing the issue. I receive this: JobState=PENDING Reason=AssocGrpCPUMinutesLimit within the ""scontrol show job"" output. I thought the requested CPU time (run time in minutes \\* numCPUs) should be under what is available.: http://available.Am Am I calculating the time incorrectly (6 hrs \\* 60 name/hr \\* 64 CPU)? Current job number is 4650524. Thank you. ; Hi name, Thanks for reaching out! I just checked your job script for 4650524, it shows that your requested 8 nodes on {{wholenode}} partition, so the requested name would be about name = 8 (node) \\*128 (CPUs per node)\\*6 (hours)=6144. Because we charge 128 CPUs per node from {{wholenode}} partition. If this is not your intention, please use {{shared}} partition for your job, then the name would be calculated with the actual number of CPUs you requested for your job. Please check the user guide about how we compute the SUs. https://www.rcac.purdue.edu/knowledge/anvil/run/accounting: https://www.rcac.purdue.edu/knowledge/anvil/run/accounting|smart-link One more thing I'd like to mention is we should firstly cancel the current job pending on the queue, then change the submit script, then re-submit the job. SLURM won't pick up the new submit script for a job which is already submitted. Let me know if you have further questions. Regards, name, PhD (She/Her/Hers) Sr. Computational Scientist ; Hello, I cancelled and changed the script back to requesting the 128 CPUs which is what I would like to use. I am still receiving the same message for why the job is pending: AssocGrpCPUMinutesLimit. Could you let me know what this means (whether it is saying I have reached the CPU minutes limit)? Best, name ; Hello, It says you updated a comment but I'm not seeing any changes to what was in the last message. Best, name ; In your job 4650771, you requested 8 nodes (i.e. 1024 cores) for 6 hours, which is corresponding to 1024\\*6=6144 SUs, and your account ({{MCA06N030}}) only has 779 SUs. @login01.anvil:~$ jobscript 4650771 #!/bin/sh #SBATCH -A MCA06N030 #SBATCH -p wholenode #SBATCH --nodes=8 # The number of nodes to use. #SBATCH --ntasks=128 #SBATCH --time=6:00:00 #SBATCH --job-name jms\\_smaug\\_test # The job name. # load modules from arepo compile module restore Arepo # copy Enzo.exe file into ParameterFile srun ./Arepo param\\_2\\_07.txt >output\\_run\\_03\\_15\\_1 2>error\\_run\\_03\\_15\\_1 # End of script Your account balance, $ mybalance x-jsullivan1 Allocation Type name Limit name Usage name Usage name Balance Account (account) (user) ============= ==== ========== ========== ========== ========== ast140041 CPU 0.0 55109.2 9507.9 n/a ast140041-gpu GPU 1200.0 68.6 68.6 1131.4 mca06n030 CPU 1290750.0 1289970.9 74308.2 779.1 Regards, name ;",jsullivan1@access-ci.org,James Sullivan,Nannan Shan,Purdue University,Anvil,5,4,12,2024,2024-03-18
ATS-7021,request for interactive and dashboard time,2024-03-22,2024-03-25,"Hi, I've been requesting time on both the dashboard Rstudio scRNA-seq and separately on anvil scratch for short periods of time - between 1 and 2 hours at a time, and my requests don't seem to be going through like they used to. just hours of being in queue- this never happened to me before. anyways, if it's just busy, do you think there's an optimal time to work? thank you take care! ---- ; Thanks for the update. Yes it's totally possible. Always glad to help. name ;",rgarza@access-ci.org,Renee Garza,Guangzhen Jin,Purdue University,Anvil,4,2,12,2024,2024-03-18
ATS-7033,can't use any programs on anvil,2024-03-22,2024-03-28,"Every time I click on the data mine Jupyter lab it says 404 Bad Request Your browser sent a request that this server could not understand. Size of a request header field exceeds the server limit. ; Hello! Thanks for reaching out! I am wondering if you still see issues on Jupyter app on Anvil. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Hello! Since we did not hear from you, we are considering this ticket as resolved for now. However, if you still require assistance with this issue, please reply within the next 7 days and we will keep the ticket open. After that period, please feel free to reach out to us and create a new ticket at any time. Regards, name ;",awalkins@access-ci.org,Ashertova Walkins,Nannan Shan,Purdue University,Anvil,3,5,12,2024,2024-03-18
ATS-7054,Project Directory Extension Request,2024-03-25,2024-03-25,"We are approaching 90 days since the expiration of our allocation x-phy190025 on the Anvil cluster; however, we are submitting a renewal in the next week or two. We were wondering if we could extend the time before out project directory /anvil/projects/x-phy190025 is wiped. There's <500 GB of mostly just source and compiled code in there. We have the code and compile setting backed up, but extending the time before the project directory is wiped would allow us to immediately start running jobs when our allocation is renewed. ; Hello, I hope your Monday is going well. You can read how to submit an Extension here: ( https://allocations.access-ci.org/how-to: https://allocations.access-ci.org/how-to|smart-link ). Let us know if you have any questions along the way. If you have any questions in the future, please visit this site (https://access-ci.atlassian.net/servicedesk/customer/portal/2): https://access-ci.atlassian.net/servicedesk/customer/portal/2) and submit a ticket. name Pusateri ACCESS Allocations ;",goodwil9@access-ci.org,William Good,brandonp,Purdue University,Anvil,2,1,13,2024,2024-03-25
ATS-7060,Jobs stuck at completing state,2024-03-25,2024-03-26,"I have a few jobs (4662262, 4671247, 4677890) being stuck at ""completing"" state and continue to occupy compute nodes. I could not kill the jobs by scancel. # Could you please help ending the jobs? # Is there a way for me to end them in the future? # Do they continue to take up my allocation balance? Thanks very much for your help. Ken ; Hi, Thank you for contacting us. There were some issues with those jobs and some processes from the jobs became ""zombie processes"". Let me try to kill those processes with admin power. Regarding your questions: # Yes I will. # Most of time {{scancel}} will do the trick. Or you could try to land on the specific compute node with {{ssh xxx}}, run {{htop}}then kill the processes with typing {{k}}-> {{9}}-> press enter. # No they should not as the clock has been stopped. Let me know if you have further questions. Best regards, name Senior Computational Scientist Purdue Information Technology ; name, The node didn't allow me to ssh into it because the job was already at completing state. I will just ask you again next time. Thank you very much for cleaning up the processes! Ken ; OK. Thank you for the update. All jobs have been canceled now. Will resolve the ticket then. name ;",ktsui1@access-ci.org,Kenneth Tsui,Guangzhen Jin,Purdue University,Anvil,4,2,13,2024,2024-03-25
ATS-7081,The maximum number of file limits is not enough,2024-03-26,2024-03-29,"Type Location Size Limit Use Files Limit Use ============================================================================== home x-tsun4 6.1GB 25.0GB 24% - - - scratch anvil 2.7TB 100.0TB 3% 1,000k 1,000k 100% projects x-cis230279 117.4GB 5.0TB 2% 0k 1,048k 0.09% I have a large dataset (Imagenet) that contains around 15 million image files. If you have any other to access the Imagenet, please let me know. ; Hi Tingting, Thank you for reaching out. Would you please tell us more information about your work? Have you tried working with an aggregate file format, such as zip, tar, sqlite and etc? Warm regards, name ; Thank you for responding. We will try lmdb format first. ---- ; Hi Tingting, Thanks for your effort! That sounds like a good plan. I'm tentatively marking this ticket as resolved at this point. If you still need assistance, please feel free to reopen this ticket or submit a new one to us. Thanks, name ;",tsun4@access-ci.org,Tingting Sun,Ruyi Li,Purdue University,Anvil,5,4,13,2024,2024-03-25
ATS-7133,more files,2024-03-28,2024-03-29,"Hi Anvil support team, I previously requested more space, but the number of files didn't increase. I still have a limit of 5,242k files. Would it be possible to increase this to 1M files? I would like to have this many files accompanying the storage quota. Thanks, Wenliang ; Hi Wenliang, Thank you for reaching out. The default quota on one's scratch directory is 100TB and 1M files and it seems we have already increased yours to 500TB and 5M files. Please see: $ myquota x-wangwl Type Location Size Limit Use Files Limit Use ============================================================================== home x-wangwl 10.6GB 25.0GB 43% - - - scratch anvil 111.4TB 500.0TB 22% 3,409k 5,242k 65% projects x-mcb130189 25.5TB 50.0TB 51% 4,327k 10,485k 41% Thanks, name ; Thanks for the quick reply, name. Sorry, I get the number wrong, could you increase it to 10M files? I have a lot more files to write. Thanks, Wenliang ; Hi Wenliang, I see. I've escalated your ticket to our storage expert. For how long would you like to have the quota increased to 10M? Thanks, name ; Thanks, name. Greatly appreciate it. This will be very helpful to my research. I would like to match this file limit with my 500Tb storage deadline. I remember the deadline is April 30th, 2024. I don't know for how long I can have this new quota. But I definitely can't finish my project in one month. Could you extend this deadline for both file limits and size limits to Oct 30th, 2024 for now? Thanks, Wenliang ; Wenliang, Our storage expert has increased the quota of your scratch directory to 10M files. This along with the 500TB storage will be good until Oct. 30th, 2024. They will revert to the default 100TB and 1M after that time. Please be aware that inactive files in your scratch directory will be purged periodically (see https://www.rcac.purdue.edu/knowledge/anvil/storage/filesystems: https://www.rcac.purdue.edu/knowledge/anvil/storage/filesystems|smart-link), so you would need to have a good data management strategy in place to have your data backed up. I'm tentatively marking this ticket as resolved at this point. Thanks, name ;",wangwl@access-ci.org,Wenliang Wang,Ruyi Li,Purdue University,Anvil,6,2,13,2024,2024-03-25
ATS-7364, No email notifications on jobs,2024-04-09,2024-04-15,"Dear Anvil support team, I started not getting email notifications on my jobs on Anvil. My colleagues who are using the machine also experience the same issue. I always specify below in my job submission file, which should send me emails on job status: #SBATCH --mail-user=: mailto:--mail-user= #SBATCH--mail-type=all Could you help me how to solve the issue? Thanks, Saerom name ; Hi Saerom, Thank you for reaching out. We are aware of the issue and our engineers are investigating the issue. We'll let you know if there are any updates. Warm regards, name ; Hi Saerom, We appreciate your patience. The job emails should be working now. Would you please confirm that on your end? Thanks, name ; Hi name, Thanks for letting me know. I receive notification emails on my job. Thanks, Saerom ; Hi Saerom, No problem. Thanks for confirming! I'll go ahead and mark this ticket as resolved then. Thanks, name ;",stsr@access-ci.org,Saerom Yu,Ruyi Li,Purdue University,Anvil,5,5,15,2024,2024-04-08
ATS-5796,Adding library libpng to Anvil,2024-01-30,2024-04-02,"Hello, I need libpng to compile my C++ code but I can't find it on Anvil (I tried through module spider and I searched through the user guide). Perhaps I am missing something, but how can I add this library? Is there a library path I can add to my Makefile.in: http://Makefile.in or is it possible to make it available to my project somehow? Thank you, name ; Hi name, Thanks for reaching out! I am wondering which compilers or modules you have been used to compile your c++ code on Anvil? If you can more details about your workflow, it would be helpful. Regards, name, PhD (She/Her/Hers) Sr. Computational Scientist ; Hi Nannah, Thank you for replying. Apologies for not conveying this info in the first ticket. I am loading mod tree/cpu, which gives me the compiler gcc/11/2/0 and opempi/4.0.6 that I need to use as compiler and mpi, respectively. It also gives me zlib/1.2.11 which I need to compile my code. I also need libpng (this is the module I can't find; I would need version 1.2 or later). The error I get when I compile is that it can't link due to the absence of libpng (I've attached a log file and the Makefile.in) \\_PngImage.hpp:34:10: fatal error: png.h: No such file or directory\\_ \\_34 | #include\\_ \\_<\\_ \\_png.h\\_ \\_>\\_ \\_| ^~~~~~~\\_ \\_compilation terminated.\\_ Please let me know if you need further information. Thank you for your time and help, name On Feb 5, 2024, at 12:20 PM, ACCESS Ticket Submission wrote: ^logMakeSrc\\_2024-02-05-15-27 (39ba6d7c-d2c4-408a-ba96-e001ce9688a6) \\_(0.0 kB)\\_ ^logMakeSrc\\_2024-02-05-15-27 \\_(0.0 kB)\\_ ^Makefile (3b53e1a2-3bf4-46ae-adb5-89582ee000c2).in \\_(0.0 kB)\\_ ^Makefile.in \\_(0.0 kB)\\_ ; Hi name, Thanks for the information. I would pass this to our application scientists and ask help from them. We would share updates once we found something. Regards, name ; Hi name, Sorry for letting this email slip. libpng is available in this directory ""/apps/spack/anvil/apps/libpng/1.6.37-gcc-11.2.0-ndy5dug"". Please update it in your Makefile. We will also try to push this as a module. Best regards, name. ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id You can find out application/libraries from ""/apps/spack/anvil/apps"". Please keep it in your notes and submit new module requests in the application meeting agenda. ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id Thank you, name, for the note. I just marked this ticket as resolved, as we did not hear from user and probably this is resolved. ;",tferreira@access-ci.org,Tania Ferreira,Amiya Maji,Purdue University,Anvil,7,46,5,2024,2024-01-29
ATS-6656,extra running time,2024-03-05,2024-04-01,"Hi ACCESS support team, I previously asked for extra storage of my project, now I estimate my jobs of the same projects will run longer than 4days limit on Anvil. Could you extend my running time to 10 days if possible? Thanks, Wenliang ; Hi Wenliang, Thank you for reaching out. Would you please let us know more about your workflow? Is it possible for you to set up checkpointing, so that your job can resume running from where it stops? Warm regards, name ; Thanks for the quick reply, name. I'm currently running QTLtools to identify trans meQTLs, but I will also have some other analysis that needs more than 4 days. Some of the jobs are single process, not a pipeline, so it's impossible to set checkpoints. So I hope to extend the running time limit if possible. Thanks for your consideration. Wenliang ; Hi Wenliang, Thanks for the further information. Do you have an estimate of the number of your jobs that might need to run for about 10 days? Warm regards, name ; Thanks for the reply, name. I can't estimate the exact number right now, but I think I may have ~20K jobs that will need 10 days for the current project I'm working on. ; Hi Wenliang, Based on the information, I think to create a Slurm QOS with a walltime limit of 10 days might be a good way to facilitate your work. I'll follow up with you again when the QOS is created after tomorrow's maintenance. Thanks, name ; Hi Wenliang, I just noticed that you have two allocation accounts, {{mcb130189}} and {{mcb130189-gpu}}. Which one would you use for the long-running jobs? Thanks, name ; Mcb130189. Thanks. On name 13, 2024, at 1:07 PM, name wrote: mcb130189 ; Hi Wenliang, Thanks for your reply. I'm working on set the QOS up for you. Would you please let me know in which partition you will run your jobs using this QOS? Thanks, name ; Hi name, Thanks for following up on this. I will run them using the shared partition. Thanks, Wenliang On name 15, 2024, at 12:03 PM, ACCESS Ticket Submission wrote: ; Hi Wenliang, I've set up a QOS named {{wangwl-long}}, which will allow you to request up to 10 days for your jobs. You may use it with the option {{-q wangwl-long}} in your job submission script or command. I'll tweak it a bit to limit it to the {{shared}} partition next week. Thanks, name ; Thank you so much, name. I really appreciate it. ; Hi Wenliang, I wanted to let you know that my colleague has helped set the limit on the QOS ""wangwl-long"". For now, it can only be used in the ""shared"" partition. I'm tentatively marking this ticket as resolved at this point. Please feel free to contact us again if you have any questions or requests. Thanks, name ;",wangwl@access-ci.org,Wenliang Wang,Ruyi Li,Purdue University,Anvil,13,20,10,2024,2024-03-04
ATS-7085,Job Submission Failure (QOSMaxCpuPerJobLimit),2024-03-26,2024-04-01,"I attempted to submit a job with the following specifications: #SBATCH -A cis240192 #SBATCH --time 00:10:00 #SBATCH --job-name=test #SBATCH --nodes=2 #SBATCH --ntasks=256 #SBATCH --ntasks-per-node=128 The job submission failed with the following errors: sbatch: error: QOSMaxCpuPerJobLimit sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits) It appears that my job exceeded the maximum CPU or job size limits defined for my user account. I learned that the maximum number of CPUs per user is 640, but the total number of cpus requested by the job did not exceed this limit. I also found that job submissions that request more than one node always fail. Could you please provide some insight into the specific constraints that led to the error? Additionally, would it be possible to review and potentially adjust the limits set for my user account or the queue to ensure the successful submission of my job? ; Hi Xuan, Thank you for reaching out. If you do not explicitly specify a partition when submitting a job on Anvil, it will be directed to the ""shared"" partition by default. Please note that the maximum number of nodes a job in the ""shared"" partition can use is 1 (see the specifications of the partitions at https://www.rcac.purdue.edu/knowledge/anvil/run/partitions: https://www.rcac.purdue.edu/knowledge/anvil/run/partitions|smart-link). If more than 1 node is required, you may add the directive ""\\*#SBATCH -p wholenode\\*"" to your job script. Please give it a try and let me know if you still see any errors. Thanks, name ; Hi name, Thanks a lot For the quick response! I have no problems with job submission after adding ""#SBATCH -p wholenode"", but now I got tasks that are OOM killed. The error is like ""slurmstepd: error: Detected 1 oom\\_kill event in StepId=4697573.batch. Some of the step tasks have been OOM Killed"". I use the following directives: #SBATCH -A cis240192 #SBATCH --time 00:10:00 #SBATCH --job-name=test #SBATCH --partition=wholenode #SBATCH --mem-per-cpu=1024 #SBATCH --nodes=2 #SBATCH --ntasks=256 #SBATCH --ntasks-per-node=128 I can successfully run the same executable on an interactive computing node using 64 cores. It should require no more than 1GB of memery per cpu. I would be grateful if you can help me out with the new errors. Thanks, Xuan ---- ; Hi Xuan, Would you please try running your job with ""--nodes=2 --ntasks=128 --ntasks-per-node=64"" and check how it works? Thanks, name ; Hi name, I don't have any poblems now, thanks a lot for your help! Best, Xuan ---- ; Hi Xuan, Great! Thanks for letting me know! I'll go ahead and mark this ticket as resolved then. Warm regards, name ;",xwu7@access-ci.org,Xuan Wu,Ruyi Li,Purdue University,Anvil,6,5,13,2024,2024-03-25
ATS-7108,Past couple of weeks I am noticing so many compute node are down or drain,2024-03-27,2024-04-02,"I am working on project CIS220149 and utilizing the Anvil computer for my experiments. But for the past couple of weeks, I have noticed that so many compute nodes are down and draining, and due to this, I am having a very hard time completing all my experiments. ; Hello! Thanks for reaching out! At this moment, I saw 76 out of 1048 nodes (~7%) are offline on Anvil, which is not considered as an issue. I did not see any job is pending under your account as well. If you need help with submitting jobs on Anvil, let me know. $ squeue -u x-tpatel JOBID USER ACCOUNT NAME NODES CPUS TIME\\_LIMIT ST TIME Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ;",tpatel,Trupeshkumar Patel,Nannan Shan,Purdue University,Anvil,3,5,13,2024,2024-03-25
ATS-7264,Anvil - Job stuck in CG state and cannot be killed,2024-04-03,2024-04-04,"Dear Anvil Staff, After sending a scancel command to one of my jobs, it is now stuck in a CG state. This is likely due to me wiping the directory files before ensuring the job had fully completed and was removed from the queue. The job ID in question is ""4750969"" running under user ""x-jcappola"". It is affecting node ""a249"". Thank you, name ; The job seems to have finally cleared itself from the queue. This ticket can be closed. ; Hi name, Thanks for reaching out! Yeah, the job was cancelled. I will mark this ticket as resolved. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ;",jcappola,Jonathan Cappola,Nannan Shan,Purdue University,Anvil,3,2,14,2024,2024-04-01
ATS-6861,Running a job,2024-03-14,2024-04-16,"Two of my MD simulation jobs (Job IDs 4565454 and 4565455) terminated before completion without leaving any error messages. Could you please inform me what the problem was with the job? Also, I submitted two jobs (JOB ID: 4575835 and 4575833) in Anvil yesterday, but the jobs are still in pending status. Could you please let me know why this job is still in pending status? Thank you. ; Hi, Thank you for contacting us. I cannot see anything wrong except a failed status for jobs (4565454 and 4565455). The latest two jobs have completed after a long waiting time. That long wait is only because of gpu queue being busy. I would recommend the command {{showpartitions}} to check the current status for all partitions while submitting a job. If you can confirm you were using the same workflows for all jobs, I can go ahead and refund the SUs for previous failed two jobs (~10.5 SUs). Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi, Since we haven't heard feedback from you for some time, I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name ;",mhasan1@access-ci.org,MD MEHEDI HASAN,Guangzhen Jin,Purdue University,Anvil,3,24,11,2024,2024-03-11
ATS-6866,Job not running in anvil,2024-03-15,2024-04-15,"Hello, My students are trying to run jobs in Anvil for last few days, but none of them are running. I see that I have 18.5K remaining from 28K in Anvil GPU. Could you please let me know why the jobs are not running? Thank you. ; Hi, Thank you for contacting us. There is nothing wrong with the name balance for your allocation at the moment. Could you share the jobids for those jobs so I can take a closer look? Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name ;",shahidul@access-ci.org,Shahid Islam,Guangzhen Jin,Purdue University,Anvil,3,22,11,2024,2024-03-11
ATS-7140,Unable to submit jobs,2024-03-28,2024-04-15,"I use Purdue Anvil resources. When I submitted my job script, I got an error message: 'sbatch: error: Batch job submission failed: Invalid qos specification'. The command I sent was 'sbatch --nodes=1 --ntasks=1 -p wholenode jobfile'. The content of the script jobfile is #!/bin/bash # FILENAME: jobfile cd $SLURM\\_SUBMIT\\_DIR module load anaconda conda activate gdm python mip\\_solver.py The directory where I submitted my job is /home/x-cchen14/Manuf\\_Opt/manufacturing\\_opt\\_lib. I tried multiple similar sbatch commands, but nothing works. The information I got when I executed mybalance is Allocation Type name Limit name Usage name Usage name Balance Account (account) (user) ============= ==== ========== ========== ========== ========== cis240074 CPU 100.0 0.0 0.0 100.0 cis240074-gpu GPU 100.0 0.0 0.0 100.0 Please help me solve this problem. Thank you. Sincerely, name ; Hi, Thank you for contacting us. Please add your allocation into {{sbatch}} command as well. And also note {{wholenode}} partition will force the job to request for entire node (128 cores) and charge for the amount of SUs accordingly so if you would like 1 core ({{--ntasks=1}}), submit the job to {{shared}} partition. See more details in our user guide: https://www.rcac.purdue.edu/knowledge/anvil/run/partitions: https://www.rcac.purdue.edu/knowledge/anvil/run/partitions|smart-link So the job submission will look like {{sbatch --nodes=1 --ntasks=1 -p shared -A cis240074 jobfile}} Give it a try and let me know how it works for you. Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi name, Thanks for the help. It works. Sincerely, name ;",cchen14@access-ci.org,Chang-Lin Chen,Guangzhen Jin,Purdue University,Anvil,3,13,13,2024,2024-03-25
ATS-7348,Jobs not going through queue,2024-04-09,2024-04-15,"Hi, I just got back from maternity leave, and two jobs I had submitted to the queue were still in the queue when I got back two months later. Can you help me figure out why my jobs aren't going through the queue? ; Hi Madeleine, Thank you for contacting us. I took a look at your recently submitted jobs. It seems job 4311137 requested 2 whole nodes for 72 hours. Job 4346727 requested 5 whole nodes for 12 hours and job 4790219 requested 2 whole nodes for 72 hours. $ sacct -u x-myoungs -S 2024-03-01 -o jobid%-8,account,partition,reqnodes,timelimit,state JobID Account Partition ReqNodes Timelimit State -------- ; 4311137 oce160020 wholenode 2 3-00:00:00 CANCELLED+ 4346727 oce160020 wholenode 5 12:00:00 CANCELLED+ 4790219 oce160020 wholenode 2 3-00:00:00 PENDING They would need to get 18432 SUs, 7680 SUs and 18432 SUs reserved respectively in order to finish running. However, your allocation {{oce160020}} has 4914.8 SUs available only. So those jobs could not get started. $ mybalance x-myoungs Allocation Type name Limit name Usage name Usage name Balance Account (account) (user) ============= ==== ========== ========== ========== ========== ees230085 CPU 1250000.0 22203.6 0.0 1227796.4 oce160020 CPU 333333.0 328418.2 326665.3 4914.8 And that is why job 4790219 is pending because of ""AssocGrpCPUMinutesLimit"" (insufficient SUs). $ squeue -name x-myoungs Tue Apr 09 09:10:37 2024 JOBID PARTITION NAME USER STATE TIME TIME\\_LIMI NODES NODELIST(REASON) 4790219 wholenode llc270\\_f x-myoung PENDING 0:00 3-00:00:00 2 (AssocGrpCPUMinutesLimit) I hope this explains it for you. Please let me know if you have any further question. Thanks, name ; Hi Madeleine, Since I have not heard further questions from you in a while, I'm tentatively marking this ticket as resolved at this point. Please feel free to contact us again if you have any questions. Thanks, name ;",myoungs@access-ci.org,Madeleine Youngs,Ruyi Li,Purdue University,Anvil,3,5,15,2024,2024-04-08
ATS-7436,delete client user folders,2024-04-12,2024-04-15,"We recently conducted and finished a cryo-EM data processing workshop where I added 10 external users to ACCESS and Anvil. We set up a temp folder for them at this location \\*/anvil/projects/Workshop-users\\*/ which we would like to delete now. Since other users have created the folders nested under the \\*Workshop-users\\* folder, I don't have permission to delete it. Can you delete the entire \\*Workshop-users\\* folder or let me know how to change the folder permissions to be able to delete it myself? I am running out of allowed. Best regards, Nash ; Hi, Thank you for contacting us. The entire {{./Workshop-users}} folder has been removed per request. Best regards, name Senior Computational Scientist Purdue Information Technology ;",nbogdanovi,Nebojsa Bogdanovic,Guangzhen Jin,Purdue University,Anvil,2,2,15,2024,2024-04-08
ATS-7497,coffee hour consultations slot,2024-04-15,2024-04-16,"Hi, I want to schedule RCAC coffee hour consultation slot this week. I cannot login and bool the calender. Please help me. ; Hi Gundeep, Thanks for reaching out! RCAC coffee hour is designed to be open to people at Purdue campus consulting the questions related to Purdue community clusters (not include Anvil), that's why it requires Purdue credentials to login. If you want a consultation meeting, you are welcome to register our Anvil Support Hour at https://www.rcac.purdue.edu/anvil/anvil-support-hour: https://www.rcac.purdue.edu/anvil/anvil-support-hour|smart-link , which is for Anvil users. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; thank you ;",gkaur2@access-ci.org,Gundeep Kaur,Nannan Shan,Purdue University,Anvil,3,2,16,2024,2024-04-15
ATS-7544,running error at Anvil Purdue,2024-04-16,2024-04-18,"Hi, I am running Pytorch codes on Anivil and suddenly received the error message as below. Lmod has detected the following error: Error in script ""/apps/spack/anvil/external/apps/conda/2024.02/etc/profile.d/conda.sh"": /usr/local/bin/bash: /apps/spack/anvil/external/apps/conda/2024.02/etc/profile.d/conda.sh: No such file or directory While processing the following module(s): Module fullname Module Filename ; anaconda/2024.02-py311 /opt/spack/cpu/Core/anaconda/2024.02-py311.lua /var/spool/slurm/job4848895/slurm\\_script: line 15: python: command not found The script is as follows and it runs well until this afternoon. # I would mark this ticket as resolved. Regards, name ;",zfeng2@access-ci.org,Zhigang Feng,Nannan Shan,Purdue University,Anvil,4,3,16,2024,2024-04-15
ATS-7545,Issue loading a module,2024-04-17,2024-04-18,"Hi support team, it seems like there is an issue loading anaconda on anvil. Please see below. :jobQuality $ module load anaconda Lmod has detected the following error: Error in script ""/apps/spack/anvil/external/apps/conda/2024.02/etc/profile.d/conda.sh"": /usr/local/bin/bash: /apps/spack/anvil/external/apps/conda/2024.02/etc/profile.d/conda.sh: No such file or directory While processing the following module(s): Module fullname Module Filename ; anaconda/2024.02-py311 /opt/spack/cpu/Core/anaconda/2024.02-py311.lua ; Hi Strahinja, Thanks for reaching out and reporting this to us. I think it is fixed now. Please try it again and let me know if you see any issues. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Hi name, Yes, its fixed now. Thanks Regards, name ;",trecakov@access-ci.org,Strahinja Trecakov,Nannan Shan,Purdue University,Anvil,4,2,16,2024,2024-04-15
ATS-7554,Error when loading modules,2024-04-17,2024-04-18,"During normal use yesterday, attempting to load modules, such as anaconda, suddenly began returning the following error. Around the same time, my account reached the file number limit. Since then I have deleted files to get back below the limit but the module load error persists. Lmod has detected the following error: Error in script ""/apps/spack/anvil/external/apps/conda/2024.02/etc/profile.d/conda.sh"": /usr/local/bin/bash: /apps/spack/anvil/external/apps/conda/2024.02/etc/profile.d/conda.sh: No such file or directory While processing the following module(s): Module fullname Module Filename ; anaconda/2024.02-py311 /opt/spack/cpu/Core/anaconda/2024.02-py311.lua ; Hi name, Thanks for reaching out and reporting this to us. I think it is fixed now. Please try it again and let me know if you see any issues. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Hi Dr. name, The issue appears to be fixed, thank you very much name ;",cspitler@access-ci.org,Christopher Spitler,Nannan Shan,Purdue University,Anvil,4,2,16,2024,2024-04-15
ATS-7556,Open Fabrics Error when running NEK5000,2024-04-17,2024-04-18,"I am getting compiler warnings when running the Nek5000 code on the Anvil Cluster. I am also getting another warning, seen below the Openfabrics warnings. The simulation is running at a quarter of the speed I expect, based on past experiences with other clusters. I opened a ticket for this 2 weeks ago, and have not gotten a response, so I have opened a new ticket here. For reference, a JOBID for a job getting these errors is 4848037 Below is a sample of the warning I am receiving. ---- WARNING: There was an error initializing an OpenFabrics device. h2. Local host: a442 Local device: mlx5\\_0 a421.anvil.rcac.purdue.edu:1769655] common\\_ucx.c:364 Warning: UCX is unable to handle VM\\_UNMAP event. This may cause performance degradation or data corruption. Pls try adding --mca opal\\_common\\_ucx\\_opal\\_mem\\_hooks 1 to mpirun/oshrun command line to resolve this issue. This is the jobscript I am using: #!/bin/bash -l #SBATCH --nodes=16 #SBATCH --ntasks-per-node=128 #SBATCH --time=24:00:00 #SBATCH --export=NONE #SBATCH [--mail-user=: mailto:--mail-user= #SBATCH --mail-type=ALL #SBATCH -e error\\_file\\_%j.e #SBATCH -o logfilei #SBATCH -A PHY240099 #SBATCH -p wholenode module purge module load intel/19.1.3.304 module load openmpi module load cmake module list srun -n $SLURM\\_NTASKS ./nek5000 > logfile 2>&1 ; Hi name, Thanks for reaching out! Job 4848037 status shows this job is completed. Sounds like you are concerned about calculation efficiencies. Have you run benchmarking/scaling tests for your model on Anvil? Using many cores does not always mean faster/better performance. We highly recommend to run scaling test to find out the optimal numbers of cores for your case. The scaling tests can be very quick, we can pick the structures and run a few iterations with different number of cores (for example, 16 cores, 32 cores, 64 cores, 128 cores, 256 cores …). We do not need to do many, 4 or 5 calculations should be good. Then we record the time used for each calculation. You would find that the calculation will not become 'twice' quickly as we double the numbers every time because sometimes it will take long time for I/O not for computing. You can calculate the efficiency according to the tests with different numbers of cores, and chose one for the system. Regards, name, PhD (She/Her) Senior Computational Scientist Purdue University ;",nziems@access-ci.org,Nathan Ziems,Nannan Shan,Purdue University,Anvil,2,2,16,2024,2024-04-15
ATS-2385,Kubernetes pods fail to start,2023-08-17,2024-04-23,"The init container for my kubernetes pod on Anvil fails to start. The container image has not been changed since a successful start up a couple of hours ago. ; Hi Steve, I saw you had multiple pods trying to access the same persistent volume. The PVs you created had the ReadWriteOnce access mode, which does not work well with multiple pods. I changed them to be ReadWriteMany. You might try to restart your toolsession pods to see if it works now. -name ; I am now able to redeply the toolsession workflow. The nanohub-home and nanohub-apps PVC still show up as ReadWriteOnce. My impression is that I cannot change the accessMode. To do so I will have recreate the PVC and reload the data. ; Marking resolved. ;",clarks,Steven Clark,Erik Gough,Purdue University,Anvil,5,179,33,2023,2023-08-14
ATS-1865,PURDUE-Anvil can't resolve host name fermifactory02.fnal.gov,2023-07-17,2024-04-22,"Our jobs had been running successfully at PURDUE-Anvil for about a week since we got our new allocation in July and then they started failing. The error was that the jobs could not resolve the hostname fermifactory02.fnal.gov: http://fermifactory02.fnal.gov, which is our remote batch submission host which our jobs call back to get all their information from. There was already a ticket ATS-299 in which we had reported some issues reading our data from the remote site at Fermilab but it got worse now. We suspect some network connection issue between the worker nodes and the outside world is responsible. From the anvil login node we can resolve fermifactory02.fnal.gov: http://fermifactory02.fnal.gov just fine. Please investigate name Timm ; Hi name, Our networking department identified the cause of this issue and outgoing connections from Anvil are stable now. Let me know if you see any improvement on your side. Thanks! -name ; Hi Yes we are seeing glidein jobs run correctly on Anvil again.. thank you very much. Steve Timm ---- ; Hi name, Since the issue has been fixed, we'll close out this ticket then. Thanks, name ;",stimm,Steven Timm,Erik Gough,Purdue University,Anvil,4,201,29,2023,2023-07-17
ATS-3540,Purdue Data Mine Storage Request,2023-10-05,2024-04-22,"Hello RCAC Team, Doug and I were talking and we wanted to see if we could request an additional 5 TB for the cis-220051 Data Mine allocation. We've been working to monitor and clean up our allocation, but as the projects continue we think we are probably going to get close to our current limit. If this should be submitted as a supplement please let me know. I checked that interface, but I could only find options for additional credits. Thank you, name (he/him) ; Hello, I hope your Thursday is going well. If you need additional ACCESS Credits, please submit a Supplement. You can read about Supplements here: (https://allocations.access-ci.org/manage-allocations-overview#supplements).: https://allocations.access-ci.org/manage-allocations-overview#supplements).|smart-link Once you have ACCESS Credits, please submit an Exchange Request to exchange your ACCESS Credits for time on resources. You can read about Exchange Request here: (https://allocations.access-ci.org/manage-allocations-overview#exchanges-and-transfers).: https://allocations.access-ci.org/manage-allocations-overview#exchanges-and-transfers).|smart-link Let us know if you have any questions along the way. If you have any questions in the future, please visit this site (https://access-ci.atlassian.net/servicedesk/customer/portal/2): https://access-ci.atlassian.net/servicedesk/customer/portal/2) and submit a ticket. name Pusateri ACCESS Allocations ; Hi name, Thanks for the update Have a great day! name (he/him) The Data Mine - Managing Director of Data Science Schedule a meeting with me via Calendly: https://calendly.com/dglass-tdm/30min \\* \\*From:\\*\\* name (RCAC) \\*Date:\\* Thursday, October 5, 2023 at 5:35 PM \\*To:\\* name \\*Subject:\\* ATS-3540 Purdue Data Mine Storage Request | ---- \\*External Email\\*: Use caution with attachments, links, or sharing data ---- | —-—-—-— Reply above this line. name (RCAC) commented: name, Please check now. You should be up to 20TB. Thanks, name View request: https://access-ci.atlassian.net/servicedesk/customer/portal/2/ATS-3540?sda\\_source=notification-email · Turn off this request's notifications: https://access-ci.atlassian.net/servicedesk/customer/portal/2/ATS-3540/unsubscribe?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ0Z3QiOiJhbm9ueW1vdXMtbGluayIsInFzaCI6ImRkMzQzMzNlMTI4Njk0ZDkzZTE0NzNjMmUxOGVhOWFjOWI2NTI4NzUwNmQxZDE0Nzk2OGFhN2YzNDc5YjZkOTEiLCJpc3MiOiJzZXJ2aWNlZGVzay1qd3QtdG9rZW4taXNzdWVyIiwiY29udGV4dCI6eyJ1c2VyIjoicW06YjkxYzliMTctNjYwZi00YTUzLWE2N2EtNTAwMzYxMDZmNTlhOjExNTFmMzk1LWYyODAtNGIwMi04NjJiLWFhY2MwNjMxZTNiMyIsImlzc3VlIjoiQVRTLTM1NDAifSwiZXhwIjoxNjk4OTYwOTIyLCJpYXQiOjE2OTY1NDE3MjJ9.KaZDSCzVmww8PZEmBUIN6TyjBp84jOEtcSFTDDNCQFU This is shared with name and Doug name. Sent on October 5, 2023 4:35:22 PM CDT ; Hi name, We believe the request in this ticket has been fulfilled and the output of {{myquota}} on your end should be corrected. We are closing this ticket out. Thanks, name ;",dgi804,David Glass,Eric Adams (RCAC),Purdue University,Anvil,8,143,40,2023,2023-10-02
ATS-4316,Anvil Kubernetes - Any way to get same storage volume on multiple namespaces?,2023-11-08,2024-04-23,"On Anvil Kubernetes we have two deployments (a web portal our student is developing and managing in Rancher manually, and a JupyterHub that has been deployed with helm). We would like for them to share the same storage volume to facilitate users uploading data from the client app (Jupyter) to the publishing endpoint (student's portal)... BUT we put them in different namespaces (geoedf and geoedf-jupyter). Each deployment has several components, and we would like to keep them separated in different namespaces if possible for easier organization and managing of the two. Is there a way to get the same storage available across both namespaces? Normally, we know a PVC can only reside in one namespace, but perhaps there is some sort of kubernetes YAML magic an admin can spin that can create another PVC in the other namespace referencing the same underlying location in Anvil storage? The volume in question we would like to hop across namespaces is geoedf-staging that is currently in the geoedf namespace. It was created from the storage class that allows it to be mounted by multiple pods, before we realized the namespace boundary would be an issue. Our other options are to dump them into the same namespace or investigate some sort of internal mounting within the pod through an exposed service like sshfs or nfs; but we were hoping there would be a magic kubernetes way to do it on the underlying storage path outside the pods and without having to change our system design. Thanks for any insight. ; Hi name, Thanks for reaching out! I have passed your questions to our scientist. You would hear from us later. Thanks for your patience. Regards, name, PhD (She/Her) Sr. Computational Scientist ; Hi name, Unfortunately PVCs are namespace scoped so there is no way around your current issue, even with admin magic. Your idea about running an NFS pod would work. Attach the PVC to an NFS server pod, then you would be able to connect to that NFS server from multiple namespaces. -name ; Marking resolved. ;",thompscs@access-ci.org,Christopher Thompson,Erik Gough,Purdue University,Anvil,4,120,45,2023,2023-11-06
ATS-6022,cpu-per-task,2024-02-08,2024-04-26,"I have been setting cpus-per-task=20 when I submit jobs. The jobs start at 20, but after a minute, the CPUs jumps to 40 or 80 depending on the job. Why is this happening? Am I being charged more for this? Thanks ; !WhatsApp Image 2024-02-08 at 13.41.28.jpeg|thumbnail! ; Hello Bianca, The reason for this is the size of your memory request within the job. Anvil compute nodes have 128 cores and 256 GB of memory, and so memory and cores are allocated proportional to one another. After all, if you are using 3/5 of the memory on the node and only 20 cores, it prevents others from using the remaining cores because there is not enough memory for them to do their work. You are allocated a little less than 2 GB of memory per core you request and the opposite is also true (1 core per 2 GB of memory). The reason it is not exactly 2 GB is because we have to reserve a little memory for the operating system. You are charged for these cores, so try to get a good idea of what your memory requirements are so you can tailor your memory request to just slightly above your needs. Kind regards, name ; Hello Bianca, Because we haven't heard back, I am going to go ahead and mark this ticket as resolved. If you have any further questions, please feel free to open a new ticket. Kind regards, name ;",bchampenois@access-ci.org,Bianca Champenois,rderue,I do not know the RP,Anvil,4,57,6,2024,2024-02-05
ATS-6475,Time reservation and allocation,2024-02-27,2024-04-22,"This is an attempt to reopen the https://access-ci.atlassian.net/browse/ATS-5850: https://access-ci.atlassian.net/browse/ATS-5850|smart-link ticket I have answered the questions below. Please let me know how we can move forward. I appreciate your support. ACCESS team: ""We are trying to figure out an approach that might best fit your needs. Would you please share more information about your workshop? How many users will be participating? What kind of GPU jobs do you plan to run? How much GPU memory will be required? How much data is going to be used?"" Nash (me): \\*There will be 10 participants during 3 full days. \\*We will also need access for two instructors, myself and another person. \\*We will run Relion and CryoSparc on GPU via Open Ondemand. \\*we will need 10-15 TB of scratch space \\*I will assign 10 users to my ACCESS project \\*each user +2 instructors will need 1 GPU=12 GPUs=3 full nodes reserved \\*Workshop dates are 27-29 March, 2024. Could you please let me know if we can work this out? It would be a tremendous help to our educational efforts. I look forward to hearing from you. Best regards, Nebojša Bogdanović, Ph.D. ; Hi Nash, Thank you for the information. We had a discussion about your request. Since our GPU nodes are quite oversubscribed at the moment, we would not be able to provide a reservation for your workshop. Sorry about that. We would suggest you consider NCSA Delta. We are tentatively marking this ticket as resolved at this point. Please feel free to contact us again if you have any other questions. Sincerely, name ; Hello name, Thank you and the team for making efforts to help us organize this. We know it is not an easy task. On the other hand, we will try to login several users through our project as intended and see what is available.. On the other hand, NCSA Delta does not have Relion and Cryosparc installed so that creates further complications in this case... Thank you once again. Best regards ---- ; Hello again name, Is there any other way we could hold resource reservations other than via the standard project access? We as a SECM4 center would probably be able to assign some funds for the resource allocation. I am not sure whether your center does support such arrangements, but we would be glad to explore that possibility. Please let me know if there is a way. Best regards ---- ; Hi Nash, I talked to our PI about your request. We are wondering if there is any flexibility in your workshop. Would you be able to use 12 GPUs on a single day and then reduce usage? Considering the obstacles you are facing, we might try reserving 8 GPUs for you for 3 days, or 12 GPUs for 1 day and fewer GPUs on the other days of your workshop. Thanks, name ; Hi name, Thank you so much for the proactive approach. We appreciate it very much. Since the workshop will run for 3 days, it would be better if we could have 8 GPUs for 3 days. It would be a tremendous help. Kindly let me know what you and your team have decided, and we will try to secure the rest of the resources on local machines (less efficient) or probably another ACCESS resource. Given such a short period before the WS starts, we would probably have difficulties getting Cryosparc and Relion to work on those remote resources. I am very much looking forward to hearing from you, and again, we really appreciate it. Best regards, Nash ---- ; Hi Nash, Thanks for your reply. We are working on creating a reservation of 8 GPUs from 6am 27 March to 6pm 29 March for you. We plan to tie the reservation to allocation {{see230013-gpu}}. Is it okay with you if all jobs during that period use the reservation automatically? Thanks, name ; Hi name, That is great news, thank you very much. Yes, it is ok for all the jobs to run on see230013-gpu. We will have 10 people who I will have to secure ACCESS IDs and I will assign them onto my project see230013. In that way, they should be automatically getting mails with their Anvil user credentials? If user stuff is out of scope of this thread, just let me know. Looking forward to hearing from you. You and your team are very helpful. We appreciate it a great deal. Best regards, Nash ---- ; Hi Nash, I wanted to let you know that our experts have set up a reservation of 2 GPU nodes for allocation {{see230013-gpu}} from 03/27/2024 6:00 EDT to 03/29/2024 18:00 EDT. Any jobs submitted with {{see230013-gpu}} during that time will be included in the reservation. If you want to have the start and end times tweaked, such as for testing beforehand or for users to finish up afterwards, please let us know. It might get harder for us to do so as we get close to the reservation time. Thanks, name ; Hello name, This is great help indeed. We are very much looking forward to working with users and show them around Anvil's cryosparc/relion. It would be great if we can have an extra dayor two before and after the workshop which would be +March 26th and +March 30th and 31st. We do undertand that it would be good for the users to have some leeway time to try few things after the workshop during that weekend. We completely understand if that is not possible. Quick question: Does the reservation limit all the activities on x-see230013 project on 2 nodes? If other nodes are free, would we be able to login to them or we can only use max 8 gpu? We have 10 participants plus me as an instructor so I should be able to login and oversee them. If it is limited, I will try to pull participans to batches of 2 or alternatively try to secure another 2-3 GPUs somewhere. Looking forward to hearing from you. Best, Nash ---- ; Hi Nash, Since the workshop is going to run cryosparc/relion jobs via the Open OnDemand gateway, there will be no way for you to use the "" --reservation=XXX"" option to specify a reservation for your jobs. Therefore, our experts got the reservation set up with flag {{magnetic}}. That way, all jobs submitted using the {{see230013-gpu}} allocation during that time will be included in the reservation automatically. It also means that they can simultaneously use 8 GPUs at most. If you are going to submit jobs via ThinLinc or ssh terminal sessions, then the ""magnetic"" flag is not needed and you can submit jobs with or without specifying the reservation name, which will allow you to use idle GPUs (if there is any) outside the reservation. I hope this answers your question. Regarding extra time for the reservation, I would talk to our managers and get back to you later. Thanks, name ; Hi Nash, We have added more time for you. The reservation will start on March 26th at 8:00 am and end on March 29th at 6:00 pm. If the participants want to try things after the workshop, they still can submit jobs, but just without a reservation. Thanks, name ; Hi Nash, Hope your workshop is going well. We just noticed that allocation {{see230013-gpu}} is concurrently using 14 GPUs. It seems the reservation does not enforce a restriction on the total number of nodes that can be used. In order to ensure fare scheduling for other users, we have just temporarily added a limit on the maximum number of GPUs (14 GPUs) for your allocation using a QOS. We might set a smaller limit later and that QOS will be removed once the reservation ends. I just wanted to let you know about that. If you have any questions or concerns, please let us know. Thanks, name ; Hi name, Thank you so much for such a great support you have given us. We are very happy to share our thoughts and experiences with you. We have a pool of users that's not very experienced on the command line, but we have definitely been able to help them understand the major ideas about cryoEm pipelines. We have them do a competition in data processing tomorrow and we might make use some extra gpus to try optimise few parameters. After the workshop, it will only be me and another user running the jobs. Btw, is there anyone I could directly contact about Relion? We were unable to use MPI runs from the Relion GUI, so I found a workaround. Relion can use SBATCH job submission script which i might need help figuring out. I have a very good starting point. Best regards, Nash ---- ; Hi Nash, You are welcome. I'm following up to let you know that the reservation has been removed and the QOS has been detached from your allocation. Would you let us know how your workshop and the competition went? Regarding running Relion jobs with MPI, you could try contacting name for assistance. It seems he shared a command with you in ticket #6771. Have you got a chance to give it a try? Thanks, name ; Hi Nash, Since I have not heard back from you in a while, I'm tentatively marking this ticket as resolved at this point. Please feel free to contact us again if you have any questions. Thanks, name ;",nbogdanovi,Nebojša Bogdanović,Ruyi Li,Purdue University,Anvil,16,40,9,2024,2024-02-26
ATS-6769,Anvil Kubernetes -- network traffic between pods timing out,2024-03-11,2024-04-22,"We're having trouble with our JupyterHub in the geoedf namespace on Anvil composable being able to communicate with other containers running on Anvil via their DNS names. Our JupyterHub container needs to talk to our data portal containers in the same namespace, but it is doing so via their public DNS address with https (https://geoedf-portal.anvilcloud.rcac.purdue.edu), not any sort of a cluster internal pod name or internal IP address. Every connection attempt times out, though, with too many retries before the python lib gives up. In the same Jupyter container, from a terminal, we can see the same thing happening when trying to wget the other container's front page. However, the user's notebook session is not restricted in accessing the network. We can wget google.com: http://google.com and even purdue.edu: http://purdue.edu that's also on an 128.21\\* address. It seems to just be having problems with connections to other containers running on Anvil. We also tried using wget to access a completely unrelated project in another namespace and allocation also on Anvil, and it also timed out in the same way. Wget was able to resolve an IP address, but the connection timed out. Is there some network setting in YAML that needs to be flipped to properly route to other containers via their public addresses? The target container we are trying to access can be reached from other locations just fine. There is no issue hitting it from home or elsewhere in the campus network. The originating container with the user's running Jupyter session can access other internet locations, including non-Anvil things on campus. The only issue is trying to reach other containers on Anvil via their public DNS addresses, which do seem to resolve but don't seem to connect. ; Hi name, Just wanted to let you know we are looking at this and can reproduce. We'll let you know when it's fixed. -name ; Now I remember this one. You'll need to disable network policies to allow communication from the singleuser pods to other k8s pods. This goes in your values.yaml. {{networkPolicy: }} {{ enabled: false}} ; Thanks ; Hi name, Thanks for the update! Since the issue has been fixed, we'll go ahead and mark this ticket as resolved then. Best, name ;",thompscs@access-ci.org,Christopher Thompson,Erik Gough,Purdue University,Anvil,7,31,11,2024,2024-03-11
ATS-7555,My issue for submitting new job,2024-04-17,2024-04-23,"Hello, I hope this note finds you well. I am trying to submit a new job on cluster but I received this error in .out file: Lmod has detected the following error: Error in script ""/apps/spack/anvil/external/apps/conda/2024.02/etc/profile.d/conda.sh"": /usr/local/bin/bash: /apps/spack/anvil/external/apps/conda/2024.02/etc/profile.d/conda.sh: No such file or directory While processing the following module(s): Module fullname Module Filename ; anaconda/2024.02-py311 /opt/spack/cpu/Core/anaconda/2024.02-py311.lua h2. /var/spool/slurm/job4850460/slurm\\_script: line 13: activate: No such file or directory /var/spool/slurm/job4850460/slurm\\_script: line 14: ./configure: No such file or directory /var/spool/slurm/job4850460/slurm\\_script: line 15: build\\_mfixsolver: command not found mpirun was unable to launch the specified application as it could not access or execute an executable: Executable: ./mfixsolver Node: a241 h2. while attempting to start process rank 0. 12 total processes failed to start Could you please resolve it and let me know about this. Appreciate your help. Best regards, Javad Omidi ; ^slurm-4850460.out] ; Hi Javad, Thanks for reporting this. I believe this issue has been fixed. Please try it again and let me know if you still see errors. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Hello, Thank you for your reply and your help. Now, I am facing this issue, and I have tried to change the version of Anaconda, but I was not successful. Could you please let me know how I can do that since I am not very familiar with the Linux environment? anaconda/2024.02-py311: The default anaconda module has changed from 2021.05-py38 to 2024.02-py311. You can still use the older anaconda by loading it directly with ""module load anaconda/2021.05-py38"". ; The following have been reloaded with a version change: 1) anaconda/2021.05-py38 => anaconda/2024.02-py311 EnvironmentNameNotFound: Could not find conda environment: mfix-22.2.2 You can list all discoverable environments with `conda info --envs`. /var/spool/slurm/job4858834/slurm\\_script: line 14: ./configure: No such file or directory /var/spool/slurm/job4858834/slurm\\_script: line 15: build\\_mfixsolver: command not found I really appreciate your help. Best regards, Javad Omidi ; Hi Javad, I will need more information of what you were trying to achieve with anaconda module, and what steps you've taken to arrive the point with this error. Otherwise, I am not sure what suggestions I can share with you. Regards, name ; Hi, I am submitting a job for running MFiX software, which is running on Anaconda. So, after submitting my job, after 2 to 3 seconds, I received this error, and my run was terminated. If you need more information, please let me know. Thanks, Javad Omidi ; Hi Javad, I think it will be easier to discuss this issue over a virtual meeting. Please feel free to register our Anvil Support Hour at https://www.rcac.purdue.edu/anvil/anvil-support-hour: https://www.rcac.purdue.edu/anvil/anvil-support-hour|smart-link Regards, name ; Hi, I resolved that issue. Thank you, Javad ; Thank you for letting me know. I am glad the issue was resolved. Will mark this ticket as resolved. Thanks for reaching out! Regards, name ;",jomidi@access-ci.org,Javad Omidi,Nannan Shan,Purdue University,Anvil,9,5,16,2024,2024-04-15
ATS-7716,Lost nohup process in Anvil,2024-04-23,2024-04-24,"Hello Anvil Support Team, Summary of problem: I am using a Python script to automate Quantum Espresso job submissions to the debug queue. I used 'nohup' to send this to the background. I noted the PID, but it says no such process when I tried to kill it later on, and I cannot find the process anymore (I tried 'ps aux' and similar commands). It is now running indefinitely and continuously submitting jobs. I would appreciate help with locating it and/or shutting it down. Script name: converge\\_ecut.py Command: nohup python converge\\_ecut.py & Kill attempt: kill 722323 Attempts to locate process: ps aux | grep x-mwang5, ps aux | grep converge\\_ecut.py ; Hi name, Thank you for reaching out. I've terminated your processes on login05. Please note that Anvil has 8 login nodes. You might need to note down the host name of the specific node where you run the script. Warm regards, name ; Hi name, That makes sense, thank you so much! I really appreciate it. Best, name, No problem. Glad I was able to help. I'll go ahead and mark this ticket as resolved then. Please feel free to reach out to us again if you have any questions or need any help. Thanks, name ;",mwang5@access-ci.org,Samantha Wang,Ruyi Li,Purdue University,Anvil,4,2,17,2024,2024-04-22
ATS-7759,Long wait time in Anvil job allocation,2024-04-25,2024-04-25,"Hi, I have submitted a job request of 4 Nodes for 4 days on Anvil (job ID: 4872626) and its been around a week it is stuck in the queue. I don't know why it is taking so long to get the allocation or what should I do to get faster allocation. Any help would be highly appreciated. Regards, name Gamdha ; Hello name, One of our support staff will follow up on this ticket I'm sure but I just wanted to jump and provide the essential answer to your question since I have it. If you check on your job, Slurm reports the ""reason"" as ""AssocGrpCPUMinutesLimit"". If you run the {{mybalance}} command you'll see that your account for the job has ~37k SUs remaining. But you asked for 4 days on 4 nodes; that's 4x128x24x4 ~49k SUs required. So the scheduler assumes it cannot guarantee that time and so never schedules. Cheers, name ; Hi name, Thank for getting back. Now it makes sense, I got my answer. I think we can close this ticket. Regards, name Gamdha ; I got my answer, thanks ;",dgamdha@access-ci.org,Dhruv Gamdha,Ruyi Li,Purdue University,Anvil,4,1,17,2024,2024-04-22
ATS-7782,VASP License,2024-04-26,2024-04-26,"Hi, Materials Design provided us the VASP license. Here is their email regarding providing proof of license. Thank you Hi Shaama, If you could have the NSF administrator reach out to : mailto:, we will happily confirm your VASP license status. Thank you! \\*Chelsea Kemmerrer, M.S., P.E.\\* \\_Academic Account Manager\\_ \\*Materials Design, Inc.\\* 12121 Scripps Summit Drive, Ste. 160 | San name, CA 92131 Direct +, ext. 265: tel:+,265 : mailto: | http://www.materialsdesign.com: http://www.materialsdesign.com|smart-link ; Hi Shaama, Thanks for reaching out! On Anvil, we only verify VASP license against the database from VASP portal. If you have the VASP license from Materials Design Inc, we would recommend to compile your own VASP on your project space. Please feel free to check our user guide about how to compile VASP on Anvil. https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/vasp Regards, name, PhD (She/Her) Senior Computational Scientist Purdue University ;",ssharada@access-ci.org,Shaama Mallikarjun Sharada,Nannan Shan,Purdue University,Anvil,2,1,17,2024,2024-04-22
ATS-4334,random segfault error,2023-11-08,2024-04-29,"Hello, I am using a version of QE I compiled myself on Anvil, and noticed that about 5% of jobs I launch are terminated by the following segfault error: {{/apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/bin/mpirun: line 103: 491057 Segmentation fault mpiexec.hydra ""$@"" 0<&0}} I guess the code is trying to access some memory that it does not own, but I cannot figure out the origin of the problem. I asked to use 20G of memory, but I wonder if I am supposed to specify the memory the process uses in a ""shared"" partition? For more details: I use the following submission submission script, you can find it at {{/home/x-sgelin/scratch/research/data/photoelectrochemistry/microkinetics/name/Strain0/new\\_configs\\_ontop/RuO2-110-0-13679}}: {{# name On 3/21/24 16:51, ACCESS Ticket Submission wrote: ; That is great to hear, congratulations! Can you share with us what the fix was? I will note it for future references. Best regards, name. ; Hi name, It has been some time since I solved it and I have forgotten the details. From what I recall, the error came from the MPI compilers. I use intel compilers and it did not work with impi, I had to switch to openmpi: Here are the modules I load: module load emacs intel openmpi intel-mkl hdf5 fftw/3.3.8 Here is the MPI library used to compile QE: qe/qe-7.2/build/CMakeCache.txt:CMAKE\\_C\\_COMPILER:STRING=/apps/spack/anvil/apps/openmpi/4.0.6-intel-19.0.5-gg3uqqz/bin/mpicc I hope it helps, name On 3/21/24 17:30, ACCESS Ticket Submission wrote: ; Got it! The intel/19.0.5 version does have some MPI bugs in it. That may have been contributing to your issues. Glad to hear that you found a workaround. Best regards, name. ; Hi name, Thanks for sharing your workaround with us. We'll go ahead and mark this ticket as resolved then. Thanks again for contacting us. Warm regards, name ;",sgelin@access-ci.org,Simon Gelin,Amiya Maji,Purdue University,Anvil,12,124,45,2023,2023-11-06
ATS-5938,Anvil: trouble starting job on queue,2024-02-05,2024-04-29,"anvil username: x-aadhikari job id(s): 4366319, 4366325, 4366356, 4366359, 4366363, 4366367 application: /home/x-aadhikari/nmesh/exe/nmesh detailed error message: {{slurmstepd: error: \\*\\*\\* JOB 4366367 ON a608 CANCELLED AT 2024-02-05T21:51:33 DUE TO JOB REQUEUE \\*\\*\\*}} log output files: /anvil/projects/x-phy230109/ananya/migration/pmHot.1HGaBfvaf5l.03\\_n28.par.o4366319 /anvil/projects/x-phy230109/ananya/migration/pmHot.1HGaBfvaf5l.03\\_n28.par.o4366325 /anvil/projects/x-phy230109/ananya/migration/pmHot.1HGaBfvaf5l.03\\_n28.par.o4366356 /anvil/projects/x-phy230109/ananya/migration/pmHot.1HGaBfvaf5l.03\\_n28.par.o4366359 /anvil/projects/x-phy230109/ananya/migration/pmHot.1HGaBfvaf5l.03\\_n28.par.o4366363 /anvil/projects/x-phy230109/ananya/migration/pmHot.1HGaBfvaf5l.03\\_n28.par.o4366367 ; Hello, I tried run a job with our own C-based program on Anvil on the wide and wholenode partitions. However, when I tried to use more than 6 nodes, my jobs got cancelled with the error message: {{slurmstepd: error: \\*\\*\\* JOB 4366367 ON a608 CANCELLED AT 2024-02-05T21:51:33 DUE TO JOB REQUEUE \\*\\*\\*}} My sbatch command looked like: {{sbatch -t 3:30:00 --nodes=8 --ntasks=1024 --cpus-per-task=1 -J pmHot.1HGaBfvaf5l.03\\_n28.par -p wide -o pmHot.1HGaBfvaf5l.03\\_n28.par.o%J /home/x-aadhikari/bin/slurm\\_mpirun\\_script}} Since I was requesting 1024 procs (well within the 7,168 or 2,048 max core per job limits of wide and wholenode partitions respectively) and there about ~400 idle nodes of both partition types, I don't understand why my job request did not go through and what this error message means, and why the ones with 6 or less node requests went through. Here is a the location of a log output file from a successful job submission with 6 nodes: /anvil/projects/x-phy230109/ananya/migration/pmHot.1HGaBfvaf5l.03\\_n28.par.o4366368 This successful job (ID:4366368) started with this sbatch command: sbatch -t 3:30:00 --nodes=6 --ntasks=768 --cpus-per-task=1 -J pmHot.1HGaBfvaf5l.03\\_n28.par -p wide -o pmHot.1HGaBfvaf5l.03\\_n28.par.o%J /home/x-aadhikari/bin/slurm\\_mpirun\\_script Please advise. Thank you, Ananya Adhikari. ; Hi Ananya, Thank you for reaching out. I've escalated your ticket to our computational scientists. They would look into the issue and contact you later. Warm regards, name ; Hi Ananya, Can you please share your slurm\\_mpirun\\_script and a job output file? I suspect the job is encountering an error when using 6+ nodes and then it requeues. Best regards, name. ; Hi Ananya, Since we have not heard back from you in a while and it seems most of your recent jobs completed without being requeued, we are tentatively marking this ticket as resolved at this point. If you have any further questions, please feel free to re-open this ticket or submit a new one to us. Thanks, name ;",aadhikari@access-ci.org,Ananya Adhikari,Amiya Maji,Purdue University,Anvil,4,61,6,2024,2024-02-05
ATS-6053,GPAW 23.9.1 Installation on Anvil,2024-02-09,2024-04-30,"Hello, I'm working on research that requires the use of mpi-enabled GPAW. In a prior ticket (ATS-3184), I was unable to install GPAW. The final note in that ticket was to use Slack, and that it tested okay. I followed the instructions: spack env create -d ./gpaw spack env activate pwd/gpaw spack add py-gpaw % spack install Unfortunately it did not work, as I cannot access the gcc/12.2.0 module. Using instead the default gcc/11.2.0, I performed the following module loads before {{spack add}} and {{spack install}}, module --force purge module load gcc/11.2.0 module load openmpi/4.1.6 module load intel-mkl module load fftw/3.3.8 The command {{spack install}} installs GPAW without error. When I run it, however, I get errors that indicate that an openmpi version was installed by spack which is not interfaced with SLURM. I've attempted crafting a custom packages.yaml to point to the openmpi module in Anvil, but the {{spack install}} command fails when it tries to find it. Can I get some assistance with installing the latest version GPAW package, either using Spack or via conda? Thank you for your time and help, name D. Switzer, Ph.D. Department of Physics University of Central Florida ; Hi name, Thanks for reaching out and sorry for the delay. I am wondering if we can try to {{module load openmpi}} module when running gpaw jobs. Please let me know how it goes. Regards, name, PhD (She/Her/Hers) Sr. Computational Scientist ; Hi name, I'm building it again, and will let you know the result. I thought I remembered loading the openmpi module when running the job, but it has been some time so I will attempt again. Best, name ; Hi name, I received the same (I think) error, both either as a job submitted to a debug node or as an interactive job: ; A requested component was not found, or was unable to be opened. This means that this component is either not installed or is unable to be used on your system (e.g., sometimes this means that shared libraries that the component requires are unable to be found/loaded). Note that Open MPI stopped checking at the first component that it did not find. Host: a137 Framework: pml Component: ucx ; It looks like MPI\\_INIT failed for some reason; your parallel process is likely to abort. There are many reasons that a parallel process can fail during MPI\\_INIT; some of which are due to configuration or environment problems. This failure appears to be an internal failure; here's some additional information (which may only be relevant to an Open MPI developer): mca\\_base\\_framework\\_open on ompi\\_pml failed --> Returned ""Not found"" (-13) instead of ""Success"" (0) ; It looks like MPI\\_INIT failed for some reason; your parallel process is likely to abort. There are many reasons that a parallel process can fail during MPI\\_INIT; some of which are due to configuration or environment problems. This failure appears to be an internal failure; here's some additional information (which may only be relevant to an Open MPI developer): ompi\\_mpi\\_init: ompi\\_mpi\\_instance\\_init failed --> Returned ""Not found"" (-13) instead of ""Success"" (0) ; \\*\\*\\* An error occurred in MPI\\_Init \\*\\*\\* on a NULL communicator \\*\\*\\* MPI\\_ERRORS\\_ARE\\_FATAL (processes in this communicator will now abort, \\*\\*\\* and MPI will try to terminate your MPI job as well) This is the result of a module list command upon running: Currently Loaded Modules: 1) gmp/6.2.1 4) zlib/1.2.11 7) openmpi/4.1.6 2) mpfr/4.0.2 5) gcc/11.2.0 8) intel-mkl/2019.5.281 3) mpc/1.1.0 6) numactl/2.0.14 9) fftw/3.3.8 ; Hi name, I've tried to install GPAW on my end using Spack. I think I successfully installed it but I do not know how to test it. Here are the commands I've used for the installation. Maybe you can try it one more time and test if the compiled executable can run simulations. I started an interactive job for the installation (cost name allocation time), as reserving a node will make the installation faster. But you can definitely run the installation on the login node, which won't cost your SUs. In my experiment, basically I installed both {{gcc}} and {{openmpi}} in my {{gpaw}} environment, and use my own {{gcc}} and {{openmpi}} installations for {{py-gpaw}} installation. sinteractive -N1 -n128 -p shared -t 8:00:00 cd /anvil/scratch/x-nshan/ module --force purge git clone https://github.com/spack/spack.git ./spack cd spack . share/spack/setup-env.sh spack env create gpaw spack env activate gpaw spack compilers spack install --add spack install --add spack info py-gpaw spack checksum #version(""23.9.1"", sha256=""19a24840b876003528864b7a0b38fc0d456800b83b8666b1f724273660745b47"") spack edit py-gpaw #add this version to recipe spack spec py-gpaw #check installation details spack install --add % ls opt/spack/linux-rocky8-zen3/gcc-11.2.0/py-gpaw-23.9.1-gmyayijmuz4raj7yxbnzf4kfadbyc5sb/bin gpaw gpaw-analyse-basis gpaw-basis gpaw-plot-parallel-timings gpaw-runscript gpaw-setup gpaw-upfplot Hope it helps, name ; Hi name, I see, thank you for your notes! I will try this out on an interactive node, and let you know the result. Thanks again, name ; Hi name, I followed your instructions for both versions 23.9.1 and 24.1.0 with the following notes below: rm -rf ~/software/apps/spack ~/.spack sinteractive -N1 -n128 -p shared -t 8:00:00 cd ~/software/apps/ module --force purge git clone https://github.com/spack/spack.git ./spack cd spack . share/spack/setup-env.sh spack env create gpaw spack env activate gpaw spack compilers # Returns no compilers spack compiler find # Adds spack install --add spack compiler find # Adds #spack install --add spack install --add % # Doing this to maintain consistency with openmpi spack info py-gpaw #spack checksum #version(""23.9.1"", sha256=""19a24840b876003528864b7a0b38fc0d456800b83b8666b1f724273660745b47"") spack checksum #version(""24.1.0"", sha256=""14150bdc4b098060164b569699577ff57769a42783d79d37c9eb6cfe9cd506ea"") spack edit py-gpaw #add this version to recipe spack spec py-gpaw #check installation details spack install --add % #spack install --add % I found that if I ran {{gpaw info}} on the interactive node, I get the following error message: ; The application appears to have been direct launched using ""srun"", but OMPI was not built with SLURM support. This usually happens when OMPI was not configured --with-slurm and we weren't able to discover a SLURM installation in the usual places. Please configure as appropriate and try again. ; \\*\\*\\* An error occurred in MPI\\_Init \\*\\*\\* on a NULL communicator \\*\\*\\* MPI\\_ERRORS\\_ARE\\_FATAL (processes in this communicator will now abort, \\*\\*\\* and potentially your MPI job) If I instead attempt an mpirun -np 1 gpaw info, I get: Traceback (most recent call last): File ""/home/x-eswitzer/software/apps/spack/var/spack/environments/gpaw/.spack-env/view/bin/gpaw"", line 7, in from gpaw.cli.main import main File ""/home/x-eswitzer/software/apps/spack/var/spack/environments/gpaw/.spack-env/.\\_view/on4tjsns24m6o4w43kygiw2dddizshka/lib/python3.11/site-packages/gpaw/\\_\\_init\\_\\_.py"", line 191, in from gpaw.calculator import GPAW as OldGPAW File ""/home/x-eswitzer/software/apps/spack/var/spack/environments/gpaw/.spack-env/.\\_view/on4tjsns24m6o4w43kygiw2dddizshka/lib/python3.11/site-packages/gpaw/broadcast\\_imports.py"", line 82, in exec\\_module return self.load\\_from\\_cache(module) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File ""/home/x-eswitzer/software/apps/spack/var/spack/environments/gpaw/.spack-env/.\\_view/on4tjsns24m6o4w43kygiw2dddizshka/lib/python3.11/site-packages/gpaw/broadcast\\_imports.py"", line 91, in load\\_from\\_cache exec(code, module.\\_\\_dict\\_\\_) File ""/home/x-eswitzer/software/apps/spack/var/spack/environments/gpaw/.spack-env/.\\_view/on4tjsns24m6o4w43kygiw2dddizshka/lib/python3.11/site-packages/gpaw/calculator.py"", line 10, in import gpaw.mpi as mpi File ""/home/x-eswitzer/software/apps/spack/var/spack/environments/gpaw/.spack-env/.\\_view/on4tjsns24m6o4w43kygiw2dddizshka/lib/python3.11/site-packages/gpaw/broadcast\\_imports.py"", line 82, in exec\\_module return self.load\\_from\\_cache(module) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File ""/home/x-eswitzer/software/apps/spack/var/spack/environments/gpaw/.spack-env/.\\_view/on4tjsns24m6o4w43kygiw2dddizshka/lib/python3.11/site-packages/gpaw/broadcast\\_imports.py"", line 91, in load\\_from\\_cache exec(code, module.\\_\\_dict\\_\\_) File ""/home/x-eswitzer/software/apps/spack/var/spack/environments/gpaw/.spack-env/.\\_view/on4tjsns24m6o4w43kygiw2dddizshka/lib/python3.11/site-packages/gpaw/mpi.py"", line 12, in from ase.parallel import world as aseworld, MPI as ASE\\_MPI ModuleNotFoundError: No module named 'ase' ; Primary job terminated normally, but 1 process returned a non-zero exit code. Per user-direction, the job has been aborted. ; mpirun detected that one or more processes exited with non-zero status, thus causing the job to be terminated. The first process to do so was: Process name: 21057,1,0 Exit code: 1 ; I'm not sure why ASE is not detected, as it's a required package to be installed with GPAW. Let me know if I can provide any more information, name ; Hi name, I checked the installed list in our gpaw environment within Spack, it looks like there is no ase installed. I am confused as well, because according to the tutorial, ase has to be installed first to install gpaw. I best guess is if we use spack installation, we do not need ase because spack will automatically install the dependences for Gpaw. I just did a quick search, in Spack recipes, we can install ase in our Gpaw environment with {{spack install --add py-ase}} Before you install {{py-ase}}, you can always run {{spack info py-ase}} and {{spack spec py-ase}} to get more information about this packages and decide which py-ase version you want. Hope it helps, name ; Hi name, Thank you for the info! I will try that out and see if it works. name ; Hi name, I added the lines for install py-ase, and now the command {{mpirun gpaw info}} works as expected, with the requested options of mpi, scalapack, and fftw enabled. When I attempt to run a test calculation with more than 1 node, however, I receive an error: ; There are not enough slots available in the system to satisfy the 256 slots that were requested by the application: gpaw Either request fewer slots for your application, or make more slots available for use. A ""slot"" is the Open MPI term for an allocatable unit where we can launch a process. The number of slots available are defined by the environment in which Open MPI processes are run: 1. Hostfile, via ""slots=N"" clauses (N defaults to number of processor cores if not provided) 2. The --host command line parameter, via a "":N"" suffix on the hostname (N defaults to 1 if not provided) 3. Resource manager (e.g., SLURM, PBS/Torque, LSF, etc.) 4. If none of a hostfile, the --host command line parameter, or an RM is present, Open MPI defaults to the number of processor cores In all the above cases, if you want Open MPI to default to the number of hardware threads instead of the number of processor cores, use the --use-hwthread-cpus option. Alternatively, you can use the --oversubscribe option to ignore the number of available slots when deciding the number of processes to launch. ; The job script I'm using (reproduced with either mpiexec or mpirun) is, #!/bin/sh -l # FILENAME: job\\_test #SBATCH -A dmr130009 # Allocation name #SBATCH --nodes=2 # Total # of nodes #SBATCH --ntasks=256 # Total # of MPI tasks #SBATCH --time=24:00:00 # Total run time limit (hh:mm:ss) #SBATCH -J spack\\_Dimer147Benzene\\_gs # Job name #SBATCH -o %j.out # Name of stdout output file #SBATCH -e %j.err # Name of stderr error file #SBATCH -p wholenode # Queue (partition) name #SBATCH --mail-user= #SBATCH --mail-type=all # Send email to above address at begin and end of job # Manage processing environment, load compilers and applications. hostname module --force purge cdir=`pwd` cd /home/x-eswitzer/software/apps/spack . share/spack/setup-env.sh spack env activate gpaw cd $cdir module list # Launch MPI code mpiexec -np 256 gpaw python calc\\_gs.py If I remove the {{-np}} option, it defaults to 128 cores in GPAW, regardless if I specify {{#SBATCH --nodes=1}} and {{#SBATCH --ntasks=128}} or {{#SBATCH --nodes=2}} and {{#SBATCH --ntasks=2}}. ; Hi name, Have you tried to use {{--use-hwthread-cpus}} option or {{--oversubscribe}} indicated in the error message? Regards, name ; Hello! Since we did not hear from you, we are considering this ticket as resolved for now. However, if you still require assistance with this issue, please reply within the next 7 days and we will keep the ticket open. After that period, please feel free to reach out to us and create a new ticket at any time. Regards, name ;",eswitzer@access-ci.org,Eric Switzer,Nannan Shan,Purdue University,Anvil,12,58,6,2024,2024-02-05
ATS-6449,Running a job,2024-02-26,2024-04-30,"I am trying to run the a NAMD simulation in anvil. I am using the attached submission script but it is not working. Could you please review the submission script and suggest the correction? Thank you. ; ^gpu\\_anvil\\_namd3.sub] ; Hello/bin/sh #SBATCH --job-name=namd #SBATCH --account=your\\_account #SBATCH --partition=gpu #SBATCH --nodes=1 #SBATCH --ntasks-per-node=8 #SBATCH --cpus-per-task=1 #SBATCH --gpus-per-node=1 #SBATCH --time=00:30:00 #SBATCH --output=namd.o%j.%N module --force purge module load modtree/gpu module purge module load ngc module load namd module list singularity run --nv /apps/ngc/images/nvcr.io\\_hpc\\_namd:3.0-alpha3-singlenode.sif namd3 complex\\_solv\\_ion-PROD-0.conf > complex\\_solv\\_ion-PROD-0.out Regards, name ; \\*\\*PRIVATE NOTE\\*\\* Talked to this user over Anvil Support Hour. Shared how to construct a submit script for NAMD job, in the end of the meeting, user is able to run their NAMD jobs on Anvil. Will keep this ticket open for another couple of days, in case user has more further questions. --name ; Hi, I performed different benchmark runs by changing the ntasks-per-node=8, 16, 32, 64 and 128. In every case the performance was found between 6.5 to 6.7 ns per day. Maybe we could enhance the performance by incorporating mpirun. Here, I am sharing a script that I am using in Expanse to run namd, using mpirun. It might be helpful to figure out how we could incorporate mpirun for namd in anvil. Could you please check and let me know? Thank you. #!/usr/bin/env bash #SBATCH --job-name=namd-2.14-expanse-gpu-1node-4V100 #SBATCH --account=chi149 #SBATCH --partition=gpu #SBATCH --nodes=1 #SBATCH --ntasks-per-node=1 #SBATCH --cpus-per-task=1 ##SBATCH --mem=93G #SBATCH --gpus=4 #SBATCH --time=48:00:00 #SBATCH --output=namd-2.14-expanse-gpu-1node-4V100.o%j.%N declare -xr SCHEDULER\\_MODULE='slurm/expanse/current' declare -xr SOFTWARE\\_MODULE='gpu/0.15.4' declare -xr MPI\\_MODULE='openmpi/4.0.4' declare -xr NAMD\\_MODULE='namd/2.14' module purge module load ""${SCHEDULER\\_MODULE}"" module load ""${SOFTWARE\\_MODULE}"" module load ""${MPI\\_MODULE}"" module load ""${NAMD\\_MODULE}"" module list mpirun --mca btl\\_openib\\_allow\\_ib true -np 1 --map-by ppr:1:node namd2 +ppn40 +setcpuaffinity +devices 0,1,2,3 complex\\_solv\\_ion-PROD-0.conf > complex\\_solv\\_ion-PROD-0.out Best Regards Md. Mehedi name ; I checked the information about NGC NAMD page, https://catalog.ngc.nvidia.com/orgs/hpc/containers/namd It looks like we could set up number of cpus and gpus in the executable line, something like: namd3 +p8 +devices 0 +setcpuaffinity complex\\_solv\\_ion-PROD-0.conf I guess you can play with number of cpus and see if it is helpful to your calculations. I highly doubt this because from my understanding, since we already used GPU to accelerate the calculation, I do not know how number of CPUs will help with the calculation. I would recommend to check NAMD tutorial and find out if the number of CPUs matters when GPU was used. Please note that, the NAMD you are using on Anvil is for single node only. Because you are able to run NAMD jobs right now, I would mark this ticket as resolved. If you want to discuss about how to optimize your calculations workflows, I would recommend to contact MATCH program where people will help to optimize workflows/code performance. https://support.access-ci.org/match/overview Good luck to your research! name ;",mhasan1@access-ci.org,MD MEHEDI HASAN,Nannan Shan,Purdue University,Anvil,32,47,9,2024,2024-02-26
ATS-6895,How to request for extra memory storage?,2024-03-17,2024-04-30,"I would like to request for extra memory storage in my ANVIL account. I could not find the details on the web page. ; Hello ; Hi Krishan, Thanks for sharing more information. Let me bring this request to our storage team and see if we can increase your scratch folder quota. It sounds like you would use these data for simulations, so I believe scratch folder quota is a good fit for you. Regards, name ; Hi Nanna, Thanks for escalating the issue. Moreover, I would further like to know two more things, which are as follows: # How long does data remain in the scratch folder? # If the data cannot remain for long time (let us say a year), then is there another long-time storage system like in EXPANSE. ---- ; Hi Krishan, Files on Scratch folder is older than 60 days will be purged, which means if the file is not accessed and just sitting there, it will be purged after 60 days. But if the file is used every day or being used very frequently, it will be there for the usage. I do not think Anvil has given users a large space (> 5TB) just for long-term storage purpose. Anvil is not designed for storage purpose, but computing. That's why we have given users HOME (25GB) and project (5TB) for storage, and (100TB) for scratch for computing. Let me know if you are interested in the increase quota of your scratch space. Regards, name ; Hi name, Thanks for considering the request. I would like to request you to increase the quota. ---- ; A couple of questions from our storage team, (1) have you considered to optimize the workflow to avoid store these large big dataset in one place? (2) How long you'd like to have the increased quota in scratch? We are not giving lifetime increase, we can give users a few months for the increase as lifetime increase has the potential to cause unknown file system problems. The recommendation from storage team is, try to optimize your workflow, because even though we extended the scratch quota, and it is not permanent storage place, ""there is data management issues for user as in how do they move those big allocations to a more permanent place? Their project area is not going to have those quotas either and are even less able to handle it."" Regards, name ; Hello! Since we did not hear from you, we are considering this ticket as resolved for now. However, if you still require assistance with this issue, please reply within the next 7 days and we will keep the ticket open. After that period, please feel free to reach out to us and create a new ticket at any time. Regards, name ; Hi name, Thanks for reaching out. I would like to increase the scratch quota for 90days. The workflow is optimized. ---- ; Hi Krishan, One more question, the there is a limit for file number on Scratch as well, which is 1000k. This setting up is because sometimes the workflow will produce tons of small files which will affect the performance of the file system. As I would ask our storage team to increase the your Scratch quota to 200TB for 90 days. In the meantime, I want to double check that you are aware of the file number limit as well. Let me know if there is a requirement for file number as well. Regards, name ; Hi name I am sorry for the delay. I did not have any idea how much 1000k would be. But when I ran a few simulations, I could see that my scratch storage is used only 2% but the files limit has reched 99%. As you said correctly, I do have a requirement for file number as well. If I need to raise a ticket again, I will do it. Krishan ;",kchand1@access-ci.org,Krishan Chand,Nannan Shan,Purdue University,Anvil,14,32,11,2024,2024-03-11
ATS-7152,Increase file number limitation,2024-03-29,2024-05-02,"Hi all, My user id on Anvil HPC is x-eeshanb. Can you please increase the limitation for the file number that I can have on the system? I use WRF-Chem and I need to run multi year, multi-domain simulations. The current limit is 1000k. Can you increase it to at least 20 times of that? Another thing that I would want to increase is my scratch storage. I will be grateful if you allocate around 200TB in my scratch. ; Hi, Thank you for contacting us. Do you have an estimation of time period when you will need that increase? Best regards, name Senior Computational Scientist Purdue Information Technology ; Thanks for the quick response. Can you increase them until the end of the year? ---- ; Hey, Can you please increase the limit of the file numbers, at least for the time being? It is a very critical issue. ---- ; Hi, I will forward your request to our storage experts so they could discuss and decide if that's OK to do so. Please stay tuned. name ; Hi name, That would be great. I really need the space as soon as possible. ---- ; Hi all, Are there any updates on this ticket? ---- ; Hi all, Are there any updates on this ticket? ---- ; Hi all, Are there any updates on this ticket? Best, Eeshan ---- ; Hi, As this request of quota increase is large, our storage experts are working with our storage vendor to make sure the change to you will not impact the entire system performance. Will get back to you as soon as it's done. name ; Hi name, Thanks for the speedy response. Can you please increase the file number limit? For the time being, I can deal with the 100TB space. ---- ; Hi all, Any update on this ticket? I really, really need relaxation on the file number limitation. Its been almost a month without any update. ---- ; Please accept our apologies for the delayed response. This request took some discussions before we could proceed. Your files quota has been extended to 20M. My understanding is you need this until the end of the calendar year. At that time it will be reset back to 1M. ; Hi name, Thank you so much for your email and increasing my file quota. It will help me a lot. ---- ; Hi all, Thank you for extending the file limit. I would also be grateful if you could increase my storage limit. The initial request was to increase both the storage and the number of files limit. I mentioned previously that I have to run multiscale WRF-Chem for several years as a part of my PhD research and am reaching my 100TB limit. Can you please look into this as soon as possible? ---- ; My apologies, I missed setting that part as well. You now have 200T blocks quota as well. ;",eeshanb@access-ci.org,Eeshan Basu,Guangzhen Jin,Purdue University,Anvil,16,25,13,2024,2024-03-25
ATS-7653,File Count Limit lower than Storage Available,2024-04-19,2024-05-02,"We have a large amount of available storage space on the Anvil resource. However, we have uploaded many small files. As a result, my labmates have run into issues where we have not approached the storage space limit but they cannot upload more data because we have hit a file limit. Is there a way to raise the file count limit per user? If not, is there another way to circumvent this issue you would recommend? ; Hi name, Thank you for contacting us. Could you please share the paths to the directories in question? It would be helpful if you could share more information about your workflow. Have your labmates tried bundling the files up to reduce the number of files? Warm regards, name ; Hi name, Thank you for your swift response and understanding. Here's the current status of our directories: \\*Type Location Size Limit Use Files Limit Use\\* =========================================================== scratch anvil 0KB 100.0TB 0% 0k 1,000k 0.00% \\* \\*projects x-med220025\\*\\* \\*\\_976.2GB 5.0TB 19% 852k 1,048k 81%\\_\\* Regarding the \\* \\*projects/x-med220025\\*\\* directory, we're encountering an issue where even +small files of 10 MB or less+ are being counted towards our +file limit+. This limitation is hindering our ability to upload datasets to our shared directory efficiently. While bundling the files might seem like a solution, the repetitive process of zipping or creating tar files, then unzipping them each time we need to access them, and subsequently deleting them afterward, becomes quite cumbersome and time-consuming. We'd greatly appreciate any recommendations you can provide to alleviate this issue. Our workflow must have a more flexible approach to file management within the given storage constraints. Looking forward to your recommendations. ; Hi name, Thanks for the info. Would you please let us know more details about the datasets? For how long will they be used? Who are using the datasets? What programs are they running? Preferably, users should use their scratch directories to store working files and then transfer results to a long-term storage space. If you could also share their data management strategies, that would be helpful. Thanks, name ; Hi name, Since I have not heard back from you in a while, I'm tentatively marking this ticket as resolved at this point. If you still need assistance, please feel free to reply to this thread to re-open the ticket or submit a new one to us. Thanks, name ;",ayanan@access-ci.org,Anthony Yanan,Ruyi Li,Purdue University,Anvil,5,10,16,2024,2024-04-15
ATS-7824,Can't access SU units,2024-04-30,2024-05-03,"Hello, I have recently exchange some of my ACCESS credits to SUs in the Purdue Anvil CPU and GPU service. From the ACCESS portal, it seems like I have already gotten the SUs. But I wasn't able to see the SUs in my Anvil server account. Can you please help me with that? Thank you Thank you Please feel free to contact us again if you have any other questions. Have a great weekend! Best, name ;",zyang3@access-ci.org,Zoey Yang,Ruyi Li,Purdue University,Anvil,14,4,18,2024,2024-04-29
ATS-7841,The anvil cluster on the Anvil Composable Subsystem is down,2024-05-01,2024-05-01,"It looks like the anvil cluster on The Anvil Composable name is down, it is in an error state and the error message says: ""Cluster health check failed: Failed to communicate with API server during namespace check: Get ""https://172.21.168.34:6443/api/v1/namespaces/kube-system?timeout=45s: https://172.21.168.34:6443/api/v1/namespaces/kube-system?timeout=45s"": context deadline exceeded"" Other information I can provide is that the provider is RKE and the Kubernetes Version is v1.26.15. If you need any other details just let me know and I can provide those as well. ; Hi name, we have resolved this issue. If you find otherwise, please feel free to reopen this ticket. -name ;",jjones4@access-ci.org,James Jones,Erik Gough,Purdue University,Anvil,3,1,18,2024,2024-04-29
ATS-7848,Purdue Anvil server job not starting / node selection,2024-05-01,2024-05-01,"Hello, Recently I have been using Purdue Anvil server via Access. However, the job that was submitted did not start in the queue for more than 12 hours. (Job ID 4935922) I acknowledge that sometimes there could be a wall time for the job but considering there are idle nodes, should start. Can you please help me get it started? In addition, when I submit the job without specifying the nodes (Anvil has multiple nodes with different names), which nodes in default Anvil start a job? Thanks, Hyunsoo name. ; Hello Hyunsoo, Thanks for reaching out! Your job is pending because there are not enough SUs on your allocation. @login01.anvil:~ $ squeue -j 4935922 -l Wed May 01 14:18:32 2024 JOBID PARTITION NAME USER STATE TIME TIME\\_LIMI NODES NODELIST(REASON) 4935922 wholenode AO\\_RL\\_lr x-sea021 PENDING 0:00 7:00:00 1 (AssocGrpCPUMinutesLimit) There are 317.6 SUs on your allocation (ele240005) and your job requested 128\\*7=896 SUs. Regarding to which partition you can choose and which one is the default one, you might want to check our Anvil 101 training about the basics of Anvil. (The default partition on Anvil is shared). https://www.rcac.purdue.edu/training/anvil101 Regards, name, PhD (She/Her) Senior Computational Scientist Purdue University ;",sea0215@access-ci.org,Hyunsoo Choi,Nannan Shan,Purdue University,Anvil,2,1,18,2024,2024-04-29
ATS-7494,Jobs aborted because of node failure,2024-04-15,2024-05-06,"Dear Sir/Madam, I have two jobs (job id 4834601 and 4835996) aborted and requeued due to NODE\\_FAIL. If they restart from the beginning, will I be charged for the hours that were aborted? Best, Aidi ; Hi, Thank you for contacting us. Yes they will be charged for the amount of SUs they used but I will refund the total SUs (23278.69) to your account. They will be ready within hours. Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name ;",zad238@access-ci.org,Aidi Zhang,Guangzhen Jin,Purdue University,Anvil,3,16,16,2024,2024-04-15
ATS-1663,Grant TDM staff ability to scancel TDM student jobs,2023-07-06,2024-05-10,"There are times when we notice students in The Data Mine will mistakenly submit large jobs to Anvil that we would like to scancel. We cannot scancel jobs we do not own, however, so this currently requires intervention on the part of RCAC admin staff. We propose the following alternative: grant members of group x-tdm-admin sudo access to run something like ""tdmscancel"". The tdmscancel script would sanitize input, confirm that the jobs given are actually using the cis220051 account, and the do a real scancel. This should work: {{#!/bin/bash}} {{IFS=$' \t'}} {{TDMACCOUNT=cis220051}} {{ }} {{# We are given a list of SLURM jobs on the command line to cancel}} {{# Check them one at a time, sanitizing them and confirming they are valid}} {{for job in $\\*}} {{do}} {{ # Strip all characters but 0-9}} {{ jobnum=$(echo $job | tr -d -c "":digit:]"")}} {{ }} {{ if ! -z ""$jobnum"" ; then}} {{ # Is this a valid job number submitted using the $TDMACCOUNT account?}} {{ if [ $(/usr/bin/squeue -A $TDMACCOUNT --job $jobnum 2>/dev/null: /usr/bin/wc -l) -gt 1 ; then}} {{ echo ""Canceling $jobnum""}} {{ /usr/bin/scancel $jobnum}} {{ else}} {{ echo ""Skipping invalid job $jobnum""}} {{ fi}} {{ fi}} {{done}} Regards, Doug ; \\*\\*PRIVATE NOTE\\*\\* name - This might be resolved if certain things come to pass. In the mean time, I haven't been sure what to do with this ; \\*\\*PRIVATE NOTE\\*\\* Hi name - I don't think we want to grant this access just yet… I would say this should be a good teaching moment for students to be responsible users of Anvil versus canceling jobs out from under them. ""Your running a long job name SUs which affect others on your allocation…"" ; If you agree, I'll respond with that comment ; Hello Doug, After some internal discussions, we feel that this should be a teachable moment for students in the Data Mine on being responsible users of Anvil. I would recommend that the students learn to cancel their own jobs and are made aware that they share this allocation with nearly 2000 other users and that their large jobs will burn through resources that are being shared with others on the Data Mine. We would also greatly appreciate if you would be able to share these helpful tips with the students (https://www.rcac.purdue.edu/knowledge/anvil/policies/tips: https://www.rcac.purdue.edu/knowledge/anvil/policies/tips|smart-link ) just as a refresher. Please pilot this and do let us know if this still remains a challenge. Best, name ; Hi name, Thanks for considering. Something else to consider: why do you have disk quotas? Why don't you use it as a teachable moment for Anvil users and educate them that they are to use just 25GB in $HOME? You have quotas because some will accidentally (or intentionally) use more than they should, even if carefully trained. No, I'm not trying to suggest you don't use quotas. I'm just trying to give you a little perspective on how we are trying to be good stewards of our allocation consumption by pointing out that training and expectations of diligence are sometimes insufficient. Regards, Doug ; Hi Doug, Point taken; you raise a good point on having additional guard rails that will prevent accidental usage. We can look into having a Slurm qos that will place limits on per-user job walltimes/cores for your allocation. If you have any recommendations for such limits, please let us know… Best, name ;",dgc,Doug Crabill,Rajesh Kalyanam,Purdue University,Anvil,6,222,27,2023,2023-07-03
ATS-4384,R Package Installations,2023-11-10,2024-05-09,"I'm a little new to R package installation/management, so I'm not the best at diagnosing errors in installation errors, but I have a number of packages I need to install for R and when running: BiocManager::install('clusterProfiler') I get the following errors: Using PKG\\_LIBS=-lfontconfig -lfreetype ; ANTICONF] ; Configuration failed to find the fontconfig freetype2 library. Try installing: \\* deb: libfontconfig1-dev (Debian, Ubuntu, etc) \\* rpm: fontconfig-devel (Fedora, EPEL) \\* csw: fontconfig\\_dev (Solaris) \\* brew: freetype (OSX) If fontconfig freetype2 is already installed, check that 'pkg-config' is in your PATH and PKG\\_CONFIG\\_PATH contains a fontconfig freetype2.pc file. If pkg-config is unavailable you can set INCLUDE\\_DIR and LIB\\_DIR manually via: R CMD INSTALL --configure-vars='INCLUDE\\_DIR=... LIB\\_DIR=...' ; ERROR MESSAGE ; :1:10: fatal error: fontconfig/fontconfig.h: No such file or directory compilation terminated. ---- ERROR: configuration failed for package 'systemfonts' \\* removing '/home/x-spatel4/R/anvil/4.1.0-gcc-11.2.0-yaooqbd/systemfonts' \\* installing \\_source\\_ package 'ggtree' ... \\*\\* using staged installation \\*\\* R \\*\\* inst \\*\\* byte-compile and prepare package for lazy loading Error in get(x, envir = ns, inherits = FALSE) : object 'warning\\_wrap' not found Error: unable to load R code in package 'ggtree' Execution halted ERROR: lazy loading failed for package 'ggtree' \\* removing '/home/x-spatel4/R/anvil/4.1.0-gcc-11.2.0-yaooqbd/ggtree' ERROR: dependency 'systemfonts' is not available for package 'ggforce' \\* removing '/home/x-spatel4/R/anvil/4.1.0-gcc-11.2.0-yaooqbd/ggforce' ERROR: dependency 'ggforce' is not available for package 'ggraph' \\* removing '/home/x-spatel4/R/anvil/4.1.0-gcc-11.2.0-yaooqbd/ggraph' ERROR: dependency 'ggforce' is not available for package 'scatterpie' \\* removing '/home/x-spatel4/R/anvil/4.1.0-gcc-11.2.0-yaooqbd/scatterpie' ERROR: dependencies 'ggraph', 'scatterpie', 'ggtree' are not available for package 'enrichplot' \\* removing '/home/x-spatel4/R/anvil/4.1.0-gcc-11.2.0-yaooqbd/enrichplot' ERROR: dependency 'enrichplot' is not available for package 'clusterProfiler' \\* removing '/home/x-spatel4/R/anvil/4.1.0-gcc-11.2.0-yaooqbd/clusterProfiler' The downloaded source packages are in '/tmp/RtmpBLI38k/downloaded\\_packages' Installation paths not writeable, unable to update packages path: /apps/spack/anvil/apps/r/4.1.0-gcc-11.2.0-yaooqbd/rlib/R/library Online, the only fix I could find was this, but I'm name sure using sudo is not an option for me: sudo apt -y install libfontconfig1-dev Thank you for your time and help! ; Hi, Thank you for contacting us. Looks like it is looking for the fontconfig header file which is not installed on Anvil yet. I will escalate your request to our application team so they will take a look and see how to fix it. Stay tuned. Best regards, name Senior Computational Scientist Purdue Information Technology ; \\*\\*PRIVATE NOTE\\*\\* Anvil Applications: https://access-ci.atlassian.net/jira/people/team/0f5fcf8a-26ef-4d24-a346-4a2ef3a7afda?ref=jira$&src=issue ([~accountid:id ~accountid:id ~accountid:id:id-5a0e-4ef9-9dae-4ff21198071b ~accountid:id ~accountid:id ~accountid:id ~accountid:id ~accountid:id ~accountid:id:id-2781-404e-85f3-6f3d3f09f93f ~accountid:id) Hi team, Please take a look at the issue and see if you could have a solution. Thank you. Best, name ; Hello, Are there any updates? Best, Sahil ; Hi, Sorry for the long delay. I recently made some changes on Anvil to include {{fontconfig}} package. Could you try the following commands before running the R package installation and see how it helps? It is also preferred if the R package is installed through terminal (not inside of RStudio). module use /apps/spack/anvil/modules/lmod/linux-rocky8-x86\\_64/gcc/11.2.0/ module load fontconfig name ; Hi, Have you tried the method I sent previously? name ;",spatel4@access-ci.org,Sahil Patel,Guangzhen Jin,,Anvil,6,130,45,2023,2023-11-06
ATS-4680,Set limit on single-job requests for SEE230009,2023-11-30,2024-05-08,"Hi, We are using the allocation SEE230009 on Anvil for our HPC class at UMass Dartmouth. To avoid the risk of students accidentally using up the whole allocation, I was wondering if there is a way to place a cap of 100 CpuHrs per job for this allocation? Best, name ; Hi name, Thank you for contacting us. I've shared your request with our experts and we think there could be a solution for that. Beside of 100 SUs per job, are there any other limits you wanted to have? For example, do you also want a limit on the number of jobs each person can run? Thanks, name ; Hi name, Thanks for your prompt response. I was wondering if we could also add a total cap of 2000 SUs per user? However, would I be able to lift that cap if necessary, without submitting a ticket? Best, name ; Hi name, Thanks for your reply. I would pass the request to our experts. An admin role is required for setting and changing limits on jobs/accounts. Therefore, you would not be able to lift the limits on your own, but you are welcome to submit a ticket to us and let us know what changes you would like to make. Would you like to set up the limits now? Thanks, name ; Hi name, Sounds good. But in that case, please only place the limit of 100 SUs per job. My worry with placing the limit on total SUs per user is that we also plan to use Anvil during our exams, and if a student hits this limit during an exam, there probably won't be enough time to raise a ticket and get it resolved in real time. Not a big problem, however, and the 100 SUs per job limit should be good enough. Unrelated question: One of the ways we are trying to combat cheating in our class is by having the students report their JobIDs. Is there a way for me to check which user ran a job, if I have the JobID? Best, name ; \\*\\*PRIVATE NOTE\\*\\* Anvil Applications: https://access-ci.atlassian.net/jira/people/team/0f5fcf8a-26ef-4d24-a346-4a2ef3a7afda?ref=jira$&src=issue (~accountid:id] ~accountid:id ~accountid:id:id-5a0e-4ef9-9dae-4ff21198071b ~accountid:id ~accountid:id ~accountid:id ~accountid:id ~accountid:id ~accountid:id:id-2781-404e-85f3-6f3d3f09f93f ~accountid:id) Hi Team, Would you please help set up the requested limit (100 SUs per job) for users in project {{SEE230009}}? Thanks, name ; \\*\\*PRIVATE NOTE\\*\\* This is a test. Anvil Support Team: https://access-ci.atlassian.net/jira/people/team/cdef030e-7757-40b7-963e-b1bb61f70ccc?ref=jira$&src=issue ([~accountid:id ~accountid:id ~accountid:id ~accountid:id) ; \\*\\*PRIVATE NOTE\\*\\* I received an email saying I was mentioned. ; Hello name, I am looking into setting up this limit for you. Would students in your class need to use more than 1 node at a time for any projects on distributed computing? If so, how many nodes do they need? Kind regards, name ; Hi name, Yes, there are some cases where they will need multiple nodes. Can we set a maximum limit of 3 nodes per job? Best, name ; Hi name, Thanks for the information. I set a limit of 3 nodes and a constraint that a job cannot use more than 100 SUs (core hours). If a job request would violate this limit, the job will be denied upon submission with an error that looks like: ""salloc: error: QOSMaxBillingPerJob salloc: error: Job submit/allocate failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)"" Let me know if you have any further questions/concerns. Kind regards, name ; That's perfect, thanks Best, name ; Hi name, I just removed this limit as an immediate fix. Can you please confirm you can submit as expected? Kind regards, name ; Hi name, That fixed the issue, thanks! I'll get back to you once the semester ends about setting the limit once again. Best, name ; Hi name, Since we have not received further communications from you in a while, we are tentatively marking this ticket as resolved at this point. Please feel free to re-open this ticket if you still need to set up the limit. Thanks, name ; Hi name, Thanks for the reminder, I think now is actually a good time to put the limit back. If possible, what I'd like is: A limit of 100 SUs per job. A limit of max 3 nodes per job. A total cap of 2000 SUs per user. Looks like last time somehow the limit ended up being 100 core-minutes instead of core-hours. Thanks, name ; Hi name, Thanks for your email. I've escalated your request to name. He would contact you later. Warm regards, name ; Hello name, I apologize for the wait. I just went ahead and attempted to re-enable limits on SUs per job as well as nodes per job for users in your group. Could you give it a try and let me know if it works? I do not know that we will be able to place a limit on the number of SUs each user is allowed to consume. Such a limit has to be placed at a different level in the hierarchy of limits and due to limitations in our automation of associations on Anvil, this configuration can't be placed. Let me know if the existing limits are working properly for you, and if there is anything else you'd like me to look into. Kind regards, name ; Hi name, Thanks for setting this up. Unfortunately, it looks like we have the same problem as last time -- I think the limit has been set to 100 core-minutes instead of 100 core-hours. For example, this works: >>> sinteractive -t 00:1:00 -N 1 -n 100 -A SEE230009 as that is exactly 100 core-minutes but this fails: >>> sinteractive -t 00:1:00 -N 1 -n 101 -A SEE230009 salloc: error: QOSMaxBillingPerJob salloc: error: Job submit/allocate failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits) Best, name ; My apologies--could you please try again? ; That problem seems fixed. But, I'm not sure whether there is any limit now. For example, I'm able to get more than 100 core-hours by doing: sinteractive -t 01:00:00 -N 1 -n 128 -A SEE230009 ; Hello name, We had some correspondence following an issue with the jobs of one of your students recently and it reminded me that I should follow up here. We agreed that there should be a limit of 5 jobs per student between their running and pending jobs, so I have applied that limit. We also mentioned using a billing-type limit in the Fall semester, so we can follow up then once that time comes. In the meantime, do you mind if we mark this ticket as resolved? Kind regards, name ; Hi name, Thanks! And yes, this ticket can be closed. Best, name ; Hi name, Great--I will go ahead and mark it as resolved. If you have any issues with the new limits, you can feel free to re-open this ticket or submit a new one. Enjoy the rest of your day, name ;",vvarma@access-ci.org,Vijay Varma,rderue,,Anvil,27,115,48,2023,2023-11-27
ATS-7292,out of disk space during simulations ,2024-04-05,2024-05-06,"Hi, I'm a new user and I have been trying to run some cases. Unfortunately, my simulations keep crashing due to out-of-disk space problems. I tried to locate my cases in /anvil/projects/x-phy240018 and /anvil/scratch/x-otumuklu. It did not help. I looked the documentation and it is stated 5TB disk space. I did not use this much but it keeps crashing. Any help would be greatly appreciated. Thank you. ; Hi, Thank you for contacting us. I would recommend using command {{myquota}} to check the actual storage quota and usage. Note there are two limits for your project folder: file size limit and file number limit. Most likely your simulation ran into out of file number issue. $ myquota x-otumuklu Type Location Size Limit Use Files Limit Use ============================================================================== home x-otumuklu 7.3GB 25.0GB 29% - - - scratch anvil 211.2GB 100.0TB 0.21% 954k 1,000k 95% projects x-eng240003 0KB 5.0TB 0% 0k 1,048k 0.00% projects x-mch240020 365.6GB 5.0TB 7% 736k 1,048k 70% projects x-phy240018 81.2GB 5.0TB 2% 274k 1,048k 26% Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name ;",otumuklu@access-ci.org,Ozgur Tumuklu,Guangzhen Jin,Purdue University,Anvil,3,22,14,2024,2024-04-01
ATS-7333,sreport shows large usage by x-skannur,2024-04-08,2024-05-07,"Why does {{sreport}} indicate that {{x-skannur}} has used ~4 million hours when {{sacct}} reports that he has not yet run any jobs on the system? Note: By the time you read this, {{x-skannur}} may have submitted a test job. $ sreport cluster UserUtilizationByAccount start=2024-01-01 account=dmr140129 -t hour -n format=login,used x-skannur 4369641 x-gabs 31472 x-tomwalt 9118 x-alaink 4069 x-zshiqi 3292 x-ispiva+ 1304 x-syjlee 1140 x-pschoe+ 542 x-mootim+ 435 x-jbradl+ 210 x-joaand+ 65 $ sacct --start=2024-04-01 -u x-skannur JobID JobName Partition Account AllocCPUS State ExitCode ; -------- Furthermore, why does {{sreport}} indicate that {{x-skannur}} consumed resources in prior months? I only added this user to {{dmr140129}} last week! sreport cluster UserUtilizationByAccount start=2024-03-01 end=2024-03-31 account=dmr140129 -t hour -n format=login,used x-skannur 2672333 x-gabs 19266 x-joaand+ 8 The usage reported by {{sreport}} is consistent with my expectations for all users other than {{x-skannur}}. ; Any ideas on this? sreport now reports 5.8 million hours used by x-skannur when he has only executed a single 10 minute job. ------ name A. Anderson, Ph.D. Research Area Specialist, Chemical Engineering, University of Michigan ; It has been 1 week since my initial ticket submission. Please respond. ------ name A. Anderson, Ph.D. Research Area Specialist, Chemical Engineering, University of Michigan ; Hi, Thank you for contacting us and sorry for the delay. I don't think {{sreport}} is collecting the right data from SLURM. These hours will not be used as allocation counting as I tested. What you have seen under {{mybalance}} should be normal as expected (i.e. {{x-skannur}} only used 0.2 SUs). I will report this bug to our application experts to take a further look why it's not working as expected. For the time being, I would recommend referring to results from {{sacct}}. Let me know if you have further questions. Best regards, name Senior Computational Scientist Purdue Information Technology ; Understood. It is good to confirm that the allocation accounting is correct even though `sreport` is not. I can look into adjusting my reporting scripts to use `sacct`. However, it does not provide an easy path to separate CPU time and GPU time like sreport does with the --tres flag. ------ name A. Anderson, Ph.D. Research Area Specialist, Chemical Engineering, University of Michigan ; That's true. We have been discussing internally about creating some easy to use user tools for such purposes. Please keep an eye on our updates in the future for this. For now I would tentatively resolve this ticket. name ;",joaander@access-ci.org,Joshua Anderson,Guangzhen Jin,Purdue University,Anvil,6,22,15,2024,2024-04-08
ATS-7420,Job scheduling,2024-04-11,2024-05-06,"Hi Anvil help team, My name is Saerom name and my user ID is x-stsr. I have noticed that the expected starting time of my job keeps increasing. Is there any issue on Anvil machine? ; Hi, Thank you for contacting us. Please note the ""expected job starting time"" is just a roughly estimation from SLURM based on current resource availability. There will be many factors impacting the job waiting time (e.g. termination of current running jobs, hardware failure, etc.). I saw your job has been completed so it should be running fine. Let me know if you have further questions. Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name ;",stsr@access-ci.org,Saerom Yu,Guangzhen Jin,Purdue University,Anvil,3,18,15,2024,2024-04-08
ATS-7895,Issue with job submission system,2024-05-02,2024-05-09,"Old jobs can not be canceled (all ways CG); new jobs are always waiting. When type {{sinfo}}, lots of nodes were dead, some are ""batch node selected"", some are 'kill task failed'. Please check ; Hi, Thank you for contacting us and reporting the issue. Yes there has been an issue for job scheduling on Anvil today and our engineering team is working closely to fix it. Will give updates when it's done. Stay tuned. Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi, The scheduler issue on Anvil has been fixed. Will resolve the ticket. Feel free to re-open it if issue still exists for you. name ;",wding2@access-ci.org,Wubin Ding,Guangzhen Jin,Purdue University,Anvil,4,6,18,2024,2024-04-29
ATS-7904,"Most nodes in drain state in Anvil shared partition, can't get back-end node",2024-05-03,2024-05-09,"It looks like 160 nodes on the shared partition of Anvil are stuck in the drain state and have been all morning. It looks like a number of back-end nodes were rebooted this morning so maybe this is related? Only 18 nodes are allocated and all others are down, drain, or drng. I've been waiting a long time for even a single core on a back-end node. Can someone please take a look? login01.anvil ~ : sinfo -p shared PARTITION AVAIL TIMELIMIT NODES STATE NODELIST shared\\* up infinite 2 comp a117,202 shared\\* up infinite 6 drain\\* a001-002,007,073,181,199 shared\\* up infinite 5 down\\* a127,162,192,205,249 shared\\* up infinite 38 drng a014,027-030,035-038,043,045-048,050-052,095,123,138,182,185-186,195,197,206-208,213,216,227,240-245,248 shared\\* up infinite 160 drain a000,009-010,013,021-026,032-034,039-041,044,049,053-056,058-062,065-072,075-082,084-094,096-105,107-115,118-122,124-126,128,130-131,133-137,140-145,147-155,158-161,163-167,169-180,183-184,187-191,193-194,196,198,200,203,209-212,214-215,219,221-224,226,228-233,235,239,246-247 shared\\* up infinite 18 alloc a003-006,008,011-012,015-020,031,042,064,201,204 shared\\* up infinite 21 down a057,063,074,083,106,116,129,132,139,146,156-157,168,217-218,220,225,234,236-238 Other SLURM operations like ""showpartitions"" are quite slow as well. Regards, Doug ; Hi Doug, Thank you for reporting the issue. Yes there has been an issue for job scheduling on Anvil today and our engineering team is working closely to fix it. It should be much better now. Can you confirm as well? Best regards, name Senior Computational Scientist Purdue Information Technology ; Thanks name\! Yes, it's drastically better now! Regards, Doug ---- ; Sure. Thank you for reporting this. name ;",dgc,Doug Crabill,Guangzhen Jin,Purdue University,Anvil,4,5,18,2024,2024-04-29
ATS-7963,User not found (Purdue Anvil),2024-05-07,2024-05-07,"When attempting to login to Purdue Anvil to set up my ssh keys, I am getting the error that my user (x-tyokokura) is not found. I received the email that my account was created on 5/3. This is the URL I navigated to, which I found on the support site on setting up ssh keys. https://ondemand.anvil.rcac.purdue.edu/pun/name/dashboard: https://ondemand.anvil.rcac.purdue.edu/pun/name/dashboard ; Hi Takashi, Thank you for contacting us. It seems your account on ondemand.anvil has not been fully set up for some reason. Our experts are working on this issue and I'll keep you updated. Your patience is greatly appreciated. Warm regards, name ; Hi Takashi, It seems your account should be fully set up now. Would you please try logging into Anvil Open OnDemand gateway again and let me know if you still see any errors? Thanks, name ; Hi name, It looks good! Thanks, Takashi ; Awesome! Thanks for confirming! I'll go ahead and mark this ticket resolved then. Thanks again for contacting us. Best, name ;",tyokokura@access-ci.org,Takashi Yokokura,Ruyi Li,Purdue University,Anvil,5,1,19,2024,2024-05-06
ATS-7965,Trouble login into Purdue Anvil,2024-05-07,2024-05-08,"Dear Purdue Anvil admin, Greetings. I have trouble login to Purdue Anvil system using my access id x-yge. When I login to Open Ondemand webpage, it reports an error: Error -- can't find group for 7008340 Run 'nginx\\_stage --help' to see a full list of available command line options. I am wondering if you could help me resolve this issue. Thank you. The associated access project is PHY240119. Yours sincerely, name ; Hi name, Thank you for reaching out. We found some issues with the Unix group {{x-phy240119}} on Anvil. Experts are currently investigating. I'll let you know if there are any updates. Warm regards, name ; Hi name, Our experts have corrected the error with the Unix group {{x-phy240119}}. Would you please try logging into Anvil Open OnDemand gateway again and let me know if you still see any errors? Thanks, name ; Hi name, It looks like you have successfully logged into Anvil Open OnDemand gateway. I'm tentatively marking this ticket as resolved at this point. Please feel free to contact us again if you see any issues or have any other questions. Thanks, name ;",yge,Yang Ge,Ruyi Li,Purdue University,Anvil,4,2,19,2024,2024-05-06
ATS-7986,Cannot log in to allocated node even though there is a job running on that very node!,2024-05-08,2024-05-08,"I allocated 70 CPU cores on anvil purdue yesterday. My workload is still running there. However when I woke up in the morning, I found out that I can no longer ssh into the node (a198). It gives me the error ""Access denied by pam\\_slurm\\_adopt: you have no active jobs on this node Connection closed by 172.18.88.208 port 22"" Please I do NOT want to stop the workload, but at the same time, I want to be able to access that specific node. Thanks in advance for your help, name ; Hi name, Thanks for reaching out! What is the job ID you were referring to? Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Actually never mind. The system abruptly dropped the job. I had to run the workload one more time. Thanks, name Sent from my iPhone On May 8, 2024, at 5:14 PM, ACCESS Ticket Submission wrote: | | You don't often get email from . Learn why this is important: https://aka.ms/LearnAboutSenderIdentification | | |---- \\*External Email\\*: Use caution with attachments, links, or sharing data ---- | ; Okay, thanks for letting me know. I will mark this ticket as closed. One more thing I've noticed that is your HOME directory is about to be full. It might be a good idea to clear up some space on your HOME to avoid ""disc exceeding"" error if you plan to run jobs on your HOME space. Type Location Size Limit Use Files Limit Use ============================================================================== home x-syoussef 24.4GB 25.0GB 98% - - - scratch anvil 0KB 100.0TB 0% 0k 1,000k 0.00% Regards, name ;",syoussef@access-ci.org,Samuel Youssef,Nannan Shan,Purdue University,Anvil,4,1,19,2024,2024-05-06
ATS-7794,Request for the install of library package,2024-04-27,2024-05-16,"Dear Manager of Anvil, Hi, I am a user of Anvil. When I was installing the package, I found some packages are not in Anvil but I need. I would like to request the installation of the latest version of glib-2.0 (glib-devel) as a sudo privilege if possible. If not, it is also OK to install as a module. Sincerely, Woohyeon ; Hello Regards, name ;",bwh@access-ci.org,Woohyeon Baek,Nannan Shan,Purdue University,Anvil,5,14,17,2024,2024-04-22
ATS-7922,Control job restarting behavior ,2024-05-03,2024-05-14,"Hello, My name is name Canchila, my ANVIL username is x-ccanchilamar. I'm working under the project ""CIV230007"". I'm currently experiencing constant job restarting for a couple of GPU jobs I have submitted to Purdue ANVIL GPU supercomputer. I would like to know if it is possible to avoid these restarts. For example, for the job ""4935887"", running the command ""scontrol show job 4935887"" displays: JobId=4935887 JobName=train\\_mae\\_rc\\_prm\\_imNet1k UserId=x-ccanchilamar(7941037) GroupId=x-civ230007(7008134) MCS\\_label=N/A Priority=48569 Nice=0 Account=civ230007-gpu QOS=gpu JobState=PENDING Reason=Priority Dependency=(null) Requeue=1 Restarts=4 BatchFlag=1 Reboot=0 ExitCode=0:0 RunTime=00:00:00 TimeLimit=2-00:00:00 TimeMin=N/A SubmitTime=2024-05-03T15:03:22 EligibleTime=2024-05-03T15:05:23 (...) Based on this information, this job has being restarted four times. However, these restarts make it difficult for me to keep track of my code progress and credit consumption. For instance, I don't know how long was the job running before it was restarted or requeued. If there are any guidelines or better practices I should follow to avoid these restarts, I would appreciate if you can share with me. Thanks, name ; Hi, Thank you for contacting us. Yes this job has been requeue-ed for four times but the most recent run was ""successful"" until the walltime limit. You can check details with command: sacct -XD --format=jobid,account,partition,state,submit,end,elapsed,elapsedraw,timelimit,state,nodelist%20 -j 4935887 The 'requeue' behavior was set to default by SLURM in case your workflow run into issues. You can add an option {{#SBATCH --no-requeue}} into the job submission file to disable this function for that job. Give it a try and let me know if you have further questions. Best regards, name Senior Computational Scientist Purdue Information Technology ; Thank you name, I will try and if I have any questions, I will submit a new ticket. ; Sure. Glad to help. name ;",ccanchilamartinez@access-ci.org,Carlos Canchila Martinez,Guangzhen Jin,Purdue University,Anvil,4,8,18,2024,2024-04-29
ATS-8031,Anvil job in the queue for days,2024-05-10,2024-05-14,"I submitted a job to Anvil days ago and it hasn't started yet. Normally it is name quick or at most a day. It's the same submission script as always, so I don't think that is it. ; Hi, Thank you for contacting us. The reason is that there is enough SUs balance for your allocation. Your job was submitted to {{wholenode}} with {{#SBATCH --nodes=6}} to run 6 hours so it will require a total of 6x128x6=4608 SUs but current balance is 3181.8 for your allocation {{cda110003}}. See our user guide for detailed explanation: https://www.rcac.purdue.edu/knowledge/anvil/run/partitions: https://www.rcac.purdue.edu/knowledge/anvil/run/partitions|smart-link So the solution would be either reduce the amount of max walltime or reduce the number of nodes if you still need entire nodes for the workflow. Or you might use {{shared}} partition in which you can use the amount of cores you requested (i.e. 48x6=288 cores) so that will finish within the name balance limit. Best regards, name Senior Computational Scientist Purdue Information Technology ; Got it. Thanks! L. O. ; Glad to help. name ;",lolson@access-ci.org,Lorraine G. Olson,Guangzhen Jin,Purdue University,Anvil,5,3,19,2024,2024-05-06
ATS-8061,Execute Shell command hangs ,2024-05-13,2024-05-16,"Attempts to launch an Execute shell on devnanohub exechost fail with no response. --- name Application Engineer for Scientific Computing ; The Anvil resource is a critical component for next weeks workshop ; ssh connection to 128.211.162.15 is also failing. ssh connection to the production host 128.211.162.11 is also failing --- name Application Engineer for Scientific Computing \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_ ; \\*\\*PRIVATE NOTE\\*\\* Hi name, Would you please take a look if the issue is with the composable name? Thanks, name ; Steve, there were some issues with the cluster yesterday afternoon. These are resolved now. Do you still see any problems? We're just getting all these issues out of the way before the workshop starts. 🙂 For the workshop duration, shall we just use email or Teams for direct messages instead of the ticketing system? -name ; Hi, Thank you for contacting us. I have forwarded your issue to our engineering team so they can take a closer look. Best regards, name Senior Computational Scientist Purdue Information Technology ; \\*\\*PRIVATE NOTE\\*\\* Hi~accountid:id:id-deb3-4a00-b421-44f90764017f , Please take a look at this issue and see what we can do to help. Best, name - Harbor connection is still an issue. It's your call on the communication vehicle. What ever provides the best response. --- name Application Engineer for Scientific Computing \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_ ; Hi name, I just heard that name has talked to you outside the ticketing system, and the issue with Harbor should be fixed. I'm tentatively marking this ticket as resolved at this point. If you see any other issues, please feel free to re-open the ticket or submit a new one to us. Thanks, name ;",,,Brandon Poindexter,Purdue University,Anvil,9,4,20,2024,2024-05-13
ATS-8119,Need to install cairo.h for instaling splash,2024-05-15,2024-05-16,"Hi, I have tried to install Cairo.h in my local folder for a week but it still doesn't work. I have used the other 4 HPCs before and all of them include cairo package. I think there are too many packages to install for cairo (https://cairographics.org/news/: https://cairographics.org/news/|smart-link ). Could you please help me to install it on anvil? ; Hi name, Since this ticket is duplicate with your previous ticket, ATS-7976. I would mark this as closed to keep all the communication in one place. Regards, name, PhD Senior Computational Scientist Research Computing at Purdue University ;",cchen17@access-ci.org,Cheng Chen,Nannan Shan,Purdue University,Anvil,2,2,20,2024,2024-05-13
ATS-1638,Method to allow Data Mine staff to correct groups/permissions in /anvil/project/tdm/corporate,2023-07-05,2024-05-23,"The Data Mine uses /anvil/projects/tdm/corporate to store our student's group project work. The top level subdirectories have the groups and permissions set such that students that are in the right groups can read/write files within these subdirectories. Unfortunately, students will sometimes create files within that do not inherit the right group or will not use the right permissions. This means others in their group cannot read or write these files. The Data Mine staff are currently powerless to correct these permissions/groups and must ask the individual students to correct these permissions or ask RCAC staff to correct them on our behalf. We'd like to propose a solution that allows the Data Mine Staff to correct these permissions safely, securely, and without requiring root/sudo access. The solution is to run the following script (or something like it) via cron as root, once every 15 minutes. We essentially touch a file with a specific name, and a cron job running as root checks for the existence of that file, and if it's present, removes the file and corrects the permissions in that subdirectory. The script is attached. It's currently written with an ""echo"" in front of the chgrp/chmod commands that would actually change files so you can see what it WOULD do. The ""echo"" commands would of course be removed for real use. Thoughts? Regards, Doug ; ^fixtdmperms] ; Hi Doug, Thanks for reaching out Cheers, name ; Hi name, This wasn't actually a duplicate. I had submitted a follow-up to this ticket (ATS-1966) requesting a manual correction of permissions in /anvil/project/tdm/corporate until such a time as the more complex request I had made in this ticket (ATS-1638) was complete. I spoke with name who confirmed he had NOT actually implemented this yet. Could you please re-open this ticket? Regards, Doug ; Hi Doug, Thanks for letting me know. and sorry for the misunderstanding here. It looks like we do not have problems to close https://access-ci.atlassian.net/browse/ATS-1966: https://access-ci.atlassian.net/browse/ATS-1966|smart-link but still need work on this one (ATS-1638), correct? I would talk to name again about our next plans for these requests. Thanks for your patience with us. Cheers, name ; Correct, thanks name! Regards, Doug ; Hi Doug, Just wanted to let you know that I have not forgotten about this ticket. But with name and others gone, this may take a while. 🙂 Best regards, name. ; \\*\\*PRIVATE NOTE\\*\\* Need validation that the dir in .fixperms is only inside {{/anvil/projects/tdm/corporate}} ; \\*\\*PRIVATE NOTE\\*\\* [~accountid:id We need to resolve this ticket ; We plan to implement fix permissions in the RCAC website, similar to fix permissions on data depot. Resolving for now. Regards, name. ;",dgc,Doug Crabill,Amiya Maji,Purdue University,Anvil,12,232,27,2023,2023-07-03
ATS-1811,Jobs on Anvil machine failing due to the Node Fail,2023-07-12,2024-05-23,"Hi there, Recently I am seeing my jobs on Anvil machine fail due to ""Node Fail"" and they get requeued which results in overwriting the existing data. Could you change this so that the failed jobs are not requeued? Thank you very much, Saerom name ; Hello Saerom, I believe the default behavior of SLURM is to requeue jobs with an un-earned stop (not because of a wall time limit but for things like node failures or downtime because of system admins). This is typically desirable, but I understand how that could be an issue for some workflows that aren't tolerant of this sort of behavior. As a user, I believe you can add \\*#SBATCH --no-requeue\\* to your job script to explicitly disable this behavior. Cheers. name Lead Research Data Scientist Rosen Center for Advanced Computing ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id We need to resolve this ticket ; No response from user. ;",stsr,Saerom Yu,Geoffrey Lentner,Purdue University,Anvil,4,227,28,2023,2023-07-10
ATS-8106,Don't have access to Anvil cluster ,2024-05-14,2024-05-20,"Dear Sir/Madam, Recently, I submitted a request for Anvil cluster. I even got my User there. But unfortunately, when I tried to log in, system wrote that I don't have access to it: Error -- can't find user for x-elly Run 'nginx\\_stage --help' to see a full list of available command line options. ; Hi name, Thanks for reaching out Regards, name ;",elly@access-ci.org,Ella Ivanova,Nannan Shan,Purdue University,Anvil,5,5,20,2024,2024-05-13
ATS-8200,Require VASP access on Purdue Anvil,2024-05-20,2024-05-22,"I would like to be given access to VASP 5.4 on Purdue Anvil. Our VASP license is 5-2357. ; Hi name, Thank you for reaching out to RCAC support. I checked your license and your license was valid until June 30, 2019. So, you can only have access to VASP5 and I added you to the Unix group. Best, name Senior Computational Scientist RCAC - Purdue University ; Dear name, Thank you for the help. I am unable to see the vasp5 Unix group when I run id $USER , and I still cannot load the VASP module. Is there some other action needed on my part? Thanks, name ; Hi name, Thank for reporting the problem. We are investigating this issue, and I will keep you updated when fixed. Best, name ; Hi name, The issue is fixed, and you should now have access to vasp5. Please let me know if you need further assistance. Best, name ; Hi name, I can see my access now. Thanks for your assistance. Best, name ; Perfect! Thanks for letting me know. Best, Haniey ;",gnov501@access-ci.org,Gregory Novotny,Haniye Kashgarani,Purdue University,Anvil,7,3,21,2024,2024-05-20
ATS-8248,Anvil Permissions Update,2024-05-21,2024-05-24,"Hello RCAC Team, My last day with The Data Mine is this Friday, May 24th. I'll still be using ACCESS and Anvil through a different allocation, but I wanted to make sure I have my permissions updated for The Data Mine's allocation. Could you please update any files that I own in /anvil/projects/tdm to be owned by x-dgc instead of x-dgi804. Thank you, name (he/him) ; Hi name, Thank you for contacting us. I would work on your request and let you know when it is finished. It might take a while given the large amount of files in /anvil/projects/tdm. Wish you all the best in your next endeavor Best, name ;",dgi804@access-ci.org,David Glass,Ruyi Li,Purdue University,Anvil,3,4,21,2024,2024-05-20
ATS-8249,Request for increasing file limit quota on Anvil,2024-05-21,2024-05-24,"I hope this email finds you well. We have recently been awarded an allocation of 1.5 million SUs to perform numerical simulations of ocean waves and sea levels in the Atlantic Ocean. Our numerical model employs a parallel MPI algorithm, which decomposes the computational domain into subdomains, generating input and output files for each. Consequently, the total number of open files per simulation is very large when running the model. After initial simulations on the Anvil HPC cluster, we found that with 256 cores (which is the optimum number of cores for our simulations), each simulation will generate about 347,000 open files. Although this name within the current File Counts Quota of 1,000k on the Purdue Anvil system, it limits the number of simulations we can run concurrently, hindering our research progress. I'm writing to request an increased file quota of 1.5-2 million to facilitate the concurrent execution of simulations. This adjustment would significantly enhance our project's efficiency. Thanks for considering this request. ; Hi Reza, Thank you for contacting us and sharing the details about your work. It sounds excitingimage001.png|thumbnail! ; \\*\\*PRIVATE NOTE\\*\\* Good morning, name ~accountid:id:id-6f55-4972-a4c9-1abbc8b28d3f. Would you please help increase the file number quota on \\*/anvil/scratch/x-sajal105\\* to \\*2M\\* until \\*the end of 2024\\*? Thanks! ; \\*\\*PRIVATE NOTE\\*\\* This is done. Sorry for the delay. name ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id:id-6f55-4972-a4c9-1abbc8b28d3f Thanks a lot! ; Hi Reza, Our storage expert has increased the file number quota on {{/anvil/scratch/x-sajal105}} to 2M. The increase will be good until the end of year 2024. $ myquota x-sajal105 Type Location Size Limit Use Files Limit Use ============================================================================== home x-sajal105 41.0MB 25.0GB 0.16% - - - scratch anvil 297.8GB 100.0TB 0.29% 726k 2,097k 35% projects x-ees230077 0KB 5.0TB 0% 0k 1,048k 0.00% Hope this will facilitate your research. I'm tentatively marking this ticket as resolved at this point. Please feel free to contact us again when help is needed. Thanks, name ;",rezamar@access-ci.org,Reza Marsooli,ramonw,Purdue University,Anvil,7,4,21,2024,2024-05-20
ATS-7205,can not find wannier90 lib file ,2024-04-01,2024-05-29,"Dear Admin, When I compile vasp+wannnier90 on Anvil, I can not find the wannier90 lib file in '/apps/spack/anvil/external/vasp/wannier90-3.1.0-gcc-11.2.0'. I wonder if you can share the make.inc with me for wannier90. If so, I can compile wannier90 by myself. Best, Ruiqi ; Hi Ruiqi, Thanks for reaching out Regards, name ;",zrqustc@access-ci.org,Ruiqi Zhang,Nannan Shan,Purdue University,Anvil,8,43,14,2024,2024-04-01
ATS-7905,Archival storage,2024-05-03,2024-05-30,"hello We've a new allocation on Anvil (mth240010) that we'd requested archival storage for as well in the proposal. However, we did not receive a response on that part of the proposal, as to what resource would be best to use for large data-sets that need to accessed periodically on Anvil. The total data size is about 40TB. I understand the project has 5TB project storage by default. I am writing to inquire, if there is some way to be allocated a larger Project storage in, perhaps in exchange for ACCESS credits. If not, is there an archival storage system at Purdue that is accessible through Anvil? What do you recommend for archival storage for the data generated on Anvil/ Thank you for your time. Sincerely Sualeh ; Hi, Thank you for contacting us. Yes /anvil/projects will be the major space for project data storage. Do you have a time period in mind that until when will your workflow require this 40TB space for the dataset? Best regards, name Senior Computational Scientist Purdue Information Technology ; Many thanks for the response. We'll need the project space for about a year. Beyond that, do you guys provide any archival storage ? ---- ; OK. I will submit this request to our storage experts so they could review and decide whether it's doable. No we don't have any archival storage for Anvil. name ; Just noticed you are not the PI of this project. Since it's a request for entire project space, we will need the request from the PI. Could you contact Prof. Themistoklis Sapsis and ask him to submit the increase request? name ; Many thanks for helping with this. I am copying Prof. Sapsis with this email and he'll get in touch with you as well. Prof. Sapsis Can you please reply to the below email requesting an increase in our Project storage on Anvil from 5TB to 40TB. This will give us long term storage on anvil Sualeh ---- ; Thank you Sualeh. Indeed it would be great if we can get this space increase. Thanks Themis Sapsis On May 14, 2024, at 4:48 PM, Sualeh Khurshid wrote: Many thanks for helping with this. I am copying Prof. Sapsis with this email and he'll get in touch with you as well. Prof. Sapsis Can you please reply to the below email requesting an increase in our Project storage on Anvil from 5TB to 40TB. This will give us long term storage on anvil Sualeh ---- ; Hi, Sorry I was out of office last week. Your request has been received. I will contact our storage team and they will take a look at this request then decide if it's OK. Will get back to you after the discussions. name ; Hi ~accountid:id:id-660f-4a53-a67a-50036106f59a:c80d5f28-57a5-4242-b961-f5b3cfe3ba6e and ~accountid:id:id-660f-4a53-a67a-50036106f59a:e943320a-b6f0-46a0-83f1-0b3ccaa016c6 , According to our storage team, we will need to gather more information from you about this increase as it's asking for 8 times' increase. Could you share more information about why this increase is necessary and are there any workaround workflows that can be done with less storage? Thank you, name ; Hello Thank you for getting back to us. We currently are using unstructured (adaptive grid refinement) global climate simulation data for 10 years to train a neural network on the structured counterpart. This training setup includes reanalysis data (real world) which is assimilated in a climate simulation to generate global predictions. The unstructured data for reanalysis and unstructured simuilation are 3 TB each. The unstructred data is then projected to a structured grid (interpolated to a finer grid) and created new data sets for each of these which are 6.5TB each. We then train the neural networks on this structured data and use the trained networks to generate predictions of a separate set of 10 year global climate data (to enable climate predictions into the future). The inference input data and neural network output are 6.5TB each. Currently we're redoing this training to understand the uncertainty in the neural network predictions and therefore need all datasets available on Anvil. Once the training and UQ are complete, we are moving the data to a local computer for postprocessing. We've also moved the unstructured raw files to a local system already. In addition to above, we are extending the same project to 40 years of data instead of 10 years only. This will have the same data structure as before, so we need all the data available on Anvil for some time as the projection from structured to unstructured takes time (multiple weeks) as well as each training and inference. This is not possible to complete with the current limit of 30 days on scratch and 5TB in project directory is far too less space. Hope this explains the need. If you need any more information or clarification, please let us know Sualeh ---- ; Hi, Thank you for the details. That makes sense to me. Our storage experts have increased your project quota limit to 40TB until the end of this allocation (approximately 2025-03-18). Please check and let us know if there is other question. Best, name ;",sualeh@access-ci.org,Sualeh Khurshid,Guangzhen Jin,Purdue University,Anvil,11,20,18,2024,2024-04-29
ATS-7930,VTST Tools installation in VASP,2024-05-04,2024-05-30,"ACCESS support team, I am working on a project using VASP and need to use a program called VTST Tools for solid state CI-NEB calculations https://theory.cm.utexas.edu/vtsttools/installation.html: https://theory.cm.utexas.edu/vtsttools/installation.html|smart-link This software needs to be compiled in the VASP source code. Any advice on the best way to proceed would be greatly appreciated. Regards, Nikolas Gaugler ; Hi Nikolas, Thanks for reaching out! I am wondering which version of VASP you were trying to compile with vtst. Is it vasp5 or vasp6? Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; name, Thank you for the reply! We are using the vasp6 build on anvil and using our own vasp5 POTCAR files. Regards, Nik Gaugler ; Hi Nik, If you want to compile vtst with vasp6, I think you can reference the guidance on vtst website, all you need to do is to modify the main.F file. It should be straightforward. Please let me know if you encounter issues. https://theory.cm.utexas.edu/vtsttools/installation.html After you modified the file, you can follow our user guide to build VASP on Anvil. https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/vasp/build\\_your\\_own\\_vasp\\_6 Regards, name, Thank you for the response and advice. I will let you know if I have any other questions. Regards, Nik Gaugler ;",ngaugler@access-ci.org,Nikolas Gaugler,Nannan Shan,Purdue University,Anvil,5,19,18,2024,2024-04-29
ATS-8065,MPFR library 4.2.1 on Purdue-Anvil,2024-05-13,2024-05-29,"Dear admin, I am trying to run a name application on Anvil. However, I cannot install the packing due to missing MPFR library. I just checked and found that Anvil carrently support MPFR-4.0.2 https://www.rcac.purdue.edu/software/mpfr: https://www.rcac.purdue.edu/software/mpfr|smart-link Is it possible to have a newer version like 4.2.1? https://www.mpfr.org/mpfr-current/: https://www.mpfr.org/mpfr-current/|smart-link Best, name ; Hi, Thank you for contacting us. We might not be able to do the version upgrade centrally if that's not the request from lots of users. However, since it's an open source software you should be able to download and install the new version by yourself in your own space and use it. Let me know if you have further questions. Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi, Since we haven't heard feedback from you for some time, I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name ;",qiangz@access-ci.org,Qiang Zhu,Guangzhen Jin,Purdue University,Anvil,3,13,20,2024,2024-05-13
ATS-8363,File number quota on Anvil,2024-05-29,2024-05-29,"Hi-- Can I get my file number limit increases on Anvil? The current batch of simulations I'm running write a large number of files per data dump, and I'm having trouble writing data because I run into the 100,000 file count limit very quickly. Is it possible to get this increased to 500,000? Thanks! d. ; name, I assume you mean 5,000,000 not 500,000 as the default file quota is 1,000,000. I have set your quota to 5,000,000. name Senior Research Solutions Engineer ;",dcollins@access-ci.org,David Collins,,Purdue University,Anvil,2,1,22,2024,2024-05-27
ATS-7325,running job in Purdue Anvil,2024-04-07,2024-06-06,"Hello ACCESS support team, I am having some issue with running jobs in Purdue Anvil. After running the job file it always show me the following error although previously it was working properly. I could not find out what is the exact reason for this error. Please let me know if you have any suggestion for me. Thank you, Delower ""At line 761 of file xmltools.f90 Fortran runtime error: Bad real number in item 1220 of list input Error termination. Backtrace: #0 0x153765a58aa7 in read\\_real at /tmp/rcactest/spack-stage-gcc-11.2.0-qjtdkvszjnmbsopeuflhtcmqex5fyagb/spack-src/libgfortran/io/list\\_read.c:2026 #1 0x153765a59e2c in list\\_formatted\\_read\\_scalar at /tmp/rcactest/spack-stage-gcc-11.2.0-qjtdkvszjnmbsopeuflhtcmqex5fyagb/spack-src/libgfortran/io/list\\_read.c:2180 #2 0x98a905 in \\_\\_xmltools\\_MOD\\_readtag\\_rv at /tmp/rcactest/spack-stage-quantum-espresso-6.7-4w5v7zq7qv4aciqpem7b7fxubck6xv2w/spack-src/upflib/xmltools.f90:761 #3 0x97052a in \\_\\_read\\_upf\\_new\\_module\\_MOD\\_read\\_pp\\_nonlocal at /tmp/rcactest/spack-stage-quantum-espresso-6.7-4w5v7zq7qv4aciqpem7b7fxubck6xv2w/spack-src/upflib/read\\_upf\\_new.f90:452 #4 0x973316 in \\_\\_read\\_upf\\_new\\_module\\_MOD\\_read\\_upf\\_new at /tmp/rcactest/spack-stage-quantum-espresso-6.7-4w5v7zq7qv4aciqpem7b7fxubck6xv2w/spack-src/upflib/read\\_upf\\_new.f90:103 #5 0x7a9cd6 in \\_read\\_pseudo\\_mod\\_MOD\\_readpp\\_ \\_at /tmp/rcactest/spack-stage-quantum-espresso-6.7-4w5v7zq7qv4aciqpem7b7fxubck6xv2w/spack-src/Modules/read\\_pseudo.f90:131\\_ \\_#6 0x4c348c in iosys\\_ at /tmp/rcactest/spack-stage-quantum-espresso-6.7-4w5v7zq7qv4aciqpem7b7fxubck6xv2w/spack-src/PW/src/input.f90:1564 #7 0x560c96 in run\\_pwscf at /tmp/rcactest/spack-stage-quantum-espresso-6.7-4w5v7zq7qv4aciqpem7b7fxubck6xv2w/spack-src/PW/src/run\\_pwscf.f90:93 #8 0x40ddb3 in pwscf at /tmp/rcactest/spack-stage-quantum-espresso-6.7-4w5v7zq7qv4aciqpem7b7fxubck6xv2w/spack-src/PW/src/pwscf.f90:106 #9 0x40dbbc in main at /tmp/rcactest/spack-stage-quantum-espresso-6.7-4w5v7zq7qv4aciqpem7b7fxubck6xv2w/spack-src/PW/src/pwscf.f90:40 srun: error: a685: task 0: Exited with exit code 2 srun: Terminating StepId=4771212.0 slurmstepd: error: \\*\\*\\* STEP 4771212.0 ON a685 CANCELLED AT 2024-04-07T21:29:34 \\*\\*\\* srun: error: a685: tasks 1,3,5,7,9,11,15,25,27,29,31: Terminated srun: error: a685: tasks 2,4,6,8,10,12-14,16-24,26,28,30,32-127: Terminated srun: Force Terminated StepId=4771212.0"" ; ^job.txt ; Hi, Thank you for contacting us. Just to doublecheck before we investigate the root cause, is it a reproducible issue for you and it's still happening or it's just a one-time error? Best regards, name Senior Computational Scientist Purdue Information Technology ; Hello name, Yes, I just run a job and having the same issue. Its strange, for six months or so I have been using this job file without any issue. I could not remember the exact date when it stopped working, most likely 2-3 weeks back from today. Thank you, Delower ; Hi, Not sure what happened in the backend yet but could you try newer version of {{quantum-espresso}} (v7.2) and see how it works? Simple put the following commands into your job submission instead of the previous version. module load gcc/11.2.0 openmpi/4.1.6 quantum-espresso/7.2 name ; Hi, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name ;",delower@access-ci.org,Mohammad Delower Hossain,Guangzhen Jin,Purdue University,Anvil,6,44,14,2024,2024-04-01
ATS-7390,Different behavior on debug and wholenode queues,2024-04-10,2024-06-06,"Hi, I have been running our group's CFD code on Anvil, and I'm experiencing different behavior depending on if I run in the debug queue or the wholenode queue. I'm able to run my job with no issues on 2 nodes in the debug queue, however when I change the queue to the wholenode queue, my job crashes. The only change in my entire setup between the two tests is changing the queue name from debug to wholenode in the job submission script. I'm wondering if there are any expected differences between the nodes assigned to the two different queues? I've attached the standard output and error files when my job crashes in the wholenode queue, as well as the job script. Thanks, Chinmay Upadhye ; ^PC2\\_Anvil\\_Testing.txt ^Precice.e4802739 ^Precice.o4802739 ; Hi Chinmay, Thanks for reaching out! I have passed your questions to our scientist who is familiar with CFD modeling. You will hear from us later about suggestions. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Hi, Thank you for contacting us. I assume the error files were from the failed job on {{wholenode}}. Could you also share the outputs from the successful run on {{debug}} partition and the jobid so I can take a closer look? Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi, Yes, the error files I had attached previously were from the failed wholenode job. I've attached the same outputs from the debug job here. The jobid for the wholenode job was: 4802739 The jobid for the debug job was: 4802734 ^Precice.e4802734 ^Precice.o4802734 Thanks, Chinmay ; Hi, Sorry for the delay. Another difference I saw for the two jobs are the number of nodes and cores they requested. Can you try with 1 node on {{wholenode}} (just {{#SBATCH -N 1}}, without specifying number of tasks with {{-n}}) and see how it works? Another factor that might affect is the compiler you used for the workflow. Generally, if the code is built with OpenMPI, it can be run with a simple {{srun -n}} command. If it is built with Intel IMPI, then you also need to add the {{--mpi=pmi2}} option: {{srun --mpi=pmi2 -n 256 ./mycode}} . Also, if the current workflow was compiled on other platforms, I would highly suggest to re-compile them on Anvil (gcc+openmpi would be my first choice). Let me know if you can find anything. name ;",chinmayu@access-ci.org,Chinmay Upadhye,Guangzhen Jin,Purdue University,Anvil,6,42,15,2024,2024-04-08
ATS-7896,Awaiting account setup on Purdue Anvil,2024-05-02,2024-06-06,"Dear admin, I have been allocated CPU times on the Purdue Anvil cluster through Access. I am wondering if additional step needs to be taken since I have not been able to login to Anvil via Open Ondemand, according to their guide. It seems that my username x-yge does not exist on Anvil. Thank you for your help and patience. Yours faithfully, name ; Hi, Thank you for contacting us. I saw you are already having ondemand files under your home directory so can you confirm it is working as expected for you right now? FYI: It will usually take several days for the account propagation. Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name ;",yge@access-ci.org,YANG GE,Guangzhen Jin,Purdue University,Anvil,3,26,18,2024,2024-04-29
ATS-7945,Job submission,2024-05-06,2024-06-06,"Hi, I have submitted the Amber job in the cluster. However, my submitted job automatically got cancelled and then resubmitted automatically. Could you please check? Current job id JOBID USER ACCOUNT NAME NODES CPUS TIME\\_LIMIT ST TIME 5040966 x-abhatt bio240109-gpu new\\_co\\_tens15 1 1 2-00:00:00 R 2:28:12 5041019 x-abhatt bio240109-gpu fitting\\_15 1 1 2-00:00:00 R 2:28:12 ; Hi, Thank you for contacting us. Yes both jobs have been requeue-ed but there is no direct reason for that. Most likely something wrong happened during the simulations. Have you seen any error messages? Please share those information if yes. If you don't want jobs to be 're-submitted' while meeting with errors, you could append {{#SBATCH --no-requeue}} into your job submission. Best regards, name Senior Computational Scientist Purdue Information Technology ; Hello name, I have not seen any error message but I always got this requeue error. I will put this command #SBATCH --no-requeue. Hopefully I will not get any error. Thank you for the help Regards, Aashish ---- ; Sure. Feel free to let me know if you saw any error messages. If that's related to hardware/system issues, we could refund the wasted SUs. name ; Hello name, Currently, there are no errors, but before sending this email to you, I lost several hours on these tasks. If possible, could you please refund the name? Regards, Aashish ---- ; Which jobs did you refer to when you ""lost several hours on these tasks""? I can check them and refund the SUs. name ; Dear name, I am writing to provide details regarding the cancelled jobs you requested information about. Below are the specifics: Slurm Job\\_id=5041019 Name=fitting\\_15 Began, Queued time 00:27:29 5th Sunday 9:38 Am Slurm Job\\_id=5041019 Name=fitting\\_15 Failed, Run time 19:51:19, NODE\\_FAIL, ExitCode 0 6th Monday 5:29 Am Slurm Job\\_id=5041019 Name=fitting\\_15 Requeued, Run time 19:51:19 6th Monday 5:32 Am Slurm Job\\_id=5041019 Name=fitting\\_15 Began, Queued time 00:02:54 6th Monday 5:43 Am \\*Slurm Job\\_id=5040966 Name=new\\_co\\_tens15 Began, Queued time 00:22:34 5th Sunday 8:54 Am\\* \\*Slurm Job\\_id=5040966 Name=\\* \\*new\\_co\\_tens15\\* \\*Failed, Run time 20:34:43, NODE\\_FAIL, ExitCode 0 6th Monday 5:29 Am\\* \\*Slurm Job\\_id=5040966 Name=\\* \\*new\\_co\\_tens15\\* \\*Requeued, Run time 19:51:19 6th Monday 5:32 Am\\* \\*Slurm Job\\_id=5040966 Name=\\* \\*new\\_co\\_tens15\\* \\*Requeued, Run time 00:10:43\\* \\*6th Monday 5:43 Am\\* Please let me know if you require any further details regarding these cancelled jobs. I am here to help. Regards, Aashish ---- ; Hi, Got it. I can go ahead and refund the total SUs (116.25) spent on the two jobs if that sounds good for you. name refund has been performed. Marking ticket as resolved. ;",abhatt@access-ci.org,AASHISH BHATT,Guangzhen Jin,Purdue University,Anvil,9,24,19,2024,2024-05-06
ATS-8352,Extremely slow parallel jobs,2024-05-28,2024-06-20,"Dear Access Support, When I try to run a LAMMPS job in parallel (three threads, OPENMP) on Anvil, it runs extremely slowly, as in, two orders of magnitude slower than if I just run it in serial. I'm using the same SLURM options as I've been using successfully on my local cluster, but I'm wondering if I need to use different options on Anvil, or to load different modules. My submission script is attached. Currently Loaded Modules: # xalt/2.10.45 (S) 2) modtree/cpu 3) gmp/6.2.1 4) mpfr/4.0.2 5) mpc/1.1.0 6) gcc/10.2.0 7) zlib/1.2.11 8) numactl/2.0.14 9) libfabric/1.12.0 10) openmpi/4.0.6 11) cmake/3.20.0 (The same thing occurred with gcc/11.2.0 relevant because I tried re-compiling LAMMPS with both versions of GCC to see if one of them avoided this issue, but neither did]. As an unrelated aside, when compiling some C++ code, gcc/11.2.0 threw up an error saying it couldn't find the library while gcc/10.2.0 found it without issue) Do you see anything in my modules or job script that could explain this behaviour? Best wishes, name ; Hi name, Thank you for reaching out. To help us investigate, would you please share the IDs of the jobs in question as well? Thanks, name ; Dear name, Thank you for offering your help with this! I had cancelled all my jobs, since they were never going to finish. I've now submitted job 5261176\\_0 for the sake of serving as an example. Best wishes, name ; Hi name, Thanks! I've escalated your ticket to our scientist in Computational Chemistry. She would look into the issue and contact you later. Warm regards, name ; Hi name, Thanks for reaching out! Can you register one of our Anvil Support Hour? In this way, we can talk about your question over a Zoom meeting. [https://www.rcac.purdue.edu/anvil/anvil-support-hour|https://www.rcac.purdue.edu/anvil/anvil-support-hour|smart-link Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Hello! Since we did not hear from you, we are considering this ticket as resolved for now. However, if you still require assistance with this issue, please reply within the next 7 days and we will keep the ticket open. After that period, please feel free to reach out to us and create a new ticket at any time. Regards, name ; Hi, I was too late to get a slot last Thursday and I'm not available this Thursday, so I'm waiting to book a slot for the 20th, hence my lack of reply. Sorry for the confusion. Best wishes, name ; Hi name, Are you able to join Anvil Support Hour today (2pm-2:20pm EST). Feel free to join the Zoom meeting. Join Zoom Meeting https://purdue-edu.zoom.us/j/91663753188?pwd=WUJKdHAwNFpoTkZGMERYOHRKL3JEQT09: https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fpurdue-edu.zoom.us%2Fj%2F91663753188%3Fpwd%3DWUJKdHAwNFpoTkZGMERYOHRKL3JEQT09&data=05%7C02%7Cnshan%40purdue.edu%7Cf73875811c5b4fe2ce0608dc8c0e3e6d%7C4130bd397c53419cb1e58758d6d63f21%7C0%7C0%7C638539240008487384%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&sdata=1lzxvyCs%2B1Fmqk4l1EzV14m2Bm5kA8moCBzVWfJ2fUo%3D&reserved=0 Meeting ID: 916 6375 3188 Passcode: 459597 Regards, name ; Hi name, Since you did not show up on Anvil Support Hour 2-2:20pm EST today (June 20, 2024), I assume the problem has been resolved. Please let me know if you have further questions. Regards, name ;",rchacko@access-ci.org,Rahul Chacko,Nannan Shan,Purdue University,Anvil,10,18,22,2024,2024-05-27
ATS-8500,vasp not running on specific partition,2024-06-04,2024-06-19,"Hi there, I have compiled my own version of vasp. It works perfectly when I submit to the debug queue. However, when I change to wholenode or shared, vasp does not run. I see repeated output like this: Assertion failed in file ../../src/mpid/ch4/src/intel/ch4\\_shm\\_coll.c at line 1477: node\\_info->numa\\_num <= ((MPIDI\\_SHMGR\\_SYNCPAGE\\_SIZE / MPIDI\\_SHMGR\\_FLAG \\_SPACE) - 1) Assertion failed in file ../../src/mpid/ch4/src/intel/ch4\\_shm\\_coll.c at line 1477: node\\_info->numa\\_num <= ((MPIDI\\_SHMGR\\_SYNCPAGE\\_SIZE / MPIDI\\_SHMGR\\_FLAG\\_SPACE) - 1) /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(MPL\\_backtrace\\_show+0x34) 0x14f88e9b7154] /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(MPIR\\_Assert\\_fail+0x21) 0x14f88dfbe271 /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(+0x23c7db) 0x14f88e0f07db /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(+0x2d41a4) 0x14f88e1881a4 /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(MPI\\_Barrier+0x26e) 0x14f88dfcbb8e /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/libmpifort.so.12(pmpi\\_barrier+0xc) 0x14f88efa173c /home/x-coses/bin/vasp\\_std() 0x419ef0 /home/x-coses/bin/vasp\\_std( Abort(1) on node 118: Internal error /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(MPL\\_backtrace\\_show+0x34) 0x151304981154 /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(MPIR\\_Assert\\_fail+0x21) 0x151303f88271 /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(+0x23c7db) 0x1513040ba7db /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(+0x2d41a4) 0x1513041521a4 /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(MPI\\_Barrier+0x26e) 0x151303f95b8e /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/libmpifort.so.12(pmpi\\_barrier+0xc) 0x151304f6b73c /home/x-coses/bin/vasp\\_std() 0x419ef0 /home/x-coses/bin/vasp\\_std( Abort(1) on node 91: Internal error Assertion failed in file ../../src/mpid/ch4/src/intel/ch4\\_shm\\_coll.c at line 1477: node\\_info->numa\\_num <= ((MPIDI\\_SHMGR\\_SYNCPAGE\\_SIZE / MPIDI\\_SHMGR\\_FLAG\\_SPACE) - 1) Assertion failed in file ../../src/mpid/ch4/src/intel/ch4\\_shm\\_coll.c at line 1477: node\\_info->numa\\_num <= ((MPIDI\\_SHMGR\\_SYNCPAGE\\_SIZE / MPIDI\\_SHMGR\\_FLAG\\_SPACE) - 1) /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(MPL\\_backtrace\\_show+0x34) 0x14e6be425154 /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(MPIR\\_Assert\\_fail+0x21) 0x14e6bda2c271 /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(+0x23c7db) 0x14e6bdb5e7db /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(+0x2d41a4) 0x14e6bdbf61a4 /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(MPI\\_Barrier+0x26e) 0x14e6bda39b8e /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/libmpifort.so.12(pmpi\\_barrier+0xc) 0x14e6bea0f73c /home/x-coses/bin/vasp\\_std() 0x419ef0 /home/x-coses/bin/vasp\\_std( It is very strange that this is specific to the partition. Am I missing something in the compilation? Is it possible some of the nodes do not have the same shared libraries? Any help would be greatly appreciated. For reference, I created two directories, one running with debug and the other with wholenode. debug (still running): /home/x-coses/scratch/XBENCHMARKS/AFLOW/LIB2.5.4.4/LIB/ClNa\\_sv/AB\\_cF8\\_225\\_a\\_b.AB wholenode: /home/x-coses/scratch/XBENCHMARKS/AFLOW/LIB2.5.4.4/LIB/ClNa\\_sv/AB\\_cF8\\_225\\_a\\_b.AB\\_STD The submission scripts are called xbatch\\_iaflow\\_debug.sh and xbatch\\_iaflow.sh, respectively. I include a snapshot of the diff between the two submission files to show there is no difference. Best regards, name ; Hi name, Thank you for contacting us. I've escalated your ticket to our expert in VASP. She would look into the issue and contact you later. Warm regards, name ; Dear name, I wanted to follow up, can you please provide me with the VASP contact? Thanks, name -- Dr. name Oses Assistant Professor Department of Materials Science and Engineering Johns Hopkins University [entropy4energy.ai|https://entropy4energy.ai/ ; Hi name, Thanks for reaching out Regards, name ; Thanks name Regards, name ;",coses@access-ci.org,Corey Oses,Nannan Shan,Purdue University,Anvil,12,12,23,2024,2024-06-03
ATS-7948,"Though following the guide to use Purdue Anvil, but cannot login to the on demand page. ",2024-05-06,2024-06-06,"I am following the guide here: https://www.rcac.purdue.edu/knowledge/anvil/access/login/ood: https://www.rcac.purdue.edu/knowledge/anvil/access/login/ood|smart-link , and enters by access id and password, but the webpage then jumps to a new page and says: Error -- can't find user for x-sliang4 Run 'nginx\\_stage --help' to see a full list of available command line options. ; Hi, Thank you for contacting us. Your account was not propagated to Anvil system so I just re-added you. Please allow another day or two for the system propagation. Let me know if you still cannot access Anvil Open Ondemand next week. Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name ;",sliang4,Shanchao Liang,Guangzhen Jin,Purdue University,Anvil,4,24,19,2024,2024-05-06
ATS-8768,unable to install some packages for R,2024-06-18,2024-06-19,"I am writing as I need your help. I am trying to use Anvil for data processing. I need ""raster"" and ""terra"" packages in R. But I am not able to install them on my own space. This is the error I get: ""configure: error: libproj or sqlite3 not found in standard or given locations."" I have already loaded geos, gdal, and proj. It seems that I also need sqlite. But there is no sqlite module available to be loaded. I would appreciate your help on installing raster and terra packages. These are important and efficient for general geospatial data analysis. ; Hi Iman, Thank you for contacting us. I just did some tests on Anvil and could see the same error when trying to install the ""raster"" and ""terra"" packages. To resolve the issue, you could try installing sqlite3 in your home directory. If you need help with that, please let me know. Warm regards, name ; Dear name, Thanks a lot! Would you please point to some instructions on how to install sqlite3? When I try to install it in R, I get the following error: Selection: 68 Warning message: package 'sqlite3' is not available for this version of R A version of this package for your version of R might be available elsewhere, see the ideas at https://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Installing-packages: https://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Installing-packages Iman \\*From:\\* ACCESS Ticket Submission \\*Sent:\\* Tuesday, June 18, 2024 2:15 PM \\*To:\\* Haqiqi, Iman \\*Subject:\\* ATS-8768 unable to install some packages for R | | You don't often get email from : mailto:. Learn why this is important: https://aka.ms/LearnAboutSenderIdentification | | | ---- \\*External Email\\*: Use caution with attachments, links, or sharing data ---- | —-—-—-— Reply above this line. name commented: Hi Iman, Thank you for contacting us. I just did some tests on Anvil and could see the same error when trying to install the ""raster"" and ""terra"" packages. To resolve the issue, you could try installing sqlite3 in your home directory. If you need help with that, please let me know. Warm regards, name ---- Automation for Jira changed the status to Waiting for customer. View request: https://access-ci.atlassian.net/servicedesk/customer/portal/2/ATS-8768?token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ0Z3QiOiJhbm9ueW1vdXMtbGluayIsInFzaCI6ImFkNzE1Y2ZiMmIzNzcwMTY2NDQxMGIyNWJlOWFlZWI2MDBkNDc4Njc1NmRhOGM1OTJiNDc2Y2U1ZDAxMTk0Y2YiLCJpc3MiOiJzZXJ2aWNlZGVzay1qd3QtdG9rZW4taXNzdWVyIiwiY29udGV4dCI6eyJ1c2VyIjoiMTU1MjMiLCJpc3N1ZSI6IkFUUy04NzY4In0sImV4cCI6MTcyMTE1MzcyNywiaWF0IjoxNzE4NzM0NTI3fQ.ympwcFDnredBa9nK7W-5xu8988Urolw57nmcBbajLVQ&sda\\_source=notification-email · Turn off this request's notifications: https://access-ci.atlassian.net/servicedesk/customer/portal/2/ATS-8768/unsubscribe?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ0Z3QiOiJhbm9ueW1vdXMtbGluayIsInFzaCI6ImI3Mzg2MTNjZDEyOTgwNmIwMTMyNDk5MjFiMTY5N2M0YTE0MjkyNzRlNTgxNjUxMGIxYmE5ZDA3NmVhOWRjNTIiLCJpc3MiOiJzZXJ2aWNlZGVzay1qd3QtdG9rZW4taXNzdWVyIiwiY29udGV4dCI6eyJ1c2VyIjoicW06YjkxYzliMTctNjYwZi00YTUzLWE2N2EtNTAwMzYxMDZmNTlhOjBjOTdlZGE1LTVmODMtNDk4NS04MGU5LWI3NTJhODkzODE0YiIsImlzc3VlIjoiQVRTLTg3NjgifSwiZXhwIjoxNzIxMTUzNzI3LCJpYXQiOjE3MTg3MzQ1Mjd9.yNU23k6kcM7Dsw-YbB-NRbber8y7pHNNcEHWZdsjnFk This is shared with : mailto:. Sent on June 18, 2024 1:15:27 PM CDT ; Need to finalize computation for NSF project report. I need to have terra package in R on Anvil. ; Hi Iman, Apologies that I had meetings yesterday afternoon and this morning. SQLite is a C-language library and could not be installed using ""install.packages()"" in R. Instead, you may try installing it in your home directory via the following steps: # Create a directory for applications, for example: {{$ mkdir ~/apps && cd ~/apps}} # Download the source code: {{$ wget https://sqlite.org/2024/sqlite-autoconf-3460000.tar.gz}} # Extract the files: {{$ tar -xvf sqlite-autoconf-3460000.tar.gz}} # Configure and install: {{$ cd sqlite-autoconf-3460000}} {{$ ./configure --prefix=/home/x-ihaqiqi/apps}} {{$ make}} {{$ make install}} # Add locations to the environment variables: By now, {{sqlite3}} should be installed in your {{~/apps}} directory, which is not a conventional location for libraries - - you would need to add the corresponding locations to some environment variables, so that it can be used. To do that, you may add the following lines in your {{~/.bashrc}} file: {{export PATH=""$PATH:/home/x-ihaqiqi/apps/bin""}} {{export LD\\_LIBRARY\\_PATH=""$LD\\_LIBRARY\\_PATH:/home/x-ihaqiqi/apps/lib""}} {{export LIBRARY\\_PATH=""$LIBRARY\\_PATH:/home/x-ihaqiqi/apps/lib""}} {{export CPATH=""$CPATH:/home/x-ihaqiqi/apps/include""}} {{export MANPATH=""$MANPATH:/home/x-ihaqiqi/apps/share/man""}} {{export PKG\\_CONFIG\\_PATH=""$PKG\\_CONFIG\\_PATH:/home/x-ihaqiqi/apps/lib/pkgconfig""}} # Start a new login session, so that the newly added settings in {{~/.bashrc}} can take effect. Then you can try to install the R packages ""terra"" and ""raster"". If you run into any issues, please let me know and I would be happy to arrange a virtual meeting with you for it. Thanks, name ; Thanks a lot for detailed step-by-step instructions! It worked! Iman ; Great! Glad to hear that. I'll mark this ticket resolved then. Please feel free to contact us again if you have any other questions. Warm regards, name ;",ihaqiqi@access-ci.org,Iman Haqiqi,Ruyi Li,Purdue University,Anvil,7,2,25,2024,2024-06-17
ATS-8496,ANVIL compiling OpenACC version of VASP & Coffee hour consultation ,2024-06-04,2024-06-05,"Dear Anvil help team, My name is Saerom name and my user name is x-stsr. I need a help on compiling the OpenACC version of VASP to run on a GPU node. I'd like to know the environment and the compiler options. Could you give me a compilation instructions? If you could provide a makefile.include as in the link (https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/vasp/build\\_your\\_own\\_vasp\\_6) that would be great. I could not find any VASP-GPU related article on the Anvil website. I tried to sign-up for the coffee hour consultation for this, but was unable to do so because it requires a login to the Purdue system, which I am not a part of. I appreciate your help in advance. Best, Saerom name ; Hi Saerom, Thank you for contacting us. Would you please try signing up for Anvil Support Hour via the below link? https://purdue.ca1.name.com/jfe/form/SV\\_0c7EMtiyOWjuG0K: https://purdue.ca1.name.com/jfe/form/SV\\_0c7EMtiyOWjuG0K|smart-link It should not ask you to log into Purdue system. If it does not work for you, please let me know. Warm regards, name ; Hi name, I was able to sign up through the link. Thank you for your help. Best, Saerom ; Hi Saerom, Awesome! Thanks for letting me know! Our expert would assist you with VASP compilation at the support hour. I'm tentatively marking this ticket as resolved at this point. Thanks, name ; \\*\\*PRIVATE NOTE\\*\\* On Anvil Support Hour, I shared we should use {{nvhpc}} for the GPU VASP compilation according to VASP official website. Right now, the current {{nvhpc}} module ({{nvhpc/21.7}}) does not work because it does not include mpi library. I will deploy new version of {{nvhpc/23.3}} soon on Anvil, which can be used for GPU VASP installation. Or I shared user can install the {{nvhpc}} with {{mpi}} on their own project space for this purpose. In addition, we talked about the makefile for the compilation. I shared to Saerom and how to setup the tags in makefile.include for GPU VASP installation. User said they will try to install {{nvhpc}} while they are waiting for the new {{nvhpc}} module on Anvil. ;",stsr@access-ci.org,Saerom Yu,Ruyi Li,Purdue University,Anvil,5,2,23,2024,2024-06-03
ATS-8497,"""myquota"" command on Purdue Anvil has stopped working",2024-06-04,2024-06-06,"The ""myquota"" command on Anvil, which should return the quota of the different file systems, has stopped working. Nothing about my module environment etc. has changed on my end, however the command now returns: Type Location Size Limit Use Files Limit Use ============================================================================== "")syntax error: invalid arithmetic operator (error token is "" (standard\\_in) 1: syntax error FILELIMITH "")syntax error: invalid arithmetic operator (error token is "" (standard\\_in) 1: syntax error FILELIMITH home x-jbamber 19.2GB 25.0GB 77% - - - KB userKB 0% 0k k 0% KBfilesetKB 0% 0k k 0% As this is a built-in command on Anvil, I don't think I can fix this myself. ; Hi Jamie, Thank you for reaching out. I just did a test on {{login05.anvil.rcac.purdue.edu}} -- {{myquota}} worked for me with no issues. To help us investigate, would you please let us know on which host(s) you got the error? Warm regards, name ; Debugging your issue, I found that line 37 (and probably 38) of your .bashrc causes an error in bash, which is why the output is weird. Those lines are: bind '""\eA"": history-search-backward' bind '""\e[B"": history-search-forward' And the error I see is: /home/x-jbamber/.bashrc: line 37: bind: warning: line editing not enabled If you comment out those lines it should work for you. name Senior Research Solutions Engineer ; Dear name, Thank you very much for finding the issue. best wishes, Jamie On 4 name 2024, at 13:02, ramonw <[: mailto: wrote: ; Hi Jamie, I'm writing to let you know that we've also modified {{myquota}}, so that users' startup files won't get in the way. Since the issue has been fixed, we'll go ahead and close this ticket out. Thanks, name ;",jbamber@access-ci.org,Jamie Bamber,Ruyi Li,Purdue University,Anvil,5,3,23,2024,2024-06-03
ATS-8525,Can Anvil and Geddes share the same PVC storage space?,2024-06-05,2024-06-06,"Hello, we are just wanting to see if it is possible for Anvil persistent volume storage to be accessed by applications running on Geddes or if those persistent volumes can even be shared accross systems like that? ; Hi name, currently Geddes and Anvil each have their own Ceph and PVCs cannot be accessed between resources. We have deployed a new central Ceph resource that will be available across both systems, but is not integrated yet. We plan to have that integrated this name ; Great! Thank you for your response, I'll be sure to pass this information along. ;",jjones4@access-ci.org,James Jones,Erik Gough,Purdue University,Anvil,3,2,23,2024,2024-06-03
ATS-7393,Job automatically rerun on Anvil ,2024-04-10,2024-06-13,"Hi, Recently, my GPU jobs on Anvil automatically rerun when the jobs are almost finished. It happened three times. I don't know what happened to the system or job setting. Best, Pin-name ; Hi Pin-name, Thanks for reaching out! Can you share your job ID for me to take a look? Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; A recent one that happened yesterday was 4789471. I have canceled the job, though. ---- ; Hi Pin-name, I checked the status of your job, 4789471, looks like this job got re-queued once. The reason for re-queue on SLURM can be node failed or network connection errors. It is hard to track back the reason unless we take down the node to investigate. If it happened to you many times and you'd like to have a re-fund of the SUs, you can let us know all the job IDs and we can refund SUs to you. $ sacct -j 4789471 -DX --format=jobid%10,state%10,timelimit%10,elapsed%10,nodelist%10,submit%20,end%20 JobID State Timelimit Elapsed NodeList Submit End ; 4789471 REQUEUED 2-00:00:00 1-14:47:41 g011 2024-04-08T21:36:11 2024-04-10T12:23:53 4789471 CANCELLED+ 2-00:00:00 03:56:33 g008 2024-04-10T12:24:05 2024-04-10T16:22:39 Regards, name ; Hello! Since we did not hear from you, we are considering this ticket as resolved for now. However, if you still require assistance with this issue, please reply within the next 7 days and we will keep the ticket open. After that period, please feel free to reach out to us and create a new ticket at any time. Regards, name ; Hi name, Yes, you can close the ticket. I did not remember which jobs failed, and it did not cost a lot of SUs. I don't need a refund for that. Best, Pin-name ---- ; Thanks for letting me know. I am closing this ticket. --name ; Hi name, I have still experienced a lot of requeues recently. JobID State Timelimit Elapsed NodeList Submit End ; 4928640 REQUEUED 2-00:00:00 09:58:01 g002 2024-04-30T08:16:35 2024-04-30T18:14:37 4914687 REQUEUED 2-00:00:00 10:02:54 g001 2024-04-26T09:43:28 2024-04-26T19:46:24 4917436 REQUEUED 2-00:00:00 04:04:32 g006 2024-04-26T19:59:01 2024-04-27T00:05:02 4923705 REQUEUED 2-00:00:00 1-19:38:55 g004 2024-04-28T22:35:39 2024-04-30T18:14:37 4928640 REQUEUED 2-00:00:00 09:58:01 g002 2024-04-30T08:16:35 2024-04-30T18:14:37 4924988 REQUEUED 2-00:00:00 1-02:30:03 g006 2024-04-29T15:44:32 2024-04-30T18:14:37 I would like to get a refund for these jobs, and please investigate the situations causing requeue. This is a significant delay of research progress. Best, Pin-name ---- ; Hi Pin-name, I just refunded 366 SUs for the jobs you mentioned to Account {{chm230023-gpu}}. |Job ID|SUs|Account| |4928640|90.0522|chm230023-gpu| |4914687|10.1819|chm230023-gpu| |4917436|52.0773|chm230023-gpu| |4923705|124.108|chm230023-gpu| |4924988|88.9263|chm230023-gpu| |sum|365.3457| | We still do not know the reason why these jobs got re-queued, which is a rare case indeed. We have one way to prevent a job re-queue, that we can add {{#SABTCH --no-requeue}} in our job script. Thanks for your patience and let me know if you have further questions. Regards, name ;",laip416@access-ci.org,PIN-KUANG LAI,Nannan Shan,Purdue University,Anvil,9,47,15,2024,2024-04-08
ATS-7887,What are the best ways to expand a persistent volume in Anvil?,2024-05-02,2024-06-14,"So, we are going to need to be able to expand some of our persistent volumes in the future, and I am researching a number of ways to handle this name challenge and want to see what the best solution for this would be. A few requirements are that we would need to be able to mount these volumes as part of the Kubernetes container file system and would need to be able to expand this to meet our system's needs. Right now I have 3 ideas. # When a data volume needs to be expanded, create a new, larger volume and copy the data over. ## The problem is that this is too slow, has to be handled manually, will cause system downtime, and doesn't scale very well. # Resize the Persistent Volume using anvil-block storage. ## Currently our system uses volumes with a storage class of anvil-filesystem, which does not support allowVolumeExpansion, but if we were to use anvil-block that would be supported. ## A few questions: ### How big can a single volume be? ### Does the file system still work the same in anvil-block as it does with anvil-filesystem or would that cause issues? ### How quickly can a volume be resized and ready to use? How much downtime would there be? # We could eventually move on to a system where different volumes can be attached to pods dynamically based on what directories need to be mounted. Perhaps one or more Persistent Volume Claims can be created and attached through a template. ## The only issue is that this methodology would take a bit of time to develop and test, and we are looking for a solution with a faster turn around. ## Also, is there a limit to how many persistent volumes can be attached to a container? In addition to my self, can you make sure that my colleague Steve name is CC'd in this ticket as well, his email address is : mailto: Thank you for your time on this matter, name ; Also in addition to this, is it possible to ""mount"" the PVC with a user quota? We would like for the user's home directory to have a size quota associated with it. Is that possible? ; I have a few more details related to how to associate size quotas with users. Steve tried to use setfattr on a user's home directory and got a Permission denied error, even when running as a root user from the exechost pod terminal. The command looks like this, do you know why he's getting the permissions's error? {{# setfattr -n ceph.quota.max\\_bytes -v 5Gi /home/nanohub/clarksm setfattr: /home/nanohub/clarksm: Permission denied}} ; The command l included has the wrong line break it looks like: {{# setfattr -n ceph.quota.max\\_bytes -v 5Gi /home/nanohub/clarksm}} {{setfattr: /home/nanohub/clarksm: Permission denied}} ; Hi name, I fixed the anvil-filesystem StorageClass so it now supports volume expansion. You should be able to edit your PVC to increase the size. I will look into this setfattr error and get back to you. I recall trying this in the past and getting the same error. Thanks, -name ; Is is possible to CC Steve name in these ticket responses? ; Hello, I've been researching the issue with applying the ceph.quota.max\\_bytes xattr to the user's home directory folder and wonder if it could be due to a CephFS authentication configuration as outlined in this documentation page. https://docs.ceph.com/en/latest/cephfs/client-auth/: https://docs.ceph.com/en/latest/cephfs/client-auth/|smart-link I don't think its a problem with the root user's permissions exactly, but I'm not sure at this time. Do you have any insights? ; name, I'm going to mark this one resolved. If you have more questions it will probably be best to open a new ticket. ;",jjones4@access-ci.org,James Jones,Erik Gough,Purdue University,Anvil,8,32,18,2024,2024-04-29
ATS-7909,Can 2 IP addresses for Anvil Kubernetes be provisioned and can the resource quotas be increased?,2024-05-03,2024-06-14,"Hello, we are going to be setting up a production environment in Anvil Kubernetes soon and we need 2 IP address allocated for this environment to use, can those be provisioned for our cluster? Also, the current default resource quota for Anvil is 12 CPUs and 24Gi of memory, the current quota used is default-2btrc in the nanohub namespace, but when we move over to the production namespace the quota will need to be increased. Is it possible to increase that to 300 CPUs and 600 GiB or memory for production? Can you also make sure that my colleague Steve name is CC'd in on this ticket? His email address is : mailto:. Thank you in advance for your time, name ; Two more IPs have been provisioned for your use. 128.211.162.15 and .16 We are working on converting a set of batch nodes for your use and will update your Project quota to reflect the new limits when that is complete. -name ; Is is possible to CC Steve name in these ticket responses? ; Hello, Is there any progress on converting the batch nodes and updating the quota for the nanohub namespace like we discussed? name ; Hi name, The nodes have been provisioned and the quota is updated. If you want to schedule on these nodes you will need to add a toleration for the following taint: dedicated=nanohub:NoSchedule Let me know how it goes. I think I successfully added Steve this time. -name ; Hello name, I saw that the quotas have been increased and I can change the resource limits for nanohub to 300 CPUs and 176Gi Memory, but I estimate that we will probably need more memory than that, I think we talked about 600Gi of memory but I can't set it to higher than 176Gi, does it take more time to get that memory? ; Sorry, that was a mistake on my part. The memory quota is now set to 864 GB. ; Yep, I got it now. Thank you for your help. ; I'd keep the ticket open just in case we need support on the taint tolerance, but other than that the resource quota issue seems to be resolved. ; Hi name, Just want to confirm a few things about how taints and tolerances are applied, so the node we want deployments to go to already has the taint applied? And if we apply a tolerance to a deployment it should be structured like this example: apiVersion: apps/v1 kind: Deployment metadata: name: test-deployment labels: app: web spec: replicas: 1 strategy: type: RollingUpdate template: metadata: labels: app: web octopusexport: OctopusExport spec: containers: - name: nginx image: nginx ports: - containerPort: 80 tolerations: - key: dedicated operator: Equal value: nanohub effect: NoSchedule ; Hello, We are testing sending sessions to the dedicated nodes but we are running into an error upon scheduling sessions to the dedicated nodes using the tolerances. We see the following events and error messages: Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 86s default-scheduler Successfully assigned devnanohub/toolsession-0003-6d5947c549-n729s to a004 Normal SuccessfulAttachVolume 85s attachdetach-controller AttachVolume.Attach succeeded for volume ""pvc-401b8c22-86ad-41d3-ab4d-89a0447bc0ac"" Normal SuccessfulAttachVolume 85s attachdetach-controller AttachVolume.Attach succeeded for volume ""pvc-7b92fe7a-db6d-4ed9-b98e-862ddbb48c8e"" Normal SuccessfulAttachVolume 85s attachdetach-controller AttachVolume.Attach succeeded for volume ""pvc-fcd134e0-a7cd-4842-968e-b092216bd9b5"" Warning FailedMount 19s (x8 over 83s) kubelet MountVolume.MountDevice failed for volume ""pvc-fcd134e0-a7cd-4842-968e-b092216bd9b5"" : kubernetes.io/csi:: http://kubernetes.io/csi: attacher.MountDevice failed to create newCsiDriverClient: driver name rook-ceph.cephfs.csi.ceph.com: http://rook-ceph.cephfs.csi.ceph.com not found in the list of registered CSI drivers Warning FailedMount 19s (x8 over 83s) kubelet MountVolume.MountDevice failed for volume ""pvc-7b92fe7a-db6d-4ed9-b98e-862ddbb48c8e"" : kubernetes.io/csi:: http://kubernetes.io/csi: attacher.MountDevice failed to create newCsiDriverClient: driver name rook-ceph.cephfs.csi.ceph.com: http://rook-ceph.cephfs.csi.ceph.com not found in the list of registered CSI drivers Warning FailedMount 19s (x8 over 83s) kubelet MountVolume.MountDevice failed for volume ""pvc-401b8c22-86ad-41d3-ab4d-89a0447bc0ac"" : kubernetes.io/csi:: http://kubernetes.io/csi: attacher.MountDevice failed to create newCsiDriverClient: driver name rook-ceph.cephfs.csi.ceph.com: http://rook-ceph.cephfs.csi.ceph.com not found in the list of registered CSI drivers It looks like the CSI driver for mounting the volumes isn't registered on the dedicated nodes, can this be checked on or confirmed? ; The cephfs csi was not running on the new dedicated nodes. Not it is running and your mount should succeed. Let me know how it goes. -name ; Edit: \\*Now it is running ; Thank you, the tolerance looks like it is working as intended. ; Marking this one resolved. ;",jjones4@access-ci.org,James Jones,Erik Gough,Purdue University,Anvil,15,31,18,2024,2024-04-29
ATS-8051,Issues running jobs,2024-05-12,2024-06-11,"Hello, I am running PLUMED/LAMMPS jobs, particularly multiple-walker metadynamics. I have been granted special access to an 8-day wholenode QOS by Anvil staff, which has helped my jobs run a lot, and for which I am very grateful Thanks, name ; Hi name, Thanks for reaching out! And I am sorry your ticket was slipped from my monitoring. Sorry for the delay. I am wondering if you still have issues to run LAMMPS on Anvil. Please feel free to let me know. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Hello! Since we did not hear from you, we are considering this ticket as resolved for now. However, if you still require assistance with this issue, please reply within the next 7 days and we will keep the ticket open. After that period, please feel free to reach out to us and create a new ticket at any time. Regards, name ;",psharma3@access-ci.org,Pranav Sharma,Nannan Shan,Purdue University,Anvil,3,22,19,2024,2024-05-06
ATS-8304,Need to increase the storage limit of number of files,2024-05-24,2024-06-14,"Previously, I requested for extra storage (100TB). However, the limit of number of files I can store is 1000k. This limits the usage of extra storge as I cannot use the full potential of 100TB due to the cap of 1000k files. I request to increase this limit (20,000k times) to use the 100TB storage. ; Hi Krishan, Thanks for reaching out! I think we talked about the quota increase to 200TB previously, while we did not talk about the file number limit back then. Can you register one of our Anvil Support Hour to talk about your request? https://www.rcac.purdue.edu/anvil/anvil-support-hour: https://www.rcac.purdue.edu/anvil/anvil-support-hour|smart-link Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Hi name, I will definitely register for Anvil Support Hour. ---- ; \\*\\*PRIVATE NOTE\\*\\* On Anvil Support Hour, user shared during their simulation, many small files (~10MB per file) will be generated and this will quickly reach the file limit on their scratch. I shared they can archive these small files into one tarball or zip file to reduce the file number. This will solve the problem when they run simulations. Then Krishan asked about the post analysis of these output files. When they run the post analysis, they need to untar these files. Is there a way to read the files without untar these files? They shared they were using nektar++ (https://www.nektar.info/: https://www.nektar.info/|smart-link ) for their data analysis, which is in C++. I told Krishan I do not know how to to this, but I would bring this question to our Data Scientist to ask the suggestions. So Geoff, do you have suggestions for them? How to avoid many small files during the post data analysis? Is there a way to read the files without untar a tarball? Thank you! [~accountid:id --name ; Hi Krishan, I've talked to our data scientist about your post analysis of the data. It is recommended to use /tmp or /dev/shm folder to re-extract the files for analysis. Please remember these folders are temporary and will be cleaned every day I think, so it is not good for the storage but good for analysis. Hope it helps. name ; Thanks for sharing the information, name. ---- ;",kchand1@access-ci.org,Krishan Chand,Nannan Shan,Purdue University,Anvil,7,16,21,2024,2024-05-20
ATS-8805,"unable to submit any batch job, invalid value for --ntasks",2024-06-20,2024-06-20,"I am unable to submit any job on Anvil. I always get this error: ""sbatch: error: Invalid numeric value """" for --ntasks."". I tried the followings sbatch --nodes=1 --ntasks=1 gen\\_gdd.sub sbatch gen\\_gdd.sub And here is my simple file: #!/bin/sh -l #SBATCH -A cis220065 #SBATCH --nodes=1 #SBATCH --ntasks= 1 #SBATCH -p standard #SBATCH --time=24:00:00 #SBATCH --mem=40GB module load geos ; Hi Iman, Thank you for reaching out. I see an extra space after your --ntasks= which is causing the problem. Please modify your script as follows: #!/bin/sh -l #SBATCH --account=cis220065 #SBATCH --nodes=1 #SBATCH --ntasks=1 #SBATCH --partition=standard #SBATCH --time=24:00:00 #SBATCH --mem=40GB module load geos Then, you can submit it with `sbatch gen\\_gdd.sub`, and this should solve your problem. Best, name Senior Computational Scientist RCAC - Purdue University ; Dear name, Thanks for your help. I couldn't find it without your help! It works now. Iman ; Thanks for letting me know that the issue is resolved. Best, name ;",x-ihaqiqi,Iman Haqiqi,Haniye Kashgarani,Purdue University,Anvil,4,1,25,2024,2024-06-17
ATS-8305,"I am unable to launch tool session Pods in the Anvil Kubernets cluster, it keeps saying ""FailedToCreatePodSandbox"" in the event logs",2024-05-24,2024-06-14,"When I try to launch a tool session pod I see event errors saying ""(combined from similar events): Failed to create pod sandbox: rpc error: code = Unknown desc = failed to create a sandbox for pod ""toolsession-0042-7c97f99dd9-vv6sm"": Error response from daemon: error creating overlay mount to /tmp/docker/overlay2/0eb5a458ee945112325613d445f5fb54b8d958dd8f528b2f900d91ed847a83d8-init/merged: no such file or directory"" I'm not sure what is causing this or how to fix it and need advice on what is happening. I am providing a screenshot of the even log as well in this ticket Can you make sure to CC my collegue Steve name as well, his email address is : mailto: ; We are taking a look at this now name. ; Can you try again and let me know if it works? I will write out an explanation for this issue. ; Thank you this is working now. Yes, if you can write out an explanation of the issue we can document that for future reference. name ; The main issue here was that a /tmp cleanup script that is configured to run on the batch nodes (which were converted to k8s nodes for you), wiped some of the docker directories. This script has been modified to exclude /tmp/docker, so we shouldn't see the issue again. /tmp/docker is used instead of /var/lib/docker, as /tmp is the only mounted filesystem on the node. The OS and associated dirs just run in a rootfs memory filesystem. -name ; This solution sounds great. We'll keep a note just in case we ever see anything similar. Thank you for your support, name ;",jjones4@access-ci.org,James Jones,Erik Gough,Purdue University,Anvil,7,16,21,2024,2024-05-20
ATS-8379,"Expanding the PVC for nanohub-home fails, is causing the exechost deployment to stop and restart",2024-05-29,2024-06-14,"I've noticed that the exechost deployment has been stopping and restarting and we are seeing the following error after attempting to expand the nanohub-home volume to 200GiB: ""{{NodeExpandVolume.NodeExpandVolume failed for volume ""pvc-fb06da00-c68c-497f-803b-a268aa4e9d2f"" : Expander.NodeExpand found CSI plugin kubernetes.io/csi/rook-ceph.cephfs.csi.ceph.com to not support node expansion}}"" Doesn't this storage class support expansion? Also, is there a webhook for monitoring errors in Anvil so that when they happen they can be forwarded to us through email or Slack, I've been researching some possible solutions using Prometheus on Anvil. But this is a side-note. Fixing the volume expansion issue and getting exechost on nanohub is the main priority. Can you make sure to CC name and Steve name on this ticket their emails are: : mailto: : mailto: ; Hi name, I took a look here and saw the filesystem was expanded to 300Gi. Were you able to get past this issue? The storage class does support volume expansion. This reminds me of the first time we hit this issue and the solution was to scale the exechost deployment down to 0 and then back to 1, which allowed the volume to resize and be remounted. Then, there was a separate issue with the exechost Pod restarting, perhaps due to the waitForAllClear.sh script, which Steve provided some guidance on in our ""Anvil & NanoHub Status for Workshop?"" email thread. Let me know if how else I can help here. Thanks, -name ; Are you suggesting that all pods that have the PVC mounted need to be shutdown and restarted? Today I shutdown and restarted the execution host multiple times but there are few toolsession pods that also have the PVC mounted. The toolsession pods are also reporting resize errors but continue to function. --- name Application Engineer for Scientific Computing \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_ ; I thought the issue with waitForAllClear.sh was fixed. Do you think that the issues with the exechost stopping and restarting are unrelated to the errors about the persistent volume expansion. Also, if the persistent volume successfully expanded, then why are we still seeing the errors cropping up? ; I'd say this Warning message will require some deeper investigation from our side. Initial perusing of some GH issues may indicate a bug that is fixed in a later version of Rook, but I cannot say for certain. If restarting the toolsession Pods allows them to see the expanded volume, I would suggest doing that for now. -name ; Killing the exechost and all toolsession pods seems to have restored order. Should the PVC resize trigger a restart of pods that have it mounted? --- name Application Engineer for Scientific Computing \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_ ; Theoretically, it should resize the PVC while the Pods are running without issue. We need to investigate further why this does not happen with the version of Rook and the cephfs CSI we are running on Anvil. ; It doesn't look like killing the exechost and toolsessions fixed the issue, because the exechost is down and has restarted 26 times. I'm looking in the Events and I don't see the errors about the volume resizing but I do see one saying |Back-off restarting failed container exechost in pod exechost-66f9f699d4-pzxfm\\_nanohub(5b747268-89c7-4351-9c6c-4f983a3e35b2)| I examined the exechost once it started running again and it looks like this is because of the ""waitForAll"" command not completing again. ; So, it seems like restarting or redploying the exechost doesn't work when it is in this cycle or restarting and shutting down. The waitForAllClear.sh script never completes and eventually kicks the pod out. So I have a few questions: # Is there a way to handle a restart or redeploy in a way that this script does not cause an issue? A kind of graceful way to handle restarting. # What is the purpose of the waitForAllClear.sh, is that our script or does that come from somewhere else? # What exactly is it checking for and what conditions are not being met for it to finish? ; We also don't know what exactly caused the exechost to start restarting itself either, so another thing we need to think about is whether there is a way to montior when a pod is terminated due to an error and report that information to developers, either through email or through Slack. That way we can capture the exact moment and cause of the issue. We seem to lose pod information once the pod is removed from the system, shortly after the next pod is restarted, so this is important for diagnosing issues as well. ; waitForAllClear.sh is my creation. It's purpose is to wait for configuration and secrets to be installed before going into name Application Engineer for Scientific Computing \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_ ; We seem to still have issues with exechost going into this cycle of trying to restart itself, the events stored for Anvil are not helpful since not enough events are being kept, I'm not sure if they expire overnight or what. I noticed that Prometheus can be enabled for Monitoring, I've used this tool in the past to keep track of Pod metrics like CPU, Memory, and even Pod logs. I think this can be helpful for monitoring and event logging can the RCAC support look into if this can be useful, and if so, enabled? ; One thing I noticed is that the exechost Pod does not produce any logs when using ""kubectl get logs"". This would probably require a rebuild of the container to send logs from whatever processes the container runs to stdout/stderr. This could help in determining what is causing the Pod to exit. You might also be able to see more information via ""kubectl describe"" than what is provided via the UI. I gave you access to the Monitoring system, which should allow you to view Prometheus/Grafana and create AlertmanagerConfigs. https://ranchermanager.docs.rancher.com/reference-guides/monitoring-v2-configuration: https://ranchermanager.docs.rancher.com/reference-guides/monitoring-v2-configuration|smart-link ; I've been looking at the monitoring, this is good for if the issues are caused by too much resource utilization like CPU or memory usage. I forgot that I installed an addon for Prometheus for indexing Pod logs called Loki, whether that is installed should probably be left up to RCAC, but I will add a link to it here: https://github.com/grafana/loki: https://github.com/grafana/loki But another thing to look into is whether or not there is a way to save the Cluster Events or view older ones. I would like to be able to scroll through them and see when the exechost needs to crash, I often only see events about it restarting. ; I should clarify, I installed Loki with Prometheus in other projects, not related to Anvil. ; Okay, I did more research into the events that show up in the Rancher UI and those are Kuberentes Events, they can be retrieved by running the following kubectl command: kubectl get events -n nanohub These events are only stored for about an hour before they are removed. They also are not stored into Prometheus's dashboard by default and need other tools for exporting like Loki and Kubernetes Event Exporter. https://github.com/resmoio/kubernetes-event-exporter: https://github.com/resmoio/kubernetes-event-exporter . These are just examples of ways to index the events. ; I also setup a Slack webhook that should send Prometheus alerts for nanohub to a Slack channel Steve and I are subscribed to. Hopefully the alerts that are sent to the channel will help when monitoring nanoHUB on Anvil. ; I also see that a013 and a019 are unavailable, according to the Nodes UI they have been down for the past 2 days, are these not some of the dedicated Nodes for nanohub? ; These were provisioned for some testing on our side and aren't available anymore. Your 384 cores are provide by a000, a004 and a006. If you need more nodes let us know. ; No, that's fine. Just checking if that was expected. ; Both dev and production exechost failed at 5:28AM today. Both report this type of error: Status: Failed Reason: Evicted Message: The node was low on resource: ephemeral-storage. Container exechost was using 88304876Ki, which exceeds its request of 0. We don't explicitly use ephemeral-storage (emptyDir} in the exechost pods. --- name Application Engineer for Scientific Computing \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_ ; I was looking at the Disk Utilization for the nodes that were hosting the exechost for devnanohub and nanohub, the other day it was cloud03 and as of this writing it is cloudgpu00 and something seems to be using up disk space on those machines, but I'm not sure what is filling up the space, but for cloudgpu, the utilization percent is around 84%. At around 5:20 on 6/1 and 6/2 on the cloud03 machine the utilization percent was around 85%. ; What was the cloudgpu00 utilization at around the same time this morning? --- name Application Engineer for Scientific Computing \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_ ; Yeah, the disk space usage for cloudgpu00 is already beyond 90%, most of it seems to be from /var/lib/docker I attached a screenshot, we should probably address whatever is in that directory on the node. ; The Disk Utilization for this node has been high for the past 3 days, as a matter of fact since the metrics have been recorded in Prometheus. ; I pruned unused images on cloudgpu00, which freed up a bit more space. If you would like, you can isolate all your workloads on the nodes we tainted which would prevent any noisy neighbors from impacting your workloads. You would just need to add a nodeSelector for the label dedicated=nanohub. nodeSelector: dedicated=nanohub ; nodeSelector: dedicated: nanohub My bad, I put the wrong format on the previous yaml. ; Thanks, I can see that pruning the image reduced the amount used, I also wanted to make sure that exechost isn't writing to anything outside of the mounted volumes. I did find that the /var/log/mw-service/service.log file is outside of the volume mount for /var/log/mw-service/open-sessions, but does this file get log rotated or pruned before it could fill up the disk space too much? ; In this case I think we were the noisy neighbor. That being said, can we set or request a limit to avoid having the pod terminated? --- name Application Engineer for Scientific Computing \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_ ; We could potentially become the noisy neighbor, but at the moment the service.log is only 64K, but in the cases where the pods terminated, the file could have been potentially much larger. Are there any other things in exechost that could potentially write in ephemeral storage? ; I'm seeing a bunch of warnings in the Anvil cluster, its saying ""Failed to create pod sandbox: rpc error: code = Unknown desc = failed to create a sandbox for pod ""toolsession-0116-597b8c986f-d4qk8"": Error response from daemon: error creating overlay mount to /tmp/docker/overlay2/5a2eebd5b199e22c4bb5eca22f1938add0091a7b5b7d2da8d9b61618519608d7-init/merged: no such file or directory"" name, I think this was an error we saw the other day. I believe this was the solution last time: ""The main issue here was that a /tmp cleanup script that is configured to run on the batch nodes (which were converted to k8s nodes for you), wiped some of the docker directories. This script has been modified to exclude /tmp/docker, so we shouldn't see the issue again./tmp/docker is used instead of /var/lib/docker, as /tmp is the only mounted filesystem on the node. The OS and associated dirs just run in a rootfs memory filesystem."" ; name, sorry that this error has cropped up again. Even though /tmp/docker was configured to be excluded, the cleanup script still removed files there. I reconfigured your reserved nodes to move the docker folder out of /tmp, hopefully eliminating this problem for good. -name ; Thanks! We are able to get tool sessions launching again. Separate note, I'm setting up automated alerts to tell when pods are unexpectedly failing or stuck in a pending state for too long. I believe I have the Slack notifications working, is there by chance a webhook for notifiying RCAC when the alerts are being generated as well? ; name - Just a heads up - students should start using the nanoHUB tools on Monday (6/10) and the workshop runs through 7/12. --- name Application Engineer for Scientific Computing \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_ ; Marking this one resolved. ;",jjones4@access-ci.org,James Jones,Erik Gough,Purdue University,Anvil,35,13,22,2024,2024-05-27
ATS-8407,Issue executing vasp_std,2024-05-30,2024-06-12,"I am trying to submit VASP jobs (using submission scripts adapted from those found on the Anvil site) but the program is not finding the VASP executable vasp\\_std. I am attaching a screenshot with my submission script (submitted using ""sbatch submit.job"") and the output from the standard error file. I have already been given permissions for VASP5.4.4. ; Hi name, Thank you for reaching out to RC support. I have spoken with our VASP expert ~accountid:id] , and I would appreciate it if you could request an Anvil Support Hour. She will be there to assist you with this problem. Here is the link for Anvil Support Hour: https://www.rcac.purdue.edu/anvil/anvil-support-hour Best, name Senior Computational Scientist ; Hi name, I have requested a time at the Anvil Support Hour, but I would really like to figure out how to solve this issue before a week from now. Is there any way for me to get help earlier than next Thursday? Best, name ; Hi name, Are you able to attend Anvil Support Hour today at 2:00pm (ET) talk about your questions regarding to VASP run? Here is the Zoom link, [https://purdue-edu.zoom.us/j/91663753188?pwd=WUJKdHAwNFpoTkZGMERYOHRKL3JEQT09: https://purdue-edu.zoom.us/j/91663753188?pwd=WUJKdHAwNFpoTkZGMERYOHRKL3JEQT09|smart-link Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; \\*\\*PRIVATE NOTE\\*\\* User came to Anvil Support Hour but he cannot share screen to show the problem because he was using his phone and away from his laptop. We scheduled another Zoom meeting to talk about it. The meeting will be at 3:30pm-4pm (ET) today (June 6, 2024). ; \\*\\*PRIVATE NOTE\\*\\* Talked with name about VASP5 module loading on Anvil. The issue is there is no problem for name to load {{vasp/5.4.4.pl2}} module, the problem is after loading the module, the executables cannot be found. Even manually adding PATH ({{export PATH=/apps/spack/anvil/external/vasp/vasp.5.4.4.pl2-openmpi-4.1.6/bin/:$PATH}}) did not solve the problem. In the end, I tried to remove/add name from/to {{vasp5}} unix group. name will let me know tomorrow morning if this will fix the problem. ; \\*\\*PRIVATE NOTE\\*\\* User sent me an email said it still did not work after I remove and re-added him back to {{vasp5}} unix group. I told user we will discuss this within team and get back to him later in email. ; Hi name, Can you give it a try and test if you can use vasp\\_std now? We found some permission issues and they were fixed now. Regards, name ; Hi name, Looks like I can see vasp\\_std now! Thanks for your help. I will try my calculations and let you know if I have any issues come up. Best, name ; Great! I am glad it works. I would mark this ticket as resolved. If you have further questions within 7 days, replying to this ticket will re-open it. After 7 days, you can send a new ticket with your questions. --name ;",gnov501@access-ci.org,Gregory Novotny,Nannan Shan,Purdue University,Anvil,11,10,22,2024,2024-05-27
ATS-8456,Quota on Anvil all zero?,2024-06-03,2024-06-11,"Hi there-- I went to restart my jobs on my allocation, and it seems I can't write files because my file limit is now zero. It says I'm using zero files and have a zero file limit. Did something break? d. ; Hi name, Thank you for reaching out. Would you please let us know which directory you were using for the jobs? If you could share the output of the {{myquota}} command, it would be very helpful. Warm regards, name ; Hi d. name Collins Associate Professor, Physics Florida State University On name 7, 2024, at 9:17 AM, name : mailto: wrote: ; Awesome! Thanks for confirming! I'll go ahead and mark this ticket resolved then. Please feel free to contact us again if you encounter any issues or have any questions. Thanks, name ;",dcollins@access-ci.org,David Collins,Ruyi Li,Purdue University,Anvil,11,7,23,2024,2024-06-03
ATS-7809,Anvil FORTRAN compile namelist issue,2024-04-29,2024-06-25,"Good afternoon, I am running a mpi program on anvil, and seem to be having trouble with the fortran compiler. The program compiles correctly, but when I run it, it seems to have issues with the namelist command in fortran. I am using the open mpi module with gcc/11.2.0. Thank you for your help ; Hi, Thank you for the update. That sounds good. name ; Hi, I would temporally resolve this ticket. Feel free to let me know if you need our assistance on this issue later. name ;",jwoodruff@access-ci.org,Johnathan Woodruff,Guangzhen Jin,Purdue University,Anvil,11,42,18,2024,2024-04-29
ATS-8581,VASP access on Anvil,2024-06-08,2024-06-14,"Hi, Could I get access to VASP 5.4 on Anvil? Our VASP License number is 5-2357 Thanks, name ; Hi name, Thanks for reaching out! You have been added to vasp5 group on Anvil. Your membership will be ready within a few hours. Please check our user guide for VASP calculations on Anvil. . https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/vasp: https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/vasp|smart-link Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ;",pdeshlah@access-ci.org,Prashant Deshlahra,Nannan Shan,Purdue University,Anvil,2,5,23,2024,2024-06-03
ATS-8621,Unable to submit jobs requiring more than 1 node,2024-06-11,2024-06-11,"Hi there, I am attempting to submit a job using 2 nodes and 256 processors on Anvil's shared partition. However, whenever I attempt to submit a job requiring more than 1 node and 128 processors, I receive the following error message: sbatch: error: QOSMaxCpuPerJobLimit sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits) The job that I currently am attempting to submit requires up to 32 nodes and (32 x 128) processors. Please do let me know what I can do to access more nodes. Cheers, Lillian ; Hi Lillian, Thank you for reaching out. In the {{shared}} partition, a job can not request more than 1 node. Whereas, a job can request up to 16 nodes in the {{wholenode}} partition and up to 56 nodes in the {{wide}} partition. Please see the information about the partitions on Anvil at the following link: https://www.rcac.purdue.edu/knowledge/anvil/run/partitions: https://www.rcac.purdue.edu/knowledge/anvil/run/partitions|smart-link You may use the {{-p }} flag (e.g. {{-p wide}}) in your job submission commands/scripts to specify the partitions you are going to use. I hope it helps. Please let me know if you have any further questions. Thanks, name ; Good morning name, Thank you for catching this. I managed to resolve my error by switching to the 'wide' partition. Cheers, Lillian ; Awesome I'll go ahead and mark this ticket as resolved then. Please feel free to contact us again if you have any other questions. Thanks, name ;",lbl59@access-ci.org,Lillian Lau,Ruyi Li,Purdue University,Anvil,4,1,24,2024,2024-06-10
ATS-7976,need to install cairo/cairo.h for instaling splash,2024-05-07,2024-07-01,"When I installed splash (https://splash-viz.readthedocs.io/en/latest/getting-started.html: https://splash-viz.readthedocs.io/en/latest/getting-started.html|smart-link ), I encountered the problem ""giza-private.h(25): catastrophic error: cannot open source file ""cairo/cairo.h"" #include "" I may need your help to instal cairo.h (https://cairographics.org/: https://cairographics.org/|smart-link ) so I can install splash successfully. ; Good afternoon, on which resource are you running and attempting to install splash? (Bridges, Anvil, Expanse, etc). Thanks! ; Hi, The HPC i use is Anvil. Thanks, name ACCESS Ticket Submission 於 2024年5月8日 上午10:23 寫道: | | \\*CAUTION:\\* External Message. Use caution opening links and attachments. | | ; Hello! Thanks for reaching out! Please check our policy about software installation. https://www.rcac.purdue.edu/knowledge/anvil/policies/software\\_installation\\_request\\_policy Basically, if the software is not a widely requested one, we would recommend to install the software in your own space, like project space. If you cannot find the installation instruction of the software you are interested on Linux system without sudo/admin privilege, we would recommend to contact people who developed this software and get the instruction. Regards, name, PhD (She/Her) Senior Computational Scientist Purdue University ; Hi Nanna, I have tried to install cairo by myself in my own space but it doesn't work. I follwed the INSTALL instructions (please download the package via the link: https://www.cairographics.org/releases/LATEST-cairo-1.18.0), but it looks there is bug when the code tries to install subproject pitman. I'm wondering if it's possible for you to help me to test it. Thanksm name 於 2024年5月9日 上午8:59 寫道: | | \\*CAUTION:\\* External Message. Use caution opening links and attachments. | | ; Hi name, What is the error message you've seen while you were installing it on Anvil? What commands you used for this installation? We can talk about it over a virtual meeting, feel free to register one of our Anvil Support Hour sessions at https://www.rcac.purdue.edu/anvil/anvil-support-hour: https://www.rcac.purdue.edu/anvil/anvil-support-hour|smart-link Regards, name ; Hi name, Here below is the error message when I installed cairo on Anvil. \\*cairo-xlib-surface.c:71:10:\\* \\*fatal error:\\* X11/extensions/XShm.h: No such file or directory 71 | #include \\*\\* | \\*^~~~~~~~~~~~~~~~~~~~~~~\\* compilation terminated. I have checked there is no XShm.h in /usr/include/X11/extensions and I may need your help to instal libxext-dev for X11. Thanks, name 於 2024年5月16日 中午12:57 寫道: | | \\*CAUTION:\\* External Message. Use caution opening links and attachments. | | ; Hi name, What ssh client you were using? Does your SSH client software support graphical display by itself? For example, SecureCRT or PuTTY does not support X11 display. Have you enable X11 forwarding in your SSH connection? To do so, we can use {{ssh -Y -l username hostname}} . Please note, submitting multiple tickets will not help because we need to work on different tickets and collect all the information for your questions . Let's keep all the discussion on one place, i.e. this ticket. Regards, name ; Hi name, I use macos's terminal and I use ssh -Y username hostname to connect anvil. It always works on other HPCs (Cherry-creek, Dial3, Arc4 and Sulis) I used before to plot my output dumpfiles, however, I can't install SPLASH without Cairo on anvil. On the other hand, I found to install Cairo, it also needs XShm.h in ""/usr/include/X11/extensions/"" which doesn't include on anvil. I believe Cairo is a low-level system library used in many applications and that's why other HPCs have already installed. If you can install Cairo on anvil, it will be the best solution. Or you can help me to add the XShm.h extension in X11 and I can try to install Cairo in my local folder again to see whether it works. Thanks, name 於 2024年5月20日 下午2:24 寫道: | | \\*CAUTION:\\* External Message. Use caution opening links and attachments. | | ; Hi name, Thanks for your patience on this and I do not know why the status of this ticket did not change after your response, so it was not on my monitoring list. Sorry about that. I would escalate your request to our application team and let them decide how we proceed next. You will hear from them later. Regards, name ; Hi name, I think the {{cairo}} module is available on Anvil now. Please give it a try and let me know if you have further questions. @login01.anvil:~ $ module spider cairo ; cairo: cairo/1.16.0 ; This module can be loaded directly: module load cairo/1.16.0 Help: Cairo is a 2D graphics library with support for multiple output devices. Regards, name ;",cchen17,Cheng Chen,Nannan Shan,Purdue University,Anvil,11,40,19,2024,2024-05-06
ATS-3570,Missing GLIBCXX_3.4.21 and CXXABI_1.3.9 in libstdc++.so.6 in the latest intel module,2023-10-06,2024-06-20,"My project requires PETSc, and versions of PETSc of 3.12.4 and later appear to require the libraries GLIBCXX\\_3.4.21 and CXXABI\\_1.3.9 which are not present in the libstdc++.so.6 provided by the latest intel module intel/19.0.5.281 on Anvil. I did note that the libstdc++.so.6 in /apps/anvil/external/apps/intel/cluster.2020.4/inspector\\_2020.3.0.604771/lib64 appears to have the requisite GLIBCXX\\_3.4.21 and CXXABI\\_1.3.9 according to strings /apps/anvil/external/apps/intel/cluster.2020.4/inspector\\_2020.3.0.604771/lib64/libstdc++.so.6 | grep GLIBCXX\\_ however when I try to link against that I get seg fault errors: a946:3606564:0:3606564] Caught signal 11 (Segmentation fault: address not mapped to object at address (nil)) Configuring an earlier version of PETSc (versions 3.10 and 3.11) fails with the error UNABLE to CONFIGURE with GIVEN OPTIONS (see configure.log for details): ; Must give a default value for known-mpi-shared-libraries since executables cannot be run and I am unsure whether those versions would even work with my project code ([https://github.com/GRTLCollaboration/GRChombo: https://github.com/GRTLCollaboration/GRChombo|smart-link ). Therefore if possible I would like to be able to use a later PETSc version on Anvil. Do you have any advice for resolving this issue? many thanks, Jamie ; Hi, Thank you for contacting us. Let me take a look at this issue and get back to you when I have a clue. Stay tuned. Best regards, name Senior Computational Scientist Purdue Information Technology ; \\*\\*PRIVATE NOTE\\*\\* Hi name, Do you think it's the same issue as we discussed before about intel compiler built with an older gcc? Could you give some advices to the user? Best, name ; Hi Jamie, Thank you for reporting this issue. Can your code use the GCC compiler, or is Intel a hard dependency? If you must use Intel, I'll recommend using the Intel oneAPI compilers. You can download it for free from the Intel website and install in your project space. We also plan to deploy it on Anvil, but cannot provide an ETA yet. Best regards, name. ; Dear name, Thank you very much for your reply. While our code can in principle use the GCC compilers (which is a solution I am exploring now on Anvil) it typically runs about 30% slower than when compiled with the Intel compilers, which for the large simulations we plan to run is a significant cost. However I will look into installing the Intel oneAPI compilers and using those. many thanks, Jamie On 13 Oct 2023, at 11:51, ACCESS Ticket Submission : mailto: wrote: ; Dear name, I have had a look at the Intel website, and I can't quite work out how to install the oneAPI compilers as a non-root user. They seem to mostly provide guides for installing as a system administrator. Would you be able to give me some advice as to how best go about installing the intel oneAPI tools in the project directory? very best wishes, Jamie On 13 Oct 2023, at 11:51, ACCESS Ticket Submission : mailto: wrote: ; Hi Jamie, Sorry for letting this ticket slip by. We have deployed a newer version of Intel (intel/19.1.3.304) on Anvil. Can you please check if you still get the error with this module? Best regards, name. ;",jbamber@access-ci.org,Jamie Bamber,Amiya Maji,Purdue University,Anvil,7,185,40,2023,2023-10-02
ATS-4627,Problems compiling with Intel libraries on Anvil,2023-11-27,2024-06-20,"I have tried compiling Quantum Espresso and another software using the intel libraries on Anvil, but for some reason my jobs always error out if I ask for more than about 32 cores on a node. I've tried using wholenode and I run into the same issue. I'm using an updated version of Quantum Espresso than the precompiled module because it interfaces better with another software I have to use. An example of the error I'm running into can be found in the $SCRATCH directory at /anvil/scratch/x-egormley/MOF5/scf My compilations have worked fine running on only a few cores at a time, but I will need multiple entire nodes for some of the calculations I plan to run. Thank you Eoghan ---- ; Hi Eoghan, Sorry for letting this ticket slip by. Are you still facing this issue? Have you tried the QE module on Anvil? I noticed one odd thing in your compile line, not sure if that is a typo. You specified ""-DCMAKE\\_C\\_COMPILER=mpicc"". For Intel compiler+impi this should be ""mpiicc"". Let us know if things work better with that change. Best regards, name. ;",egormley,Eoghan Gormley,Amiya Maji,Purdue University,Anvil,4,149,48,2023,2023-11-27
ATS-6066,random error when running simulations,2024-02-10,2024-06-20,"I recently ran simulations with pure MPI application. I got the following error in random places. I tried to debug my program, but this seems to be more generic about mpi. Would you please let me know what's going on and how to solve it? .724450] a419:676420:0 mm\\_xpmem.c:136 UCX ERROR failed to attach xpmem apid 0x12000a5244 offset 0x150602e62000 length 12288: Cannot allocate memory .724912 a419:676420:0 ucp\\_rkey.c:476 UCX ERROR failed to unpack remote key from remote md5: Input/output error .730344 a419:676420:0 pgtable.c:643 UCX WARN failed to remove pgtable region0x2029e50 0x2029..0x602767bf43123598 .977580 a419:676420:0 rcache.c:624 UCX WARN xpmem\\_remote\\_mem: destroying inuse region 0x2029e50 0x2029..0x602767bf43123598 g- rw ref apid 0x11000a5244 attach\\_addr (nil) rmem 0x1aa0b50 ; Hi name, Thanks for reaching out! I am wondering if you were using intel mpi for your program. If so, can you share your job script used to submit a job on Anvil? Regards, name, PhD (She/Her/Hers) Sr. Computational Scientist ; Thanks a lot for your reply, name. I'm using gcc and openmpi when compiling. The job folder is at /anvil/scratch/x-hliastro/starforge/RUNs/test/ Let me know what else I need to provide to help you diagnose. Cheers, name \\*From:\\* ACCESS Ticket Submission \\*Sent:\\* Thursday, February 15, 2024 3:35 PM \\*To:\\* \\*Subject:\\* ATS-6066 random error when running simulations —-—-—-— Reply above this line. name commented: Hi name, Thanks for reaching out! I am wondering if you were using intel mpi for your program. If so, can you share your job script used to submit a job on Anvil? Regards, name, PhD (She/Her/Hers) Sr. Computational Scientist ---- Automation for Jira changed the status to Waiting for customer. View request: https://access-ci.atlassian.net/servicedesk/customer/portal/2/ATS-6066?token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ0Z3QiOiJhbm9ueW1vdXMtbGluayIsInFzaCI6IjU5NTZkOTQ4MDQ1MjhhZWVmMjM1NDljYTQyNzIzODU1ZjE5OWIyN2JlMGQwMGM2MjhhY2FiYmU1NzQxNjAwZTUiLCJpc3MiOiJzZXJ2aWNlZGVzay1qd3QtdG9rZW4taXNzdWVyIiwiY29udGV4dCI6eyJ1c2VyIjoiMTQwOTQiLCJpc3N1ZSI6IkFUUy02MDY2In0sImV4cCI6MTcxMDQ1MjA4MiwiaWF0IjoxNzA4MDMyODgyfQ.hQ2xXzFdg6k\\_OByYB3wo2favF4mrqZanVxmkgLw6MNQ&sda\\_source=notification-email · Turn off this request's notifications: https://access-ci.atlassian.net/servicedesk/customer/portal/2/ATS-6066/unsubscribe?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ0Z3QiOiJhbm9ueW1vdXMtbGluayIsInFzaCI6Ijg0NWNmZjE4Mzg2Yzk0M2QwNjM0Zjg5MzJiMzQ5NTc5MGFlZDM4M2YyMTZiOTBmNmNiMmViMmYyNGQ3ZTQ1NWQiLCJpc3MiOiJzZXJ2aWNlZGVzay1qd3QtdG9rZW4taXNzdWVyIiwiY29udGV4dCI6eyJ1c2VyIjoicW06YjkxYzliMTctNjYwZi00YTUzLWE2N2EtNTAwMzYxMDZmNTlhOjU1ZGExODc1LTY4MjUtNDUyMi04YTE5LWFlYjc5ZmQ1NDQ2YiIsImlzc3VlIjoiQVRTLTYwNjYifSwiZXhwIjoxNzEwNDUyMDgyLCJpYXQiOjE3MDgwMzI4ODJ9.pJEAw3hCZHHIGnLXDs4pCJaqUSr2kcJ20vDTG-tU3tY This is shared with name. Sent on February 15, 2024 3:34:42 PM CST ; \\*\\*PRIVATE NOTE\\*\\* Hi name, [~accountid:id Do you have ideas what this related? I checked their job script, #!/bin/bash #SBATCH -A phy220084 #SBATCH -p wholenode #SBATCH -J 5e5 #SBATCH --nodes=1 #Request 1 node #SBATCH --ntasks=128 #Request 4 tasks (cores) #SBATCH --time=80:00:00 #Request runtime of 30 minutes #SBATCH --mem-per-cpu=1900 #Request 2G of memory per CPU module purge module load gcc gsl gmp openmpi hdf5 export LD\\_LIBRARY\\_PATH=$LD\\_LIBRARY\\_PATH:/home/x-hliastro/local/sundials/instdir/lib64 echo $SLURM\\_NTASKS mpirun -n $SLURM\\_NTASKS ./Arepo param.txt 1 1> output/OUTPUT.$SLURM\\_JOB\\_ID 2>output/ERROR.$SLURM\\_JOB\\_ID Thanks! name ; Dear name, Any updates? It is quite urgent since I have been stuck with this bug for a long time. Thank you so much. Cheers, name ; Hi name, Sorry for the delay. I forgot to let you know that I passed your questions to our application scientists and I lost track of this ticket. Apologize for any inconvenience this caused. I just checked with our scientists and they said they would put this ticket in the high priority. Thank you for your patience and we will keep you posted. Regards, name ; Hi name, Do you have job IDs for this and is this still happening? This sounds like an intermittent MPI error which may either be a bug in the MPI library or hardware error. Please let us know if it is still happening. Best regards, name. ; Hi name, Thank you so much for your reply. Yes, I still stored the runs with such errors located at /anvil/scratch/x-hliastro/starforge/RUNs/r32\\_alpha1/openmpi/output You can see the last few lines of the output files for error messages. Another issue: Recently, I changed the mpi module from openmpi to mvapich2 and the error disappeared. However, when using mvapich2, when I use more than 4 nodes, I got error: 101 => 456: post\\_srq\\_send(ibv\\_post\\_sr (post\\_send\\_desc)): ret=12, errno=2: failed while avail wqe is 63, rail 0 This run is stored at: /anvil/scratch/x-hliastro/starforge/RUNs/r32\\_alpha1/256/output\\_mpi\\_fail It never happened before using openmpi and never happened when using less than 4 nodes. Please let me know if you have any clue on this matter as well. Thank you so much for your help. ; Hi name, Another quick check would be to try the ""openmpi/4.1.6"" module. I know the old openmpi/4.0.6 version has some known bugs. L'll check your error files. Best regards, name. ;",hliastro@access-ci.org,Hui Li,Amiya Maji,Purdue University,Anvil,9,94,6,2024,2024-02-05
ATS-8530,software question,2024-06-06,2024-06-17,"I am using OpenFOAM to perform my calculations. One functionality that I am hoping to use is for viscoelastic flows. These first appeared in OpenFOAM version10. From what I can tell, the latest version that I can find across the Access sites is version 8 on Anvil (bridges-2 has version 6; I requested a credit exchange for Darwin, which has openfoam, but looks like earlier version according to user guide - awaiting username). Are there any options to have the most recent version of openFOAM (version 11) installed on one of the ACCESS sites? I have installed on my lab computer to set up/stage jobs and perform smaller calculations so it would be very convenient to have the same version as well. Thank you for considering this request. Mark Nicosia ; Hi Mark, Thank you for reaching out to Anvil support. Our software installation policy only allows us to install software that is in high demand. You can find more details about our policy here: Software Installation Policy: https://www.rcac.purdue.edu/knowledge/anvil/policies/software\\_installation\\_request\\_policy. OpenFOAM has two separate distributions (openfoam.org: http://openfoam.org/ and openform.com: http://openform.com/), each with its own multiple versions, and the most widely used version we currently support is 8-20210316. I would suggest trying to install the software yourself in your home directory or within your allocated project space. Alternatively, you might consider building a Singularity container with your preferred version of OpenFOAM. We have a tutorial: https://www.rcac.purdue.edu/training/containers101 on containers which might be helpful for you. Also, you can find pre-built OpenFOAM docker images on Docker Hub: https://hub.docker.com/search?q=openfoam which you can convert them to singularity using the steps mentioned in the tutorial. I hope this information is useful. Please let me know if you need further assistance. Best regards, name Senior Computational Scientist RCAC - Purdue University ;",nicosia@access-ci.org,Mark Nicosia,Haniye Kashgarani,Purdue University,Anvil,2,8,23,2024,2024-06-03
ATS-8551,Borked Virtual Env because of file source package dependency 'fs' and 'httpuv',2024-06-06,2024-06-20,"I'm having dependency issues in R (v 4.3.2) in my conda env called R5, I cannot install 'fs' and 'httpuv' when I try installing them with the following commands: conda activate R5 R CMD INSTALL fs R CMD INSTALL httpuv It gives me the error I have attached in the screenshot. These dependencies were working before, as the package 'Seurat' was functioning before. However, now I cannot load it with the following command: library(Seurat) It gives an error that it cannot install due to httpuv dependency absence. I tried creating a new conda environment, but the following bug still shows up. This is the closest forum I could find to the c++ compiling error: https://bbs.archlinux.org/viewtopic.php?id=242682: https://bbs.archlinux.org/viewtopic.php?id=242682|smart-link . I think the GNU compiler version is causing this error, but don't understand linux enough to say that for sure. My current version is: (R5) \\*:library\\* $ as --version GNU assembler version 2.30-123.el8 Copyright (C) 2018 Free Software Foundation, Inc. This program is free software; you may redistribute it under the terms of the GNU General Public License version 3 or later. This program has absolutely no warranty. This assembler was configured for a target of `x86\\_64-redhat-linux'. I found the forum where it tells me to run the following command: sudo pacman -U http://archlinux.arkena.net/archive/packages/e/elfutils/elfutils-0.174-1-x86\\_64.pkg.tar.xz http://archlinux.arkena.net/archive/packages/l/libelf/libelf-0.174-1-x86\\_64.pkg.tar.xz sudo pacman -U http://archlinux.arkena.net/archive/packages/b/binutils/binutils-2.30-5-x86\\_64.pkg.tar.xz However, when I try running it, it asks for a password and I'm not sure what password to use, as my Anvil ACCESS password doesn't work. Any guidance to install fs and httpuv by resolving the binutils and elfutils dependency conflict will solve my problem ; Hi, Thank you for contacting us. General users on Anvil are not allowed to run {{sudo}} commands. Could you share your detailed workflow so we could reproduce this error? Can you also share why you will need this conda env for the R workflow? Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name ;",swiftj@access-ci.org,Joseph Swift,Guangzhen Jin,Purdue University,Anvil,4,11,23,2024,2024-06-03
ATS-8614,Glib-2.0 Library problem,2024-06-10,2024-06-18,"I have a problem of linking glib-2.0. When I checked the library by 'locate glib-2.0' I cannot find the 'include' location. I think that the Anvil has glib-2.0 library on lib64 directory but failed to find the header files on include directory. I was wondering if you can check it and update to the latest version if possible. Sincerely, Woohyeon ; Hi Woohyeon, Thank you for contacting us. We had discussions on your inquiry and will work to add essential parts for glib-2.0 later. It might take a while. I'll keep you updated. We appreciate your patience. Thanks, name ; Hi Woohyeon, Thank you for your patience. Our scientists have just deployed a module for glib. You may run the following command to get access to it: module load glib/2.68.3 We hope this would help you install the software that is needed for your research. If you see any issues, please feel free to reply to this ticket with the details. Thanks, name ; Hi Woohyeon, I'm checking in to see if you have tried using the {{glib/2.68.3}} module. Please let us know if there is something we can help with. Thanks, name ; Hi name, Thank you for the update. I tried the module and it works fine, which solved my problem. Sincerely, Woohyeon ; Hi Woohyeon, Awesome! Glad it solved the problem. We appreciate your feedback. I'll go ahead and mark this ticket resolved then. Please feel free to contact us again if you have any other questions. Thanks, name ;",bwh,Woohyeon Baek,Ruyi Li,Purdue University,Anvil,6,7,24,2024,2024-06-10
ATS-8685,Node drain ,2024-06-13,2024-06-20,"Hello, The GPU partition contains several drained nodes (such as g003, g007, g011, and g014). Additionally, I noticed that some users in the GPU queue have more than 500 pending jobs!!! I'm not sure what configuration you have in the slurm scheduler. However, this will cause a significant delay in running single jobs—possibly weeks. Would you kindly look at this? Best, name ; Hi, Thank you for contacting us and reporting the issue. Now all the drained GPU nodes have been brought back online. Our current configuration for {{gpu}} partition (called Quality of Service, QOS) is show as below: $ sacctmgr show qos part-gpu format=Name%20,GrpSubmit,MaxTRES%20,MaxTRESPerNode%20,MaxWall,MaxTRESPU,MaxJobsPU,MaxSubmitPU,MaxTRESPA,MinTRES Name GrpSubmit MaxTRES MaxTRESPerNode MaxWall MaxTRESPU MaxJobsPU MaxSubmitPU MaxTRESPA MinTRES ; part-gpu 2-00:00:00 gres/gpu=12 gres/gpu=32 gres/gpu=1 So the max GPUs one user can use is 12 and the max GPUs one allocation can use in total is 32. So it will prevent users from running GPUs job beyond those limits. We did see the concerns of longer waiting time on GPU partitions and are discussing internally about what we can do about it. I would assume the root cause is the GPU nodes quantity and we already have the plan to expand current GPU capacity later this name. Stay tuned for the news and let me know if you have further concerns. Best regards, name Senior Computational Scientist Purdue Information Technology ; Thank you for your prompt resolution and informative response. Please do not hesitate to close the ticket. name ; Thank you! name ;",mzand@access-ci.org,Mohsen Zand,Guangzhen Jin,Purdue University,Anvil,4,6,24,2024,2024-06-10
ATS-8710,Job Charging,2024-06-14,2024-06-19,"Dear Staff, Hi! I just started using the cluster Anvil from Purdue and run some jobs. It appears i used 500+ cpu hours, and from what I estimate I only used about 200 hours. I wonder if I run the job in the right way. Could you please check? Thanks, name ; Hi name, Thanks for reaching out! You can use one of our script to calculate the SUs one job is charged. To use it, we can grab the job id and run command on Anvil {{jobsu jobID}} It would print the SUs this job has been used. Let me know if you have further questions. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ;",yzhou8@access-ci.org,Yang Zhou,Nannan Shan,Purdue University,Anvil,2,4,24,2024,2024-06-10
ATS-9223,Problem with Anvil filesystem,2024-07-10,2024-07-10,"Hi, I can't seem to cd into any of anvil's directories (scratch etc.) - is there an issue? I get a stale file handle even if I do cd /anvil, let alone cd $SCRATCH Thanks, Ish ; Hi Ish, Thanks for reporting this to us. There was an issue with Anvil storage in the early morning (~2am EST today). First thing this morning engineers were able to isolate and fix the underlying issue. Please let me know if you still see problem on this. Thank you! Regards, name, PhD (She/Her) Senior Computational Scientist Purdue University ;",ikaul@access-ci.org,Ish Kaul,Nannan Shan,Purdue University,Anvil,2,1,28,2024,2024-07-08
ATS-8714,Using licenced software,2024-06-15,2024-06-20,"Hello, I hope this message finds you well. Our group possesses licenses for VASP 5.4, Gaussian 16, and GaussView. I am seeking guidance on utilizing these tools within Anvil. Although they are installed, attempts to run VASP have resulted in an error stating ""{{slurmstepd: error: execve(): vasp\\_std: No such file or directory}}"". Attached are the sh file and the error file. Additionally, I would appreciate clarification on whether VASP 5.4.4 is compiled with Wannier90 and VASPsol. Thank you for your assistance. Best regards, Basant ; ^myjob.e5457009] ^submit.sh ; Hi Basant, Thanks for reaching out! To use our VASP5 module, you will need to be added into vasp5 unix group on Anvil. Our current VASP module does not include vaspsol and wannier90. If you want to be added, let me know your email associated with your vasp license. There is no installed Gaussian ang GaussView on Anvil due to the restriction of license. I would recommend to install Guaussian and GaussView to you own project space and use them on Anvil. login01.anvil:~ $ myquota x-belshoky Type Location Size Limit Use Files Limit Use ============================================================================== home x-belshoky 35KB 25.0GB 0.00% - - - scratch anvil 1.5MB 100.0TB 0.00% 0k 1,000k 0.00% projects x-mat240047 0KB 5.0TB 0% 0k 1,048k 0.00% Please feel free to check our user guide about running jobs on Anvil. [https://www.rcac.purdue.edu/knowledge/anvil: https://www.rcac.purdue.edu/knowledge/anvil|smart-link Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Hi name, Thank you for your reply. The email associated with our group's VASP license is (). I wonder if I can recompile VASP to include vaspsol and winner90? Thank you, Basant ---- ; Hi name, Thank you for your reply. The email associated with our group's VASP license is (: mailto:). I wonder if I can recompile VASP to include vaspsol and winner90? Thank you, Basant ; Hi Basant, You did not come to Anvil Support Hour (2:20pm-2:40pm EST June 20, 2024) today. I assume you are good now. To answer your question, you can compile VASP with vaspsol and wannier90. There is instruction on vaspsol page about the installation. And you can add the PATH of wannier90 to your makefile.include to compile VASP with wannier90. The email you shared belongs to name Musgrave. If you want to be added into vasp5 unix group, I will need YOUR email address, not other person's. Your supervisor should be able to add you to VASP license with your email address. Regards, name ;",belshoky@access-ci.org,Basant Elshoky,Nannan Shan,Purdue University,Anvil,6,4,24,2024,2024-06-10
ATS-8769,Access to Purdue FORTRESS?,2024-06-18,2024-06-25,"I have an allocation on Anvil through an ACCESS allocation and am wondering if we can get access to the FORTRESS tape library at Purdue to store files? The project storage allocation on the local Anvil disk is only 5 TB, which is not enough for our group's needs. It is not clear to me from the documentation if ACCESS allocations to Anvil come with FORTRESS access or not. Thanks, name ; Hi name, Thank you for contacting us. Would you please let us know more details about your storage needs? Warm regards, name ; Hi name — Yes, we are currently carrying out a set of large simulations on Anvil that will produce about 10-20 TB of data. We expect to generate these data and store them temporarily on the $SCRATCH system of Anvil, but would like to keep copies for a year timespan so that we can continue to go back and do follow-on analysis as well as compare to later simulations. Therefore, we are looking for tape storage of at least this size (20 TB, but possibly more). It seems like FORTRESS, a tape storage system at Purdue, would be ideal for this purpose. We do have some storage through ACCESS at PSC Ocean, but since this is at a different computer system, we would have to move the data (so possible, but less than desirable). Thanks for your help, name, We can do this through a Globus share. Could you verify if it is for him or his whole group? I can then send an invite to let the members access it. name ; \\*\\*PRIVATE NOTE\\*\\* Hi name, That would be great name ; Hi name, Thanks for sharing more information name ; Hi name, Thanks for letting us know that! We'll go ahead and mark this ticket resolved then. Please feel free to contact us again if there are any issues or you have any questions. Warm regards, name ;",gbryan@access-ci.org,Greg L. Bryan,Ruyi Li,Purdue University,Anvil,15,6,25,2024,2024-06-17
ATS-8778,Code does not running in wide queue,2024-06-18,2024-06-27,"Hi, I was running my simulation. I saw that the same code runs perfectly and writes the data file in \\*wholenode\\* queue, while it does not run and produce any data in the the \\*wide\\* queue. I tried many times, but I see the same issue in wide queue with any number of nodes 10-56. The code shows running in the status, but does not produce any data or does not stop with any error message. Job ID: {{5495310}}. Could you please help me in resolving this issue? Thank you. Regards, Ratan name ; Ratan, which resources are you running this on? Expanse, Bridges, Anvil, etc? Thanks Can you share what error message you were seeing for JOB {{5495310}}? Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Him, Surprisingly, there were no error messages. The code runs without printing any data file in wide queue, while it works fine in wholenode queue. Thank you. regards, ratan name ; Thanks for letting me know. Glad the problem is resolved. --name ;",x-rkbera,Ratan,Nannan Shan,Purdue University,Anvil,6,8,25,2024,2024-06-17
ATS-8806,Problem running all batch jobs,2024-06-20,2024-06-27,"Hello, I recently received access to Anvil. My username is x-dasgari. I ran the following batch job: #SBATCH -N 1 #SBATCH -n 1 #SBATCH -o batch%a.out #SBATCH -t 40:00:00 #SBATCH --mem-per-cpu=100gb #SBATCH --array=1-20 However, out of 20 batch jobs only 2 are running and the other 18 are pending. How can I run all at the same time? My balance: Allocation Type name Limit name Usage name Usage name Balance Account (account) (user) ============= ==== ========== ========== ========== ========== bio240182 CPU 5000.0 61.4 61.4 4938.6 Thanks, Danial ; Hi Danial, Thank you for reaching out. The issue you're encountering is because you're defining a single task to run on one node, which limits the number of simultaneous jobs. To correct your job script so that your array jobs run simultaneously, please modify your script as follows: #!/bin/bash #SBATCH -o batch%a.out #SBATCH -t 40:00:00 #SBATCH --mem-per-cpu=100gb #SBATCH --array=1-20 #SBATCH -A youraccount This script removes the -N 1 and -n 1 lines, which were constraining the job to a single node and a single task, respectively. Please let me know if you need further assistance. Best, name Senior Computational Scientist RCAC - Purdue University ; Hello, I tried this. Now only one job out of 20 job is running. ; Hi Danial, The job arrays should start and run simultaneously if you have enough SUs in your queue and resources are available. If your jobs are not running concurrently, it may be due to resource availability. Also, I noticed you have a pending job with AssocGrpCPUMinutesLimit, and the reason seems to be the memory you requested. Currently, we have 2GB for one CPU (256 GB for 128 cores on A subcluster). Do you require this large memory, if so, you should increase the number of CPUs. $ jobscript 5722604 #!/bin/bash #SBATCH -o batch%a.out #SBATCH -t 40:00:00 #SBATCH --mem-per-cpu=100gb #SBATCH --array=1-20 #SBATCH --cpus-per-task=1 # Number of CPUs per task #Activate the virtual environment module load python/3.9.5 #Run your Python script with the virtual environment's Python interpreter python code.py Best, name Senior Computational Scientist RCAC - Purdue University ; Thank you for your response. So, if I want to use 100GB memory per simulation (which is what I need), I should use 50 cpus (50x2 = 100). Is that possible? ; Hi Danial, I checked your SUs again and I should explain what I found for you. You currently have 2012.0 SUs in your account, and your job script requires 100 GB of memory, which will require 55 cores on Anvil. So, the name needed for only one of your job arrays would be 55 \\* 40 (requested time) = 2200, and you have 20 job arrays. So, multiply this by 20. Each job in the array will require 2200 SUs, and you don't have this amount available in your allocation. $ mybalance x-dasgari Allocation Type name Limit name Usage name Usage name Balance Account (account) (user) ============= ==== ========== ========== ========== ========== bio240182 CPU 5000.0 2988.0 2988.0 2012.0 I found number of cores needed (55) from your completed jobinfo: $ jobinfo 5722604\\_1 Name : batch.sh User : x-dasgari Account : bio240182 Partition : shared Nodes : a190 Cores : 55 GPUs : 0 State : COMPLETED ExitCode : 0:0 Submit : 2024-06-22T15:07:30 Start : 2024-06-22T15:07:31 End : 2024-06-23T01:21:42 Waited : 00:00:01 Reserved walltime : 1-16:00:00 Used walltime : 10:14:11 Used CPU time : 10:12:14 % User (Computation): 92.96% % System (I/O) : 7.04% Mem reserved : 100G Max Mem used : 64.17G (a190) Max Disk Write : 9.00M (a190) Max Disk Read : 9.92M (a190) Best, name Senior Computational Scientist RCAC - Purdue University ; I can get more allocation (194,000). If I do that, can I run the jobs using 55 cpus per task? Is that possible? ; Yes, we have maximum of 128 core on each nodes on Anvil. https://www.rcac.purdue.edu/compute/anvil: https://www.rcac.purdue.edu/compute/anvil|smart-link Best, name ; Hi, I changed the batch job to: #!/bin/bash #SBATCH -J code #SBATCH -N 1 #SBATCH -n 1 #SBATCH -o batch%a.out #SBATCH -t 10:00:00 #SBATCH --mem-per-cpu=25gb #SBATCH --cpus-per-task=15 #SBATCH --array=1-20 Yet I get this error message: Batch job submission failed: Requested node configuration is not available ; I figured out the problem. Sorry for the last email. Danial ; No problem, Danial. Thank you for letting me know that the issue is resolved. Best, name ;",dasgari@access-ci.org,Danial Asgari,Haniye Kashgarani,Purdue University,Anvil,11,6,25,2024,2024-06-17
ATS-7177,Continued discussion from ATS-510: Installing Schrodinger Maestro,2024-03-31,2024-07-02,"Hi, a ticket I raised earlier (ATS-510) was closed due to inactivity. I posted a comment on it today, but it did not reopen. I'm posting this just to bring it to your attention, in case you don't get notified for comments on closed tickets. Please close this if you can manually reopen that one. Otherwise, let us continue the discussion here. Thanks ; Hi name, I was wondering if you had a chance to look into this. Please let me know if you need any other information. Thanks ; I also wanted to add that I have no issues running Maestro on Bell and Gilbreth. Only on Anvil. ; Hi name, just wanted to know if you had a chance to look into this. Thanks. ; Hi, Sorry for the delay. I have tested under your account and didn't see this error (saw some other QT debugging messages). I suspect the environment change in your {{~/.bashrc}} might have effects with this issue. Can you temporally rename {{~/.bashrc}} (e.g. {{~/bashrc\\_backup}}) and \\*start a new session\\* then try again? You might need to run a {{module use /anvil/projects/x-bio230051/apps/modulefile}} to allow lmod finding the schrodinger module. So commands will look like: module use /apps/spack/anvil/modules/lmod/linux-centos8-x86\\_64/Core/ module load libxkbcommon/0.8.2 module use /anvil/projects/x-bio230051/apps/modulefile module load schrodinger/2023-4 export QT\\_DEBUG\\_PLUGINS=1 maestro name ; Hi Guanhzhen. Thanks for your effort in investigating this issue. Unfortunately, I get the same error again. Please see the attached file. ; Hi, I tried again with your account and still didn't see the error. It might be better for us to jump into a quick call and troubleshoot this together. I am fully booked this week so could you share your availability next week so we can arrange a meeting? name ; Sounds great. I'm available anytime during Monday to Wednesday. Please let me know a time that works for you. Thanks ---- ; Hi name, The Schrodinger team sent a link to this page which lists all the packages required for various distributions. Please have a look and let me know if you have any questions. Thanks a lot for your help with this. schrodinger/linux\\_package\\_requirement: Script to check required packages for Schrödinger suite on Linux machine (github.com): https://github.com/schrodinger/linux\\_package\\_requirement/tree/main Best regards, name, Thank you for the update. I have access to the allocation now but there is another layer of group control for the modulefile use which is the {{x-tdm-atom}}. Do you recall who added you into this unix group so we can ask to add my account {{x-name}} into the group to do the test? name ; Schrodinger is installed in the bio230051 project space, so you should be able to access the installation without having access to TDM. TDM is Data Mine's allocation which I am a part of, but no schrodinger files are installed there. This is where it is installed: /anvil/projects/x-bio230051/apps/ Modulefiles are in the same folder. ---- ; Oh I see what you mean. The modulefiles folder was a part of the x-tdm-atom group. I have moved it to x-bio230051 now. Please try again and let me know. ---- ; OK. Now it works with the {{modulefiles}} folder but you might need to check the permissions for the installation location {{/anvil/projects/x-bio230051/apps/schrodinger/}} as well because I got permission error while trying to use everything inside. You might need to add group read and execute permissions to it and all the subfolders. :[apps $ ll schrodinger -d drwx--S---+ 3 x-pballaney x-bio230051 4096 Jan 23 23:25 schrodinger name ; Does this look okay? If not, please let me know how to give you access. drwxrws---+ 2 x-pballaney x-bio230051 4096 name 5 16:11 schrodinger/ ; I meant the permissions for the \\*installation location\\* {{/anvil/projects/x-bio230051/apps/schrodinger/}} not the modulefile location. If you could do a {{chmod -R g+rx /anvil/projects/x-bio230051/apps/schrodinger/}} which will give group read/execute permissions to the above folder and its subfolders, that will fulfill the task. name ; Hey, Any change taking a look at those changes? name ; Hi name, Sorry I ran the command earlier, but I forgot to reply here. Please check if you can access it now. Best regards, name ---- ; Hi, After some experiments I think I've fixed the issues on the system so {{maestro}} GUI can start without reporting those library issues. But now it is giving a license error for me (see attached) so can you also check about it? Here are the steps I used and if you can confirm it's working for you. module use /apps/spack/anvil/modules/lmod/linux-centos8-x86\\_64/Core/ module load libxkbcommon/0.8.2 module use /anvil/projects/x-bio230051/apps/modulefiles module load schrodinger/2023-4 module load xcb-util-wm xcb-util-image xcb-util-keysyms xcb-util-renderutil export QT\\_DEBUG\\_PLUGINS=1 maestro -SGL name ; Hi, Any updates on this issue? name ;",x-pballaney,Pranav Ballaney,Guangzhen Jin,Purdue University,Anvil,26,67,13,2024,2024-03-25
ATS-8798,Looking for Your Help to Run on Anvil,2024-06-20,2024-07-01,"Hello Anvil Team, I am trying to access Anvil through the SSH Keys. I created the public key of my local PC and pasted it on the .ssh directory on Anvil. However, it still asks for a password when I try to connect from my terminal on the local PC. Also, I do not know if there is a working directory that I should be in when submitting my jobs or if it is ok to work on the home directory and the large files will be kept in the home directory. The last thing is I want to use LAMMPS on Anvil. Would the following command be correct to submit my jobs? #================================= #echo commands to stdout set -x export OMP\\_NUM\\_THREADS=1 INPUT=input.file\\_name module purge module load cpu/0.15.4 gcc/10.2.0 mvapich2/2.3.4 module load lammps/20200721-openblas EXE=`which lmp` srun --mpi=pmi2 -n 1280 $EXE -in $INPUT #================================= My Anvil ID is \\*x-abdlmwla\\* Please let me know if any information is needed from my side, as I will be looking forward to your help. Thanks, name ; Hi name, Thank you for reaching out. To set up the SSH key for Anvil, please remove all contents of /home/x-abdlmwla/.ssh/\\* and then copy and paste your public key into /home/x-abdlmwla/.ssh/authorized\\_keys. This should solve your problem. Here is our user guide for setting up the SSH key for Anvil: https://www.rcac.purdue.edu/knowledge/anvil/access/login/sshkeys. Regarding your second question, you can see the directories that you have access to using the myquota command: $ myquota x-abdlmwla Type Location Size Limit Use Files Limit Use ============================================================================== home x-abdlmwla 39KB 25.0GB 0.00% - - - scratch anvil 0KB 100.0TB 0% 0k 1,000k 0.00% projects x-mss190008 4.9TB 5.0TB 98% 35k 1,048k 3% Based on the output, you have access to: \\* /home/x-abdlmwla with 25GB of space. Try using this space for setting up your environment, etc. Ensure this directory has some space; otherwise, you'll have problems connecting to OnDemand. \\* /anvil/projects/x-mss190008 with 5TB of data. This space is shared with your group members. \\* /anvil/scratch/x-abdlmwla with 100TB of space. Remember our purge policy: files older than 30 days will be purged. Use this as temporary space for up to 30 days. You can read more about our file systems at https://www.rcac.purdue.edu/index.php/knowledge/anvil/storage/filesystems. For submitting LAMMPS jobs, please visit our user guide at https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/lammps/lammps\\_job\\_submit\\_script. Try the sample script and modify it as needed. If you have any questions, feel free to reach out again. Please let me know if you have any other questions. Best, name Senior Computational Scientist RCAC - Purdue University ; Hi name, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name Senior Computational Scientist RCAC - Purdue University ;",abdlmwla@access-ci.org,Amir Abdelmawla,Haniye Kashgarani,Purdue University,Anvil,3,8,25,2024,2024-06-17
ATS-8807,Interactive Rstudio issues- libproj.so.15: cannot open shared object file,2024-06-20,2024-06-30,"I am trying to use RStudio with terra and raster packages. I have installed them yesterday on my local space. However, when trying to load them in the interactive session, i get this error: Error: package or namespace load failed for 'raster' in dyn.load(file, DLLpath = DLLpath, ...): unable to load shared object '/home/x-ihaqiqi/R/x86\\_64-pc-linux-gnu-library/4.0/terra/libs/terra.so': libproj.so.15: cannot open shared object file: No such file or directory How can I solve this? ; Hi Iman, Thank you for reaching out. I am curious if you were able to successfully install terra and raster on Anvil. When I try, I see the need for a 'sqlite' dependency, which is currently not available on Anvil, and I will bring this up with my colleagues again. However, if you were able to install successfully, based on the error you shared, you need to load the module ""proj"" in the terminal. On OnDemand, open the Desktop Interactive session, and in a terminal do: $ module load gcc $ module load gdal $ module load proj $ module load r $ module load rstudio $ rstudio Then you'll see the Rstudio and you should be able to load the package if you could successfully install it. Best, name Senior Computational Scientist RCAC - Purdue University ; Dear name, Thanks for your response. Yes. I was able to install sqlite on my space and then terra and raster packages on my user library. name helped me with that. However, I am struggling to use R for my geospatial data analysis. The terra, raster, and sf are the most common packages in R for this purpose but it is really difficult to use them on Anvil. As you said, it first requires sqlite. After that, I am not able to test and troubleshoot my codes as the Rstudio had problems. Even using desktop, there are issues loading it. Look below: qt.qpa.xcb: could not connect to display :1.0 qt.qpa.plugin: Could not load the Qt platform plugin ""xcb"" in """" even though it was found. This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem. My submitted jobs are killed without a proper error message and I need to run a sample job on Rstudio to see if I can find the causes. Unfortunately when I am trying to run a very simple job of raster\\_sum = raster\\_a + raster\\_b, the R session crashes and needs to restart. I spent the whole week on this and its getting frustrating. Thanks for your help. Iman ; Thank you for this comment and clarifying the issue. I will keep you updated if the dependencies could be installed or not. But in the meantime you should be able to install the dependencies as name suggested in the previous tickets or using singularity/apptainer containers. Let me know if you have any other questions. Best, name Senior Computational Scientist RCAC - Purdue University ; Hi Iman, ""udunits2"" and ""sqlite3"" are now available as a module on Anvil. Try loading: module load gcc module load r module load gdal module load proj module load udunits/2.2.28 module load sqlite/3.35.5 Then, try to install the sf, raster, and terra package in R, and this should solve your problem. I will mark this ticket as resolved now, but you can reopen the ticket if you have questions or concerns. Best, name Senior Computational Scientist RCAC - Purdue University ;",x-ihaqiqi,Iman Haqiqi,Haniye Kashgarani,Purdue University,Anvil,5,7,25,2024,2024-06-17
ATS-8809,Issue locating tirpc library,2024-06-20,2024-07-02,"Hello, I have recently gotten access to Anvil and am attempting to compile our software BOCS. It requires the use of the tirpc/rpc library, specifically the xdr.h file. On most other clusters, I have been able to provide this information in my cmake file, setting the location of these libraries like this: set ( RPC\\_HOME ${RPC\\_HOME} /xxx/xxx/path/to/tirpc/library ) include\\_directories(${RPC\\_HOME}/include/tirpc) set ( RPC\\_LIB ${RPC\\_LIB} ${RPC\\_HOME}/lib/libtirpc.so ) and then this file is used in various src files like this: #include I have been unable to make this work on Anvil. I cannot find the tirpc library, and found a version of the xdr.h file elsewhere, but not the libtirpc.so file - which has caused my compilations to fail. Any help is much appreciated as I require this software to build my models. The code I am attempting to compile can be found here: /anvil/projects/x-che240094/Software/BOCS\\_v5/force-matching, with compilations instructions in the README file. Thanks, name ; Hi name, Thank you for reaching out. By using the following command you can find the path to the installed libtirpc library on Anvil . $ locate libtirpc.so /usr/lib64/libtirpc.so.3 /usr/lib64/libtirpc.so.3.0.0 Please try setting your variable with the correct path and try again and this should solve your issue. set(RPC\\_HOME /usr/lib64) # Set the path to libtirpc.so include\\_directories(${RPC\\_HOME}) set(RPC\\_LIB ${RPC\\_HOME}/libtirpc.so) #include Best, name Senior Computational Scientist RCAC - Purdue University ; Hi name, I made the suggested changes to my CMakeLists.txt file, but upon compiling I still ran into the error that ""xdr.h: No such file or directory"" Do you have any other suggestions? Any help is appreciated. Thanks, name ; Hi name, Upon your request, we will deploy 'tirpc' library as a module which will ease the process for the compilation. I will escalate the ticket to my colleague, ~accountid:id , who will work on deploying the module. Normally, on Anvil, we deploy modules for the core compiler version GCC 8.4.0, but could you please let me know which version of the compiler you'll need? Best, name Senior Computational Scientist RCAC - Purdue University ; Thank you very much - the module option would definitely help ; Thank you for the information. I will escalate the ticket now. In the meantime, xdr.h is located in the paths below. Please include it in your code based on the compiler you need: $ find /apps/spack/anvil/apps/libtirpc/ -name xdr.h /apps/spack/anvil/apps/libtirpc/1.2.6-aocc-3.1.0-hg3w37j/include/tirpc/rpc/xdr.h /apps/spack/anvil/apps/libtirpc/1.2.6-gcc-11.2.0-4ssmhoa/include/tirpc/rpc/xdr.h /apps/spack/anvil/apps/libtirpc/1.2.6-gcc-8.4.0-u7oh6k4/include/tirpc/rpc/xdr.h /apps/spack/anvil/apps/libtirpc/1.2.6-aocc-3.1.0-tojz4ky/include/tirpc/rpc/xdr.h /apps/spack/anvil/apps/libtirpc/1.2.6-gcc-11.2.0-23hdgls/include/tirpc/rpc/xdr.h /apps/spack/anvil/apps/libtirpc/1.2.6-intel-19.1.3-ndobbnp/include/tirpc/rpc/xdr.h /apps/spack/anvil/apps/libtirpc/1.2.6-gcc-8.4.1-4nltasv/include/tirpc/rpc/xdr.h /apps/spack/anvil/apps/libtirpc/1.2.6-intel-19.0.5-hzrvzns/include/tirpc/rpc/xdr.h /apps/spack/anvil/apps/libtirpc/1.2.6-intel-19.0.5-mzpbgr6/include/tirpc/rpc/xdr.h /apps/spack/anvil/apps/libtirpc/1.2.6-gcc-10.2.0-5vbhukf/include/tirpc/rpc/xdr.h /apps/spack/anvil/apps/libtirpc/1.2.6-gcc-10.2.0-pdy6cw5/include/tirpc/rpc/xdr.h Best, name ; Hi, Please allow me to chime in and assist my colleague name. We have deployed the {{libtirpc}} module on Anvil so you could use it by {{module load libtirpc}} and it will help add all its library files into system path (learn more about what it will do with command {{module show libtirpc}}) so your process can pick them up. Give it a try and see if it can help resolve this issue. Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi name, Thanks for your help here. I have modified my CMakeLists.txt file to now allow for the libtirpc library. With some additional changes to the make process, I was able to compile the software successfully. At this point, this issue is resolved and the ticket can be closed. Thanks! name ; Hi, That's awesome! Thank you for the update. Will resolve the ticket for now. Best, name ;",rszukalo@access-ci.org,Ryan Szukalo,Guangzhen Jin,Purdue University,Anvil,9,9,25,2024,2024-06-17
ATS-8810,unable to install packages in R,2024-06-20,2024-06-30,"I am trying to install the sf package in R on Anvil. I get this error: byte-compile and prepare package for lazy loading Error in loadNamespace(j <- i1L, c(lib.loc, .libPaths()), versionCheck = vIj) : namespace 'units' 0.6-7 is being loaded, but >= 0.7.0 is required Calls: ... namespaceImportFrom -> asNamespace -> loadNamespace Execution halted Would you please help me so I can solve it? ; Hi Iman, Thank you for reaching out! It looks like installing the 'sf' package requires the 'units' package. I checked and found that, by default, we're on version 0.6-7 of 'units' when using R 4.1. However, the 'sf' package needs 'units' version >=0.7.0. I attempted to update the 'units' package, but it turns out that it also depends on 'udunits2'. Unfortunately, we don't currently have 'udunits2' on Anvil. I've discussed this with my colleagues, and we're looking into installing it. At the moment, I don't have a definite ETA for when it will be available. In the meantime, I'd recommend setting up containers, such as Singularity/Apptainer. We have a helpful tutorial on how to use Singularity/Apptainer on this page: https://www.rcac.purdue.edu/training/containerizing-hpc-applications-with-singularityapptainer I'll also keep a note in my tasks to update you as soon as 'udunits2' is installed on Anvil. Best, name Senior Computational Scientist RCAC - Purdue University ; Hi Iman, ""udunits2"" is now available as a module on Anvil. Try loading: module load gcc module load r module load gdal module load proj module load udunits/2.2.28 Then, try to install the sf package in R, and this should solve your problem. I will mark this ticket as resolved now, but you can reopen the ticket if you have questions or concerns. Best, name Senior Computational Scientist RCAC - Purdue University ; Thanks, name, for helping to resolve the issue. ;",ihaqiqi@access-ci.org,Iman Haqiqi,Haniye Kashgarani,Purdue University,Anvil,4,7,25,2024,2024-06-17
ATS-8851,Adding VASP license to my account,2024-06-22,2024-07-01,"Hi name, I hope this email finds you well. Sorry for missing our previous meeting, I had an urgent family issue and could not attend or cancel the meeting. I am still waiting for my supervisor to add me to the group's VASP license. However, I tried to compile my own VASP.5.4.4 including VASPsol and Wannier90. However, I have the following problems: 1. When compiling with Wannier90, I have this error (cannot find /apps/spack/anvil/external/vasp/wannier90-3.1.0-gcc-11.2.0/libwannier.a: Permission denied) 2. After compiling VASP without Wannier90, the jobs take too much time (more than usual on other machines I used before using the same number of cores and the same memory allocation). # Vasp doesn't write the OSZICAR or CONTCAR during the run which means this is a compilation error, although I followed all the instructions on Anvil using the GNU compilation. When I used Intel compilation, I received an error during the compilation process. # The jobs give an Out of Memory Error although I am sure the provided memory should be enough. Please, advise. Thank you in advance. Best Regards, Basant ; Hi Basant, Thanks for reaching out and came to the Anvil Support Hour today. Like we discussed, please add {{--mpi=pmi2}} argument to {{srun}} to test if this can help to get rid of {{numa\\_num}} error. You have been added to {{vasp5}} unix group on Anvil. Your membership will be ready in 4 hours. If you cannot load {{vasp.5.4.4.pl2}} module tomorrow. Let me know. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ;",belshoky@access-ci.org,Basant Elshoky,Nannan Shan,Purdue University,Anvil,2,6,25,2024,2024-06-17
ATS-13144,Need access to VASP on Anvil,2025-01-12,2025-01-31,"Hi, I wish to use VASP on the Anvil server. My VASP license number is 22-0315. Kind regards, name ; Hi name, Thank you for reaching out to us. We will confirm your status as soon as we can. Best Regards, Eli name Purdue IT ; Hi I was granted access a while back. Kind regards, name ---- ; Hi name, Glad to hear this. Best Regards, Eli name Purdue IT ; Already given access ;",evarghese@access-ci.org,Emin Varghese,Elian Inigo Rieza,Purdue University,Anvil,5,15,2,2025,2025-01-06
ATS-8912,Submitting batch jobs on Purdue Anvil,2024-06-25,2024-07-03,"Hello. This is a preventative question about running jobs on Anvil to potentially save a lot of problems down the road. I submitted a couple batch jobs on Anvil using our access allocation 230071. My username on anvil is x-mankola. The first issue is that my jobs have now been pending for a couple of days. I don't think this is too unusual, but I have not run on anvil before and I am wondering if this is something to be expected or not. The other issue is that before I was able to run these jobs successfully, I ran into some errors with my job requests: sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits) I got messages like ""sbatch: error: QOSMaxNodePerJobLimit"" or ""sbatch: error: QOSMaxCpuPerJobLimit"" and I changed those requested numbers around a bit until the jobs were submitted successfully, but it seems to be that all of the requests were within the limits posted by anvil here: https://www.rcac.purdue.edu/knowledge/anvil/run?all=true: https://www.rcac.purdue.edu/knowledge/anvil/run?all=true|smart-link Could there be some additional limits imposed on my account or our allocation? I am not aware of any of these. There is a disconnect here for me as, even though I submitted the jobs, I am not sure what the limits were that I got under. Please let me know if there is some clear way to understand this, as it has been confusing me a bit. Thanks, Andi ; Hi Andi, Thank you for reaching out. For the first issue, it seems the remaining SUs in allocation {{phy230071}} are insufficient for any of your currently queued jobs. If you run the command {{squeue --me -l}}, you would see that your jobs are pending because of {{AssocGrpCPUMinutesLimit}}. $ squeue -u x-mankola -l Wed name 26 08:02:29 2024 JOBID PARTITION NAME USER STATE TIME TIME\\_LIMI NODES NODELIST(REASON) 5727925 wholenode iEBEMUSI x-mankol PENDING 0:00 4-00:00:00 16 (AssocGrpCPUMinutesLimit) 5727857 wholenode iEBEMUSI x-mankol PENDING 0:00 4-00:00:00 8 (AssocGrpCPUMinutesLimit) You have 81612.5 SUs available in allocation {{phy230071}}, while your jobs need 98304 SUs (job 5727857) and 196608 SUs (job 5727925) respectively. Slurm won't get them started to ensure the SUs won't be wasted in case they could not finish the work. $ mybalance x-mankola Allocation Type name Limit name Usage name Usage name Balance Account (account) (user) ============= ==== ========== ========== ========== ========== phy210068 CPU 0.0 40158685.2 7109.4 n/a phy230071 CPU 100000.0 18387.5 18387.5 81612.5 For the second issue, it would be helpful if you could share your job submission script/command and corresponding error, so that we could take a closer look. Thanks, name ; Hi name, Thanks for the reply. This is very helpful. Can I ask where you are able to see the ""jobs need 98304 SUs (job 5727857) and 196608 SUs (job 5727925) respectively"" Is this information available upfront, or do I just try to estimate it before submitting? For the second issue, I will quote any new cases of it to you as I submit more jobs again. But I imagine the issue that came up above wouldn't be flagged like this? Thanks, Andi ; Hi Andi, You may use the command {{jobsu }} to check the amount of SUs needed for a job. For example: $ jobsu 5727925 Job SUs for 5727925 Job 5727925 submitted to: wholenode, with allocation: phy230071 Reserved Walltime: 4-00:00:00 (96 hours) Job status: PENDING Used Walltime: 00:00:00 (0 hours) Reserved CPUs: 2048 Total CPU SUs Needed for Reserved Walltime: ; Total CPU SUs used for all jobs: 0.0000 Total GPU SUs used for all jobs: 0.0000 The command {{jobsu}} calculates the SUs needs and usage for jobs based on the job accounting strategy documented at the following link: https://www.rcac.purdue.edu/knowledge/anvil/run/accounting: https://www.rcac.purdue.edu/knowledge/anvil/run/accounting|smart-link According to the error messages ""sbatch: error: QOSMaxNodePerJobLimit"" and ""sbatch: error: QOSMaxCpuPerJobLimit"", I would suspect those jobs might have requested more nodes or cpus than the limits - you could see each queue has specific \\*Max Nodes per Job\\* and \\*Max Cores per Job\\* limits at the following webpage: https://www.rcac.purdue.edu/knowledge/anvil/run/partitions: https://www.rcac.purdue.edu/knowledge/anvil/run/partitions|smart-link If you see those errors again, please share your job submission script/command and we'd like to check what the causes could be. Thanks, name ; Hi Andi, Since I have not heard further questions from you in a while, I'm tentatively marking this ticket resolved at this point. Please feel free to submit a ticket to us again if you encounter any issues or need any help. Thanks, name ;",mankola@access-ci.org,Andi Mankolli,Ruyi Li,Purdue University,Anvil,5,7,26,2024,2024-06-24
ATS-9083,Am I allowed to install PLUMED on Anvil by myself,2024-07-03,2024-07-08,"Hello! I am a new user and I was curious to know if I am allowed to install PLUMED by myself on Anvil, as my computations require cp2k+plumed software. If not, do I have to raise a ticket so that PLUMED can be installed successfully for use? Please let me know so that I can proceed accordingly. Thank you Best regards Komal ; Hi Komal, Thank you for reaching out. You should be able to install the software in your space. Please give it a try and let me know if you encounter any problems or concerns. According to the documentation, you'll need to load the GCC module before installing. You can follow the instructions here: PLUMED Installation Guide: https://www.plumed.org/doc-v2.9/user-doc/html/\\_installation.html. To load the GCC module, use the following command: $ module load gcc Best, name Senior Computational Scientist RCAC - Purdue University ; Hello name, Thank you so much for the email. I have now successfully installed cp2k+plumed in my home directory. Best regards Komal ; Awesome! Thanks for letting me know that the issue is resolved. Best, name ;",kyadav@access-ci.org,Komal Yadav,Haniye Kashgarani,Purdue University,Anvil,4,4,27,2024,2024-07-01
ATS-9177,Cannot sbatch job array,2024-07-09,2024-07-12,"Hi Officer, I cannot submit my array job, it shows sbatch: error: Slurm temporarily unable to accept job, sleeping and retrying ; Hi Jiaao, Thank you for reaching out. To help us investigate the issue, would you please share your job submission script and command? A screenshot of the error message would be very helpful too. Warm regards, name ; Thanks. I think I found where the problem is. The slurm can submit limit in total 10000jobs for all the users. So you might need to change the slurs limit systemwidely. name : mailto:于2024年7月9日 周二上午8:42写道: ; Hi Jiaao, Yeah, the queue size hit the limit yesterday. The issue should be fixed now. Would you please try submitting your array job again and let me know if you still see any error? Thanks, name ; Hi Jiaao, The issue should be fixed now. I'm tentatively marking this ticket as resolved. At this point, we would not change the limit on the queue size, taking the current resources and number of users into consideration. We would suggest you adjust the array size in order to fit in the limit if that is necessary. If you have any further questions or concerns, please feel free to re-open this ticket or submit a new one to us. Thanks, name ;",x-wang3,Jiaao Wang,Ruyi Li,,Anvil,5,4,28,2024,2024-07-08
ATS-9184,"Shared partition on Anvil has most nodes in ""comp"" state, SLURM requests take a LONG time",2024-07-09,2024-07-12,"On the shared partition of Anvil, there are no idle nodes. 133 nodes are in the ""comp"" state and seem to have been stuck there for a while. Getting a SLURM job in the shared partition is taking a long time. Something looks broken. Can you please take a look? login03.anvil ~ : sinfo -p shared PARTITION AVAIL TIMELIMIT NODES STATE NODELIST shared\\* up infinite 133 comp a001-003,005,007,010-011,014,019,021-022,024,026,029,031-032,036,043-045,047,051-053,059-060,064,069-071,074-075,077-078,081-083,086-090,094,096-097,100,102-106,109-112,114-116,118-119,133-180,186,194,201-205,207-209,212,215,217-218,223-224,228,230,232-234,236-238,243 shared\\* up infinite 10 drain\\* a000,004,006,066,068,073,084,108,181,199 shared\\* up infinite 1 down\\* a037 shared\\* up infinite 6 drain a009,027,038,065,098,248 shared\\* up infinite 1 resv a040 shared\\* up infinite 40 mix a008,012-013,020,025,028,030,033-035,041-042,049-050,056,061,063,085,091,099,129,182-183,188-189,191,193,196,200,206,210-211,213-214,220-221,225-226,229,239 shared\\* up infinite 57 alloc a015-018,023,046,048,054-055,057-058,062,067,072,076,079-080,092-093,095,101,107,113,117,120-128,130-132,184-185,187,190,192,195,197-198,216,219,222,227,231,235,240-242,244-247 shared\\* up infinite 2 down a039,249 Thanks ; Thanks name! I should add that when attempting to make a SLURM request at the command line from a loginNN node you will see errors like: salloc: error: Slurm job queue full, sleeping and retrying. or: srun: error: Slurm controller not responding, sleeping and retrying. Regards, Doug ; Hi Doug, Thanks for reporting the errors. Our engineers and scientists are currently working on identifying possible resolutions. We will keep you updated. Regards, name ; Hi Doug, I'm following up to let you know that both issues should be fixed now. Would you please try submitting jobs again and let us know if you still see any errors or slowness? Thanks, name ; Things are much better now, thanks name\! The nodes stuck in the comp state seem to have been freed and there are actually 107 idle nodes in the shared partition! It looks like x-btyukodi is near the end of his run and only has 48 concurrent jobs rather than 3000 as well. I'm not sure if they caused the problem, but they likely contributed to it. Regards, Doug ---- ; Hi Doug, Thanks for confirming. It seems x-btyukodi's jobs have finished running. We suspect some jobs (and nodes) got stuck in the completing state because of some issues with the /anvil filesystem. Our engineers and the vendor worked on that and got things straightened up. We are tentatively marking this ticket as this point. Please feel free to contact us again if you see any further issues. Thanks, name ;",dgc,Doug Crabill,Ruyi Li,Purdue University,Anvil,8,4,28,2024,2024-07-08
ATS-9208,Can not submit jobs,2024-07-09,2024-07-12,"I can not submit jobs, it always show ""Priority"" Sometimes, got an error: sbatch: error: Slurm temporarily unable to accept job, sleeping and retrying ; Hi Wubin, Thank you for reaching out and reporting the issue. Our engineers and scientists are currently working on identifying possible causes and resolutions. I'll keep you updated. Warm regards, name ; Hi Wubin, The issue should be fixed now. Would you please try submitting jobs on Anvil again and let me know if you still see any errors or long wait times? Thanks, name ; Yes, it is fixed now. But do you know why and how to avoid this in the future? ; Hi Wubin, For some reason, about half of the nodes in the shared partition were stuck in the ""completing"" state yesterday. We suspected that might be related to some issues of the /anvil filesystem. Our engineers worked with the vendor to fix the issues with the filesystem and have the affected nodes rebooted. We have monitoring tools implemented to keep track of the Slurm status on the clusters. That should help us identify issues and implement fixes as early as possible. Hope this helps. If you have any further questions or concerns, please let us know. Thanks, name ; Hi Wubin, Since the issue has been fixed and your questions have been answered. I'm tentatively marking this ticket as resolved at this point. Please feel free to contact us again if you see any issues or have any other questions. Thanks, name ;",wding2@access-ci.org,Wubin Ding,Ruyi Li,Purdue University,Anvil,7,4,28,2024,2024-07-08
ATS-9217,Unable to run interactive job on Anvil,2024-07-09,2024-07-12,"Hi, I am trying to run an interactive job on ANVIL, but it fails to run it successfully: $ sinteractive -N1 -n32 -A ear170001 salloc: Pending job allocation 6724773 salloc: job 6724773 queued and waiting for resources salloc: job 6724773 has been allocated resources salloc: Granted job allocation 6724773 salloc: Waiting for resource configuration salloc: Prolog name on node a055 salloc: Nodes a055 are ready for job salloc: error: \\_half\\_duplex: read error -1 Connection reset by peer The following modules were not unloaded: (Use ""module --force purge"" to unload all): 1) xalt/2.10.45 This could be maybe because of some issue with the connection between my login node and the compute node. Please help. I am trying to gdb debugger in interactive mode. ; Hi Utpal, Thanks for reaching out! I am wondering if you still see issues on Anvil. There was an issue regarding to the storage system on Anvil and our engineers have fixed it. Please feel free to let me know. Regards, name, PhD (She/Her) Senior Computational Scientist Purdue University ;",utpalkumar@access-ci.org,Utpal Kumar,Nannan Shan,Purdue University,Anvil,2,4,28,2024,2024-07-08
ATS-9222,Receiving Stale file handle when trying to access /anvil,2024-07-10,2024-07-10,"I am using 3 desktop sessions using the following nodes: \\_g005.anvil.rcac.purdue.edu \\_g008.anvil.rcac.purdue.edu When I try to cd into /anvil/scratch I am getting the following error: :\~ $ cd /anvil -bash: cd: /anvil: Stale file handle ; Hi name, Thanks for reporting this to us. There was an issue with Anvil storage in the early morning (~2am EST today). First thing this morning engineers were able to isolate and fix the underlying issue. Please let me know if you still see problem on this. Thank you! Regards, name, PhD (She/Her) Senior Computational Scientist Purdue University ;",rratna@access-ci.org,Rishit Ratna,Nannan Shan,Purdue University,Anvil,3,1,28,2024,2024-07-08
ATS-9226,error: stale file handle,2024-07-10,2024-07-10,"Dear Sir/Madam, I faced stale file handle error suddenly when I tried to use Anvil this morning. I cannot do anything even use cd or ls command. Recently, I tried to compile models on Anvil. I am not sure if I made any mistake to cause this issue. I am worried about if I will lose all my files on my account. I have not backed up many results yet. Could you please help me about this? Thank you in advance Regards, name, PhD (She/Her) Senior Computational Scientist Purdue University ; Hi Dr. name, I see, thanks for your reply and this information. Best, Libo ;",zhanglib@access-ci.org,Libo Zhang,Nannan Shan,,Anvil,3,1,28,2024,2024-07-08
ATS-9234,Anvil Storage,2024-07-10,2024-07-10,"Good Morning, I hope you guys are doing well today. I was wondering how much storage our group would receive upon obtaining an Anvil allocation? We are trying to figure out if anvil would be a good fit since the Rockfish resource is expiring. Thank you, Lucus Mussi PhD Candidate, Noid Lab ; Hi Lucus, Thanks for reaching out! Please find the details about Anvil file system at https://www.rcac.purdue.edu/knowledge/anvil/storage/filesystems: http://example.com The short answer for your question will be, 25GB for personal home directory, 100TB for personal scratch, and 5TB for project space. Regards, name, PhD (She/Her) Senior Computational Scientist Purdue University ;",lmussi@access-ci.org,Lucus Mussi,Nannan Shan,,Anvil,2,1,28,2024,2024-07-08
ATS-9244,Inquiry on Job ID 6722243,2024-07-10,2024-07-10,"Hi, Yesterday I had a job submitted with ID 6722243, which began running at around 18:00 July 9th, PST. The job was terminated with FAILED, ExitCode 135 after running for 4h 33m 31s, and we did not find an issue on our side. The code we used is very similar to the one we were able to run on Anvil many times without an issue. Could you check this one and let us know what could have been the problem? The directory in which the job ran is /anvil/scratch/x-skim2/jovian/thermal\\_profile/shifted/test02 Also if it is on your side, may I ask for the return of the expensed allocation? Best regards, Sungkyu name ; Hi Sungkyu, Thanks for reaching out! Anvil file system was suffering an issue last night (started around 2am EST July 10th), I guess this might be the reason your job got aborted. Please try to re-run your simulation and let me know if you continue seeing issues. Regards, name, PhD (She/Her) Senior Computational Scientist Purdue University ; Hi name, I re-ran the job and it was completed without an issue, thanks! Are we going to be charged for the interrupted job in this case? If that is the case, could you give us a refund for that amount of allocation? Best regards, Sungkyu name : mailto:님이 작성: ;",skim2@access-ci.org,Sungkyu Kim,Nannan Shan,Purdue University,Anvil,3,1,28,2024,2024-07-08
ATS-16671,VASP Access Request,2025-05-20,2025-05-20,"I am a new user to Anvil and I'd like to gain access to VASP 6. A screenshot of our group license is attached. Please let me know if further information is needed. ; Hi He, Thanks for reaching out! Your VASP license with your email : mailto: has been validated. You have been added to vasp5 and vasp6 groups on Anvil. Your membership will be ready within a few hours. Please check our user guide for VASP calculations on Anvil. https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/vasp: https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/vasp|smart-link Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ;",hzhu16,He Zhu,,,Anvil,3,1,21,2025,2025-05-19
ATS-9028,VASP intel compiled error,2024-07-01,2024-07-17,"Hi name, I hope this email finds you well. I am, trying to use my compiled VASP (intel compiled). I have used the --mpi=pmi2to solve the numa\\_num error and it worked successfully. However, after three jobs, VASP started to give a different error even for the ones that were successful before. Abort(205068943) on node 20 (rank 20 in comm 0): Fatal error in PMPI\\_Alltoallv: Other MPI error, error stack: PMPI\\_Alltoallv(371)..........................: MPI\\_Alltoallv(sbuf=0xe146500, scnts=0xd481580, sdispls=0xd480d00, MPI\\_DOUBLE\\_COMPLEX, rbuf=0xd076de0, rcnts=0xd4808c0, rdispls=0xd480040, datatype=MPI\\_DOUBLE\\_COMPLEX, comm=comm=0xc4000000) failed MPIDI\\_Alltoallv\\_intra\\_composition\\_alpha(1051): MPIDI\\_NM\\_mpi\\_alltoallv(806)..................: MPIR\\_Alltoallv\\_intra\\_scattered(115)..........: MPIR\\_Waitall(176)............................: MPIR\\_Waitall\\_impl(55)........................: MPIDI\\_Progress\\_test\\_impl(195)................: MPIDI\\_OFI\\_handle\\_cq\\_error(991)...............: OFI poll failed (ofi\\_events.h:991:MPIDI\\_OFI\\_handle\\_cq\\_error:Invalid argument) Kindly advise. Best Regards, Basant ; ^myjob (1).e6377369 ^submit (1) (2b208022-0515-4b9d-8e1e-5311b57d28f0).sh ; Hi Basant, Thanks for reaching out! I cannot recognize this error message you shared. My best guess is it is related MPI library. Have you googled this error message to find some discussions on this? Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Hi Basant, Thanks for reaching out! I cannot recognize this error message you shared. My best guess is it is related MPI library. Have you googled this error message to find some discussions on this? Regards, name, PhD (She/Her) Senior Computational Scientist Purdue University ; Hi name, Thank you for your reply. I have googled the error. Most likely this is due to non-updated intel and/or impi used for compilation. I recompiled VASP using intel/19.1.3.304 impi/2019.9.304 intel-mkl/2020.4.304 and loaded them to run the job, this solved the problem. Thank you, Basant ; Hi name, I tried to update intel, impi, and mkl to newer versions to allow more features in VASP. However, when I used the sudo command, I was asked for a password which I don't have. Could you please, help me update them? Thank you in advance. Best regards, Basant ; Hi Basant, We do not have plan to update the intel compilers because they are on sunset status right now. We will deploy oneapi (the new intel compiler bundle) in the next few months on Anvil. At this point, I would recommend to use gcc compiler, openmpi and intel-mkl library to compile VASP on Anvl. Regards, name ;",belshoky@access-ci.org,Basant Elshoky,Nannan Shan,Purdue University,Anvil,7,13,27,2024,2024-07-01
ATS-9072,"Anvil Kubernets - Access pod via hostname, not IP?",2024-07-03,2024-07-18,"In the Rancher system on Anvil Composable, what do I need to add to a deployment or pod config to allow other pods in the same namespace to reach it via a hostname instead of an IP? I don't need to access it externally, just by name from other pods in the same subnet/namespace. i.e., If I have two pods in the same namespace, {{my\\_db\\_pod}} and {{my\\_other\\_pod}}, what do I need to set in {{my\\_db\\_pod}} config so that from a shell inside {{my\\_other\\_pod}} I will able to do something like {{psql -h my\\_db\\_pod}} instead of {{psql -h 10.1.2.3}}? ; Hi name, Thanks for reaching out --name ; Any thoughts on this? Where in the Rancher interface can I set a fixed hostname for a pod so that each time it respawns it gets the same name that other pods can reference, like ""database"" instead of ""database-11dfasdf5"" with the random unique instance hash? I just want to be able to use a fixed address for making a connection between pods in the same namespace that won't break on reboots or changes in IP assignments. Thanks! ; Whoa, guess I missed this ticket. For this, you would want to use a ClusterIP service and map whatever port(s) you need to access from the Pod. Then you can access the Pod via the ClusterIP name instead of the Pod. -name ; Thanks! That is working for me. ~ name ---- ; Good to hear. I'll mark this resolved. ;",thompscs@access-ci.org,Christopher Thompson,Erik Gough,Purdue University,Anvil,7,12,27,2024,2024-07-01
ATS-9232,Anvil Batch job error,2024-07-10,2024-07-17,"Hi ; Hi Nikhil, Thanks for reaching out! I think there is a glitch for the sync between ACCESS website and Anvil cluster, so you are not under the allocation phy240036. I just fixed it I think. Please let me know if you still cannot use this allocation tomorrow. Regards, name, PhD (She/Her) Senior Computational Scientist Purdue University ; Hi! I tried running a batch script and it didn't go through. Same error. Nikhil ---- ; Thanks for letting me know. I will ask our engineer to check this. I will keep you posted. --name ; Hi Nikhil, I think your account on Anvil is ready. You should have access to PHY24006 now. Please let me know if you still see issues. @login01.anvil:~ $ mybalance x-nbisht1 Allocation Type name Limit name Usage name Usage name Balance Account (account) (user) ============= ==== ========== ========== ========== ========== ast140008 CPU 0.0 2126026.3 23755.2 n/a phy240036 CPU 7800000.0 1000954.6 2754.6 6799045.4 Regards, name ;",nbisht1,Nikhil Pratap Singh Bisht,Nannan Shan,,Anvil,5,6,28,2024,2024-07-08
ATS-9255,run job error,2024-07-11,2024-07-16,"Hi, I have received the following error while runs the script below. Any help will be greatly appreciated. sbatch: error: Batch job submission failed: Requested node configuration is not available # Zhigang ; Hi Zhigang, Thank you for reaching out to RC support. In your job script, you're assigning 2GB for each task/core, but the maximum amount of memory you can use per CPU core is 1.896 GB. Therefore, if you modify the script as follows, you should be able to submit the job. Also, it's recommended that you choose the number of nodes as 1 to ensure all CPUs are allocated on one node. #/bin/sh #SBATCH -N1 #SBATCH --ntasks-per-node=100 #SBATCH --cpus-per-task=1 #SBATCH --mem-per-cpu=1896 #SBATCH --time=20:00:00 #SBATCH --job-name=politicalcycle\\_mpi #SBATCH --error=/anvil/scratch/x-zfeng2/political/job.%J.err #SBATCH --output=/anvil/scratch/x-zfeng2/political/job.%J.out module --ignore\\_cache load gcc/11.2.0 openmpi/4.0.6 mpirun /anvil/scratch/x-zfeng2/political/debt\\_ext\\_21 cgget -r memory.usage\\_in\\_bytes /slurm/uid\\_${UID}/job\\_${SLURM\\_JOBID}/ cgget -r memory.max\\_usage\\_in\\_bytes /slurm/uid\\_${UID}/job\\_${SLURM\\_JOBID}/ mem\\_report Zhigang ; Hi Zhigang, Thank you for reaching out. I see that you are not loading the modules correctly. You need to check for the available modules (with module spider) you want and then try to load the specific version you need. $ module spider gcc ; gcc: ; Versions: gcc/8.4.1 gcc/10.2.0 gcc/11.2.0 ; For detailed information about a specific ""gcc"" package (including how to load the modules) use the module's full name. Note that names that have a trailing (E) are extensions provided by other modules. For example: $ module spider gcc/11.2.0 ; $ module spider openmpi ; openmpi: ; Versions: openmpi/3.1.6 openmpi/4.0.6 openmpi/4.1.6 ; For detailed information about a specific ""openmpi"" package (including how to load the modules) use the module's full name. Note that names that have a trailing (E) are extensions provided by other modules. For example: $ module spider openmpi/4.1.6 ; If you want to load gcc v11 and openmpi v4.1 modules you need to do: \\*$ module load gcc/11.2.0 $ module spider openmpi/4.1.6\\* Best, name Senior Computational Scientist RCAC - Purdue University ; It seems that the issue is resolved with your script. I will mark this ticket as resolved, but feel free to reach out with any questions or concerns. Have a wonderful week! Best, name ;",zfeng2@access-ci.org,Zhigang Feng,Haniye Kashgarani,Purdue University,Anvil,8,4,28,2024,2024-07-08
ATS-9259,Node fail error,2024-07-11,2024-07-18,"My simulations are running into NODE\\_FAIL errors, even though previous simulations of the same settings have been conducted and did not have any errors. Here are the notifications I received: \\* Slurm Job\\_id=6877315 Name=De2\\_VE\\_fixed\\_twobody Failed, Run time 01:32:37, NODE\\_FAIL, ExitCode 0 \\* Slurm Job\\_id=6868543 Name=newtTrasphSphd Failed, Run time 01:37:17, NODE\\_FAIL, ExitCode 0 May I know what issue this may be? Thank you! ; Hi Selena, Thank you for reaching out to RC support. I don't see any ""Node failed"" errors in your jobs: $ jobinfo 6877315 Name : De2\\_VE\\_fixed\\_twobody User : x-schiu1 Account : phy220092 Partition : standard Nodes : None assigned Cores : 128 GPUs : 0 State : CANCELLED by 7940380 ExitCode : 0:0 Submit : 2024-07-11T12:59:41 Start : None End : 2024-07-11T13:11:46 Waited : 00:10:04 Reserved walltime : 4-00:00:00 Used walltime : 00:00:00 Used CPU time : 00:00:00 % User (Computation): -- % System (I/O) : -- Mem reserved : 245400M Max Mem used : -- Max Disk Write : -- Max Disk Read : -- $ jobinfo 6868543 Name : newtTrasphSphd User : x-schiu1 Account : phy220092 Partition : standard Nodes : a556 Cores : 128 GPUs : 0 State : COMPLETED ExitCode : 0:0 Submit : 2024-07-10T13:34:56 Start : 2024-07-10T13:37:31 End : 2024-07-10T14:17:06 Waited : 00:00:34 Reserved walltime : 1-00:00:00 Used walltime : 00:39:35 Used CPU time : 3-11:46:40 % User (Computation): 99.93% % System (I/O) : 0.07% Mem reserved : 245400M Max Mem used : 829.14M (a556) Max Disk Write : 4.15G (a556) Max Disk Read : 24.64M (a556) Could you please share more information about the error you're receiving? Also, could you please submit your jobs again and see if it's a reproducible error? Best, name Senior Computational Scientist RCAC - Purdue University ; Hi Selena, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name Senior Computational Scientist RCAC - Purdue University ;",schiu1@access-ci.org,Selena Chiu,Haniye Kashgarani,Purdue University,Anvil,3,6,28,2024,2024-07-08
ATS-9324,VASP license request for Purdue Anvil,2024-07-15,2024-07-16,"Hello, I am a PI of a computational materials science lab at UC name. I am writing to request to be added to the VASP 6.3 license installed in Purdue Anvil. Would you please add the following users to the VASP license? - name : mailto: ACCESS Username: elee2 - Joni name ACCESS Username: jspencer - name To ACCESS Username: sto Attached a screenshot of my VASP license. Thank you ; Hi name, Thank you for contacting us. I've verified your license and added you to the vasp5 and vasp6 Unix groups. For now, you should be able to access the vasp modules on Anvil. $ groups x-elee2 x-elee2 : x-mat240067 vasp5 vasp6 $ groups x-jspencer x-jspencer : x-mat240067 vasp6 vasp5 $ groups x-sto x-sto : x-mat240067 vasp6 vasp5 We have a documentation on running VASP jobs at the below link: https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/vasp: https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/vasp|smart-link Hope this helps. I'm tentatively marking this ticket as resolved at this point. If you have any questions, please feel free to reopen this ticket or submit a new one. Thanks, name ;",elee2@access-ci.org,Elizabeth Lee,Ruyi Li,,Anvil,3,2,29,2024,2024-07-15
ATS-9422,Enable VASP license permission to run on Anvil HPC,2024-07-19,2024-07-22,"Dear ACCESS/ANVIL Support, I am name Cappola, a PhD student at Arizona State University working under Dr. name. My ANVIL account is ""x-jcappola"" and I'm under the ACCESS MAT210034 project. We have a VASP license purchased through ASU and others in my group have already been approved to run VASP on ANVIL, but my account does not seem to have the same privilege. Could my ANVIL account ""x-jcappola"" be given access to run VASP on ANVIL? My advisor can be contacted at : mailto: if license confirmation is needed. Regards, name Cappola Graduate Research Assistant Arizona State University ; Hello, I hope you are doing well. Thank you for reaching out to RC Support with your question Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Hi name, Sorry for the confusion on the accounts. The email address for VASP is : mailto: under VASP license 23-0266. Thanks, name ; Hi name, You have been added to vasp5 and vasp6 groups on Anvil. Your membership will be ready within a few hours. Please check our user guide for VASP calculations on Anvil. https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/vasp Regards, name ;",jcappola@access-ci.org,Jonathan Cappola,Nannan Shan,Purdue University,Anvil,5,2,29,2024,2024-07-15
ATS-9342,VASP License,2024-07-16,2024-07-16,"Hello, I would like access to VASP in the ANVIL cluster by Purdue. I have attached some information needed in the screenshots (license) as well as other information here. Thank you for the help ; Hi name, Thank you for reaching out. Your PI sent us the same request earlier and you should have access to the vasp modules on Anvil now. For detailed instructions on loading the vasp modules, please reference the following guide: https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/vasp I'm tentatively marking this ticket as resolved at this point. Please feel free to re-open it if you have any questions. Thanks, name ;",sto@access-ci.org,Sydney To,Ruyi Li,Purdue University,Anvil,3,1,29,2024,2024-07-15
ATS-9516,How to know priority queue status,2024-07-24,2024-07-24,"Hi, I want to know about the priority queue status on Anvil. As in what does my jobs staying pending depend upon. Is there any number like ""fairshare""? I have been using Anvil for quite some time and my jobs (while small in time, requiring 1 GPU, but many in nunmber) used to start instantly, but now, they seem to stay pending. This happenend after my sinteractive allotted session with GPU (I nvidia-smi'd) ran and my python script gave an error of initializing CUDA driver, you might not have a CUDA GPU. Thus, I want to know what mkes this weird behaviour come up and what does premption depend upon, there should be a metric or a number that decides a user's priority level. How can I know my priority in this? ; Hi Shikhhar, Thanks for reaching out! Since we are using SLURM as our job scheduler on Anvil, all jobs will be scheduled based on the parameters from SLURM setup. Generally speaking, small jobs will get started quicker than large jobs. You mentioned GPU partition on Anvil. This is the busiest queue on Anvil, simply because there are total 64 GPUs on Anvil and a few thousands users are sharing these GPUs. Sometimes, the GPUs queue is not busy, so our job can get started instantly, sometimes the GPU queue is very busy (like right now, there is no GPU available at this moment), our job will need to wait on the line until SLURM find available GPUs. SLURM has its own way to allocate the resource. We are working on a project targeting to tell Anvil users how long they will need to wait for their jobs after they submit jobs on Anvil. I believe this project is about to finish. Please stay tunes about this on Anvil News in the near future. Regards, name, PhD (She/Her) Senior Computational Scientist Purdue University ;",ssiingh,Shikhhar Siingh,Nannan Shan,Purdue University,Anvil,2,1,30,2024,2024-07-22
ATS-9517,Home directory quota,2024-07-24,2024-07-25,"Is it possible to increase the quota from 25GB? I've used most of the available capacity and am unable to download conda packages. ; name, Thanks for your message - could you please let me know which resource you are utilizing so that I can send your request to the correct provider? E.g. Anvil, Expanse, Bridges… ; I'm referring to Anvil. Thanks Am 7/24/24 um 19:59 schrieb Alana.Romanella : |---- \\*External Email\\*: Use caution with attachments, links, or sharing data ---- | ; Hi name, Thank you for reaching out. The quota on a user's home directory is a hard limit - it could not be changed. If running the ""\\*ncdu $HOME\\*"" directory, you could see that your ""~/.cache/"" and ""~/.conda/pkgs/"" are taking up about 2.7GB and 1.7GB space respectively. Files in those two directories can be deleted safely. Also, your ""~/.local/lib/python3.8/"" directory is taking up about 2.4 GB space. If all your needed Python packages are installed in Conda environments, you may considering clearing up the ""~/.local/lib/python3.8/"" directory as well. Besides, you can install Python packages in your group shared project directory (""/anvil/projects/x-cis230283/"") if your home directory gets too crowded. I hope this helps. I'm tentatively marking this ticket as resolved at this point. Please feel free to reopen it if you have any further questions. Thanks, name ;",christophert@access-ci.org,Christopher Tan,Ruyi Li,Purdue University,Anvil,4,2,30,2024,2024-07-22
ATS-9520,Quota,2024-07-24,2024-07-25,"Hi all, The command "" myquota"" does not work for me. Do I need to use another command to see the available space? ; Hi Eeshan, Thank you for reaching out. I suspect that {{myquota}} did not work for you because of your complicated shell environment. The first step you could try is to rename your {{~/.bashrc}} file, start a new login session and see if that solve the issue with {{myquota}}. $ mv ~/.bashrc ~/.bashrc.bak For restoring your startup file ({{~/.bashrc}}), I would suggest you move the {{module load}} commands and other environment variable settings from it to the corresponding job scripts or other separate scripts to be sourced later. Warm regards, name ; Hi name, Thanks for the comment. Yes, moving .bashrc to .bashrc.bak helps me fix the myquota issue. I have created a new very simple .bashrc now. You can check it. When I open a new terminal and the .bashrc gets sourced, the ""myquota"" does not work again. I am guessing this might be a system problem. Many people in our group have the same problem. I have had a complicated .bashrc for a long time, but this issue started happening very recently. ---- ; Hi Eeshan, Could you please remove the ""echo …"" command from your ~/.bashrc file and try it again? Thanks, name ; Hi name, The problem is the echo. Now, my old complicated bashrc also works when the echo is commented out. ---- ; Hi Eeshan, Thanks for letting me know that! Glad ""myquota"" works for you now. I'll go ahead and mark this ticket as resolved then. Please feel free to contact us again if you encounter any other issues. Best regards, name ;",eeshanb@access-ci.org,Eeshan Basu,Ruyi Li,Purdue University,Anvil,6,2,30,2024,2024-07-22
ATS-9212,cp2k+plumed job crashes after running for sometime,2024-07-09,2024-08-02,"Hello! I have successfully installed cp2k+plumed on ANVIL and the jobs run fine initially. However, the jobs get canceled after a certain time. The output file generated shows ""Cannot allocate memory"". I believe I have provided reasonable memory for the jobs (the same jobs with the same amount of memory run fine in our local clusters). The corresponding files are in ""/home/x-kyadav/TestRevPBE/Restart/Test"" and ""/home/x-kyadav/TestRevPBE/Restart/"". I am not sure where the issue is. I am also attaching the run script. It would be very helpful if you could assist me with resolving this issue. Thanks Komal ; ^run-cp2kAnvilhome.sh] ; Hi Komal, Thank you for reaching out. Sorry about the issue. Would you please also share the IDs of the problematic jobs? We would like to take a closer look. Thanks, name ; Hello name, I believe I have faced this issue with all the jobs that I have run till now. The IDs of two of them (for the path I mentioned in my email) are 6652263 and 6656375. Please let me know if you need any other information. Thank you Best regards Komal ; Hi Komal, Thanks for sharing more information. Looking at the submission script and the output of job 6652263, we suspect the issue might be related to memory contention, as it requested 90000MB memory for 64 tasks. We would suggest you start troubleshooting with decreasing the number of tasks or increasing the amount of memory. If the error persists, please let us know and we would help you take further investigations. Warm regards, name ; Hello name, Thank you for the suggestion. I tried several permutations and combinations by decreasing the number of CPUs and increasing the memory. The jobs' running times vary (some run longer than others), but they still get killed after some time, showing the same 'cannot allocate memory' error. I am unable to figure out the source of the error at this point. Here are some of the job IDs for your reference: 6887108, 6887038, 6887105, 6886048. Since I have to perform my computations soon as the project is ongoing, it would be very helpful if you could please help me out with this. Please let me know if you need any other information. Thank you Best regards Komal ; Hi Komal, Sorry to know that, but thanks for sharing the job IDs. Would you please try setting --mem=242000M (approximately the maximum memory a job can get from a node in the ""shared"" partition) and adjust the number of tasks (e.g. --ntasks-per-node=8, --ntasks-per-node=16 or --ntasks-per-node=32) to see if the error persists? Thanks, name ; Hi Komal, I'm checking in to see if you still see any errors with your jobs. Please let us know if there is something else we can help with. Thanks, name ; Hi name, I tried using 32 CPU with full node memory as you suggested but it failed. The jobs with 16 and 8 CPUs with full node memory ran for 1 day, but the speed was very slow (as expected) and hence could not be afforded. Right now I am just restarting my jobs whenever it fails. I have encountered another issue and I would be glad if you could help me with it. I am not able to run my jobs now as it says ""Disk quota exceeded"". I believe the maximum that I am using right now is ~ 25 GB but the limit is ~100 GB. I am unable to figure out the actual reason for this error. It would be very helpful if you could please have a look and let me know. Thank you Best regards Komal ; Hi Komal, The fact is that your home directory has a quota of 25GB, and it seems it is currently full. $ myquota x-kyadav Type Location Size Limit Use Files Limit Use ============================================================================== home x-kyadav 24.9GB 25.0GB 100% - - - scratch anvil 0KB 100.0TB 0% 0k 1,000k 0.00% projects x-che240097 0KB 5.0TB 0% 0k 1,048k 0.00% You might want to move some files to your project directory ({{/anvil/projects/x-che240097}}) in order for your program to work properly. Also, you may try setting up your working directory in the scratch filesystem ({{/anvil/scratch/x-kyadav}}), which is a short-term storage with a quota of 100TB. For more information about the filesystems on Anvil, please see the following documentation: [https://www.rcac.purdue.edu/knowledge/anvil/storage/filesystems: https://www.rcac.purdue.edu/knowledge/anvil/storage/filesystems|smart-link I spot-checked some of your 32-core jobs, and noticed that they were with {{--mem-per-cpu=1500M}}, which might not be sufficient. Would you please try submitting your jobs with {{--mem-per-cpu=7500M}} or {{--mem-per-cpu=5000M}} and see if the error happens again? Thanks, name ; Hi Komal, Since I have not heard further questions from you in a while, I am assuming that your issues have been resolved. I'm tentatively marking this ticket resolved at this point. Please feel free to contact us again if you need any help. Thanks, name ;",kyadav@access-ci.org,Komal Yadav,Ruyi Li,,Anvil,11,19,28,2024,2024-07-08
ATS-9548,NAMD3 on Purdue Anvil GPU,2024-07-26,2024-07-30,"Hello, I am a user on Purdue Anvil (x-mjarcari) and I had read that NAMD3.0 was available, but I cannot find the module to load. Also, I was wondering if the version of NAMD3.0 had been updated to the official release, the last listed version (on the anvil website) was an alpha version. Thank you Mark J. Arcario, M.D., Ph.D. Instructor Divisions of Cardiothoracic Anesthesiology and Basic Research Department of Anesthesiology Washington University in Saint name 660 S. Euclid Ave., Campus Box #8054 St. name, MO 63110 ( ORCID: 0000-0001-5017-1519 ---- ; Hi Mark, Here is an example submit script I created for a GPU NAMD job. # Mark J. Arcario, M.D., Ph.D. Instructor Divisions of Cardiothoracic Anesthesiology and Basic Research Department of Anesthesiology Washington University in Saint name 660 S. Euclid Ave., Campus Box #8054 St. name, MO 63110 ( ORCID: 0000-0001-5017-1519 ---- ;",marcario1@access-ci.org,Mark Arcario,Nannan Shan,Purdue University,Anvil,5,3,30,2024,2024-07-22
ATS-9562,Disk quota exceeded ,2024-07-26,2024-07-29,"Hi Anvil team, I got this error while I still have a lot of disk quota. ""Unexpected error while saving file: scratch/AD3C/05.pseudobulk/MergeAllc.ipyn: file: scratch/AD3C/05.pseudobulk/MergeAllc.ipyb Errno 122 Disk quota exceeded: '/home/x-wangwl/scratch/AD3C/05.pseudobulk/.~MergeAllc.ipynb'"" It's not in my home directory, I just make a soft link of my scratch to the home directory. Thanks, Wenliang ; Hi Wenliang, Thank you for reaching out. Your disk usage seems to be within the limits at the moment. Could you please let us know if you still see the ""Disk quota exceeded"" error? If yes, could you please share a screenshot showing the error message and the commands you used as well? We would like to take a closer look. $ myquota x-wangwl Type Location Size Limit Use Files Limit Use ============================================================================== home x-wangwl 13.2GB 25.0GB 53% - - - scratch anvil 252.2TB 500.0TB 50% 8,958k 10,485k 85% projects x-mcb130189 49.6TB 200.0TB 25% 7,119k 20,971k 34% Warm regards, name ; Thanks for the reply, name. I didn't realize my number of files exceeds the quota. I have deleted some, now it's back to normal. Sorry about that. Wenliang ; Wenliang, No problem. Glad the issue has been resolved. I'll go ahead and close this ticket out then. Please feel free to contact us again if you see any other issues. Thanks, name ;",wangwl@access-ci.org,Wenliang Wang,Ruyi Li,Purdue University,Anvil,4,2,30,2024,2024-07-22
ATS-9653,I have the license of the Vienna Ab initio Simulation Package (VASP). My license number is 24-0042. I want to add that version on Anvil.,2024-07-31,2024-08-01,"I have the license of the Vienna Ab initio Simulation Package (VASP). My license number is 24-0042. I want to add that version on Anvil for my work. Below, I have attached the license proof of VASP version vasp.6.4.3. My supervisor is Dr. name. ; Hi Musiha, Thanks for reaching out! What is your email address associated with this VASP license. I need your email address, not your supervisor's email to add you to vasp unix groups on Anvil. We need to use your email address to check if you are under a valid VASP license. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Hi, Thank you for your reply. My email address is : mailto: . Best regards Musiha Mahfuza Mukta ; Hi Musiha, After I put your email on VASP portal, it tells me you are on the License WA21-0050 5-2452, which is eligible for {{vasp5}} only. Did you used the same email address for you new license? Or you used another email address? I cannot add you to {{vasp6}} with this email. Mahfuza Musiha : mailto: June 30, 2019 HPC license member Regards, name ; Hi name, Can you please check again with : mailto: this email address. This email was used for new VASP license. I'm sorry for the wrong information. Email: : mailto: Full Name: Musiha Mahfuza Mukta Regards, Mukta ; Hi Mukta, I found you. I have add you to vasp6 unix group on Anvil. Your membership will be ready in few hours. Regards, name ;",mmukta@access-ci.org,Musiha Mahfuza Mukta,Nannan Shan,Purdue University,Anvil,7,2,31,2024,2024-07-29
ATS-9306,Anvil multi core processing with batch jobs,2024-07-15,2024-08-09,"I am running a Python script and I am attempting to utilize multiple cores. I have requested multiple cores and have added export OMP\\_NUM\\_THREADS=$SLURM\\_CPUS\\_PER\\_TASK to the script. When I log into the compute node I only see one core running. A few questions: # Can a python script utilize multiple cores? # If so, is adding export OMP\\_NUM\\_THREADS=$SLURM\\_CPUS\\_PER\\_TASK the correct way to allow python to utilize multi cores? # Is logging into the node the correct way to check CPU usage? FYI, I have requested multiple cores as I need access to more memory than one core allocates. # Is there any difference between requesting more memory vs requesting more cores. Thank you for your time, I look forward to your response. ; Hello name ; \\*\\*PRIVATE NOTE\\*\\* No response ;",mradice@access-ci.org,Matthew Radice,Sean Lee,Purdue University,Anvil,6,20,29,2024,2024-07-15
ATS-9701,script for nwchem/7.0.2,2024-08-02,2024-08-06,"Dear Colleague, I am urgent to calculate something by nwchem/7.0.2 because my supervisor's project is due. Could you please send me a script for submitting jobs? Thank you. Best regards, Minglei ; Minglei, what resource are you running on? Bridges, Expanse, Anvil, etc? ; Dear Alana, Thank you for the swift reply. I am using Anvil now. Best, Minglei ; Thanks Minglei - this will now be directed over to the Anvil team. ; Thank you for your help! Alana.Romanella : mailto:于2024年8月3日 周六21:31写道: ; Hi Minglei, Thanks for reaching out! Please find an example script for your n #!/bin/sh #SBATCH --job-name=nwchem #SBATCH --account=dmr100029 #SBATCH --nodes=1 #SBATCH --ntasks-per-node=1 #SBATCH --cpus-per-task=16 #SBATCH --time=00:30:00 #SBATCH --output=nwchem.o%j.%N module --force purge module load gcc/11.2.0 openmpi/4.0.6 module load nwchem/7.0.2 module list mpirun -np $SLURM\\_NTASKS nwchem ... Hope this helps. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; This is great, thank you so much! Best, Minglei ;",x-msun3,Minglei Sun,Nannan Shan,Purdue University,Anvil,7,3,31,2024,2024-07-29
ATS-9885,"My longwalltime QoS does not allow jobs more than 4 days, but it should allow up to 30 days",2024-08-13,2024-08-13,"Hello, I previously submitted a request https://access-ci.atlassian.net/browse/ATS-8955: https://access-ci.atlassian.net/browse/ATS-8955|smart-link for a longwalltime QoS to run my Bayesian inverse problem model parameter fitting job. However, the QoS does not appear to work as intended in that ticket. I posted details about my job and the outputs. Please extend the submitted job time and help me understand how to access the 30 day advertised limit. Pariksheet ; Hi Pariksheet, Thank you for reaching out. I have set some flags for the QoS which should let you run the jobs for 30 days now. Could you please check if longwalltime qos work now? Best, name Senior Computational Scientist RCAC - Purdue University ; Yes, it works now. I submitted job 7627798. Thank you so much! Pariksheet ; Awesome! Thanks for letting me know that the issue is resolved. ;",pnanda@access-ci.org,Pariksheet Nanda,Haniye Kashgarani,Purdue University,Anvil,4,1,33,2024,2024-08-12
ATS-9737,Purdue Anvil,2024-08-05,2024-08-07,"Hello, the Anvil HPC seems to have access to G16 given by the following link: https://purduercac-applications.readthedocs.io/en/latest/Applications.html#computational-chemistry: https://purduercac-applications.readthedocs.io/en/latest/Applications.html#computational-chemistry|smart-link However, it seems that the HPC is not listed on your list on ACCESS. Does this mean that the G16 software is available on Anvil but not accessible to users from ACCESS? best regards, name ; Hello Best regards, name ; Hello! Sorry for the confusion. I was referring to this page here: https://purduercac-applications.readthedocs.io/en/latest/Applications/gaussian16.html: https://purduercac-applications.readthedocs.io/en/latest/Applications/gaussian16.html|smart-link We also have a similar list on the RCAC website found here: https://www.rcac.purdue.edu/knowledge/applications/gaussian16: https://www.rcac.purdue.edu/knowledge/applications/gaussian16|smart-link Thanks, name ; Hello name, I see! I understand what I am looking at now. Thanks, name ; Happy to help! ;",rayz97@access-ci.org,ramon trevino,Sean Lee,,Anvil,6,3,32,2024,2024-08-05
ATS-9761,file limits,2024-08-06,2024-08-06,"Hi Anvil team, My current analysis will generate a huge amount of files, could you set my file limits to 20M? It will be great if you can expand the limit untill November. I greatly appreciate you help. Thanks, Wenliang ; Hi Wenliang, Thank you for reaching out. Would you please share more information about your analysis? Is it possible for you to bundle up part of the files in your scratch directory to free up some inodes or use an aggregate format of data for your analysis? Warm regards, name ; Hi name, I wanted to extend my heartfelt thanks for your prompt and thoughtful responses to my inquiries, which have been incredibly helpful Wenliang ; Hi Wenliang, Thanks for sharing more details. Our storage expert has increased the file number limit on your scratch directory to 20M and also extended the block quota increase (100TB to 500TB) for you. Both of those will expire on November 1st. $ myquota x-wangwl Type Location Size Limit Use Files Limit Use ============================================================================== home x-wangwl 13.2GB 25.0GB 53% - - - scratch anvil 177.4TB 500.0TB 35% 8,396k 20,971k 40% projects x-mcb130189 32.4TB 200.0TB 16% 6,976k 20,971k 33% Please keep in mind that inactive files in the scratch filesystem will be purged periodically and there is no way for us to turn it off. Make sure you have a good data management workflow in place to ensure the security of your data. I'm tentatively marking this ticket as resolved at this point. Thanks, name ; Thank you so much, name. This is greatly helpful for my analysis. I really appreciate it. ;",wangwl@access-ci.org,Wenliang Wang,Ruyi Li,Purdue University,Anvil,5,1,32,2024,2024-08-05
ATS-9769,Submitting a job on Anvil.,2024-08-06,2024-08-08,"Hello, I hope all is well with you. When I submit a VASP job on Anvil, I get an error attached to this ticket. I would be thankful if you could help me to fix this problem. Thank you in advance for your help. Kindly, Matin Mostaan ; ^myjob.err] ^vasp1.sb ; Hi Matin, Thanks for reaching out! I've noticed that you are not a member to our vasp groups on Anvil. Do you want to be added in? If so, I need your email address associated with your VASP license to validate your VASP license. Without being added to vasp groups on Anvil, you were not able to submit jobs with VASP modules on Anvil. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Hello, Thank you for your response. My email address is . Thank you for your help. I appreciate it. ---- ; Hi Matin, You have been added into both {{vasp5}} and {{vasp6}} unix groups on Anvil. Your membership will be ready in the next few hours. Please check our user guide about how to submit VASP jobs on Anvil. [https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/vasp: https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/vasp|smart-link Regards, name ;",mmostaan@access-ci.org,Matin Alsadat Mostaan,Nannan Shan,,Anvil,5,3,32,2024,2024-08-05
ATS-9791,Jobs submitted remain pending in the queue and do not run,2024-08-07,2024-08-07,"I previously submitted 10 jobs to the queue yesterday, but the job status remains as 'pending' for an extended period of time. I have not been able to run these submitted (but pending) jobs. I have since canceled them but re-submitted a few new jobs to test if there was a large job taking up the entire partition yesterday, but the problem still persists today. Please let me know if the Anvil {{wholenode}} or {{wide}} partition is currently down are busy. ; Hi Lillian, Thank you for contacting us. If you run the {{squeue -l --me}} (or {{squeue -name x-lbl59}}) command on Anvil, you would see that your jobs are pending because of {{AssocGrpCPUMinutesLimit}}. $ squeue -name x-lbl59 Wed Aug 07 20:27:14 2024 JOBID PARTITION NAME USER STATE TIME TIME\\_LIMI NODES NODELIST(REASON) 7600005 wholenode S11\\_c32m x-lbl59 PENDING 0:00 5:00 4 (AssocGrpCPUMinutesLimit) 7600007 wide S12\\_c32m x-lbl59 PENDING 0:00 5:00 4 (AssocGrpCPUMinutesLimit) 7600006 wide S12\\_c32m x-lbl59 PENDING 0:00 5:00 4 (AssocGrpCPUMinutesLimit) That indicates you do not have enough SUs in your account to get those jobs started. It looks like each of your jobs is requesting 512 cores for 5 minutes, so needs at least 42.67 SUs (512 \\* 5 / 60) to be finished. However, allocation {{eve230004}} has only 20.7 SUs left. Slurm will not get your jobs started until you have enough SUs in account in order to avoid possible waste. $ mybalance x-lbl59 Allocation Type name Limit name Usage name Usage name Balance Account (account) (user) ============= ==== ========== ========== ========== ========== eve230004 CPU 50000.0 49979.3 49979.3 20.7 I hope this explains it. You might want to transfer additional ACCESS credits to SUs on Anvil to continue your work. I'm tentatively marking this ticket resolved at this point. If you have any further questions, please feel free to reopen it or submit a new ticket to us. Thanks, name ; Hi name, Thank you for bringing this to my attention. Appreciate the help! Best, Lillian ;",lbl59@access-ci.org,Lillian Lau,Ruyi Li,Purdue University,Anvil,4,1,32,2024,2024-08-05
ATS-9813,"Delete directory ""/anvil/projects/tdm/corporate/.DELETEME""",2024-08-08,2024-08-09,"Please recursively delete the directory ""/anvil/projects/tdm/corporate/.DELETEME"" from the Anvil cluster. We've deleted as many files as we can as part of an annual purge, but many files were created by dozens of other people ways that ignored group permissions and ACLs, so I've moved them all to this .DELETEME folder so you can easily recursively remove them. Regards, Doug ; Hi Doug, Thank you for reaching out. Could you please confirm that you want to remove the entire data directory located at ""/anvil/projects/tdm/corporate/.DELETEME""? Best, name Senior Computational Scientist RCAC - Purdue University ; Hi name, Yes, please remove that entire directory. There should be on the order of 1.2TB there if I recall correctly. Thanks! Doug ---- ; Hi Doug, The path you mentioned is incorrect I don't see any .DELETEME in the directory: /anvil/projects/tdm/corporate $ ls -name total 272 drwxrwsr-x+ 2 x-kamstut x-tdm-admin 131072 Aug 9 10:18 . drwxrwsr-x+ 15 root x-tdm-admin 8192 Jul 27 17:33 .. Best, name ; Hi name, My guess is one of your colleagues was already in the process of deleting it and waited for the deletion to finish before closing the ticket (that's what I'd have done 🙂)? It's gone now, so thanks!!! Regards, Doug ---- ; Hi Doug, Yes, it seems it's already been deleted. So, I will mark this ticket as resolved now. Let me know it I can help you with anything else. Best,. name ;",dgc,Doug Crabill,Haniye Kashgarani,Purdue University,Anvil,6,2,32,2024,2024-08-05
ATS-16684,AnviGPT access request,2025-05-20,2025-05-21,"I want to use the Purdue RCAC GenAI studio API ; Hi Erfan, Please use this https://genai.rcac.purdue.edu/: https://genai.rcac.purdue.edu/ to access PurdueGenAI studio, and you should be able to log in using your Purdue career account login details. ;",eesmaeilifakhabi,Erfan Esmaeili Fakhabi,Ashish Malik,,Anvil,2,2,21,2025,2025-05-19
ATS-9645,Loopback Port Access on HPC,2024-07-31,2024-08-12,"We are trying to setup and test https://toil.readthedocs.io/en/latest/running/server/wes.html: https://toil.readthedocs.io/en/latest/running/server/wes.html|smart-link (WES Toil) service on HPC. The service needs to access a rabbitmq server on loopback port. However, starting the service results in following error {{INFO: Using cached SIF image ERROR: Network bridge is not permitted for unprivileged users. INFO: Cleanup error: while unmounting /var/apptainer/mnt/session/final directory: no such file or directory, while unmounting /var/apptainer/mnt/session/rootfs directory: no such file or directory FATAL: container creation failed: network requires root or a suid installation with /etc/subuid --fakeroot; non-root users can only use --network=none unless permitted by the administrator}} While running service on HPC is generally not a good idea, we are trying to do a few benchmarks which only requires access to a specific port on loopback address (127.0.0.1). Is there any possible way around to access the port? ; \\*\\*PRIVATE NOTE\\*\\* Some additional context: Furqan works with me on the I-GUIDE project and I suggested he submit this ticket. They are doing this work as part of OGC's TestBed20 https://www.ogc.org/initiatives/ogc-testbed-20/: https://www.ogc.org/initiatives/ogc-testbed-20/|smart-link to see if such workflows can be run on HPC without requiring cloud resources. Hence, deploying the RMQ on Anvil Composable is not an option (I proposed that first). ; Hi Furqan, Thanks for reaching out! I have passed your questions to our container experts, they will get back to you when they find a clue. Thanks for your patience. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Hi Furqan, Thank you for your patience. I've taken a look at what you're trying to launch, and I think you shouldn't need to set up a bridge network interface. Docker would require a bridge. Apptainer is much more permissive though, and you should be able to use the loopback interface directly on Anvil. Certain RCAC-maintained apps are already using this approach. Basically, you should remove any {{--network}} options passed to {{apptainer}}. Please let me know if you have any questions. Best, -name ;",fbaig21@access-ci.org,Furqan Baig,Nannan Shan,Purdue University,Anvil,4,9,31,2024,2024-07-29
ATS-9793,Can't access to Anvil cluster,2024-08-07,2024-08-12,"Hi! I'm trying to login into ANVIL using my ACCESS crediantals. But I got the following error: ssh -l x-alancelin anvil.rcac.purdue.edu: http://anvil.rcac.purdue.edu (: mailto:) Password: Connection closed by 128.211.133.142 port 22 I also try to add my pub ssh-key ed25519 to https://ondemand.anvil.rcac.purdue.edu/pun/name/dashboard: https://ondemand.anvil.rcac.purdue.edu/pun/name/dashboard. But I got the following error Error -- can't find user for x-alancelin Run 'nginx\\_stage --help' to see a full list of available command line options. What should I do ? Maybe you can add my public key manually (I attached it to this email) Best, Amaury Lancelin ; Hi Amaury, Thank you for reaching out. Could you please check again now? There was an issue with your account on Anvil, and it should be resolved now. Best, name Senior Computational Scientist RCAC - Purdue University ; Since we haven't heard feedback from you for some time, issues seem to have been solved. I will mark this ticket as resolved. Feel free to reach out again if you still need assistance on this issue. Best, name Senior Computational Scientist RCAC - Purdue University ;",alancelin@access-ci.org,Amaury Lancelin,Haniye Kashgarani,Purdue University,Anvil,3,4,32,2024,2024-08-05
ATS-9871,Anvil Cluster is down but no update,2024-08-12,2024-08-13,"It appears that every partition on the Anvil cluster is currently down, yet I cannot find any notifications or information on RCAC site or otherwise as to scheduled or unscheduled outages/maintenance. What is the reason for the partitions being down and when can I expect a return to normal operations? Thank you. ; Hello! Anvil's scheduling was paused for about 3 hours today while we dealt with an issue. It should be back to normal now. I apologize for the lack of communication. Thanks, name ; \\*\\*PRIVATE NOTE\\*\\* Resolved. ;",ehightow@access-ci.org,Erin Hightower,Sean Lee,,Anvil,3,2,33,2024,2024-08-12
ATS-9483,Issue with accessing Anvil (Purdue),2024-07-23,2024-08-23,"Dear Professional, We have received the NAIRR-240101: https://nairrpilot.org/awarded-projects grant to access Purdue's Anvil GPU. I have obtained Purdue's email (: mailto:) and set up my access account. My access user name is ""aanand3."" Next, to log in to Anvil, I visited https://www.rcac.purdue.edu/knowledge/anvil/access/login/ood: https://www.rcac.purdue.edu/knowledge/anvil/access/login/ood|smart-link , though it returns me the below-mentioned error {{Error -- failed to map user ()}} Can you please assist me in resolving this bottleneck? Please reply to : mailto: or : mailto: -- Very respectfully, name ; Hi name, We're still sorting out the details of this NAIRR sign-up process, and you're one of the lucky first few new users to go through it. As such a lucky user though, there are some bumps in the road still, and your account was not quite finished being set up. This should be good to go now though, so give things a try and see if you're able to log in now. Thanks for your patience ---- ; Hi name, We finally got your account on Anvil. Thanks for your patience. Now you should be able to login Anvil with your username, {{anand211}}. Let me know if you still see issues with your NAIRR account on Anvil. $ myquota anand211 Type Location Size Limit Use Files Limit Use ============================================================================== home anand211 25KB 25.0GB 0.00% - - - scratch anvil 0KB 100.0TB 0% 0k 1,000k 0.00% Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Hello Dr. name, Thanks so much for the updates, though I need help logging in to Anvil. As soon as I reach point 3 (on step 2 - attached figure), it continues to give me the error shown in step 3. Can you please assist me in resolving this error? Thank you very much ; Hi name, NAIRR is not ACCESS, so you will not be able to login Anvil with your NAIRR username. Please use ssh to login Anvil with your {{anand211}} username. Let me know how it goes. Regards, name ; Hello name, Thank you for your clarification about NAIRR and ACCESS. I appreciate your guidance. I'd like to share the steps I've taken so far in my attempt to connect to Anvil using SSH, following the instructions from the Purdue RCAC knowledge base (https://www.rcac.purdue.edu/knowledge/anvil/access/login/sshkeys): # I generated an SSH key pair using the command ==> ssh-keygen # I navigated to the .ssh directory ==> cd ~/.ssh # I viewed the contents of my public key ==> cat id\\_rsa.pub The output was ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDdn/SpC0N4x1ASMD8pmgUUjyLhIobusDld+GnE95xLDpMu+sARyg/e9gt6WqXBFkaWYPEHqtI0DjzE9MQnbF76t/a3nTjc0XzptZW4ZEXLi0poGsiBbEOjTrkc8p2cGWnyCz7BaPFiotmn8SJ0GR1YHltTmZtOsjP9N6pz8EPBWk9ubj08qd6xmzNzs/WvToxkmCzZ3yT5wpu5C5MEW7LxW4ppyycOl+Bq8kCJVmnlvs8pnlRJoj4Q0jIs9hxlm/bNzRZtuhM7888aemBjSRpn0BjpngFvAaUB3S9DtVpCmCHUGcE2hzJwuBM9/3O8HCW02zcFPLbew1AHRqvcgBXGwH7Iu9zpLy2b+G0cUYzR3JJLhErDxCdP6LnotK04sKNvQ7AAezJ8I+FV8p0ZrPZ1nxHesxcK915bO2sl1mVcwgYjOYpl/czwGH6m5HMh9trubgG4MSBPcmRnz/z0sNpbGlAl3nC+w0C+hBIgoguheoIl8s5olIsOVBz8+/6Ys5M= aa21b@ENG-57NFFF3 # I attempted to log in to Open OnDemand (AS MENTIONED IN THE LINK FOR FIRST TIME USERS) at ondemand.anvil.rcac.purdue.edu using my ACCESS username and password but received an error: ""failed to map user () ## # Due to the error in step 4, I was unable to access the Anvil Shell through OnDemand to perform the following steps: The next step involved ## mkdir -p ~/.ssh ## ~/.ssh/authorized\\_keys # I couldn't complete this step of copying the public key's contents to ~/.ssh/authorized\\_keys on the Anvil system. # Finally, I attempted to SSH into Anvil using ==>ssh However, this didn't work as expected, likely because steps 5 and 6 weren't completed. \\_Given that I couldn't access Open OnDemand to set up the authorized\\_keys file on Anvil, I'm not sure how to proceed. Could you please advise on an alternative method to add my public key to the Anvil system? Or, if possible, could you please add my public key to my account on Anvil? Here's my public key again for reference:\\_ ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDdn/SpC0N4x1ASMD8pmgUUjyLhIobusDld+GnE95xLDpMu+sARyg/e9gt6WqXBFkaWYPEHqtI0DjzE9MQnbF76t/a3nTjc0XzptZW4ZEXLi0poGsiBbEOjTrkc8p2cGWnyCz7BaPFiotmn8SJ0GR1YHltTmZtOsjP9N6pz8EPBWk9ubj08qd6xmzNzs/WvToxkmCzZ3yT5wpu5C5MEW7LxW4ppyycOl+Bq8kCJVmnlvs8pnlRJoj4Q0jIs9hxlm/bNzRZtuhM7888aemBjSRpn0BjpngFvAaUB3S9DtVpCmCHUGcE2hzJwuBM9/3O8HCW02zcFPLbew1AHRqvcgBXGwH7Iu9zpLy2b+G0cUYzR3JJLhErDxCdP6LnotK04sKNvQ7AAezJ8I+FV8p0ZrPZ1nxHesxcK915bO2sl1mVcwgYjOYpl/czwGH6m5HMh9trubgG4MSBPcmRnz/z0sNpbGlAl3nC+w0C+hBIgoguheoIl8s5olIsOVBz8+/6Ys5M= aa21b@ENG-57NFFF3 Please let me know if you need any additional information or any other steps I should take. I appreciate your help in resolving this issue. -- Very respectfully, name ---- ; Hi name, We're name new to NAIRR ourselves, so the process here is a bit muddled with ACCESS, especially when it comes to instructions. I suspect the instructions you're going off were an automated email for ACCESS users, and gave you incorrect guidance. As a non-ACCESS user of Anvil, you can directly ssh to anvil.rcac.purdue.edu: http://anvil.rcac.purdue.edu. When prompted for a password, use your chosen password, but add "",push"" (literally comma-p-u-s-h) after your password. This will then trigger a Duo notification, and then after that, your ssh will complete. If you have trouble with Duo push due to network or timing, you can also use a Duo code after a comma instead of ""push"" and do the same. We're in the process of standing up an Open OnDemand instance which supports NAIRR login. Currently, the OOD instance you tried only supports ACCESS users. Let us know if OOD is something you were particularly hoping to use. Hope this helps -name ;",aanand3@access-ci.org,Akshay Anand,Nannan Shan,Purdue University,Anvil,12,24,30,2024,2024-07-22
ATS-9938,Node a037 is not responding since 10:53pm last night and job output stopped at 9:32pm,2024-08-15,2024-08-19,"Good morning/bin/bash -x #SBATCH --array 1-22 #SBATCH --job-name cp-oneshot #SBATCH --output %j.out #SBATCH --partition shared #SBATCH --time 96:00:00 #SBATCH --nodes 1 #SBATCH --ntasks 128 #SBATCH --exclusive So, this means that each job array will need 96 \\* 128 = 12,288 SUs, and since you have 22 job arrays, the total SUs you'll need is 270,336. I hope this explanation makes it clear that you don't have enough SUs to run this job. Best, name Senior Computational Scientist RCAC - Purdue University ; Hi name, Thank you. name transferred more hours last week and the remaining jobs started running on Friday. The last few are now completing. Pariksheet ;",pnanda@access-ci.org,Pariksheet Nanda,Haniye Kashgarani,Purdue University,Anvil,3,3,33,2024,2024-08-12
ATS-10011,Extended storage time,2024-08-19,2024-08-20,"Hello, I have some files (about 60T) located at my scratch (/anvil/scratch/x-wding2), could you please extend the storage time? I mean DO NOT delete those files in the next few months, otherwise, I have to download and process them again, which would waste the computational resources. ; Hello name ; How about the project? We have 200T under our project, but it is temporary. Can you extend the time for this 200T ? ; Unfortunately, no, we cannot extend time for scratch. As name noted, it's part of the filesystem configuration and not something we tune on a per-user basis. We have other tiers of the file system. The 200T isn't your project space, it's your scratch space. We should have a conversation (video call) to discuss your data management needs. What are your goals for this data? If you are not processing the data right now, when do you expect to do so? There is project space we could allocate if appropriate. There is also a tape archive for long-term storage. At 60T we should have a conversation about what is included in the data (if it's appropriate to store all of it forever). You can and should consider transferring data with the Globus transfer service. -- \\*name\\* \\_Lead Research Data Scientist\\_ \\_Rosen Center for Advanced Computing\\_ ; We have 200T project space; can you extend the time for this 200T project space? ; Ah I see. Indeed you do have project space. Your original inquiry specifically mentioned your scratch directory though, so I'm confused now. Anything in /anvil/scratch will get purged per the filesystem policy. Are you instead asking about your allocation deadline? If you are asking about extending your project allocation that is a completely different matter and one that we can discuss. ; Yeah. I am now talking about extending the project allocation since the scratch is hard-coded. ; The project space exists for the duration of the allocation and can easily be extended by the PI (or allocation manager) by submitting a request. Your project allocation still has 200+ days however. ; Got it. Thank you very much. ;",wding2@access-ci.org,Wubin Ding,Sean Lee,Purdue University,Anvil,9,2,34,2024,2024-08-19
ATS-10031,Cannot log on to resource: Anvil Purdue,2024-08-20,2024-08-20,"Error -- can't find user for x-abernard Run 'nginx\\_stage --help' to see a full list of available command line options. Good morning ACCESS, I am receiving the above error when I attempt to log in to Purdue Anvil on demand: https://ondemand.anvil.rcac.purdue.edu/ I received the confirmation of the allocation on Thursday name 15th, 2004 and have been assigned the username: x-abernard. Any help you could provide would be appreciated. Thanks, name ; Hi name, Thank you for reaching out and sorry about the issue. It seems your account on Anvil OnDemand gateway was not properly set up. It should be fixed now. Would you please try logging in again and let me know if you still see any errors? Warm regards, name ; Hi name, Yes! Thank you. I've logged in and did not receive any errors. Many thanks for your help and quick response. name ---- ; Hi name, Thanks for confirming! Glad you were able to log in. I'll go ahead and mark this ticket resolved. Thanks again for contacting us. Best regards, name ;",abernard@access-ci.org,Andrea Bernard,Ruyi Li,Purdue University,Anvil,4,1,34,2024,2024-08-19
ATS-9846,Support with rsync for anvil cluster,2024-08-10,2024-08-29,"Hello, I have an access account and can successfully log into the cluster on my shell with my ssh key alias: alias ssh-anvil='ssh ' ╭─annagulcher@dhcp-74-167 ~ ╰─➤ ssh-anvil ============================================================================== == Welcome to the Anvil Cluster == However, my \\*rsync\\* command doesn't work since a password is asked, and I'm wondering whether I am doing anything wrong, I cannot find the information from the website: ╭─annagulcher@dhcp-74-167 ~/Dropbox/Software/StagYY/stagyy\\_master\\_2024aug ╰─➤ rsync --progress -r -u \\* :/anvil/scratch/x-aglcher/StagYY/. 255 ↵ () Password: Connection closed by 128.211.133.145 port 22 rsync: connection unexpectedly closed (0 bytes received so far) sender rsync error: unexplained error (code 255) at /AppleInternal/Library/BuildRoots/9e200cfa-7d96-11ed-886f-a23c4f261b56/Library/Caches/com.apple.xbs/Sources/rsync/rsync/io.c(453) sender=2.6.9 Would you be able to help me with this? thanks name, What is the name and location of your local ssh key file? I'm wondering if a command like this would work for you (note the added '-e' option with associated string): rsync --progress -r -e 'ssh -i ~/.ssh/ssh\\_key\\_name' -u \\* :/anvil/scratch/x-aglcher/StagYY/. 255 Where '~/.ssh/ssh\\_key\\_name' is replaced with the name and path to your local ssh key file. Thanks, name, Since we have not heard from you in a while, I am going to tentatively mark this ticket as resolved. If this is not the case and you are still running into issues, please respond to this ticket within 7 days. Otherwise, you will need to submit a new ticket. Thanks, name ;",,,Michael Carlson,Purdue University,Anvil,3,14,32,2024,2024-08-05
ATS-9847,Anvil compiling and modules questions,2024-08-10,2024-08-29,"Hello, I have previously compiled and run a code (https://github.com/ptackley/StagYY: https://github.com/ptackley/StagYY) on the Euler cluster in Lugano with the instructions described below. I am in need of running this in Anvil, as I don't have Euler access anymore and I do have an Anvil account (x-aglcher). I was hoping to ask you some advice on getting my code compiled on Anvil? Installation on Euler requires two steps. First, following the instructions on Euler\\_PETSC\\_compile.md This file also informs how to install PETSC and I was wondering whether this works the same way on Anvil or not (I prefer version 3.20.2 for PETSc). However, already in the Load Modules I get errors on Anvil running (step 2 in the Euler\\_PETSc\\_compile.md file): module purge module load stack/2024-06 module load openmpi/4.1.6 hdf5 git openblas petsc/3.20.1 libpng/1.6.39-fz4tvmr cmake/3.27.7 (2) Then after doing these installation, the MAKEFILE I was using for Euler with PETSC is the one attached: My question is how to adapt this Makefile such that it works for Anvil? I'd be happy to provide more information if needed, any help is greatly appreciated, Thanks, name ; ^Euler\\_PETSc\\_compile.md \\_(3 kB)\\_ ^makefile.euler.petsc \\_(1 kB)\\_ ; name, I am unsure of what modules are included in the 'module load stack/2024-06' command. My guess is that this is a software stack that is defined by Euler staff. I think the thing that would come closest to it would be 'module load rcac', but it's difficult to know without knowing what modules were actually included in their stack. As for the other modules, we do have openmpi/4.1.6, and we do have HDF5. Git is already installed, so no need to module load it. We have a version of openblas. We do not have PETSc 3.20.1, we only have 3.15.3, but I'm unsure of why you need to load it if you're installing your own version right after. We don't have libpng/1.6.39, but we do have libpng/1.6.37. Lastly, we don't have cmake/3.27.7, only cmake/3.20.0 So, in summary: run these commands: module purge module load rcac module load openmpi/4.1.6 hdf5 openblas petsc/3.15.3 libpng/1.6.37 cmake/3.20.0 I believe I have also edited the makefile to have it be applicable to anvil. I will try to attach it to this ticket, but I may end up emailing it to you if I can't figure it out. Let me know if you have any additional questions. Thanks, name ; \\*\\*PRIVATE NOTE\\*\\* ^makefile.anvil.petsc Here is the makefile for Anvil. It is unclear as to what it wants filled out and what will be automatically filled out, but this should work. ; name, I actually told you wrong, you will be unable to use the command 'module load rcac' on Anvil, it's 'module load modtree/cpu'. Other than that, I believe my information is correct. Thanks, name, I apologize, another edit: PETSc/3.15.3 will not load with openmpi/4.1.6, it will only load with openmpi/4.0.6 (which we also have), but I also don't know that you need to module load PETSc if you're going to compile it again in the next step. Thanks, name ; Hi name, Thank you for all of your replies! I'll contact the code developer (mostly out of interest) why petsc has to be manually installed (and whether using petsc from the cluster directly would also be okay), and what the ""stack"" module on the Euler cluster contains of. I'll have a go with your suggestions and see how far I get. I may reply if I come across further questions. Many thanks name On Aug 16, 2024, at 07:40, name wrote: ; name, I have tried going through the install directions in my own space to see what I need to do to make it work. In step 5, I had to add in the option --download-cmake to the ./configure command because the version of cmake on the cluster is not recent enough. I got all the way until step 8, where it looks like the StagYY project is access controlled. So I cannot test whether the makefile I edited will work or not. If you run into any problems, let me know and I can try to help troubleshooting it. Thanks, name, Since we have not heard from you in a while, I am going to tentatively mark this ticket as resolved. If this is not the case and you are still running into issues, please respond to this ticket within 7 days. Otherwise, you will need to submit a new ticket. Thanks, name ;",,,Michael Carlson,Purdue University,Anvil,9,14,32,2024,2024-08-05
ATS-9985,Cannot write or edit files on Anvil,2024-08-18,2024-08-27,"I cannot write or edit any file anymore. Please fix this issue for my account. Thank you ; Seyyedfaridoddin, I notice that your home folder is getting full (it's using 23.6 GB out of 25 GB, which you can check using the 'myquota' command). It may be that is what is causing you to have problems with editing or writing files to your home directory. To fix this, you will need to move or delete some files in your home directory. I hope this helps, name ; Seyyedfaridoddin, Since we have not heard from you in a while, I'm going to tentatively mark this ticket as resolved. If you're still encountering problems, please respond to this ticket within 7 days. Otherwise, you will need to submit a new ticket. Thanks, name ;",sfatta2@access-ci.org,Seyyedfaridoddin Fattahpour,Michael Carlson,Purdue University,Anvil,3,7,33,2024,2024-08-12
ATS-10072,My students whom I added to my project EES240013 are not able use the allocations. They appear under my project but they are not added to the groupid. Could you please give them the proper permissions.,2024-08-21,2024-08-26,"My students whom I added to my project EES240013 are not able use the allocations. They appear under my project but they are not added to the groupid. Could you please give them the proper permissions. ; Hi Inanc, Thank you for reaching out. I have fixed the allocation for users x-cnx, x-kchand1, and x-tim48, and they should now be able to see the allocation using the 'mybalance' command output. Are there any other students who have issues and need to be added to your allocation? $ mybalance x-tim48 Allocation Type name Limit name Usage name Usage name Balance Account (account) (user) ============= ==== ========== ========== ========== ========== ees230052 CPU 2325843.0 2317053.7 801760.6 8789.3 ees240013 CPU 6750000.0 0.0 0.0 6750000.0 Best, name Senior Computational Scientist RCAC - Purdue University ; Since we have not heard back from you, we assume that the problem is resolved. I will go ahead and mark this ticket as resolved. Feel free to reopen the ticket within seven days if you have any questions or concerns. Best, name K ;",senocak@access-ci.org,Inanc Senocak,Haniye Kashgarani,,Anvil,3,4,34,2024,2024-08-19
ATS-10076,Issue with accessing Anvil (Purdue),2024-08-22,2024-08-28,"Dear readers, # We got approved for the NAIRR project → \\*NAIRR240101 → Resource Allocated → Anvil GPU\\* # Purdue IT created a http://purdue.edu: http://purdue.edu|smart-link account for me (: mailto:) # On access, my user name is ""aanand3."" # I received an email from name (08/19) : mailto: →, telling me I should finally be able to log in to Anvil with the user name ""anand211."" # Continue to keep receiving error messages as failed to map user """" I'd be extremely grateful if you could assist me in resolving this or connect me with the right person to get in touch. Thanks a bunch ; Hi name, Thanks for reaching out! You've mentioned in the previous ticket, https://access-ci.atlassian.net/browse/ATS-9483: https://access-ci.atlassian.net/browse/ATS-9483|smart-link, that you can login Anvil with ssh. Are you still have issues to login? We can have a virtual meeting to discuss this. Or you can register one of our Anvil Support Hour sessions at https://www.rcac.purdue.edu/anvil/anvil-support-hour: https://www.rcac.purdue.edu/anvil/anvil-support-hour|smart-link Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ;",aanand3@access-ci.org,Akshay Anand,Nannan Shan,Purdue University,Anvil,3,5,34,2024,2024-08-19
ATS-11663,Purdue Anvil update removes the necessary modules for Hy2Foam to run.,2024-10-24,2024-10-31,"With the last update the required module CGAL 6.0.1 has been removed which makes Hy2Foam obsolete. I was wondering if the module could be reloaded or if there was another solution could be found. Unfortunately without this module all hypersonic research cases must stop. ; Hi name, Thank you for reaching out. cgal should be a part of the openfoam module. Could you please try to load the openfoam module and let us know if it works for you? You can load the module using the following command: module load openfoam Warm regards, name ; Hi name, Since I have not heard back from you in a while, I'm tentatively marking this ticket as resolved at this point. If you need any help, please feel free to reopen this ticket or submit a new one to us. Thanks, name ;",lgutierrez@access-ci.org,Mateo Gutierrez,Ruyi Li,Purdue University,Anvil,3,6,43,2024,2024-10-21
ATS-10196,Facing an error while running a Job,2024-08-27,2024-09-04,"I am running a simulation through the account: ees240013. The working directory is "" /anvil/scratch/x-kchand1/rotation/unstratified\\_case/re400/lsa\\_validation/piw6404\\_pis0.25/domain\\_8times/rung"", where batch file is ""mpi"". If I run on a smaller grid, the simulation runs. But when running a job on a larger grid, I am getting the following error: Out of Memory issue. slurmstepd: error: Detected 1 oom\\_kill event in StepId=7705082.0. Some of the step tasks have been OOM Killed. srun: error: a939: task 1759: Out Of Memory ; Hi Krishan, Thank you for reaching out. As indicated by the error message, your job was terminated because of the out-of-memory issue. If you run the {{sacct}} command, you would see that job step 7705082.0 encountered the issue. $ sacct -j 7705082 -o jobid,jobname%25,account,alloccpus,state%15,exitcode JobID JobName Account AllocCPUS State ExitCode ; -------- 7705082 8 times domain ees240013 4096 CANCELLED by 7+ 0:0 7705082.bat+ batch ees240013 128 CANCELLED 0:15 7705082.ext+ extern ees240013 4096 COMPLETED 0:0 7705082.0 IncNavierStokesSolver ees240013 4096 OUT\\_OF\\_MEMORY 0:125 I would suggest you lower the number of tasks per node and give it another try. Alternatively, you could look into ways to use the ""highmem"" queue. You may also consider using the {{monitor}} tool to keep track of the memory usage of your job: https://www.rcac.purdue.edu/knowledge/anvil/run/examples/slurm/monitor: https://www.rcac.purdue.edu/knowledge/anvil/run/examples/slurm/monitor|smart-link Thanks, name ; Hi Krishan, Since I have not heard further questions from you in a while, I'm tentatively marking this ticket resolved at this point. Please feel free to reopen the ticket or submit a new one to us if you still need assistance. Thanks, name ;",kchand1@access-ci.org,Krishan Chand,Ruyi Li,,Anvil,3,7,35,2024,2024-08-26
ATS-10597,AnvilGPT Access Request,2024-09-11,2024-09-11,"I am requesting both UI and API access for the AnvilGPT. My startup project is ""INI200001: Startup Allocation for Cloud based workloads"" my access username is tmiddelk. I plan on using this to to know more about the service to communicate more information to the research computing and data community through our EAGER award (https://www.nsf.gov/awardsearch/showAward?AWD\\_ID=2436057&HistoricalAwards=false: https://www.nsf.gov/awardsearch/showAward?AWD\\_ID=2436057&HistoricalAwards=false|smart-link) and to provide feedback on the service. By the way, the instructions for creating this ticket do no include what boxes to select and there is no ""subject"" to place the ""AnvilGPT Access Request"" line, and I'm not sure if I got the ""allocation number"" right. I arrived from here - https://www.rcac.purdue.edu/knowledge/anvil/anvilgpt: https://www.rcac.purdue.edu/knowledge/anvil/anvilgpt|smart-link ; Hi name, Thanks for providing that information. I have approved your account. Thank you also for the feedback on the ticket creation process. We will update our documentation to provide more details. Thanks, name ;",tmiddelk@access-ci.org,Timothy Middelkoop,Sarah Rodenbeck,,Anvil,2,1,37,2024,2024-09-09
ATS-10276,"Can't submit jobs, when session is requested it says Invalid qos specification",2024-08-29,2024-09-04,"I am ; Good morning, my apologies, I intended to add more details to the request form before submitting it. I am a recent user and, while we still have computing credits, I can't seem to be able to submit a job. I tried requesting an interactive session for GPU and tried requesting a Jupiter session through the onDemand session but received Invalid qos specification error. The Jupiter session does work for our CPU account. Accounts to my knowledge are bio240204 and bio240204-gpu. Best, Dariia ---- ; Hi Darria, Thank you for reaching out. I believe for a GPU session you need to select 'bio240204-gpu' as your account, choose the GPU queue/partition, and allocate a GPU to your job. Allocation Type name Limit name Usage name Usage name Balance Account (account) (user) ============= ==== ========== ========== ========== ========== bio240204 CPU 43269.0 65.6 65.6 43203.4 bio240204-gpu GPU 2200.0 0.0 0.0 2200.0 If you still have a problem, could you please share the Session ID? Best, name K Senior Computational Scientist RCAC - Purdue University ; Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name Senior Computational Scientist RCAC - Purdue University ;",dariia@access-ci.org,Dariia Yehorova,Haniye Kashgarani,Purdue University,Anvil,4,5,35,2024,2024-08-26
ATS-10460,Requesting VASP access to Purdue Anvil,2024-09-05,2024-09-06,"Hi, I have an active vasp license. Purdue anvil demands I open access hub ticket to begin the process to get access. ; Hi Mahtab, Thank you for reaching out. To access VASP on Anvil, we need to verify your license first. I checked your email address, ',' but there is no VASP license associated with it. If you have another email address linked to the license, please share it with us. Best, name Senior Computational Scientist RCAC - Purdue University ; Hi, Thanks for your prompt reply. I am working in Dr. name Leuenberger's group and I am authorized user under the license number: 21-0457 5-498. His email address is . Best regards, Mahtab ---- ; Hi Mahtab, Thank you for reaching out. I wasn't able to verify the email address '' either. You will need to ask Dr. name Leuenberger to add your email address to their license too. The license number alone isn't needed in this case; I need a valid email address associated with the license. Thanks Best, name K ; Hi, I talked with Dr. name he linked the following address with the license . Can you please check with this email address. Best regards, Mahtab ---- ; Hi, I talked with Dr. name he linked the following address with the license . Can you please check with this email address. Best regards, Mahtab ---- ; Hi Mahtab, Thanks for sharing. This email address worked, and I was able to add you to the VASP Unix group. It will take a few hours until you have access. Feel free to reach out if you couldn't access VASP in few hours. Best, name K ;",mkhan7@access-ci.org,Mahtab Khan,Haniye Kashgarani,Purdue University,Anvil,7,2,36,2024,2024-09-02
ATS-10163,Anvil - multi threaded processes only using one thread,2024-08-26,2024-09-10,"Good afternoon, I am having an issue with Anvil; I have submitted a job using the biocontainer hifiasm requesting multiple CPUs and multiple threads, however, it appears as if when the job ran, it did not make use of the multiple cpus. Any help or advice you could provide in adjusting my script to allow multi-thread/cpu use would be greatly appreciated. Forgive me if I am making a novice error, I am a new user. Thanks, name The .sh script I submitted (using sbatch) for the job was: !/bin/bash #SBATCH -A bio240187 #SBATCH -t 2:00:00 #SBATCH -N 1 #SBATCH -n 24 #SBATCH --job-name=hifiasm #SBATCH --mail-type=FAIL,BEGIN,END #SBATCH --error=%x-%J-%u.err #SBATCH --output=%x-%J-%u.out module --force purge ml biocontainers hifiasm module list # List currently loaded modules #Print hostname of compute node on which this job is running hifiasm -f37 -t24 -o $SCRATCH/uranoscopus/uranoscopus\\_hifiasm2 $SCRATCH/uranoscopus/uranoscopus.hifi.reads.trimmed.fastq.gz The efficiency of the job is below (job ID: 7686236) seff 7686236 Job ID: 7686236 Cluster: anvil User/Group: x-abernard/x-bio240187 State: TIMEOUT (exit code 0) Nodes: 1 Cores per node: 24 \\*CPU Utilized: 00:00:00\\* \\*CPU Efficiency: 0.00% of 2-00:00:24 core-walltime\\* Job Wall-clock time: 02:00:01 Memory Utilized: 25.09 GB Memory Efficiency: 56.45% of 44.44 GB ; Thanks for reaching out! We'll look into your issue and get back to you as soon as possible! Thanks, name ; Hi name, Thank you for your patience. I've taken over this ticket, and after some investigation it seems that this may be some known behavior for {{hifiasm}}, and that some inputs may spend more some in non-multithreaded or I/O-driven parts of the code. I've gone ahead and installed a newer {{hifiasm}}, {{hifiasm/0.19.9}} on Anvil. Please let me know if using this version resolves the issue. Best, -name ; Hi name, Thanks for your help. I re-ran a hifiasm job today and it ran in only a fraction of the time and the job efficiency looks good. Hopefully, this new version solves the problem. Thanks for your help. AMB ---- ; Glad to hear the new version seems to have fixed the issue! I will tentatively mark this ticket as resolved, but please let us know if the issue returns. Best, -name ;",abernard@access-ci.org,Andrea Bernard,Charles Christoffer,Purdue University,Anvil,5,12,35,2024,2024-08-26
ATS-10321,Request for Increased Disk Space Allocation – Project ees240038,2024-08-30,2024-09-09,"Hi, I am writing to inquire about the data management policies for scratch directories and to request an increase in disk space for our project, ees240038, on the Purdue Anvil system. My Access user ID is x-sajal105. Me and PhD supervisor has allocation on Purdue Anvil. Is it possible not to purge my data under scratch directory? If not, can you please increase my disk space under the project of ees240038 to 20-25 TB? It would be really helpful for us. Should this request require authorization from the PI, please advise, and I will arrange for the necessary communication from them. Thank you for considering our request. I look forward to your guidance on the procedure to potentially increase our disk limit. Regards, Azad PhD Student name Institute of Technology ; Hello, I hope you are doing well. Thank you for reaching out to RC Support with your question : | Inspired by Humanity, Powered by Technology® \\*[ \\*Marsooli Lab Website\\* |https://www.marsooli.com/ \\*:\\* \\*LinkedIn\\* : https://www.linkedin.com/in/reza-marsooli-ph-d-5b860462/ \\*:\\* \\*Google Scholar\\* : https://scholar.google.com/citations?user=iQ-oH0gAAAAJ&hl=en \\* | | | | | ; Hi, Thank you for your confirmation. This has been done. Best regards, name, PhD Senior Computational Scientist Purdue Information Technology ; Hi name, Thanks for the support. Regards, ASM Alauddin name Azad ;",sajal105@access-ci.org,A S M Alauddin Al Azad,Ankitha Mallekav,Purdue University,Anvil,8,7,35,2024,2024-08-26
ATS-10454,Purdue's Anvil-ABySS 2.3.8 installation request ,2024-09-05,2024-09-12,"Greetings, I hope you are doing well today. I wanted to ask if ABySS vs. 2.3.8 could be installed as a module to replace or complement ABySS 2.3.2 and ABySS 2.3.4 (which are already installed). Many thanks, name ; Hi name, Thanks for reaching out! I've passed your request to our scientists. You will hear from them later. Thanks for your patience. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Hi name, ABySS 2.3.8 is now available on the Anvil login nodes, and will roll out to the compute nodes over the next few hours. I will tentatively mark this ticket as resolved, but please let me know if there are any issues with the installation. Best, -name ;",jdoyle@access-ci.org,Jacqueline Doyle,Charles Christoffer,Purdue University,Anvil,3,6,36,2024,2024-09-02
ATS-10507,Could not use vasp on Purdue anvil.,2024-09-07,2024-09-09,"I've recently been added to use VASP on Purdue Anvil, but I'm running into an issue when submitting a job. I'm getting the following error: sbatch: error: Batch job submission failed: Invalid account or account/partition combination specified I'm using the job submission file from this guide: https://www.rcac.purdue.edu/index.php/knowledge/anvil/run/examples/apps/vasp: https://www.rcac.purdue.edu/index.php/knowledge/anvil/run/examples/apps/vasp|smart-link Could you please help me figure out what might be going wrong? I'd really appreciate any guidance ; Hi Mahtab, Thanks for reaching out! Can you share your submission script for me to take a look? Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Hi, I used the following script as job submission file. Best regards, Mahtab #!/bin/sh # FILENAME: myjobsubmissionfile #SBATCH --account=x-phy2402427 #SBATCH --partition=compute #SBATCH -A myallocation # Allocation name #SBATCH --nodes=1 # Total # of nodes #SBATCH --ntasks=64 # Total # of MPI tasks #SBATCH --time=1:30:00 # Total run time limit (hh:mm:ss) #SBATCH -J myjobname # Job name #SBATCH -o myjob.o%j # Name of stdout output file #SBATCH -e myjob.e%j # Name of stderr error file #SBATCH -p shared # Queue (partition) name # Manage processing environment, load compilers and applications. module --force purge module load gcc/11.2.0 openmpi/4.1.6 ##module load vasp/5.4.4.pl2 # or module load vasp/6.3.0 module list # Launch MPI code srun -n $SLURM\\_NTASKS --kill-on-bad-exit vasp\\_std # or mpirun -np $SLURM\\_NTASKS vasp\\_std ---- ; Mahtab, You will need to remove the #SBATCH -A myallocation # Allocation name line from your job submission file. I believe this should fix the 'invalid account' error you have been seeing. Let me know if this works. Thanks, name ; Hi, I remover the line in the job submission file as you suggested but I am still getting the same error. I used the following job submission file. Best regards, Mahtab #!/bin/sh # FILENAME: myjobsubmissionfile #SBATCH --account=x-phy2402427 #SBATCH --partition=compute #SBATCH --nodes=1 # Total # of nodes #SBATCH --ntasks=64 # Total # of MPI tasks #SBATCH --time=1:30:00 # Total run time limit (hh:mm:ss) #SBATCH -J myjobname # Job name #SBATCH -o myjob.o%j # Name of stdout output file #SBATCH -e myjob.e%j # Name of stderr error file #SBATCH -p shared # Queue (partition) name # Manage processing environment, load compilers and applications. module --force purge module load gcc/11.2.0 openmpi/4.1.6 ##module load vasp/5.4.4.pl2 # or module load vasp/6.3.0 module list # Launch MPI code srun -n $SLURM\\_NTASKS --kill-on-bad-exit vasp\\_std # or mpirun -np $SLURM\\_NTASKS vasp\\_std ---- ; Mahtab, Try removing the '#SBATCH -p shared' line and changing the '#SBATCH --partition=compute' to '#SBATCH --partition=cpu'. Let me know if this works. Thanks, name ; It is not working I am getting the following error message sbatch: error: invalid partition specified: cpu sbatch: error: Batch job submission failed: Invalid partition name specified I used the following job submission file #!/bin/sh # FILENAME: myjobsubmissionfile #SBATCH --account=x-phy2402427 #SBATCH --partition=cpu #SBATCH --nodes=1 # Total # of nodes #SBATCH --ntasks=64 # Total # of MPI tasks #SBATCH --time=1:30:00 # Total run time limit (hh:mm:ss) #SBATCH -J myjobname # Job name #SBATCH -o myjob.o%j # Name of stdout output file #SBATCH -e myjob.e%j # Name of stderr error file # Manage processing environment, load compilers and applications. module --force purge module load gcc/11.2.0 openmpi/4.1.6 ##module load vasp/5.4.4.pl2 # or module load vasp/6.3.0 module list # Launch MPI code srun -n $SLURM\\_NTASKS --kill-on-bad-exit vasp\\_std # or mpirun -np $SLURM\\_NTASKS vasp\\_std ---- ; Mahtab, I apologize, 'cpu' should be 'shared' so the line should read: '#SBATCH --partition=shared' Let me know if this works. Thanks, name ; It is still not working. I am getting the error message sbatch: error: Batch job submission failed: Invalid account or account/partition combination specified I used the following job submission file #!/bin/sh # FILENAME: myjobsubmissionfile #SBATCH --account=x-phy2402427 #SBATCH --partition=cpu #SBATCH --partition=shared #SBATCH --nodes=1 # Total # of nodes #SBATCH --ntasks=64 # Total # of MPI tasks #SBATCH --time=1:30:00 # Total run time limit (hh:mm:ss) #SBATCH -J myjobname # Job name #SBATCH -o myjob.o%j # Name of stdout output file #SBATCH -e myjob.e%j # Name of stderr error file # Manage processing environment, load compilers and applications. module --force purge module load gcc/11.2.0 openmpi/4.1.6 ##module load vasp/5.4.4.pl2 # or module load vasp/6.3.0 module list # Launch MPI code srun -n $SLURM\\_NTASKS --kill-on-bad-exit vasp\\_std # or mpirun -np $SLURM\\_NTASKS vasp\\_std ---- ; Mahtab, I am sorry for the inconvenience this is causing. I think there are two things that need to be fixed: First remove the #SBATCH --partition=cpu line from your script. Second, I checked your account, and I think there is an accidental 7 at the end of your account number and you don't need to 'x-' in front of it. It should be #SBATCH --account=phy240242 Let me know if this works. I apologize again for the inconvenience. Thanks, name ; Hi, Thanks for your help! I understand that troubleshooting can be a bit of a cumbersome process. Well I am again getting the same error sbatch: error: Batch job submission failed: Invalid account or account/partition combination specified I used the following job submission file now #!/bin/sh # FILENAME: myjobsubmissionfile #SBATCH --account=x-phy240242 #SBATCH --partition=shared #SBATCH --nodes=1 # Total # of nodes #SBATCH --ntasks=64 # Total # of MPI tasks #SBATCH --time=1:30:00 # Total run time limit (hh:mm:ss) #SBATCH -J myjobname # Job name #SBATCH -o myjob.o%j # Name of stdout output file #SBATCH -e myjob.e%j # Name of stderr error file # Manage processing environment, load compilers and applications. module --force purge module load gcc/11.2.0 openmpi/4.1.6 ##module load vasp/5.4.4.pl2 # or module load vasp/6.3.0 module list # Launch MPI code srun -n $SLURM\\_NTASKS --kill-on-bad-exit vasp\\_std # or mpirun -np $SLURM\\_NTASKS vasp\\_std ---- ; Mahtab, There should not be an 'x-' in front of your account name. It should just be account=phy240242. Let me know if this works for you. Thanks, name ; The jobs start submitting now. Thank you, Mahtab ---- ; Mahtab, That is excellent to hear. I am glad that we were able to get your jobs running. I am going to mark this ticket resolved as we were able to fix your script to submit your jobs. If you run into more problems, please respond to this ticket within 7 days. Otherwise, please submit a new ticket. Thanks, name ;",mkhan7@access-ci.org,Mahtab Khan,Michael Carlson,,Anvil,15,1,36,2024,2024-09-02
ATS-10546,vasp- My account cannot use VASP on Anvil,2024-09-09,2024-09-09,"Need access to VASP on my x-scasanova account on Anvil. ; Hi name, Thank you for reaching out. I've verified your VASP license and added you to the {{vasp5}} and {{vasp6}} Unix groups for accessing the vasp modules on Anvil. $ groups x-scasanova x-scasanova : x-mat240067 vasp5 vasp6 You might need to start a new login session in order for your updated group memberships to be recognized. For detailed instructions on running VASP jobs on Anvil, please reference the following documentation: https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/vasp: https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/vasp|smart-link I'm tentatively marking this ticket resolved at this point. Please feel free to reach out to us again if you have any questions. Thanks, name ;",scasanova@access-ci.org,Sebastian Casanova,Ruyi Li,,Anvil,2,1,37,2024,2024-09-09
ATS-10577,Purdue's Anvil-running ABySS 2.3.4 ,2024-09-10,2024-09-12,"Hi! I hope you are doing well today. While waiting to hear back about installing ABySS 2.3.8, I am experimenting with ABySS 2.3.4. I've been able to submit the following test code on the front end: wget http://www.bcgsc.ca/platform/bioinfo/software/abyss/releases/1.3.4/test-data.tar.gz tar xzvf test-data.tar.gz abyss-pe k=25 name=test B=1G \ in='test-data/reads1.fastq test-data/reads2.fastq' I attempted to submit this as a batch job: #!/bin/sh -l #FILENAME:abyss\\_test\\_synthetic #SBATCH -A bio230100 #SBATCH -p shared #SBATCH --nodes=1 #SBATCH --ntasks=1 #SBATCH --time=10:00:00 #SBATCH --job-name abyss\\_test\\_synthetic module load biocontainers/default module load abyss/2.3.4 cd $SLURM\\_SUBMIT\\_DIR wget http://www.bcgsc.ca/platform/bioinfo/software/abyss/releases/1.3.4/test-data.tar.gz tar xzvf test-data.tar.gz abyss-pe k=25 name=test\\_synthetic B=1G in='test-data/reads1.fastq test-data/reads2.fastq' module list hostname But receive the following error: User guides for each biocontainer module can be found in https://www.rcac.purdue.edu/knowledge/biocontainers /opt/lmod/lmod/init/sh: line 14: `ABYSS-P': not a valid identifier Could you help me determine where I am going wrong? In addition, when I ultimately want to run ABySS on multiple threads, would I want to use the ""j"" flag or the ""np"" flag? Or something different? Could you possibly provide an example script? Many thanks for your support! Jackie name ; ^abyss\\_test\\_synthetic.sh] ^slurm-7783641.out ; Hi Jackie, Thank you for contacting us. I'm not sure about the reason for the issue, but as the first step for troubleshooting, would you please replace the line {{#!/bin/sh -l}} in your submission script with {{#!/bin/bash}} and try resubmitting your job? If the error persists, we'll take a closer look. Warm regards, name ; Thank you for your thoughts. I made your suggested changes to the job script and receive the same error. I have attached both the submission file and the error message. ^slurm-7796859.out ^abyss\\_test\\_synthetic (5e734910-f6ae-4427-838c-bba9ab16f180).sh ; Hi name, I've just taken over this ticket and wondered, does switching your code over to the new ABySS 2.3.8 module resolve the ""not a valid identifier"" issue? Re multithreading, I discussed with a genomics colleague who notes that you will probably want to use the {{j}} flag on a single node. He also suggested this basic ABySS guide [http://sjackman.ca/abyss-activity/: http://sjackman.ca/abyss-activity/|smart-link , but you may already know the material. Best, -name ; Hi name, Thanks for this! Yes, I think it probably makes sense to close the abyss 2.3.4 ticket while I switch over to experimenting with 2.3.8. If I have the same problem with 2.3.8, I can open a new ticket. Best wishes, Jackie ---- ; Sounds good, I will go ahead and mark this as resolved. Best, -name ;",jdoyle@access-ci.org,Jacqueline Doyle,Ruyi Li,Purdue University,Anvil,7,3,37,2024,2024-09-09
ATS-10623,Project resources not appearing on Anvil,2024-09-12,2024-09-13,"Good morning, I previously had access to Purdue's Anvil resource through the GRIT project at the University of Central Florida (CIS230083). Last month my project was approved and I allocated 500 access credits to the Anvil resource. This project is CIS240576. I see the project listed in ACCESS and I see it listed as part of the {{myquota}} output on the Anvil login node. Unfortunately, no SUs appear when checking the output of {{mybalance}}. Additionally, when trying to submit a job through slurm, it fails if I specify my CIS240576 project. Note the use of the GRIT project (CIS230083) works fine for this same job. Here is some output detail that I hope proves helpful: :~ $ mybalance Allocation Type name Limit name Usage name Usage name Balance Account (account) (user) ============= ==== ========== ========== ========== ========== cis230083 CPU 504.0 63.0 58.2 441.0 cis230083-gpu GPU 807.0 550.4 0.0 256.6 :~ $ myquota Type Location Size Limit Use Files Limit Use ============================================================================== home x-rdahlgren 146KB 25.0GB 0.00% - - - scratch anvil 0KB 100.0TB 0% 0k 1,000k 0.00% projects x-cis230083 4.8TB 5.0TB 97% 162k 1,048k 15% projects x-cis240576 0KB 5.0TB 0% 0k 1,048k 0.00% :~ $ myproject /anvil/projects/x-cis230083 :seqdec-1.0 $ sbatch ./slurm-job.sh sbatch: error: Batch job submission failed: Invalid account or account/partition combination specified :seqdec-1.0 $ head slurm-job.sh #!/usr/bin/sh #SBATCH -A cis240576 #SBATCH -p wholenode #SBATCH --nodes=10 #SBATCH --ntasks=1280 #SBATCH --ntasks-per-node=128 #SBATCH --time=00:01:00 #SBATCH --job-name rd-seqdec Thank you for your time and assistance, Ron ; \\*\\*PRIVATE NOTE\\*\\* fyi - name is looking into this as part of a broader set of issues around some recent allocations from UCF. ; Hi Ron, Thank you for reaching out. There was an issue with your allocation on Anvil, and I resent the allocation, which has resolved the problem. You should now be able to see your SUs in MyBalance. $ mybalance x-rdahlgren Allocation Type name Limit name Usage name Usage name Balance Account (account) (user) ============= ==== ========== ========== ========== ========== cis230083 CPU 504.0 63.0 58.2 441.0 cis230083-gpu GPU 807.0 550.4 0.0 256.6 cis240576 CPU 500.0 0.0 0.0 500.0 Let me know if you have any other questions or concerns. Best, name K ;",rdahlgren@access-ci.org,Ronald Dahlgren,Haniye Kashgarani,,Anvil,3,2,37,2024,2024-09-09
ATS-9832,Trouble logging into Purdue Anvil,2024-08-09,2024-09-16,"I am having difficulty logging into the Purdue Anvil GPU cluster. I am getting this error: {{Error -- failed to map user ()}} I have resources delegated to me. Please help me debug this issue. ; Hello, I hope you are doing well. Thank you for reaching out to RC Support with your question! We are actively working on addressing the issue. Rest assured, we will provide you with a response as soon as possible. Sincerely, name ; Hello, Thanks for reaching out to RC Support! Your ACCESS account looks fine. Please let me know if you are still not able to log in. Thanks, name ;",mjerge@access-ci.org,Michael Jerge,Ankitha Mallekav,,Anvil,3,27,32,2024,2024-08-05
ATS-10058,Regarding node failure ,2024-08-21,2024-09-15,"Hello Anvil support system, I am Aashish and my jobs in anvil cluster cancelled due to the node failure. could you please check what was the issue? These are some information about some cancelled job. If you need any other information, please let me know. Slurm Job\\_id=7663029 Name=alpha\\_40 Failed, Run time 00:28:16, NODE\\_FAIL, Slurm Job\\_id=7662996 Name=name\\_fol\\_30 Failed, Run time 00:34:44, NODE\\_FAIL, Slurm Job\\_id=7662677 Name=8ddj Failed, Run time 02:18:34, NODE\\_FAIL, ExitCode 0 \\*Slurm Job\\_id=7662810 Name=2vv5\\_20dyn Failed, Run time 01:43:52, NODE\\_FAIL,\\* \\*Slurm Job\\_id=7662658 Name=alpha\\_fold\\_r2 Failed, Run time 02:33:16, NODE\\_FAIL,\\* \\*Slurm Job\\_id=7662676 Name=alpha\\_folf Failed, Run time 02:19:01, NODE\\_FAIL,\\* \\*Slurm Job\\_id=7662659 Name=name\\_fol\\_t20 Failed, Run time 02:32:41, NODE\\_FAIL,\\* \\*Slurm Job\\_id=7662788 Name=8ddj\\_20 Failed, Run time 01:53:55, NODE\\_FAIL,\\* \\*Slurm Job\\_id=7662482 Name=8ddj Failed, Run time 00:05:19, NODE\\_FAIL,\\* Slurm Job\\_id=7662478 Name=name\\_fol\\_30 Failed, Run time 00:06:07, NODE\\_FAIL Slurm Job\\_id=7662487 Name=8ddj\\_20 Failed, Run time 00:03:32, NODE\\_FAIL, Slurm Job\\_id=7662477 Name=name\\_fol\\_t20 Failed, Run time 00:06:25, NODE\\_FAIL, ExitCode 0 Slurm Job\\_id=7662480 Name=alpha\\_folf Failed, Run time 00:05:44, NODE\\_FAIL, ExitCode 0 Slurm Job\\_id=7662044 Name=name\\_fol\\_30 Failed, Run time 01:12:29, NODE\\_FAIL, ExitCode 0 Slurm Job\\_id=7662083 Name=alpha\\_folf Failed, Run time 01:02:49, NODE\\_FAIL, ExitCode 0 Slurm Job\\_id=7662087 Name=8ddj Failed, Run time 01:01:03, NODE\\_FAIL, ExitCode 0 Slurm Job\\_id=7662091 Name=8ddj\\_r2 Failed, Run time 01:00:13, NODE\\_FAIL, ExitCode 0 Slurm Job\\_id=7662117 Name=2vv5\\_20dyn Failed, Run time 00:45:46, NODE\\_FAIL, ExitCode 0 Slurm Job\\_id=7662041 Name=name\\_fol\\_t20 Failed, Run time 01:13:33, NODE\\_FAIL Slurm Job\\_id=7662246 Name=alpha\\_fold\\_r2 Failed, Run time 00:26:24, NODE\\_FAIL, ExitCode 0 Slurm Job\\_id=7662040 Name=8ddj\\_30 Failed, Run time 01:14:49, NODE\\_FAIL, ExitCode 0 Slurm Job\\_id=7662037 Name=8ddj\\_20 Failed, Run time 01:15:45, NODE\\_FAIL, ExitCode 0 Slurm Job\\_id=7661074 Name=alpha\\_30 Failed, Run time 00:02:03, NODE\\_FAIL, ExitCode 0 Slurm Job\\_id=7661074 Name=alpha\\_30 Failed, Run time 00:08:07, NODE\\_FAIL, ExitCode 0 Slurm Job\\_id=7661074 Name=alpha\\_30 Failed, Run time 00:03:51, NODE\\_FAIL, ExitCode 0 \\*Slurm Job\\_id=7653842 Name=8ddj\\_r2 Failed, Run time 1-02:22:34, NODE\\_FAIL, ExitCode 0\\* Regards, Aashish ; Hi Aashish, Thanks for reaching out Regards, name ;",abhatt@access-ci.org,AASHISH BHATT,Nannan Shan,Purdue University,Anvil,10,18,34,2024,2024-08-19
ATS-10476,Not all users within ACCESS Project BIO240254 can use Purdue Anvil,2024-09-06,2024-09-20,"Users x-mvaraganti x-fabir x-mali3 are added to BIO240254 and appear to be given access to Purdue Anvil CPU and GPU. Yet, when they run {{mybalance}} neither the cpu nor gpu allocations appear. These users already had accounts at Purdue under CIS230083 and could spend SUs from that allocation, they have since been offboarded but discovered they don't have access to BIO240254. These users were added to the newly awarded BIO240254 ACCESS project and we requested access to the CPU and GPU clusters on Purdue roughly a week ago. ; Hello, I hope you are doing well. Thank you for reaching out to RC Support with your question Best, name ; Hi name, Thank you for your patience! We believe all the user issues have been fixed for these two allocations and I have verified that mybalance returns the right results for them. Best, name ; Spoke with users, issue is resolved, thank you! ;",bkeene@access-ci.org,Benjamin Keene,Kevin Colby,Purdue University,Anvil,8,11,36,2024,2024-09-02
ATS-10586,Purdue's Anvil-running Masurca,2024-09-10,2024-09-19,"Hi again, I am experimenting with the Masurca module installed on Purdue's Anvil. I have attached my submission script and the error message I receive after submission. Could you help me trouble shoot? Best wishes, name ; ^masurca\\_18\\_3\\_trimmed.sh ^slurm-7785651.out ; Hi Jackie, For the Masurca job, would you please try using {{#!/bin/bash}} as well? Please let me know if the error persists. Thanks, name ; Thank you for your thoughts. I made your suggested changes to the job script and receive the same error. I have attached both the submission file and the error message. Just to see if it would work, I attempted to run the command {{masurca -i Inia\\_18\\_3\\_trimmed\\_R1.fastq,Inia\\_18\\_3\\_trimmed\\_R2.fastq}} on the front end for a few seconds and it appeared to be proceeding, so presumably the problem is with the job submission file or the multi-threading? ^slurm-7796858.out ^masurca\\_18\\_3\\_trimmed (1).sh ; Hi Jackie, I've shared this ticket with our expert as well. He would look into the issue and contact you later. We appreciate your patience. Thanks, name ; Thank you! ; Hi! I hope you are doing well today. I have experimented with MaSurCa some more (e.g., attempting to run it on the highmem node) but receive the same error message (environment: `build\\_human\\_reference.sh': not a valid identifier) each time I try to run a batch job. I can run MaSurCa on the front end, but as I anticipate that the assembly will take multiple days to complete, it seems like it would be best to run it on a node. I am wondering, is there a typical issue when a job will run on the front end but not as a batch job? If you have any suggestions, I can try to troubleshoot. ; Hi name, If you change the top line of your script to say {{bash}} instead of {{sh}}, does the job work? Best, -name ; That did it, thanks so much! ; Glad to hear it! I will go ahead and mark this ticket as resolved. Best, -name ;",jdoyle@access-ci.org,Jacqueline Doyle,Charles Christoffer,Purdue University,Anvil,10,8,37,2024,2024-09-09
ATS-10619,Require Anvil Composable allocated to the project,2024-09-12,2024-09-20,"Hi, We need Anvil Composable allocation for the project. I dont see it in the allocation list. Can someone please assign it to our project? Thanks, Kireet ; \\*\\*PRIVATE NOTE\\*\\* This is allocation SOC240028 ; Hi Kireet, I created a project for you on Anvil Composable. Can you log in here with your ACCESS account (choose Shibboleth)? https://composable.anvil.rcac.purdue.edu/: https://composable.anvil.rcac.purdue.edu/ Once you log in I can give you access to the project. Thanks, -name ; Hi name, I use CILOGIN with purdue SSO for my access account. I don't see this SSO login in the link you have provided Thank you, Kireet ; Ahh, ok. For the Kubernetes system you will need to set a password and two factor for your access account. Did you set an ACCESS password when you logged in with your existing identity? ; I created an access password and managed to login to anvil composable Thank you Kireet ; Cool, you should now see the ""SOC240028"" in your project list in Rancher. ;",kgannavarapu@access-ci.org,Kiran Naga Kiree Gannavarapu,Erik Gough,Purdue University,Anvil,7,7,37,2024,2024-09-09
ATS-11704,AnvilGPT Access Request,2024-10-25,2024-11-01,"Hello, I am collaborating with Yunfan on the I-GUIDE platform LLM integration project and would like to request access to AnvilGPT. Thank you for your assistance. ; Hi Hala, Your request has been approved, and you have been given access to both the UI and the API for AnvilGPT. Feel free to start exploring the service and let us know if you have any questions or need further assistance. ;",hmansour2@access-ci.org,Hala Mansour,Ashish Malik,Purdue University,Anvil,2,6,43,2024,2024-10-21
ATS-10657,Job submission,2024-09-13,2024-09-17,"Hello, I have submitted a job on the Anvil cluster, but all my jobs are still pending. Could this be due to a long queue, or might there be another issue? I've checked my quota, and I still have about 10,000 hours remaining. Allocation Type name Limit name Usage name Usage name Balance Account (account) (user) ============= ==== ========== ========== ========== ========== bio240109-gpu GPU 22401.0 12576.3 12576.3 9824.7 mcb160119 CPU 0.0 0.2 0.2 n/a ; Dear Aashish Bhatt, I have received your inquiry, and I'll look into the issue and as soon as I get the right info, I let you know. Best, name, Sr. Computational Scientist RCAC Team ; \\*\\*PRIVATE NOTE\\*\\* pending jobs on queue for long time. ; Hi , Thank you for your patience. I wonder if you could provide me with the job id to look it up from my end. Best, I.name RACAC support team ; \\*\\*PRIVATE NOTE\\*\\* The user was contacted to provide job id to investigate the long wait of his submitted jobs. ; Hi, Now is working. Thank you for your help. Regards, Aashish ---- ; So glad to hear that. Thanks for contacting us. Best, I.name: http://I.name RCAC support team ; \\*\\*PRIVATE NOTE\\*\\* The user indicated that the issue was resolved. ;",abhatt@access-ci.org,AASHISH BHATT,Ibrahem Alshybani,Purdue University,Anvil,8,3,37,2024,2024-09-09
ATS-10663,Urgent need for high memory nodes,2024-09-13,2024-09-17,"Hello Anvil support. I am running very large and highly memory-intensive jobs, which run best on the highmem partition of Anvil. I notice that that partition is currently under-utilized (+30 idle nodes+). I am curious if I could get access to 4 of these nodes for three weeks to run some very large fluid dynamics simulations. This would be very helpful for my work. I have received access to the wide-highmem queue in the past for another project (mch220029) and now I would like to use it for PHY230172. I submitted this request initially on name 1st and have not heard back and my allocation will run out in \\*30 days\\*, so if we could get this set up ASAP, I would greatly appreciate it. Thank you, Brendan ; Hi Brendan, Thanks for reaching out! Sorry for the delay. I think we can set up something for your allocation, phy230172. I'd like to confirm something from you. You want to use the {{highmem}} partition up to 4 nodes and up to 3 days for your jobs, correct? Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Hey Brendan, I've noticed that the previous wide-highmem will allow you to run your job using up to 16 nodes for up to 2 days, is it also good for your current jobs? Or you have tested your code, it has to run for 3 days? If so, we might need to create a new rule for you. Regards, name ; Hi name, If you want to allow the same rules for this partition, that would be fine. Two days is sufficient, because I can save files for restarts. I will actually need 8 nodes at a time. If it is easier for you, you can keep the rules the same as for the other account and I will just use the number of nodes I need (which will be less than 16 at a time). Thanks again, Brendan ---- ; Hi Brendan, The wide-highmem has been added to your allocation, PHY230172. Please add the following line when you submit jobs with PHY230172 using this qos. This reservation will be end on Oct 8, 2024. {{#SBATCH -q wide-highmem}} One more question, do you still need to run jobs with wide-highmem on mch220029? I saw it is still there, I am not sure if my colleague forgot to change it. Regards, name ; Hi name, I am still running jobs on wide-highmem on mch220029 for a little bit longer. Thank you for checking. And thank you for getting this queue set up again. Cheers, Brendan ---- ;",bchristensen,Brendan Christensen,Nannan Shan,Purdue University,Anvil,6,3,37,2024,2024-09-09
ATS-10743,Error -- No space left on device ,2024-09-17,2024-09-18,"I am working on ANVIL, on demand. When I try to enter https://ondemand.anvil.rcac.purdue.edu/: https://ondemand.anvil.rcac.purdue.edu/ I received this ERROR message: Error -- No space left on device @ fptr\\_finalize\\_flush - /var/lib/ondemand-nginx/config/puns/x-mcontrerasza.conf Run 'nginx\\_stage --help' to see a full list of available command line options. ; Hello, Can you please delete the NanoString directory in /anvil/scratch/x-mcontrerasza/NanoString. And also the UCD4 directory in anvil/scratch/x-mcontrerasza/ATACseq/UCD4 . I can't access to do it by myself because the Error No space left on device Thanks, MJ ; Hi name, Thank you for contacting us. The issue with the Open OnDemand gateway should be fixed now. Would you please try logging in again and let me know if you still see any errors? Thanks, name ; Hi name, I believe the issue should be fixed and you should be able to delete the mentioned directories for now. I'm tentatively marking this ticket resolved at this point. Please feel free to contact us again if you still see any issues. Thanks, name ;",mcontreraszarate,Maria Jose Contreras Zarate,Ruyi Li,Purdue University,Anvil,4,2,38,2024,2024-09-16
ATS-10796,RAG functionality of AnvilGPT,2024-09-19,2024-10-15,"Hi, I'm trying to pilot RAG functionality of AnvilGPT, and having issues with documentation upload and completing the knowledge section in the model workspace. I realize this is in the very early stages and you must be inundated with service requests, so this is not urgent. Just wanted to reach out to check if others have reporterd issues? Specifically, I cannot tell if my group of document selection are being uploaded. Uploading a single document at-a-time does seem to work. When going to the model workspace however, and adding the documents, the save & update bottom does not resolve. Thanks again for all this work, it's an excellent tool https://drive.google.com/file/d/1LdsvajhDL4bGihQTawkVPJ2wrfIlAOcj/view?usp=sharing: https://drive.google.com/file/d/1LdsvajhDL4bGihQTawkVPJ2wrfIlAOcj/view?usp=sharing Let me know if I can add more details. -Mitch ; Hi Mitch, The issue was related to file size, which has now been fixed. However, there is one specific document titled \\*""Chandregowda et name 2022""\\* that we are unable to open on our end. This document might be causing the issue again. Could you try excluding this file and let us know if the issue persists? Thank you for your patience, and please feel free to reach out if you need further assistance. Best regards, name ;",mhorn108@access-ci.org,Mitchell Horn,Ashish Malik,Purdue University,Anvil,5,19,38,2024,2024-09-16
ATS-10771,"Anvil shared partition has no free nodes, 90 nodes stuck in ""COMP"" state",2024-09-18,2024-09-18,"Hi all, There are 90 nodes in the shared partition of Anvil that are stuck in the ""comp"" state and are unusable. This has happened a few times before and I think you have to just reboot those nodes. I had thought you had something in place in your Nagios that was checking for this condition, but maybe not? Can you please take a look soon? Regards, Doug ; Hi Doug, Thank you for contacting us. We will get back to you as soon as we have the answer. Best regards, name ; Thanks Doug for bringing this up! We appreciate it! Currently our team is looking into it and discuss for a best solution. Best, name ; Hi all, I see there are 25 more nodes stuck in this comp state now. You might want to take a look at https://slurm.schedmd.com/troubleshoot.html#completing: https://slurm.schedmd.com/troubleshoot.html#completing, which describes why nodes can enter this state (unkillable processes), and how to quickly put them back in service (down and up the node using scontrol). Based on that suggestion, I wrote a simple script to do this (remove the echos): for i in $(sinfo -p shared -t COMP -o %n | tail -n +2); do echo scontrol update NodeName=$i State=down Reason=name\\_proc; echo scontrol update NodeName=$i State=resume; done Regards, Doug ; Thanks Dough for reporting. I've forward your message to the name team for further discussion and process. Best, name ;",dgc@access-ci.org,Doug Crabill,Xiao Liu,Purdue University,Anvil,5,1,38,2024,2024-09-16
ATS-10783,Purdue's Anvil-running ABySS 2.3.8,2024-09-18,2024-09-19,"Greetings, I hope you are doing well today. I am attempting to submit a batch job to run ABySS. I am attempting to run a test job using synthetic data, as follows: wget http://www.bcgsc.ca/platform/bioinfo/software/abyss/releases/1.3.4/test-data.tar.gz tar xzvf test-data.tar.gz abyss-pe k=25 name=test B=1G \ in='test-data/reads1.fastq test-data/reads2.fastq' I can successfully run this job on the front end but run into trouble whenever I try to use a job submission file. I would like to figure out how to submit a batch job, as when I shift to using my real data, I suspect genome assembly will take closer to 20 hours. I am attaching three different job submission files that I have tried. With each, I receive the follow error message: {{environment: `ABYSS-P': not a valid identifier}} Could you help me trouble shoot? Best wishes, name ; ^abyss\\_test\\_synthetic1.sh ^abyss\\_test\\_synthetic2.sh ^abyss\\_test\\_synthetic3.sh ; Hi name, Thank you for reaching out. Please check our user guide: https://www.rcac.purdue.edu/index.php/knowledge/biocontainers/abyss. You're currently using \\*""/bin/sh""\\* as the shebang in you slurm job script, if you change it to \\*""/bin/bash""\\*, it should fix the issue. Don't forget the ""#!"" at the beginning, Jira doesn't let me write the shebang completely. Let me know if you have any other questions. Best, name Senior Computational Scientist ; Many thanks! ;",jdoyle@access-ci.org,Jacqueline Doyle,Haniye Kashgarani,Purdue University,Anvil,4,2,38,2024,2024-09-16
ATS-10786,VASP licence on Anvil,2024-09-18,2024-09-19,"I would like to use VASP.5.4.4 software on Anvil computer. The license details are below \\*VASP license holder\\*: Mikalai Artsiusheuski \\*License number:\\* 5-1632 \\*Email for license holder\\*: : mailto: \\*VASP versions\\*: version-5 \\*Primary user\\*: Mikalai Artsiusheuski \\*Primary user email:\\* : mailto: ; Hi Mikalai, Thank you for reaching out. I have checked your license, and it was valid until June 30th, 2019. Therefore, I can only provide you access to VASP 5, as you requested. The access has been granted, and you should now be able to use the module. Best, name Senior Computational Scientist RCAC - Purdue University ;",martsiusheuski@access-ci.org,Mikalai Artsiusheuski,Haniye Kashgarani,Purdue University,Anvil,2,2,38,2024,2024-09-16
ATS-10105,Node fails,2024-08-23,2024-10-01,"I am running single GPU jobs on Anvil and my jobs keep restarting. I get email stating NODE\\_FAIL. This is from latest two jobs: Slurm Job\\_id=7670615 Name=Train.sub Ended, Run time 16:42:09, NODE\\_FAIL, ExitCode 0 Slurm Job\\_id=7670613 Name=Train.sub Ended, Run time 16:43:59, NODE\\_FAIL, ExitCode 0 Both jobs have since restarted. ; I have just noticed that the jobs are now running at very low speeds, compared to similar jobs previously run on same dataset ; Hello, I hope you are doing well. Thank you for reaching out to RC Support with your question! We are actively working on addressing the issue. Rest assured, we will provide you with a response as soon as possible. Sincerely, name ; Any updates on this? ; Hi, Sorry for the delay. We have been investigating this issue and found something might went wrong on Anvil SLURM recently. Can you help double check if it is still happening at the moment? Can you also share the jobid of those impacted jobs (due to {{NODE\\_FAIL}}) so we can refund the SUs for you? Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name ;",ssharma7@access-ci.org,Sharu Paul Sharma,Guangzhen Jin,Purdue University,Anvil,6,28,34,2024,2024-08-19
ATS-10118,Run Issue: SBATCH,2024-08-25,2024-10-03,"I want to run a job. I get the following error: ""sbatch: error: Batch job submission failed: Invalid qos specification"" every time I run the command: ""sbatch my\\_script.sh"" ; Thanks for your question -which system (anvil, bridges, expanse etc) are you attempting to run this on? ; Thank you for your reply. I am attempting to run this on Anvil ---- ; name, Would it be alright if I took a look at your job submission script? I can do it with your permission on your account (if you tell me where it's located), or you can share it through the ticket. Thanks, name ; Dear Mr. name, Thank you for your reply. Kindly find attached the script. Regards, name Yehia ---- ^script.txt \\_(0.5 kB)\\_ ; name, You will still need to specify the account you want this script to run with. I see the note in the script saying you will add the GPU account later, but no account is specified currently. This leads to the invalid QOS error you are seeing. I believe once you add an account, this error will go away. Let me know if you have any additional questions. Thanks, name ; Dear Mr. name, I actually tried to add the GPU account at first, but I got the same error. Regards, name Yehia ---- ; name, In addition to specifying the account, could you also add the line: #SBATCH -p gpu To your job script and try re-running. This specifies the partition you want to use. The default partition is the Wholenode partition, which I don't think your GPU allocation has access to. Thanks, name ; Dear Mr. name, Now I get the following error message: sbatch: error: QOSMaxWallDurationPerJobLimit sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits) I tried to change the time and size, but I am still getting an error I do not encounter such issues when using gpgpu at my university. Regards, name Yehia ---- ; name, I'm sorry I didn't catch this earlier, the GPU partition only allows for 2 days of wall time, so it is being rejected because you are asking for 3. Please change the wall time so that it is less than 48 hours and your job should run. Thanks, name, Since we have not heard from you in a while, I am marking this ticket as resolved. If that is not the case, please respond to this ticket within 7 days to reopen it. Otherwise, you will need to submit a new ticket. Thanks, name ; Dear Mr. name, Sorry for the late reply. I had some issues with my computer I have changed the wall time so that it is less than 48 hours. I am still getting the following error: ""sbatch: error: Batch job submission failed: Invalid qos specification"" Regards, name Yehia ---- ; name, Could you please send me your current submission script so I can try to debug it? Thanks, name ; Dear Mr. name, Kindly find attached the submission script Regards, name Yehia ---- ^script (84b224c5-855a-4085-84d5-0e3c48da1092).txt \\_(0.4 kB)\\_ ; name, Can you specify the partition to submit to, by specifying #SBATCH -p gpu in your submission file? Thanks, name ; Dear Mr. name, Thank you very much. It worked. The job has been submitted, but it is currently in the pending state. Regards, name Yehia ---- ; name, It looks like your job was able to finish after waiting in the queue for about half an hour. I'm marking this ticket as resolved, because I believe we have figured out the solution to your original question. Thanks, name ;",oyehia1@access-ci.org,Omar Yehia,Michael Carlson,Purdue University,Anvil,17,29,34,2024,2024-08-19
ATS-10675,Request for CUDA12.1 support on Purdue Anvil GPU,2024-09-13,2024-10-16,"I would like to request an update to include \\*CUDA 12.1\\* support on the Purdue Anvil GPU system. The current CUDA versions (11.0.3, 11.2.2, 11.4.2, 12.0.1) do not meet the requirements of our project, and upgrading to \\*CUDA 12.1\\* is essential for us. Your assistance in making this update would be greatly appreciated. ; name, Thank you for reaching out to RCAC for support. I apologize for the delay in my response. Are you able to use anaconda to download and install cudatoolkit and use that? We are planning on upgrading cuda during our upcoming October Anvil maintenance. Please let me know if this helps, or if you have any further questions. Thanks, name, Since I have not heard from you in a while, I am going to mark this ticket as resolved. If you are still encountering problems, please reach out within 7 days, otherwise you will need to submit a new ticket. Thanks, name ;",sshi,Shu Shi,Michael Carlson,,Anvil,3,24,37,2024,2024-09-09
ATS-10859,Project disk quota,2024-09-23,2024-09-30,"Hi ~, We have 200TB temporary disk space under Project, but when the total usage reached about 65 TB, we got ""No space left on device "" error. Please check whether the 200TB is real. ; Hi Wubin, Thank you for reaching out. To help us investigate the issue, would you please share more information about how you received the error? It would be helpful if you could share a screenshot of the error message as well. Warm regards, name ; After deleting some files, there is no error now. Previously, we had about 65TB of space under the project; we asked for support to expand to 200 TB. But the actual maximal space is still 65TB. The 200TB is fake, not real. -- Wubin name ; Hi Wubin, I checked the quota on the {{/anvil/projects/x-mcb130189}} directory. It appears that its block limit is set to 200TB. If you see the error again, would you please let us know what your name is and where you receive the error (in the terminal or any output files)? Thanks, name ; Got it. Thank you. -- Wubin name ; Hi Wubin, Thanks for your understanding. Since I have not received your report of the issue again in a while, I'm tentatively marking this ticket resolved at this point. However, it looks like the usage of {{/anvil/projects/x-mcb130189}} stays under 65 TB recently - if you see any issues when the usage goes up over 65 TB, please do not hesitate to reach out to us again. Best regards, name ;",wding2@access-ci.org,Wubin Ding,Ruyi Li,Purdue University,Anvil,7,6,39,2024,2024-09-23
ATS-10947,VASP5.4.4 vtst compilation on Anvil,2024-09-25,2024-10-07,"Hello I need to use vtst (https://theory.cm.utexas.edu/vtsttools/: https://theory.cm.utexas.edu/vtsttools/) addition to vasp on vasp5.4.4 module on Anvil/ Can vtvt tool be intalled to Vasp5.4.4 module on Anvil computer? Currently it is only available for vasp 6.3 (as vasp/6.3.0-vtst module), but our group has license only for 5.4.4 version of vasp Thank you Mikalai ; Hi Mikalai, Thanks for reaching RCAC. Is vtvt tool a module that depends on Vasp? If so, it's worth to try, given the license limitation you have now. Let me know if it works or not! Best, name ; Hi name VTST can be installed to any version of VASP. It for sure can be installed on both VASP 5 and VASP 6, see the link (https://theory.cm.utexas.edu/vtsttools/installation.html: https://theory.cm.utexas.edu/vtsttools/installation.html|smart-link ). In code there is special folder for VASP 5, so it is compatible Can you please install it on VASP5 on Anvil? There is a detailed instruction https://theory.cm.utexas.edu/vtsttools/installation.html: https://theory.cm.utexas.edu/vtsttools/installation.html|smart-link Thanks in advance Mikalai ; Hi Mikalai, Thanks for reaching out. I inquired from our applications team and yes we can install the vtst tool on VASP5 as well. I will now escalate the ticket to name who will take care of it. Thank you for your patience while she looks into this issue. Best, name K ; Hi name Thank you, this sounds great. I highly appreciate your prompt support Best, Mikalai ; Hello Are there any updates on the installing vtst for vasp5.4.4. on anvil? Thanks Mikalai ; Hi Milalai, Thanks for reaching out! The {{vasp/5.4.4.pl2-vtst}} module is available on Anvil now. To use this module, you can add the below commands to your submit script. module --force purge module load gcc/11.2.0 openmpi/4.1.6 module load vasp/5.4.4.pl2-vtst Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ;",martsiusheuski@access-ci.org,Mikalai Artsiusheuski,Nannan Shan,Purdue University,Anvil,7,9,39,2024,2024-09-23
ATS-11016,Jobs taking too long on queue,2024-09-30,2024-10-08,"Hello, I have some jobs waiting on queue, some of which have been there for over a week. I am intrigued by this, since even jobs with larger walltimes would usually just take a couple of days maximum on queue. I am wondering if we have reached our computation time, or if there is another similar issue. Could you please take a look and let me know? I appreciate it. Best, Inês ; Hi , Let me look into the issue and I'll come back to you if I need further information. Best, I.name: http://I.name RCAC support team ; Hi Ines I can see that your 10 jobs are currently running. Is everything working fine? Let me know if you still have issues Best, I,name Anvil support team ; Hello, I'm sorry I missed the last few emails. My jobs started running a few days ago and it seems that everything is going well. Thank you for your assistance. Best, Inês Rainho name : mailto: escreveu (segunda, 7/10/2024 à(s) 22:22): ; \\*\\*PRIVATE NOTE\\*\\* The user confirmed that the issue has been resolved ! ;",iandraderainho@access-ci.org,Ines Andrade Rainho,Ibrahem Alshybani,Purdue University,Anvil,7,7,40,2024,2024-09-30
ATS-11021,Purdue Anvil BioContainer Help,2024-09-30,2024-10-17,"I require assistance/instructions on how to download, install, and run a BioContainer (Mitohifi) on Purdue Anvil. MitoHifi is NOT currently one of the BioContainers pre-downloaded and wrapped into a software module. Any guidance you could provide would be very helpful. Thank you. ; Hi name, Thank you for contacting RCAC support team. I r you recommend going through this link: https://biocontainers-edu.readthedocs.io/en/latest/what\\_is\\_biocontainers.html: https://biocontainers-edu.readthedocs.io/en/latest/what\\_is\\_biocontainers.html if you still need help, please reach out to me. I'll be happy to assist. Best, I.name: http://I.name RCAC support team ; \\*\\*PRIVATE NOTE\\*\\* waiting for the user's response. ; Hi name, It has been sometime since we last responded to your ticket with no response from your side. I'm following up to check if everything works fine I've looked over the biocontainer instructions, but I'm really at a loss. I'm not sure where to begin. Is Docker already installed on Anvil? Can I pull the mitofish biocontainer to my scratch folder on Anvil? Any guidance would be appreciated. AMB ---- ; Hi name, I've put together a brief tutorial on how to use the container to run MitoHifi, which you can find here: https://rcac-bioinformatics.readthedocs.io/en/latest/mitohifi.html: https://rcac-bioinformatics.readthedocs.io/en/latest/mitohifi.html|smart-link If you have any questions or if there's something specific you'd like to see covered, please feel free to reach out. Your feedback would be really helpful in making the documentation even better. Edit: I forgot to answer your questions: Is Docker already installed on Anvil? You will need to use {{singularity}} for using this container, and it should be available on Anvil. It is also referred as {{apptainer}} Can I pull the mitofish biocontainer to my scratch folder on Anvil Yes! Thanks, name Lead Bioinformatics Scientist, RCAC ; Hi name, This is so incredibly kind of you. Thank you. I'll go through the tutorial, run some hifi data through it and let you know how it goes. Again, thank you. This is so lovely of you. Have a great weekend. name ---- ; Hi name, I'm following up to see if everything works fine and if you've got everything set up correctly. Best, I.name Anvil support team ; Good afternoon. Thanks for the follow-up. Yes. Mitohifi is set up and is working well. I ran my own data through the pipeline yesterday. Many thanks for all of your help and guidance. name ---- ; Hi name, Glad to hear that you're able to proceed with your project. Thank you for reaching out and we'll be happy to assist whenever needed! Best, I.name Anvil Support Team ;",abernard@access-ci.org,Andrea Bernard,Ibrahem Alshybani,Purdue University,Anvil,10,14,40,2024,2024-09-30
ATS-11062,Access to PRAW Python API,2024-10-01,2024-10-04,"I'm trying to use the PRAW Python API in order to scrape Reddit, but it looks like I'm unable to install it. Is there any way this could be done? ; Good evening, which resource are you running on (anvil, expanse, bridges, etc)? Thanks ;",thoang2@access-ci.org,Tien Hoang,Xiao Liu,Purdue University,Anvil,6,4,40,2024,2024-09-30
ATS-11070,CIS240473 ACCESS accounts not showing up on Purdue allocation,2024-10-02,2024-10-04,"Hello, I am again having issues with users within an ACCESS project not appearing as eligible users in our allocations on Purdue Anvil. I have 14 users in CIS240473 with access to Purdue Anvil CPU and GPU allocations, yet only the following users show up. :\~] $ sacctmgr show assoc account=cis240473 format=user -p User: | x-bkeene| x-bsoykan| x-mfakhan| x-mnagaraj| x-mramaswami| x-nandan| :\~ $ sacctmgr show assoc account=cis240473-gpu format=user -p User| | x-bkeene| x-bsoykan| x-mfakhan| x-mnagaraj| x-mramaswami| x-nandan| We're in a bit of a crunch, with a workshop planned for faculty and graduate students this Friday 10/4. ; \\*\\*PRIVATE NOTE\\*\\* [~accountid:id this is the allocation we are already debugging since their recent exchange of SUs from 09/30 also doesn't show up. Maybe the same issue. ; Hi name, Thanks for reaching out! we are looking into this allocation since your transfer of 499 SUs also seems to have been held up. We did get several allocation updates from ACCESS due to the October 1 start date for this cycle, so it's possible that your updates may have been held up due to an unrelated issue. We will look into it and get back as soon as possible. Best, name ; Hi name, We believe this issue should be fixed and you should now see the 500 name balance and all the 14 users on the allocation. Please let us know if you have any further issues with this allocation. Best, name ; Ask and you shall receive! Thank you \\*very much\\* name! ---- ; Hi name, Since the issue on this ticket has been addressed, we'll mark the ticket resolved. Thanks again for contacting us. Best regards, name ;",bkeene@access-ci.org,Benjamin Keene,Ruyi Li,Purdue University,Anvil,6,3,40,2024,2024-09-30
ATS-11334,Anvil shared partition effectively down,2024-10-13,2024-10-16,"The shared partition on Anvil seems to be broken and won't launch new jobs. Scontrol show job for the job I've been waiting to launch for the last 40 minutes on the Anvil shared partition says: JobState=PENDING Reason=ReqNodeNotAvail,\\_UnavailableNodes:a000-249] sinfo -p shared says there are 200 nodes idle, but there have been no new jobs started in the shared partition in the last hour. The nodes aren't in the down state, but SLURM doesn't think they are available. More detail: login01.anvil ~ $ date name Oct 13 09:29:52 EDT 2024 login01.anvil ~ $ squeue --me JOBID USER ACCOUNT NAME NODES CPUS TIME\\_LIMIT ST TIME 8022683 x-dgc cis220051 TDM/Jupyter 1 1 4:00:00 PD 0:00 login01.anvil ~ $ scontrol show job 8022683 JobId=8022683 JobName=TDM/Jupyter UserId=x-dgc(7044182) GroupId=7001389(7001389) MCS\\_label=N/A Priority=14843 Nice=0 Account=cis220051 QOS=cpu JobState=PENDING Reason=ReqNodeNotAvail,\\_UnavailableNodes:a000-249 Dependency=(null) Requeue=1 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0 RunTime=00:00:00 TimeLimit=04:00:00 TimeMin=N/A SubmitTime=2024-10-13T08:50:52 EligibleTime=2024-10-13T08:50:52 AccrueTime=2024-10-13T08:50:52 StartTime=Unknown EndTime=Unknown Deadline=N/A SuspendTime=None SecsPreSuspend=0 LastSchedEval=2024-10-13T09:29:55 Scheduler=Backfill:\\* Partition=shared AllocNode:Sid=192.168.133.160:493288 ReqNodeList=(null) ExcNodeList=(null) NodeList= NumNodes=1 NumCPUs=1 NumTasks=1 CPUs/Task=1 ReqB:S:C:T=0:0:\\*:\\* ReqTRES=cpu=1,mem=1896M,node=1,billing=1 AllocTRES=(null) Socks/Node=\\* NtasksPerN:B:S:C=0:0:\\*:\\* CoreSpec=\\* MinCPUsNode=1 MinMemoryCPU=1896M MinTmpDiskNode=0 Features=(null) DelayBoot=00:00:00 OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null) Command=(null) WorkDir=/home/x-dgc/ondemand/data/name/dashboard/batch\\_connect/name/tdm\\_jupyter/output/a0215d4b-e925-4907-ab57-24f69a12c63e StdErr=/home/x-dgc/ondemand/data/name/dashboard/batch\\_connect/name/tdm\\_jupyter/output/a0215d4b-e925-4907-ab57-24f69a12c63e/output.log StdIn=/dev/null StdOut=/home/x-dgc/ondemand/data/name/dashboard/batch\\_connect/name/tdm\\_jupyter/output/a0215d4b-e925-4907-ab57-24f69a12c63e/output.log Power= TresPerTask=cpu:1 login01.anvil ~ $ sinfo -p shared PARTITION AVAIL TIMELIMIT NODES STATE NODELIST shared\\* up infinite 3 comp\\* a079-080,240 shared\\* up infinite 1 drng\\* a118 shared\\* up infinite 6 drain\\* a073,181,183,185-187 shared\\* up infinite 32 mix\\* a060,064-065,068,072,084,092,116-117,189-190,192-193,195-196,198,202-204,207,211-213,233-234,241,243-248 shared\\* up infinite 3 alloc\\* a101,188,217 shared\\* up infinite 200 idle\\* a000-036,038-059,061-063,066-067,069-071,074-078,081-083,085-091,093-100,102-115,119-179,191,194,197,199-201,205-206,208-210,214-216,218-232,235-239,242 shared\\* up infinite 5 down\\* a037,180,182,184,249 ; Two hours later, I tried too, and I also cannot get an Open OnDemand session on Anvil. ; Looks like this is related to an all-campus computing power outage here at Purdue: [https://www.rcac.purdue.edu/news/6847: https://www.rcac.purdue.edu/news/6847|smart-link ; Doug, Thank you for your investigation into this. Mark is right that this was probably related to the power outage in the data center. Are you still seeing problems with Anvil nodes? If so, we can do more digging to find a root cause. Thanks, name ; Hi name, This was certainly caused by the power outage\! Things seem better now! Regards, Doug ---- ; Doug, I'm glad to hear things are going well now. I'm going to mark this ticket as resolved, but don't hesitate to reach out if you encounter more problems. Thanks, name ;",dgc@access-ci.org,Doug Crabill,Michael Carlson,Purdue University,Anvil,6,3,41,2024,2024-10-07
ATS-11113,Job aborted telling that it is out of memory while running seff followed by the job ID shows otherwise.,2024-10-03,2024-10-08,"My job (for example ID = 7967188) was aborted and running {{seff }} shows the following: \\*:\~\\* $ scontrol show job 7967188 slurm\\_load\\_jobs error: Invalid job id specified \\*:\~\\* $ seff 7967188 Job ID: 7967188 Cluster: anvil User/Group: x-bwoldegiorgi/x-ees240082 State: OUT\\_OF\\_MEMORY (exit code 0) Nodes: 1 Cores per node: 128 CPU Utilized: 00:03:24 CPU Efficiency: 0.02% of 10-12:35:12 core-walltime Job Wall-clock time: 01:58:24 Memory Utilized: 177.32 MB Memory Efficiency: 0.07% of 237.00 GB Why am getting {{OUT\\_OF\\_MEMORY}} message while the memory utilization is 0.07%. I have tried a couple of things (based on suggestion from internet), such as defining the TMPDIR, and purging, although I have the impression that {{localscratch}} may not be an appropriate path for the system I was using. None of them worked. Any help is appreciated. Thank you in advance for the anticipated help. ; Hello, I hope you are doing well. Thank you for reaching out to RC Support with your question! We are actively working on addressing the issue. Rest assured, we will provide you with a response as soon as possible. Best Regards, name RC Support ; Hello, Thank you for reaching out! Please note that the {{seff}} command will only record the last status before the job crashes. This means that the process may request a large amount of RAM at once, which can lead to the job crashing. For OUT\\_OF\\_MEMORY issues, we typically recommend trying more cores or submitting your job to the \\*highmem\\* partition. Let us know if you have any further questions or need additional assistance. Best regards, name RC Support Team ; Dear name, Thank you very much for the suggestion. I will try it out. Kind regards, Befekadu ; Hello, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best Regards, name RC Support ;",bwoldegiorgis@access-ci.org,Befekadu Taddesse Woldegiorgis,Ankitha Mallekav,,Anvil,6,4,40,2024,2024-09-30
ATS-11115,Running a job in anvil,2024-10-03,2024-10-08,"Hi, I am trying to run my jobs on anvil supercomputer. I am submitting my job using slurm job scheduler using partition gpu and gpu-debug. But these days the jobs are remaining pending for a very long time (even more than a day). Could you suggest some ways to resolve the problem? Thank you. ; Hello, I hope you are doing well. Thank you for reaching out to RC Support with your question Best regards, name RC Support Team ; Hi, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best Regards, name RC Support ;",mhasan1@access-ci.org,MD MEHEDI HASAN,Ankitha Mallekav,Purdue University,Anvil,4,4,40,2024,2024-09-30
ATS-11167,Anvil Training not Opening,2024-10-06,2024-10-08,"Hello ACCESS, I was recently emailed welcoming me to my ACCESS allocation and sharing a link to Anvil Training. However, when I click on the training link, the webpage gets stuck loading. I have not seen the training load after waiting several minutes. Is there something that I am missing here? Thank you for any help, Ernie Parke ; Dear User, Thank you for contacting Anvil support team. Is it possible to provide me with the training link? Best, I.name Anvil Support Team ; Hello, I am using the following link: https://urldefense.com/v3/\\_\\_https://www.rcac.purdue.edu/training/anvil101\\_\\_; Best wishes, Ernie Parke ; This links works just fine with two videos provided in the webpage: https://www.rcac.purdue.edu/training/anvil101: https://www.rcac.purdue.edu/training/anvil101 Let me know how that goes ; \\*\\*PRIVATE NOTE\\*\\* The issue is resolved! ;",eparke@access-ci.org,Ernie Parke,Ibrahem Alshybani,I do not know the RP,Anvil,7,2,40,2024,2024-09-30
ATS-11223,How to increase storage on Anvil account,2024-10-08,2024-10-08,"Hello, Is it possible to increase the amount of data that can temporarily be stored on my Anvil account? ; Hi name, Thank you for reaching out. It seems your home directory on Anvil is full, while you still have plenty of free space in {{/anvil/scratch/x-lintravaia}} and {{/anvil/projects/x-bio240052}}. You can run the {{myquota}} command to check the quotas and usage of the spaces you have access to: $ myquota x-lintravaia Type Location Size Limit Use Files Limit Use ============================================================================== home x-lintravaia 25.0GB 25.0GB 100% - - - scratch anvil 0KB 100.0TB 0% 0k 1,000k 0.00% projects x-bio240052 0KB 5.0TB 0% 0k 1,048k 0.00% For more information about the file systems on Anvil, please check out the following documentation: https://www.rcac.purdue.edu/knowledge/anvil/storage?all=true: https://www.rcac.purdue.edu/knowledge/anvil/storage?all=true|smart-link If you have any further questions, please let me know. Regards, name ; Thank you! ; No problem. Be aware that the scratch directory is for short-term storage only - inactive files there are purged on a regular basis. You would need to have your data backed up promptly to avoid possible data loss. I'm tentatively marking this ticket resolved at this point. Please feel free to contact us again if you have any other questions or need any help. Thanks, name ;",lintravaia@access-ci.org,Lauren Intravaia,Ruyi Li,Purdue University,Anvil,4,1,41,2024,2024-10-07
ATS-11251,Can we access Purdue's Depot Space from Anvil?,2024-10-09,2024-10-09,"We have depot space in our research team and wish to use this storage with our Anvil allocation. Is it possible to do this? ; Hi, Unfortunately the answer is no. Depot is not for Anvil users. Depot is for Purdue users on community clusters. Let us know how we could further help. Best, name ;",bchou@access-ci.org,Benjamin Shiue-Hal Chou,Xiao Liu,Purdue University,Anvil,2,1,41,2024,2024-10-07
ATS-11259,ANVIL - request to install libjpeg,2024-10-09,2024-10-15,"I would like to request that a module for libjpeg: https://libjpeg.sourceforge.net/ be installed on Anvil. This is a prerequisite for a lot of R packages, some of which I would like to install myself. Specifically for r/4.4.1 Please let me know if you have any questions. Thank you! name ; Hi name, Thanks for reaching RCAC. I've brought it up for the group to discuss, to see if we can install it as a general module for all users. Will let you know how it goes. BTW, if you are hurry to use it, feel free to follow this https://www.rcac.purdue.edu/training/software-installation: https://www.rcac.purdue.edu/training/software-installation|smart-link to install it for now. Best, name ; Thanks, name. After submitting the ticket, I realized that this probably the better version of libjpeg to install if you are able to do so: https://github.com/libjpeg-turbo/libjpeg-turbo: https://github.com/libjpeg-turbo/libjpeg-turbo Best, name ; Hi name, We found something in Anvil. Are these something you need? \\*:\~]\\* $ locate libjpeg /usr/lib64/libjpeg.so.62 /usr/lib64/libjpeg.so.62.2.0 /usr/share/doc/libjpeg-turbo /usr/share/doc/libjpeg-turbo/ChangeLog.md /usr/share/doc/libjpeg-turbo/README.ijg /usr/share/doc/libjpeg-turbo/README.md /usr/share/licenses/libjpeg-turbo /usr/share/licenses/libjpeg-turbo/LICENSE.md Best, name ; Hi name, Thanks for checking. Unfortunately the header files (acquired from the ""-devel"" version of the package) are required to build packages that use libjpeg/libjpeg-turbo. So the existing system library along is not enough. Best, name ; Hi name, Can you explain more about the issue (what is ""idevel"" version of what package)? Doe it mean you need to build a specific version of {{libjpeg-turbo}} with this package? As far as I know, I double if we can do it. Let me check with folks to see what suggestions that we can give to you? Best, name ; Hi name, I just meant that the system-installed version of libjpeg-turbo doesn't include the ""devel"" version: https://rpmfind.net/linux/rpm2html/search.php?query=libjpeg-turbo-devel that provides the header files. The header files for a specific library are almost always required when building a different application that uses that library. When building the library from source (and, for example, creating a module for it), those header files are automatically included. However, when installing from the system package manager the ""devel"" version needs to be specifically installed alongside the standard library version. It would be great to get a module for libjpeg-turbo on Anvil, but if that's not possible, I can build my own version. Best, name ; Hi name, Thanks for explaining. I will bring it up to discuss on Wednesday meeting. Will get back to you later Wednesday or Thursday morning. Best, name ; Hi name, I ended up building my own version of the library, so you can go ahead and close this. Best, name ; Hi name, Okay, let us know when you need help. Best, name ; Hi name, we discussed the package in the meeting, and found this: :[~ $ ls /apps/spack/anvil/apps/libjpeg-turbo/2.1.0-gcc-11.2.0-gapliy5/include jconfig.h jerror.h jmorecfg.h jpeglib.h turbojpeg.h Are these header files show one of the {{libjpeg-turbo}} there meet your requirement? Best, name ;",decarlson@access-ci.org,David Carlson,Xiao Liu,Purdue University,Anvil,11,5,41,2024,2024-10-07
ATS-11314,AnvilGPT Access Request,2024-10-11,2024-10-15,"Hello Anvil admins, I'd like to evaluate AnvilGPT as an LLM inference service for different projects. The first project is a possible collaboration with Dr Bernie name from Southern Oregon University on a RAG system for capturing and querying the 'tacit knowledge' of research groups. My ACCESS allocation: CCR190024 I'd like access to both the UI and the API. ; Hello! We are processing your request. Thanks, name ; Hi Julian, Your request has been approved, and you have been given access to both the UI and the API for AnvilGPT. Feel free to start exploring the service and let us know if you have any questions or need further assistance. ;",julianp@access-ci.org,Julian Pistorius,Ashish Malik,Purdue University,Anvil,2,3,41,2024,2024-10-07
ATS-11347,ERROR: Could not install packages due to an OSError: [Errno 122] Disk quota exceeded: '/home/x-wliu1/.local/lib/python3.11/site-packages/nvidia/__init__.py',2024-10-13,2024-10-18,"sed: couldn't open temporary file /home/x-wliu1/.ssh/sedvvhFyQ: Disk quota exceededsed: couldn't open temporary file /home/x-wliu1/.ssh/sedaV0IUq: Disk quota exceededhome x-wliu1 25.3GB 25.0GB 101% - - - scratch anvil 714.2GB 100.0TB 0.70% 1,651k 4,194k 39%projects x-cis230405 1.5TB 5.0TB 32% 17k 1,048k 2% ; Hi name, Thank you for reaching out. It looks like your home directory is full. Could you please free up some space and try again? That should resolve the issue. $ myquota x-wliu1 Type Location Size Limit Use Files Limit Use home x-wliu1 25.3GB 25.0GB 101% - - - scratch anvil 509.6GB 100.0TB 0.50% 1,104k 4,194k 26% projects x-cis230405 1.5TB 5.0TB 32% 17k 1,048k 2% Best, name Senior Computational Scientist RCAC - Purdue University ; Hi name, It becomes full right just I copy an Anaconda virtual environment of multimae to multimae\\_diff. But I only has 3 virtual environment now. I wonder if you could help me increase the size limit of my home directory. Thanks so much. Best regards, name ---- ; Unfortunately, it's not possible to increase the capacity of your home directory. However, I noticed that your {{~/.cache}} directory is using 2.3 GB of space, and you can safely remove it to free up some room. Best, name K ;",wliu1@access-ci.org,Wei Liu,Haniye Kashgarani,Purdue University,Anvil,4,5,41,2024,2024-10-07
ATS-11382,cannot request interactive job with more than one node on Anvil,2024-10-15,2024-10-15,"Hi, I can't request more than a single 128-core Milan node on the Purdue Anvil system. Here's an example of the command I'm trying and followed by the output. sinteractive -N2 -n256 -A mth240048 salloc: error: QOSMaxCpuPerJobLimit salloc: error: Job submit/allocate failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits) I need more than one node for interactive jobs. Do I need to apply for the next level of NSF allocation for this? On the Anvil website, where they give an example command, their example command asks for two nodes. ; Hi name, Thank you for reaching out. It looks like you did not specify a partition in your command, so Slurm tried to allocate resources in the {{shared}} partition to your job by default. However, each job in the {{shared}} partition can only request up to 1 node, so the error was reported. The good news is that some partitions, such as {{wholenode}} and {{wide}}, allow jobs to request multiple nodes. You can specify the partition in your command using the {{-p}} flag. For example: {{sinteractive -N2 -n256 -A mth240048 -p wholenode}}. Would you please give it a try and let me know if it works for you? For more information about the partitions on Anvil, please check out the following documentation: https://www.rcac.purdue.edu/knowledge/anvil/run/partitions: https://www.rcac.purdue.edu/knowledge/anvil/run/partitions|smart-link Thanks, name ; Hi name, Thanks for your quick reply. That works great -name O. ; Hi name, Great Best regards, name ;",loconnor@access-ci.org,Liam P O'Connor,Ruyi Li,Purdue University,Anvil,6,1,42,2024,2024-10-14
ATS-11402,AnvilGPT Access Request,2024-10-15,2024-10-15,"Hello, We would like to explore the use of AnvilGPT both API and WebUI for our project. We are trying to streamline RAG pipeline for multiple research projects and need access to multiple LLM. Our allocation number CIS240301 ; Hi Nirav, Your request has been approved, and you have been given access to both the UI and the API for AnvilGPT. Feel free to start exploring the service and let us know if you have any questions or need further assistance. ;",nirav@access-ci.org,Nirav Merchant,Ashish Malik,Purdue University,Anvil,1,1,42,2024,2024-10-14
ATS-11404,AnvilGPT Access Request,2024-10-15,2024-10-15,"I'm a PhD candidate working on computational fluid dynamics at Northwestern. I'm interested in using GPT to improve my paper-writing and communication. My allocation is ""MTH240048"". I would like UI + API access. ; Hi name, Your request has been approved, and you have been given access to both the UI and the API for AnvilGPT. Feel free to start exploring the service and let us know if you have any questions or need further assistance. ;",loconnor@access-ci.org,Liam P O'Connor,Ashish Malik,,Anvil,1,1,42,2024,2024-10-14
ATS-11412,AnvilGPT Access Request,2024-10-15,2024-10-16,"Hello, I'd like to get access to anvilGPT to start evaluating it for use within the Galaxy project (galaxyproject.org: http://galaxyproject.org). I spoke with name) about this at the Science Gateways conference last week. We've piloted use of chatgpt as the backend for a Galaxy-specific help agent within the app and would like to explore the use of anvilgpt instead to have more control over content tuning. ; Hi Enis, In order for us to approve your request could you please provide your ACCESS allocation number? Thanks! name ; Thanks for getting back to me. My dev allocation is CCR160022 and the overall Galaxy allocation is MCB140147. Regards. ; Hi Enis, Your request has been approved, and you have been given access to both the UI and the API for AnvilGPT. Feel free to start exploring the service and let us know if you have any questions or need further assistance. ;",eafgan@access-ci.org,Enis Afgan,Ashish Malik,Purdue University,Anvil,3,2,42,2024,2024-10-14
ATS-11413,"Unable to Load VASP Module: ""Lmod unable to find vasp""",2024-10-15,2024-10-15,"Hi, I encountered an issue while running vasp calculations today. I tried running module spider vasp but got the error: Lmod has detected the following error: Unable to find: ""vasp"". (similar result with vasp/5.4.4.pl2 and vasp/6.3.0) Could you please assist with this issue? Thanks, name M. Orvati Movaffagh ; Hi name, Thank you for reporting the issue. I saw the same error a moment ago, but it should be resolved now. Would you please give it another try and let me know if the error persists? Warm regards, name ; Hi name, Thank you very much for your prompt response. The issue is resolved, and the calculations are running. Best regards, name, No problem. Glad to hear that. I'll go ahead and mark this ticket resolved then. If you see similar issues, please do not hesitate to contact us again. Best regards, name ;",aorvatimovaffagh@access-ci.org,Amir Orvati Movaffagh,Ruyi Li,Purdue University,Anvil,4,1,42,2024,2024-10-14
ATS-11471,"One job stuck in ""CG"" state after scancel",2024-10-17,2024-10-18,"There is one job (JOBID 8084067) stuck at CG state for me after I did scancel on it, making other slurm operations (sbatch, squeue, …) very slow now. Thanks. ; Hi Jianlun, It seems the issue is fixed, as I don't see any jobs under your account stuck in the CG state. Let me know if you have any other issues. Best, name K ; Hi name, Is it possible to track down what happened to Job 8084067? It was stuck in CG for like 2 hours after I cancelled it and made everything slow. Thanks. Best, Jialun ; Hi Jialun, I don't anything wrong with it, except your project space for chm240060 allocation is full: $ myquota x-jialunw Type Location Size Limit Use Files Limit Use home x-jialunw 1.3GB 25.0GB 5% - - - scratch anvil 7.4TB 100.0TB 7% 1k 1,000k 0.18% projects x-chm240060 4.9TB 5.0TB 100% 33k 1,048k 3% projects x-cts130035 2.2GB 5.0TB 0.04% 4k 1,048k 0.46% This might be the reason for slowness, you're jobs might be looking for more space? Best, name K ; Hi name, I'm running things on scratch now, so it shouldn't be a problem. Thanks anyway since this problem was fixed. Best, Jialun ;",jialunw@access-ci.org,Jialun Wang,Haniye Kashgarani,,Anvil,5,2,42,2024,2024-10-14
ATS-11495,AnvilGPT Access Request,2024-10-18,2024-10-18,"Hi, I am a graduate student at Purdue University. I am part of LyoHub lab. I need access to open source LLM like llama for my research. Please grant access to the same. ;",njagadeesha@access-ci.org,Nishchal Jagadeesha,Ashish Malik,Purdue University,Anvil,0,1,42,2024,2024-10-14
ATS-11497,AnvilGPT Access Request,2024-10-18,2024-10-18,"I am a graduate student at Purdue University and a Research Assistant at LyoHub lab. At our lab, we are building a RAG LLM architecture grounded with LyoHub research papers and documents. For this project, I need access to the UI and API of opensource LLM like Llama-3. Please approve my request for the same. ; Hi Nischal, In order for us to approve your request could you please provide your ACCESS allocation number? Thanks! name ; Hey name, Can you please let me know how to obtain the Access allocation number? Our lab is using Access for the first time. Best, Nishchal ---- ; Hi Nischal, You can find all the information on how to get an allocation at the link below. For Researchers - Access (access-ci.org): https://access-ci.org/get-started/for-researchers/ ; Hi Nishchal, For now, you will be provided temporary access to ANVIL GPT. We will soon be releasing PurdueGPT, which will have the same functionality and features. Once that happens, you'll be switched to PurdueGPT. In the meantime, feel free to use ANVIL GPT, and let us know if you have any questions. Best regards, name ; Hey name, Thanks a lot for your help. I am able to access ANVIL GPT now. Please let me know if I have to provide any information for migration to PurdueGPT in the future. Best, Nishchal ---- ;",njagadeesha@access-ci.org,Nishchal Jagadeesha,Ashish Malik,Purdue University,Anvil,5,1,42,2024,2024-10-14
ATS-11503,AnvilGPT Access Request,2024-10-18,2024-10-18,"I am name, and I am a graduate student working under Professor name in the Department of Mechanical Engineering at Purdue University. We are conducting research on automating our simulation software using large language models (LLMs). For this, we would like to request access to the Anvil GPT WebUI. Our allocation number is MCH2200103. ; Hi name, We have provided you with access to ANVILGPT; feel free to use it and let us know if you have any questions. Best regards, name ;",rdeotale@access-ci.org,Rushikesh Prafulla Deotale,,Purdue University,Anvil,1,1,42,2024,2024-10-14
ATS-10651,Anvil Node Failure Error,2024-09-13,2024-10-24,"Encountered ""slurmstepd: error: \\*\\*\\* JOB 7779953 ON g005 CANCELLED AT 2024-09-12T15:25:16 DUE TO NODE FAILURE, SEE SLURMCTLD LOG FOR DETAILS\\*\\*\\*"" when running a simulation in Anvil GPU. The jobs were automatically resubmitted to the queue to begin overwriting all existing files. ; Hi Zamana, Thank you for reaching out to us. I've reported the issue, and I'll get back to you as soon as possible. Thank you for your patience. RCAC Team, name ; \\*\\*PRIVATE NOTE\\*\\* Slurm Issues ; Hi Ahdaf Zaman, Thank you for your patience. I wonder if the issue is still there! if it does, let me know if we can schedule a meeting to look it up and help you resolving it. Best, I.name RCAC support team ; \\*\\*PRIVATE NOTE\\*\\* waiting for customer's response. ; \\*\\*PRIVATE NOTE\\*\\* no response from user ~ due ; Hi, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, I.name: http://I.name Anvil support team ;",azaman@access-ci.org,Ahdaf Zaman,Ibrahem Alshybani,Purdue University,Anvil,7,30,37,2024,2024-09-09
ATS-11034,Out of memory error on exclusive node even though SLURM reported MaxRSS much less than node memory,2024-09-30,2024-10-24,"Hello, My single-node multicore parallelized job 7901710 crashed from running out of memory, but SLURM only shows the job as having used ~179 GB even though the node has about 242 GB. I don't understand whether the per-process memory limits are applying in a shared-memory program job and how I should go about fixing that. Please help. The job submission script is located at {{/anvil/scratch/x-pnanda/ModelRuns/2024-09-19-A-gr-abcsmc-secretion/run-pyabc-multicore.sbatch}} and the job and node information is: $ pwd /anvil/scratch/x-pnanda/ModelRuns/2024-09-19-A-gr-abcsmc-secretion $ head run-pyabc-multicore.sbatch # Best, I.name: http://I.name RCAC support team ; Hi Pariksheet, Could you let me know how many processors you're using for the job? Also, are you using MPI in your code? I suggest trying to define a specific number of CPUs and explicitly set the memory allocation per CPU, which might help address the memory issue. Let me know if you need further assistance with this! Best, I.name RCAC support team ; Hi name, I'm using all 128 cores and multicore parallelism without MPI using python's builtin multiprocessing module. I don't want any processor to have any memory limit because I'm using the entire node exclusively. Therefore, setting a memory allocation per CPU is counterproductive. How do I do this? Pariksheet ; Hi Pariksheet, Sorry for the late response as I did not receive a notification based on your response on the system. I suggest you book a meeting with me to resolve the issue. The booking link is provided below and you need also to provide ticket number details : ATS-11034 Book time with name: Research Computing Support • This single-use link will expire on: January 22, 2025: https://outlook-sdf.office.com/bookwithme/user//meetingtype/g9TnSUWvwEaFuMv9PSaS3w2?bookingcode=19c1c9c8-c261-44c5-8523-fffcfcdac844&anonymous&ep=mcard Best, I.name: http://I.name Anvil support team ; Hi name, I set --cpus-per-task=0 that the sbatch man page says removes the per-task memory limit and from scontrol I can see that it now seems to use the whole node memory for my --exclusive job. I've run the job on another SLURM cluster and it hasn't crashed so far, but that cluster also has more memory than the Anvil nodes so it's not clear if the memory issue is really fixed. Closing this ticket for now. Pariksheet ; Sorry I meant --mem-per-cpu=0 ;",pnanda@access-ci.org,Pariksheet Nanda,Ibrahem Alshybani,Purdue University,Anvil,7,19,40,2024,2024-09-30
ATS-9503,Invalid account error/partition when running jobs on Anvil,2024-07-24,2024-10-31,"Raising ticket on behalf of Dr. Sabina Maskey. Issue reported via personal email follows: My students are not able to run the simulations. When they submit jobs, they get invalid account error/partition. I am able to use the same script file to submit jobs. I am currently collaborating on project Bio230137. ; \\*\\*PRIVATE NOTE\\*\\* Further note from PI (have also asked them for the location of the job submission script). Here is the list of the students: (None of them can run simulations) Ramez Hassenen Sara Salameh Saniya Vaish Hansa Tonguc name Kadir Mahee name ; \\*\\*PRIVATE NOTE\\*\\* job submission script attached. ^gpu\\_submit (1).sh] ; Hi Sabina, Thanks for reaching outhttps://atlas-trk.prd.msg.ss-inf.net/q/w5cTJ6wC9cbJBVt5UQ7DLA~~/AAAAAQA~/RgRohOyLPlcLYXRsYXNzaWFudXNCCmagi2eiZgRyU3NSFXNhYmluYS5tYXNrZXlAYnN1LmVkdVgEAAAAAA~~ Regards, name ; Hello name, Sorry for the late response, another student was able to submit the job. It seems NAMD and GPU are not scalable. Same simulation done with AMBER run faster. Thanks, Sabina ---- ; Hi Sabina, Can we have a virtual meeting to discuss about the GPU performance? You can let me know the email address of your students, then we can schedule a Zoom meeting on this. Let me know. Regards, name ; Hello name, Yes, we can schedule a zoom meeting to discuss the GPU performance. I am available. Mondays and Fridays 11:00 am-2:30 pm. As for my students, it might be hard scheduling the time, as their high school started, and availability is limited to weekends for one of them. Another is currently is attending ACS conference. Please let me know time, I will be happy to discuss the GPU performance. Thanks, Sabina ---- ; \\*\\*PRIVATE NOTE\\*\\* change status ; Hi Sabina, I will send your a ZOOM link later for our discussion on Monday. Can you share an example which I can test before our meeting? You can let me know the directory, I can copy the files for my tests on Anvil. Probably I can find something before our meeting. Regards, name ; Hi Sabina, Thanks for the patience on this topic and sorry for the delay. I am wondering if you still use NAMD or Amber on Anvil. I remember last time we spoke, you mentioned the GPU NAMD is much slower comparing to Amber on Anvil. Is it still the case or you transferred to Amber. I want to check with you if you still see issues for NAMD performance. If so, I will find time to work on this in the next few weeks. Please let me know. Thank you! Regards, name ; Hello! Since we did not hear from you, we are considering this ticket as resolved for now. However, if you still require assistance with this issue, please reply within the next 7 days and we will keep the ticket open. After that period, please feel free to reach out to us and create a new ticket at any time. Regards, name ;",rkalyana@access-ci.org,Rajesh Kalyanam,Nannan Shan,,Anvil,25,72,30,2024,2024-07-22
ATS-11332,"Request to be added to the VASP license list due to an error preventing the use of VASP on Anvil, with error details attached.",2024-10-12,2024-10-24,"Hello, I encountered an error while trying to use VASP on Anvil, and I've attached a screenshot of the issue to this ticket. Both versions of VASP—5.4.4.pl2 and 6.3.0—did not work for me. Could you please add me to the VASP license list to resolve this issue? Thank you for your assistance. Best regards, name, I have verified your VASP license and added you to the correct groups to be able to use VASP5 and VASP6. It may take some time for the changes to propagate through the system, but you should be able to use them by tomorrow. Let me know if you have any additional questions. Thanks, name, It's been some time since I've heard from you. It seems as though we have resolved your problem of not being able to access VASP on Anvil. If you're still encountering problems, please respond to this ticket within 7 days to reopen the ticket. Otherwise, you will need to open a new ticket. Thanks, name ;",aorvatimovaffagh@access-ci.org,Amir Orvati Movaffagh,Michael Carlson,Purdue University,Anvil,4,9,41,2024,2024-10-07
ATS-11338,Deletion of home directory,2024-10-13,2024-10-24,"Hello, By mistakenly I deleted contents of my home directory with the command rm -rf /home/x-vsharma6/ Is there any way to reverse this. Thank you. ; Vivek, The easiest way to recover these files would be to browse the snapshots using the 'flost' command. The details of 'flost' can be found here: https://www.rcac.purdue.edu/knowledge/anvil/storage/recover/flost Basically, you specify where the files you deleted were, for example 'flost -w /home'. Then you enter the date that you deleted the files and it will search for a snapshot from around that time. Let me know if you have any additional questions. Thanks, name ; Vivek, It's been some time since I've heard from you, so I'm assuming that this issue has been resolved. As such, I'm going to close out this ticket. If you're still encountering issues, please respond to this ticket within 7 days. Otherwise you will need to open a new ticket. Thanks, name ;",vsharma6@access-ci.org,Vivek Sharma,Michael Carlson,Purdue University,Anvil,3,9,41,2024,2024-10-07
ATS-11622,Extention of file number/disk size quota,2024-10-23,2024-10-24,"Hi Anvil team, my current quota on file number and disk amount will end next week. But my project is not finished yet. I'm wondering if it's possible to extend for another six months? Thanks, Wenliang ; Hi Wenliang, Thanks for reaching RCAC. we need the approve of your PI to extend your quota. Could you please let us know the information as the attached picture and have you PI approve it? Best, name ; Hi Joe, I'm asking for a extra disk quota extension on Anvil as the project is not finished yet. Could you approve this? Hi name, Thanks for the reply. Please find the information below: # User Name: x-wangwl # Project ID: x-mcb130189 # Directory: /anvil/scratch/x-wangwl # Old quota: 100T/10M # New quota: 500T/20M Thanks, Wenliang \\* \\*From:\\*\\* name \\*Reply-To:\\* """" \\*Date:\\* Wednesday, October 23, 2024 at 11:47 AM \\*To:\\* Wenliang name \\*Subject:\\* ATS-11622 Extention of file number/disk size quota —-—-—-— Reply above this line. name commented: Hi Wenliang, Thanks for reaching RCAC. we need the approve of your PI to extend your quota. Could you please let us know the information as the attached picture and have you PI approve it? Best, name View request: https://urldefense.com/v3/\\_\\_https:/access-ci.atlassian.net/servicedesk/customer/portal/2/ATS-11622?token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ0Z3QiOiJhbm9ueW1vdXMtbGluayIsInFzaCI6ImFhNmVkMDFhNDNmMmQ5NmRjZGIzMzRjMzk0YjI2MjVlYzk3YWUzNGQ0ZDU4MzE5NjQ2Y2NkNmI2YjdlYjFiZWMiLCJpc3MiOiJzZXJ2aWNlZGVzay1qd3QtdG9rZW4taXNzdWVyIiwiY29udGV4dCI6eyJ1c2VyIjoiMTI5MjYiLCJpc3N1ZSI6IkFUUy0xMTYyMiJ9LCJleHAiOjE3MzIxMjg0NDUsImlhdCI6MTcyOTcwOTI0NX0.mnP4bSKE98kf0mV4kwYN97f9iCdEgN7Luf8SWArVBIE&sda\\_source=notification-email\\_\\_; ; Thank you. I will submit your request to the deployment team. They will address your extension. Let us know if you need further help. Best, name ;",wangwl@access-ci.org,Wenliang Wang,Xiao Liu,Purdue University,Anvil,5,2,43,2024,2024-10-21
ATS-11675,Extended work hours for jobs,2024-10-24,2024-10-25,"Hi, I am working on Anvil and I am trying to run phonon jobs using VASP software. However, those jobs need more than 96 hours on 1 node to finish. There is no possibility to continue the job after it finishes and using more than 1 node does not affect the speed of the job, actually, it even crashes on using more than one node. Please, advise. I would need to use Anvil for more than 96 hrs. I think 240 hrs would be good to finish the jobs. Thank you, Basant ; Hello! I see you submitted a duplicate issue. I'll reply to the other ticket. Thanks, name ;",belshoky@access-ci.org,Basant,Sean Lee,Purdue University,Anvil,2,2,43,2024,2024-10-21
ATS-10637,I can not run the MACS2  for ANVIL ,2024-09-12,2024-10-28,"I always recieve this error when I try to run Macs2 for peak calling. Using Jupiter notebook - ANVIL open on demand #use bash module load biocontainers module load macs2/2.2.7.1 data\\_path=/anvil/scratch/x-mcontrerasza/ATACseq/UCD12/data/align out\\_path=/anvil/scratch/x-mcontrerasza/ATACseq/UCD12/data/macs2 macs2 callpeak -t $data\\_path/12-2a-1\\_S7\\_deduped\\_SORT.bam -f BAM -g hs -n S7\\_peaks --outdir $out\\_path User guides for each biocontainer module can be found in https://www.rcac.purdue.edu/knowledge/biocontainers Traceback (most recent call last): File ""/usr/local/bin/macs2"", line 653, in main() File ""/usr/local/bin/macs2"", line 49, in main from MACS2.callpeak\\_cmd import run File ""/usr/local/lib/python3.9/site-packages/MACS2/callpeak\\_cmd.py"", line 23, in from MACS2.OptValidator import opt\\_validate File ""/usr/local/lib/python3.9/site-packages/MACS2/OptValidator.py"", line 20, in from MACS2.IO.Parser import BEDParser, ELANDResultParser, ELANDMultiParser, \ File ""\\_\\_init\\_\\_.pxd"", line 206, in init MACS2.IO.Parser ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject ; Hi name, Thanks for reaching out Regards, name ; Hello! Since we did not hear from you, we are considering this ticket as resolved for now. However, if you still require assistance with this issue, please reply within the next 7 days and we will keep the ticket open. After that period, please feel free to reach out to us and create a new ticket at any time. Regards, name ;",mcontreraszarate@access-ci.org,Maria J Contreras-Zárate,Nannan Shan,Purdue University,Anvil,4,33,37,2024,2024-09-09
ATS-11519,Jobs are not running,2024-10-18,2024-10-31,"I have submitted 20 jobs using gpu partitions, but all jobs are pending for 4 days. I dont know why these jobs are not running. Could you please tell me why my jobs are not running? ; Mehedi, Last week, some of the GPU nodes were down. This caused a pileup of jobs awaiting resources. These nodes have now been fixed and once the anvil maintenance is done, the jobs should go through the GPUs much quicker. The GPU nodes are in demand, so a long wait time is to be expected with so many people using them. You can also try using the command 'jobinfo' (followed by a jobid) to see why the job is currently pending. E.g. you could do 'jobinfo 8042304' and right now, under 'State' it says: 'PENDING (ReqNodeNotAvail, Reserved for maintenance)', which makes sense because there's an Anvil maintenance happening right now. If it says '(priority)' that means that there are other jobs that have been waiting longer for resources and they will get resources before your job(s). If it says something else, we can discuss what that means. Let me know if you have any other questions. Thanks, name ; Mehedi, Since I've not heard from you in a while, I'm going to tentatively mark this ticket as resolved. If that's not the case and you're still encountering problems, please respond to this ticket within 7 days to reopen it. Otherwise, you will need to submit a new ticket. Thanks, name ;",mhasan1@access-ci.org,MD MEHEDI HASAN,Michael Carlson,Purdue University,Anvil,3,10,42,2024,2024-10-14
ATS-11632,Interactive jobs on Anvil,2024-10-23,2024-10-28,"Hi there-- I have been using interactive queues on Anvil to develop my code and debug my simulation setup. I did it this morning. I tried to get one today, and I get a very alarming error that says that doesn't work any more, and then my job got stuck waiting waiting. The error message says: If you need an interactive parallel capability, please contact your site support team and ask them to consider enabling LaunchParameters=use\\_interactive\\_step I very much need interactive capability again, please restore the configuration. The full warning message is as follows: ======================================================================== This Slurm installation v.24.05.3 is affected by default behavior change introduced in version 20.11 (see https://slurm.schedmd.com/faq.html#prompt). sinteractive will start an interactive job now. Serial or multi-threaded processes inside this job will run as expected, but any calls to 'srun' or 'mpirun' will hang (see above link for explanations). If you need an interactive parallel capability, please contact your site support team and ask them to consider enabling LaunchParameters=use\\_interactive\\_step in Slurm configuration. ======================================================================== Thank you very much d. name Collins Professor, Department of Physics Florida State University On Oct 24, 2024, at 2:43 PM, name <[: mailto: wrote: ; Okay, I will mark this ticket as resolved for now. Let us know if you need further help. Best, name ;",dcollins@access-ci.org,David Collins,Xiao Liu,Purdue University,Anvil,5,4,43,2024,2024-10-21
ATS-11643,My issue for submitting new job,2024-10-23,2024-11-01,"Hello, I hope this note finds you well. After completing the maintenance of Anvil cluster, I could not submit any jobs and I have the attached error. I would be thankful if you could resolve this issue. Best regards, Javad Omidi ; ^slurm-8142850.out ^slurm-8144455.out ; Hi Javad, Thank you for reaching out. Could you please share the JobID for which you received this error? Additionally, a bit more elaboration on your workflow would help us better understand the issue. Best, name K ; Hello name, Thank you very much for your reply. This is not for a specific job, all my submitted jobs with various models have the same error and cannot be started. I have not had this situation before and I am not sure if my storage is a problem or any other limitations. Before the Anvil maintenance on Oct 21, everything was well but after that I could not submit a job. My job can be submitted but after a few minutes and before running, it will be cancelled. I am not sure if I did provide you with enough information or not, but if you need more elaboration, please let me know. Appreciate your help. Javad Omidi ; Hi Javad, Thank you for your reply. I am sorry for the inconvenience. There is currently an issue with Anvil, and the nodes in the shared partition are in a drained state. Our engineers are looking into this issue, and I will keep you updated. Best, name K ; Hi Javad, Thank you for your patience. The issue seem to be fixed. Please try again and let me know if you still have an issue, Best, name K ; Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name K ;",jomidi@access-ci.org,Javad Omidi,Haniye Kashgarani,Purdue University,Anvil,7,8,43,2024,2024-10-21
ATS-11674,Jobs getting too long to submit and giving error,2024-10-24,2024-11-01,"There is too much lag time in submitting the job and sometimes the following error is coming: sbatch: error: Batch job submission failed: Socket timed out on send/recv name ; Hi Apurva, Which system are you trying to submit the jobs to? Thanks, name ; Hi name, I am submitting my jobs on the Anvil cluster. Thanks, Apurva ; Hello! We are aware of the issue, and our engineers are working on the issue. The load on Anvil has been reduced, so you should start to see better performance. Our engineers are working on restoring Anvil to full capacity. Thanks, name ; Hello! I will be marking this ticket as resolved as performance has been mostly restored. If you have any issues in the future, please send in another ticket. Thanks, name ;",abhardwaj@access-ci.org,Apurva Bhardwaj,Sean Lee,Purdue University,Anvil,5,7,43,2024,2024-10-21
ATS-11676,Extended work hours for jobs,2024-10-24,2024-10-28,"Hi, I am trying to run a phonon job using VASP software on Anvil. However, the job does not finish after 96 hours on 1 node. there is no possibility to continue the job after time out and using more than 1 node did not affect the speed, actually, some times it causes crashing to the job. Please, advice, I need the job to run for 240 hrs using one node. Thank you, Basant ; Hello! We should be able to do that for you. Do you happen to have an estimate of when you would no longer need an exception to the time limit rule, or would you need it for the rest of your Anvil allocation? Thanks, name ; Thank you so much. I will need this exception for a month only. Thank you, Basant ; Thank you so much. I will need this exception for a month only. Thank you, Basant ; Thank you so much. I will need this exception for a month only. Thank you, Basant ;",belshoky@access-ci.org,Basant Elshoky,Sean Lee,Purdue University,Anvil,5,3,43,2024,2024-10-21
ATS-11685,sbatch on anvil not working,2024-10-25,2024-10-29,"Hi there-- I'm getting the following errors when I try to submit a batch job to the Anvil computer: %> sbatch Anvil2.sbatch sbatch: error: Batch job submission failed: Socket timed out on send/recv name It does actually submit the job, but does not return the job id when it completes. ; Hello d. name Collins Professor, Department of Physics Florida State University On Oct 25, 2024, at 3:09 PM, name : mailto: wrote: ;",dcollins@access-ci.org,David Collins,Sean Lee,Purdue University,Anvil,6,3,43,2024,2024-10-21
ATS-11690,Job submission not working,2024-10-25,2024-10-29,"Hello. I currently am receiving an error when I try to submit jobs on Anvil: ""sbatch: error: Batch job submission failed: Socket timed out on send/recv name."" This came after some jobs that did submit and appeared to be running didn't produce any outputs yesterday. For reference, I was running the same code and with the same submission script (time, number of nodes/cores, etc.) as I have before, which typically begins outputting files fairly quickly. However, the runs yesterday seemed to stall when reading the initial condition file and didn't output anything. I'm not sure if that and the submission error I quoted above are related. ; Hello! It appears there is an ongoing issue with Anvil. Our engineers are looking into it. I'll let you know if there are any updates. Thanks, name ; Hello! It appears that the issues with Anvil have fixed. Thanks, name ;",jsullivan1@access-ci.org,James Sullivan,Sean Lee,Purdue University,Anvil,3,3,43,2024,2024-10-21
ATS-11702, sbatch error when trying to use scRNAseq RStudio on Anvil on demand dashboard,2024-10-25,2024-10-31,"I have been trying to use the scRNAseq RStudio on Anvil on demand dashboard. I just used it sucessfully yesterday so I don't believe I'm doing anything out of the ordinary. Please see error in attachment. thank you ; Hello! I apologize for the inconvenience. Anvil's job scheduler has been slightly faulty of late. However, if you just refresh the page and try again it should work properly. Thanks, name ; Thank you for getting back to me. It does seem like it's working better now but just for your information, it is still doing it randomly. the ticket can be closed since for the most part it's working - thanks! ---- ;",rgarza@access-ci.org,Renee Garza,Sean Lee,Purdue University,Anvil,4,5,43,2024,2024-10-21
ATS-11792,AnvilGPT Access Request,2024-10-29,2024-11-01,"Good afternoon, I would like to sign up for the AnvilGPT platform. We are currently investigating the usage of LLMs for our hydrological modelling workflows, where using a natural language, we may be able to streamline workflow execution for users who are less knowledgable in terms of name work. Let me know if further information is needed. Cheers, name ; Hi name, Could you provide the information for these three questions? # ACCESS Allocation number. # What modality you plan to use (API, UI, or both) Thanks, name ; Hi name, Thank you so much for the follow up. Here are the answers: # Our project number is EES240082, # I would like to test both interfaces (API and UI). Cheers, name ; Hi name, Your request has been approved, and you have been given access to both the UI and the API for AnvilGPT. Feel free to start exploring the service and let us know if you have any questions or need further assistance. ;",kkeshavarz@access-ci.org,Kasra Keshavarz,Ashish Malik,Purdue University,Anvil,4,4,44,2024,2024-10-28
ATS-11809,CIS230253  AnvilGPT Access Request,2024-10-30,2024-11-01,"Dear Sir/Madam, We kindly request for Anvil GPT access. Thank you! Best, Yueying ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id ~accountid:id this is AnvilGPT access request ; Hi Yueying, Could you provide the information for these three questions? # ACCESS Allocation number. # How do you plan to use AnvilGPT # What modality you plan to use (API, UI, or both) Thanks, name ; Hi Yueying, Your request has been approved, and you have been given access to both the UI and the API for AnvilGPT. Feel free to start exploring the service and let us know if you have any questions or need further assistance. Please reply to the question on what's the intended use. Thank you. ;",yli19,Yueying LI,Ashish Malik,Purdue University,Anvil,4,3,44,2024,2024-10-28
ATS-11814,Permissions on my home directory,2024-10-30,2024-10-31,"The permissions on my Anvil home directory were accidentally changed to remove me and now I don't have access to my home directory. I was trying to give read access to my group on my allocation, and instead I have somehow been removed all together. ; Hi name, We just repeated your error. we will look into your problem and get back to you as soon as we have the answer. BTW, did you change .bash\\_profile recently, or any idea what you could recall recently that changed something? Best, name ; Hi, I used chmod to try to provide read permissions to others in my group. I miss typed and think I used chmod 400 on accident when I meant to use a different number Thank you name On Oct 30, 2024, at 4:17 PM, name wrote: —-—-—-— Reply above this line. name commented: Hi name, We just repeated your error. we will look into your problem and get back to you as soon as we have the answer. BTW, did you change .bash\\_profile recently, or any idea what you could recall recently that changed something? Best, name View request: https://urldefense.com/v3/\\_\\_https://access-ci.atlassian.net/servicedesk/customer/portal/2/ATS-11814?token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ0Z3QiOiJhbm9ueW1vdXMtbGluayIsInFzaCI6IjE2MDhmZDU1NGI4M2M5NzNjNDY3Mzc5MGViODEyOGQzYmI5NzRkODJhYzU5Nzg1MDE0YzEzNjBkMGZiN2U1YWEiLCJpc3MiOiJzZXJ2aWNlZGVzay1qd3QtdG9rZW4taXNzdWVyIiwiY29udGV4dCI6eyJ1c2VyIjoiMTc1MzQiLCJpc3N1ZSI6IkFUUy0xMTgxNCJ9LCJleHAiOjE3MzI3Mzg2NzAsImlhdCI6MTczMDMxOTQ3MH0.SV8qoQnFyJJ-ba5C2487j2RM3B5jM7XJqwZZH85ZNbc&sda\\_source=notification-email\\_\\_;! name ;",rthatcher@access-ci.org,Rachel Thatcher,Xiao Liu,Purdue University,Anvil,6,2,44,2024,2024-10-28
ATS-11825,AnvilGPT Access Request,2024-10-30,2024-11-01,"AnvilGPT Access Request ; Hi, Thanks for reaching RCAC. Could you provide the information for these three questions? # ACCESS Allocation number. # How to intend to use AnvilGPT # What modality you plan to use (API, UI, or both) Thanks, name ; ACCESS allocation CDA080011 Test inferencing for application Plan to test both API & UI Thanks, name ; Hi name, Your request has been approved, and you have been given access to both the UI and the API for AnvilGPT. Feel free to start exploring the service and let us know if you have any questions or need further assistance. ;",gazula@access-ci.org,Vikram Gazula,Ashish Malik,Purdue University,Anvil,4,3,44,2024,2024-10-28
ATS-11847,AnvilGPT Access Request,2024-10-31,2024-11-01,"I need to use a LLM for my project, to generate unit tests, and provide rationale for my unit tests. I intended to do this with LLama, however because I do not have sudo access I wasn't able to install it inside Anvil resources (which I also have an open ticket for). So, I wanted to try to use AnvilGPT for this, if it is easier to setup. ; Hi Betim, In order for us to approve your request could you please provide your ACCESS allocation number? Thanks If this is not the case, can you please give me some instructions on how to find my ACCESS allocation number? Kind regards, Betim ; Hi Betim, Your request has been approved, and you have been given access to both the UI and the API for AnvilGPT. Feel free to start exploring the service and let us know if you have any questions or need further assistance. ;",bsherifi,Betim Sherifi,Ashish Malik,Purdue University,Anvil,4,2,44,2024,2024-10-28
ATS-11919,AnvilGPT Access Request,2024-11-04,2024-11-06,"I have exchanged my ACCESS credits to Anvil GPU SUs, but still, the account activation is pending. Could you please take a look? Thanks! ; Hi name, You should now have access to AnvilGPT. Let me know if you can log in. Best Regards, Eli name Purdue IT https://service.purdue.edu ; Hi name, I have noticed you have logged in into AnvilGPT recently. This ticket will now be closed. Feel free to contact us if you have further questions. Best Regards, Eli name Purdue IT https://service.purdue.edu ;",happidence1@access-ci.org,Zhenhua He,Elian Rieza,,Anvil,2,3,45,2024,2024-11-04
ATS-11703,AnvilGPT Access Request,2024-10-25,2024-11-05,"As part of our MS program in Human Language Technology (HLT), the University of Arizona offers a course on advanced statistical natural language processing. Among other topics, the course explores large language models (LLMs). Students are encouraged to make use open source/open weight LLMs throughout the course, but unfortunately few students have access to the computational resources needed to efficiently run many of these models. To better support students in the course, we are requesting access to AnvilGPT ACCESS Allocation numbers: CIS240778, CIS230353, and CIS240778 ; Hi Gustave, Can you tell us more about the class size? ; Hi, name. There are currently 36 students enrolled and the last day of the course will be 12/10/2024. ; Hi Gus, Can you please share your email (University of Arizona)? I would like to schedule a meeting with you, me and my colleague to better understand your needs and provide more information. ; Sure. My University of Arizona email address is . Thanks, —Gus On Nov 1, 2024 at 12:13 PM -0700, name , wrote: \\* \\* \\*External Email\\* ---- ; Hi Gus, Your request has been approved, and you have been given access to both the UI and the API for AnvilGPT. Feel free to start exploring the service and let us know if you have any questions or need further assistance. ;",ghp@access-ci.org,Gustave Hahn-Powell,Ashish Malik,,Anvil,6,8,43,2024,2024-10-21
ATS-11750,Anvil submission not starting,2024-10-28,2024-11-07,"Hi, Anvil jobs on our allocation have not been starting. They stay in the queue for weeks at a time. All the best, Yamilée ; Hi Yamilée, Sorry for the delayed response. To help us investigate, could you please share the IDs of your jobs in question? Thanks, name ; Hi name, I am attaching a picture of what mybalance looks like. name balance for both allocations that do have credit appear as n/a. ; Hi Yamilée, Thanks for sharing the report of {{mybalance}}. Allocations {{dmr180108}} and {{eve210010}} should have SUs available in balance. Something might have got messed up. Apologies for the inconveniences it caused. I'm escalating your ticket to our expert for closer investigations. Thanks, name ; Hi name, Allocations dmr180108 and eve210010 should be active and have SUs remaining. Could you please help investigate why they show up with n/a in balance? Thanks, name ; Hi Yamilée, I'm writing to let you know that allocations {{dmr180108}} and {{eve210010}} should have the correct amounts of SUs in balance for now and you should be able to run with those allocations. $ mybalance x-yamilee Allocation Type name Limit name Usage name Usage name Balance Account (account) (user) ============= ==== ========== ========== ========== ========== dmr180108 CPU 100000.0 0.1 0.0 99999.9 dmr180108-gpu GPU 3060.0 0.0 0.0 3060.0 eve210010 CPU 140000.0 0.0 0.0 140000.0 I'm tentatively marking this ticket resolved at this point. Please feel free to contact us again if you have any further questions or need any help. Thanks, name ;",yamilee@access-ci.org,Marie Natalie Yamilee Morency,Ruyi Li,,Anvil,6,9,44,2024,2024-10-28
ATS-11884,Possibility of adding `jq` to the modules/base programs,2024-11-01,2024-11-06,"Good afternoon, I hope this message finds you well. We extensively use the JSON file format as part of our various workflows, and {{jq}} is a powerful command line program that enables parsing this specific file format. I was wondering if it would be possible to add {{jq}} to the list of modules, or even have it as a base program for the cluster's OS? It is a name light program to install and run. I notice that you have use Spack as the software to develop your module system. If such an installation is feasible and I can help with the process, let me know, as I have used the similar program for module development on our local cluster. I am looking forward to your recommendations. Cheers, name ; Hello, I hope you are doing well. Thank you for reaching out to RC Support with your question! We are actively working on addressing the issue. Rest assured, we will provide you with a response as soon as possible. Best regards, name RC Support ; Hello, Thank you for your patience! We plan to install {{jq}} on Anvil, and it's already in our pipeline. We'll notify you as soon as it's available. Best regards, name RC Support ;",kkeshavarz@access-ci.org,Kasra Keshavarz,Ankitha Mallekav,Purdue University,Anvil,3,4,44,2024,2024-10-28
ATS-11907,VASP access for Anvil,2024-11-04,2024-11-04,"Hello, my advisor asked for me to be added to the VASP users group as he holds licensces for my group to use on our HPC, I was wondering if the Anvil staff needs anything or can grant access to me soon? Thanks, Mayur ; Hi Mayur, Could I ask what email was used to sign up for the VASP license for your research group? Eli name Purdue IT https://service.purdue.edu ; I believe he used : mailto: ; Hi Mayur, Your account should now have access to vasp5. Could you confirm if this is the case? Eli name Purdue IT https://service.purdue.edu: https://service.purdue.edu/ ; yes! thanks for your prompt assistance. Mayur ; access to VASP granted ;",msingh4@access-ci.org,Mayur Singh,Elian Rieza,Purdue University,Anvil,6,1,45,2024,2024-11-04
ATS-11956,unable to find vasp installation with module spider,2024-11-05,2024-11-06,"hello I was recently added to the vasp users group for anvil I cannot seem to load or find the vasp installations to run a simulation. I tried finding them with module spider and they are still invisible. Regards, Mayur ; I can see the vasp modules now with module spider, it still says that I do not have the license. ; Hi Mayur: Apologies for the inconvenience, we have changed the group to {{vasp5}} and have removed the original group x-mch240072-vasp5 which might have caused this issue. This group update will likely take time to propagate, but please let us know if there are still any additional issues if this continues to persist. Thanks, name ; VASP works on anvil now ;",msingh4@access-ci.org,Mayur Singh,Ansen Shia,Purdue University,Anvil,5,2,45,2024,2024-11-04
ATS-6730,Running job not writing output on Anvil,2024-03-08,2024-11-22,"Hi, My job (jobID: 4552008), right now in Running status, stopped writing output after a few hours of running. This happened withmy previous job too but I cancelled it and resubmitted and it happened again. Please check the issue asap so that I can cancel the job as my alocation is being used. Thanks, name ; Hi, Thank you for contacting us and sorry for the response delay. Just to double check before we can further debug the issue. When you said ""stopped writing output"", did you refer to the SLURM output file {{open-pore-restrained-crystal.%j.%N.out}} or the model outputs (or both)? And which folder did this job try to write out such outputs? Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi name, The path of the folder is ""/home/x-mkumari/scratch/data/REMD/open-pore-restrained-along-crystal-str"" and the job stopped writing in all the output files (Csgg\\_f56q\\_200mV\\_1.\\*). ---- ; Hi, Sorry that your previous ticket fell out of our loop. Do you still need help with this issue at the moment? name ; Hi name, Thanks! It is no longer needed. name ;",x-mkumari,Monika Kumari,Guangzhen Jin,Purdue University,Anvil,4,186,10,2024,2024-03-04
ATS-11354,vasp not running on compute nodes,2024-10-14,2024-11-12,"Hi there, I recently met with name about my issues running vasp on certain compute nodes. I thought we resolved the issue but it has come back. We are experiencing similar issues again with running our own compiled version of VASP. I have traced it down to the number of cores we run: `mpirun -n XX vasp\\_std` If I run with the full node (128 cpus), I get the following errors Assertion failed in file ../../src/mpid/ch4/src/intel/ch4\\_shm\\_coll.c at line 1477: node\\_info->numa\\_num <= ((MPIDI\\_SHMGR\\_SYNCPAGE\\_SIZE / MPIDI\\_SHMGR\\_FLAG\\_SPACE) - 1) Assertion failed in file ../../src/mpid/ch4/src/intel/ch4\\_shm\\_coll.c at line 1477: node\\_info->numa\\_num <= ((MPIDI\\_SHMGR\\_SYNCPAGE\\_SIZE / MPIDI\\_SHMGR\\_FLAG\\_SPACE) - 1) Assertion failed in file ../../src/mpid/ch4/src/intel/ch4\\_shm\\_coll.c at line 1477: node\\_info->numa\\_num <= ((MPIDI\\_SHMGR\\_SYNCPAGE\\_SIZE / MPIDI\\_SHMGR\\_FLAG\\_SPACE) - 1) /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(MPL\\_backtrace\\_show+0x34) 0x14ad3c232154] /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(MPIR\\_Assert\\_fail+0x21) 0x14ad3b839271 /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(+0x23c7db) 0x14ad3b96b7db /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(+0x2d41a4) 0x14ad3ba031a4 /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(MPI\\_Barrier+0x26e) 0x14ad3b846b8e /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/libmpifort.so.12(pmpi\\_barrier+0xc) 0x14ad3c81c73c /home/x-coses/bin/vasp\\_std() 0x419ef0 /home/x-coses/bin/vasp\\_std( Abort(1) on node 42: Internal error /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(MPL\\_backtrace\\_show+0x34) 0x14e73f460154 /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(MPIR\\_Assert\\_fail+0x21) 0x14e73ea67271 /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(+0x23c7db) 0x14e73eb997db /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(+0x2d41a4) 0x14e73ec311a4 /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(MPI\\_Barrier+0x26e) 0x14e73ea74b8e /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/libmpifort.so.12(pmpi\\_barrier+0xc) 0x14e73fa4a73c /home/x-coses/bin/vasp\\_std() 0x419ef0 /home/x-coses/bin/vasp\\_std( Abort(1) on node 76: Internal error /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(MPL\\_backtrace\\_show+0x34) 0x14e22fed2154 /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(MPIR\\_Assert\\_fail+0x21) 0x14e22f4d9271 /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(+0x23c7db) 0x14e22f60b7db /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(+0x2d41a4) 0x14e22f6a31a4 /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(MPI\\_Barrier+0x26e) 0x14e22f4e6b8e /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/libmpifort.so.12(pmpi\\_barrier+0xc) 0x14e2304bc73c /home/x-coses/bin/vasp\\_std() 0x419ef0 /home/x-coses/bin/vasp\\_std( Abort(1) on node 110: Internal error However, vasp does run with 2, 12, and 24 cpus, while still requesting the full node (128 cpus). This is independent of standard, shared, or wholenode queues. The same issues occur on all. These issues do NOT occur if I run the job interactively. 128 cpus is not a problem. Do you have a solution? Alternatively, we can try running the machine compiled vasp. I am happy to provide my license. Thanks, name ; Hi , I'm sorry that you still facing issues with your vasp. I'll be happy to schedule a meeting with you to look up the issue. You can use the following link to book a meeting with me: https://outlook.office.com/bookwithme/user//meetingtype/g9TnSUWvwEaFuMv9PSaS3w2?bookingcode=634bc3d2-535d-46b4-91f7-ca373590f273&anonymous&ep=mlink Best, I.name RCAC support team ; Perfect, booked, thanks name. See you tomorrow. C -- Dr. name Oses Assistant Professor Department of Materials Science and Engineering Johns Hopkins University [entropy4energy.ai: https://entropy4energy.ai/ ; Hi name, I have provided you (just after the meeting) with some environments that you can use inside your slurm job script but got them deleted now as I thought the following might be better. Try this: export I\\_MPI\\_BARRIER=off if no sucess: try add this: I\\_MPI\\_FABRICS =shm:tcp Best, I.name: http://I.name Anvil support team ; Thanks name, will try asap. Best regards, name -- Dr. name Oses Assistant Professor Department of Materials Science and Engineering Johns Hopkins University entropy4energy.ai: https://entropy4energy.ai/ ; Hi name, Could you please try including the following in your job script and give it: {{srun -n $SLURM\\_NTASKS --mpi=pmi2}} Best, I.name: http://I.name RCAC support team ; Hi name, will try and will report back. Thanks, name -- Dr. name Oses Assistant Professor Department of Materials Science and Engineering Johns Hopkins University entropy4energy.ai: https://entropy4energy.ai/ ; name tried these solutions; they did not work. Trying the others you suggested. name -- Dr. name Oses Assistant Professor Department of Materials Science and Engineering Johns Hopkins University entropy4energy.ai: https://entropy4energy.ai/ ; Hi name, Tried these as well. Did not work. name -- Dr. name Oses Assistant Professor Department of Materials Science and Engineering Johns Hopkins University entropy4energy.ai: https://entropy4energy.ai/ ; Hi name, Tried this solution as well. Did not work. Same errors. Hope this information is useful. Best regards, name -- Dr. name Oses Assistant Professor Department of Materials Science and Engineering Johns Hopkins University entropy4energy.ai: https://entropy4energy.ai/ ; Dear name, Would we be able to schedule a meeting with name to address these issues? Best regards, name -- Dr. name Oses Assistant Professor Department of Materials Science and Engineering Johns Hopkins University entropy4energy.ai: https://entropy4energy.ai/ ; Hi name, Actually, I'm working closely with name on this issue but first we need to have the email associated with your vasp license. We'll try to validate that email with our vasp portal and see if we can add you to use our centrally managed license. If this step also fails, name said she'll meet with you to dig into the source of the issue. In meantime, I'll be waiting for the email of your vasp license. Best, I.name: http://I.name Anvil support team ; Dr. name, I need to get the email address associated with your vasp license to validate against out vasp lic posrtal. If this step is not working, we can schedule a meeting with you and name. This step was coordinated with name. Best, I.name: http://I.name RCAC support ; Hi Dr. name, I'm just following up as I haven't heard back from you. We really want to help and get you into our centrally managed vasp. If you got everything working, let us know so that we can get this ticket updated. Best, I.name: http://I.name Anvil support team ; Hi name, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, I.name Anvil support team ;",coses@access-ci.org,Corey Oses,Ibrahem Alshybani,Purdue University,Anvil,15,22,42,2024,2024-10-14
ATS-11444,install GALBA as a module?,2024-10-16,2024-11-11,"Greetings, I hope you are doing well today. I wanted to check in and see if it would be possible to install the GALBA pipeline (available here: GitHub - Gaius-Augustus/GALBA: GALBA is a pipeline for fully automated prediction of protein coding gene structures with AUGUSTUS in novel eukaryotic genomes for the scenario where high quality proteins from one or several closely related species are available.: https://github.com/Gaius-Augustus/GALBA) as a module on Anvil. GALBA can be used to annotate genomes for which RNA-seq data is not available and seems like it would be useful to many scientists working with non-model species. Many thanks, name ; Hi name, You could install it as a module by following this https://www.rcac.purdue.edu/training/software-installation: https://www.rcac.purdue.edu/training/software-installation|smart-link Let us know when you need more help. Best, name ;",jdoyle@access-ci.org,Jacqueline Doyle,Xiao Liu,Purdue University,Anvil,2,19,42,2024,2024-10-14
ATS-11603,Shared node not available on Anvil Cluster ,2024-10-22,2024-11-11,"Hi, I am trying to run my batch jobs on the Anvil cluster using a shared node but it is unavailable. Will you please assist me in this regard. ; thanks for reaching RCAC. would you please share the sbatch file that you submit the job? I can take a look and try if I can repeat the error. Best, name ; Since I have not heard back from you in a while, I'm tentatively marking this ticket resolved at this point. If you still need assistance, please feel free to reply to this email within the next 7 days to reopen the ticket. After that, you could email us at to create a new ticket at any time. ;",jkhan1@access-ci.org,Javed Khan,Xiao Liu,Purdue University,Anvil,3,15,43,2024,2024-10-21
ATS-11661,Shared nodes are drained,2024-10-24,2024-11-14,"The state of most shared nodes is draining, and the submitted jobs are waiting. Are you fixing it? ; Hi Wubin, Our team are now working on resolving it. We'll keep you updated as we get updates in this regard. Best, I.name Anvil support team ; Hi ~, How is it going, I am still facing this issue. Lots of shared nodes are down The state is either ""Kill task failed"" or ""drianing"". -- Wubin name ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id:id-dbd6-4c49-8fbc-94be97295108 ~accountid:id ~accountid:id I checked the status of shared queue nodes yesterday and found 8 nodes draining and 5 nodes are down. However, I don't know if that can still an issue for his case. Any ideas? ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id:id-b323-4e64-bddb-a3d659c0125c It seems Slurm is still a bit wonky (see the output of the command {{pbsnodes-ln}}). Engineers are trying to track down the issue and identify a fix (see discussions in the #ops channel). ; like name reacted to your message: ; Hi Wubin, Please let me know if the issue has been resolved or you still need help ! Best, I.name Anvil support team ; Hi Wubin name, Are you still facing the same issue! It's been there before but our team should have resolved it now. Best, I.name Anvil support team ; NO. It was fixed. -- Wubin name ; \\*\\*PRIVATE NOTE\\*\\* the issue has been resolved. ;",wding2@access-ci.org,Wubin Ding,Ibrahem Alshybani,Purdue University,Anvil,10,16,43,2024,2024-10-21
ATS-11824,"Getting ""Socket timed out on send/recv operation"" errors for scancel and sbatch",2024-10-30,2024-11-11,"I've noticed that even modest numbers of sbatch or jobs are resulting in the error noted in the title. In the case of sbatch, in particular, it is particularly problematic because it appears that at least sometimes, the sbatch works but I do not get the jobID back, only the error. Any suggestions? ; Hi name, Thanks for reaching RCAC. It seems the node is heavily running which might leads to the cancel error, We'll look into the problem. To confirm, your canceled jobs in the screenshot did canceled. Best, name ; Thanks, name. Let me know if you have any additional questions. name ;",seandavi@access-ci.org,Sean Davis,Xiao Liu,Purdue University,Anvil,4,9,44,2024,2024-10-28
ATS-11830,Technical question about submitting batch jobs on anvil,2024-10-30,2024-11-12,"\\*Time sensitive\\* This is a question about the batch job submission limits on Purdue Anvil. I have had success with name on Anvil questions before, if this can get to him that would be great. The issue is related to the cap on the number of files in the $SCRATCH directory on Anvil, which seems to be set at 1000k. I had not realized this was the cap until I began running a lot of jobs simultaneously, and I traced this to be the issue that was killing some of my jobs once the limit of 1000k files was reached in that directory (my script performs calculations and creates hundreds of thousands of files per batch submission. I believe I am well below any other limits as far as running jobs at scale, so this is a big bottleneck at the moment, as I am trying to run through the rest of our allocation before it expires in just under two days. I was wondering if there is any way to lift this file cap temporarily, maybe by doubling it or tripling it, for a single account's $SCRATCH directory for just a couple days while the jobs are running? If not, is there any other solution that comes to mind that might allow me to make a few more batch submissions and not be limited by this file cap before the allocation deadline? My anvil username is x-mankola Best, Andi ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id the user needs an increase of file limit. should we do that? ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id:id-b323-4e64-bddb-a3d659c0125c I think we may ask for more information about their job/workflow and see if it is possible for them to use an aggregate file format, such as tar, zip or sqlite. If that is not possible, we may consider offering a temporary increase of the file number limit (we will need to know the desired time window and limit, and ask the storage experts to set that up for them). ; like name reacted to your message: ; Hi Andi, I wonder if you can provide more details about your job and workflow. I wonder if you can use any aggregate file formats such as tar/zip etc . If not, we want to know exactly what limit increase you want and the period for having that. Knowing that will allow us to determine the best path to go to. Best, I.name Anvil support team ; Hi Andi, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, I.name Anvil support team ; Hi name, Thanks for the reply. Unfortunately I heard back too late, and our allocation had already expired by that point. I did have a question about the calculations we are currently storing on Anvil, though. Will we have access to these in the future in the project directories they are in now (we have one project directory for the allocation that just expired, and a second one for a project that expired a long time ago which we have been using to store the results of calculations we ran with those allocation), or are they set to be deleted at some point? Best, Andi ;",mankola@access-ci.org,Andi Mankolli,Ibrahem Alshybani,Purdue University,Anvil,7,10,44,2024,2024-10-28
ATS-11838,"Mayur Singh ( x-msingh4), a user of this project need VASP access at ANVIL. We have purchased VASP 5 license and Mayur is an authorized user. Please authorize Mayur to access VASP at ANVIL.",2024-10-31,2024-11-12,"Mayur name ( x-msingh4), a user of this project, needs VASP access at ANVIL. We have purchased VASP 5 license and Mayur is an authorized user. Please authorize Mayur to access VASP at ANVIL. ; Hi , Thank you for contacting Anvil support. Is Mayur's email associated with the vasp license? If yes, can I have that email ? Best, I.name Anvil support team ; \\*\\*PRIVATE NOTE\\*\\* more info about the vasp process can be found here: License · RCAC-Staff/SupportKnowledgeBase Wiki: https://github.rcac.purdue.edu/RCAC-Staff/SupportKnowledgeBase/wiki/License ; Mayur's email is associated with the VASP license my group has. I confirm that Mayur name is an authorized user of VASP. His email registered for VASP is: ---- ; Thanks for confirmation and providing the requested information. I have added him to our managed vasp5 after verifying his email. Please let me know if that is all you need for now. Best, I,name Anvil support team ; Hi Satish, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, I.name Anvil support team ;",skumar@access-ci.org,Satish Kumar,Ibrahem Alshybani,Purdue University,Anvil,6,9,44,2024,2024-10-28
ATS-4610,Multiprog Job Sumission - Output Files,2023-11-25,2024-11-18,"Hi, I'm attempting to submit {{--multi-prog}} job with {{srun}}. The job submits properly but currently the output is all condensed into a single output file. I would like for one of the jobs to output to jet.log, and the other to output to channel.log. Can you please let me know the best way to do this? I have attached the job submission script, the config file, and the single output file. Thanks, name Keeton ; ^myrun.conf] ^slurm-3853812.out ^slurmnek\\_anvil\\_wholenode.sb ; \\*\\*PRIVATE NOTE\\*\\* Anvil Applications: https://access-ci.atlassian.net/jira/people/team/0f5fcf8a-26ef-4d24-a346-4a2ef3a7afda?ref=jira$&src=issue (~accountid:id ~accountid:id ~accountid:id ~accountid:id:id-5a0e-4ef9-9dae-4ff21198071b ~accountid:id ~accountid:id ~accountid:id ~accountid:id ~accountid:id:id-2781-404e-85f3-6f3d3f09f93f ~accountid:id)Hello, We have escalated this ticket to the Applications Team. Please assign to a team member. Anvil Support ; Hi, Thank you for contacting us. We have escalated your request to our application team so they can take a look and get back to you when there is an answer. Please stay tuned. Best regards, name Senior Computational Scientist Purdue Information Technology ; \\*\\*PRIVATE NOTE\\*\\* Hi Anvil Application Team: https://access-ci.atlassian.net/jira/people/team/0f5fcf8a-26ef-4d24-a346-4a2ef3a7afda?ref=jira$&src=issue ([~accountid:id ~accountid:id ~accountid:id:id-bd45-4e12-b7de-6550f017a297 ~accountid:id ~accountid:id:id-5a0e-4ef9-9dae-4ff21198071b ~accountid:id ~accountid:id:id-c12e-4112-bfdf-3503868fdf94 ~accountid:id ~accountid:id ~accountid:id ~accountid:id) This is a test escalation ticket. Hello, We have escalated this ticket to the Applications Team. Please assign to a team member. Anvil Support ; Hi, Sorry that your previous ticket fell out of the loop. Are you still encountering this issue at the moment? name ; No, this issue can be closed. ; Thank you for the update. name ;",bkeeton,Ben Keeton,Guangzhen Jin,Purdue University,Anvil,8,256,47,2023,2023-11-20
ATS-11875,FAIRSHARE and PRIORITY on Anvil,2024-11-01,2024-11-11,"I have questions about the FAIRSHARE and PRIORITY of GPU jobs on Anvil. I just requested an GPU interactive job with only one CORE, one GPU and wall time 1:00:00 on OnDemand, the whole information is shown in the fig with command ""squeue -u x-yzhao7 -l"". Then I type ""sprio -u x-yzhao7 -l"", and get the ""FAIRSHARE=28420"" and ""PRIORITY=38420"" of my job. While ""sprio -p gpu""gets the information of FIARSHARE and PRIORITY about other GPU jobs in the queue. We have the same ""PARTITION=10000"", but their FIARSHARE and PRIORITY are much larger than mine (in fig. screenshot1.jpg, with job ID: 8250335). I know that ""PRIORITY=FAIRSHARE+PARTITION+AGE"", and jobs with higher PRIORITY will run first, and the maximum of the ""AGE"" is ""500"". So, it seems that the maximum PRIORITY of my jobs with the maximum ""AGE=500"" is ""38920"", which is still smaller than other jobs with ""AGE=0"", so my jobs cannot run as long as there are other tasks in the queue. I have tried to apply for GPU jobs with only one CORE, one GPU and wall time from 0:30:00 to 24:00:00, and get the same result of FAIRSHARE and PRIORITY (in fig. screenshot1.jpg, with job ID: 8250335,8250409,8250410,8250411,8250413). So, my question is: What can I do to improve the PARTITION, or could you please improve it so that my jobs can also run smoothly? Best Regards, name, Department of Computational Mathematics, Science and Engineering, Michigan State University ; Hello, I hope you are doing well. Thank you for reaching out to RC Support with your question! We are actively working on addressing the issue. Rest assured, we will provide you with a response as soon as possible. Best regards, name RC Support ; Dear name, Thank you for reaching out with your question regarding the FAIRSHARE and PRIORITY settings for GPU jobs on Anvil. On Anvil, we do not set explicit priorities for jobs in the system; instead, waiting times are determined by resource availability, requested wall time, and the overall demand on the nodes. This means that jobs with higher resource or time requirements may experience longer waiting times, especially when the system is busy with other queued jobs. While we understand that FAIRSHARE and PRIORITY values play a role in determining job scheduling, increasing these values alone may not necessarily result in faster processing. To improve the likelihood of your jobs running sooner, consider requesting shorter wall times or fewer resources per job where feasible, as this may increase your chances of securing available resources when the system is in high demand. If you have any further questions, feel free to reach out. Best regards, name RCAC Support ;",yzhao7@access-ci.org,Yue Zhao,Ankitha Mallekav,Purdue University,Anvil,4,7,44,2024,2024-10-28
ATS-11911,Question regarding reading files from Bell in ANVIL,2024-11-04,2024-11-14,"I have a question. Is there any way to read files from the Bell Cluster in ANVIL? I want to run my script on ANVIL, but my CSV files are located on the Bell Cluster. I would prefer not to move them. i do not want to move files, just read them directly in ANVIL ; Hi Mohammed, Due to the nature of the clusters, you will not be able to do this directly without either moving files or indirectly accessing your files. I will outline the methods that you can do below. \\*1. {{ssh}} into Bell through Anvil\\* In the case you are connected to Anvil through {{ssh}}, it is possible to {{ssh}} into your Bell account while accessing Anvil. You can copy the content of the files in Bell into Anvil using `rsync`. \\*2. Set up Data Depot\\* Another alternative would be keeping your data on a data depot storage that you can mount and use your preferred protocol of choice to mount and access. This is further elaborated on here: https://www.rcac.purdue.edu/knowledge/depot/overview in the RCAC guide. It seems that you are already part of a data depot group, so I believe that this will be the best option for you going forward. I hope this has helped, Please do not be afraid to get back to us as soon as you have completed these and still have trouble accessing your files or if you would want more direct help. Best Regards, Eli name Purdue IT https://service.purdue.edu ; Thank you very much ; Hi name, Glad to hear this. I will close the ticket as of now. Feel free to contact us if you have further issues. Best Regards, Eli name Purdue IT https://service.purdue.edu ; \\*\\*PRIVATE NOTE\\*\\* User was able to access files from Anvil using Data Depot ;",mahmadigharehtoragh@access-ci.org,Mohammad Ahmadi Gharehtoragh,Elian Rieza,Purdue University,Anvil,10,9,45,2024,2024-11-04
ATS-12012,Command Not Found after Loading module,2024-11-07,2024-11-13,"I'm attempting to run IQtree using the Anvil cluster. I'll paste my slurm below, but I keep getting the error that the command is not found even after I load the module that should contain the command. # I'm receiving the following error message: User guides for each biocontainer module can be found in https://www.rcac.purdue.edu/knowledge/biocontainers: https://www.rcac.purdue.edu/knowledge/biocontainers|smart-link User guides for each biocontainer module can be found in https://www.rcac.purdue.edu/knowledge/biocontainers: https://www.rcac.purdue.edu/knowledge/biocontainers|smart-link /var/spool/slurm/job8372048/slurm\\_script: line 15: iqtree: command not found ; Thanks for reaching out! I apologize for the late response. We are looking into your issue and will get back to you shortly. Thanks, name ; Hello! You should still load the module `iqtree` but when running the software you should call it using `iqtree2`. Thanks, name ;",halloway,Hannah Alloway,Sean Lee,Purdue University,Anvil,3,5,45,2024,2024-11-04
ATS-3712,Issues with Anvil and intel compiler,2023-10-13,2024-11-18,"Hello, I am having trouble on Anvil. I have compiled the DFT software Abinit using intel/19.0.5 and related modules; however, at runtime I am encountering an error linked to the intel compiler: ""Assertion failed in file ../../src/mpid/ch4/src/intel/ch4\\_shm\\_coll.c at line 1477: node\\_info->numa\\_num <= ((MPIDI\\_SHMGR\\_SYNCPAGE\\_SIZE / MPIDI\\_SHMGR\\_FLAG\\_SPACE) - 1)"". You can find the input file, the slurm script (rf1.slurm) and the log of the failed run (log-3188426) in the following directory: /anvil/projects/x-phy230169/electro\\_optics/halide\\_perovskites/csgebr3/001 How can I fix the problem? Is there a more recent intel compiler, hdf5 and netcdf packages that I can use at compilation and runtime? Alternatively, is there a recent working version of Abinit (>9.6) compiled on Anvil? Thank you, name Paillard. ; Hi, Thank you for contacting us. It might be related to old version of intel compiler on Anvil. Have you tried running your workflow with {{srun --mpi=pmi2 -n xxx ./mycode}} (xxx means the number of processors you need for this run)? Please let me know how it works for you. If it's still not working, re-compile your application with gcc/openmpi or use containerization might be my suggestion. Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi name, Thank you for your help. Unfortunately, --mpi=pmi2 did not fix it. I will try with gcc and openmpi. Any chance that someone has compiled abinit on Anvil before and has the configure files for it? Thank you, name. ; Hi, Let me escalate your ticket to our application team so they could take a look. Thanks. Best, name ; \\*\\*PRIVATE NOTE\\*\\* Anvil Applications: https://access-ci.atlassian.net/jira/people/team/0f5fcf8a-26ef-4d24-a346-4a2ef3a7afda?ref=jira$&src=issue (~accountid:id ~accountid:id ~accountid:id:id-5a0e-4ef9-9dae-4ff21198071b ~accountid:id ~accountid:id ~accountid:id ~accountid:id ~accountid:id ~accountid:id:id-2781-404e-85f3-6f3d3f09f93f ~accountid:id) Hi team, Please take a look at the issue and see if you could have a solution. Thank you. Best, name ; Hi, Sorry that your previous ticket fell out of our loop. Do you still need help with this issue at the moment? name ; Hi name, Thank you for coming back to me. I do not need help with this anymore. Thank you, name. ; Thank you for the update. name ;",paillard,Charles Paillard,Guangzhen Jin,Purdue University,Anvil,8,287,41,2023,2023-10-09
ATS-8716,Drives not available,2024-06-15,2024-11-22,"Hello, I was working on the Anvil cluster and suddenly got the message that grep: write error: Disk quota exceeded I use the $PROJECTS directory since we are working collaboratively on a project. For this purpose we had obtained approval for increased storage of 50T. I am quite sure that we have not used all that space. I am also not able to do myquota to check and confirm. This is what I see: (miniconda3)\\*x-name@login03\\* \\*~\\* \\*»\\* myquota Type Location Size Limit Use Files Limit Use ============================================================================== home x-name Home directory quotas are currently inaccessible. - - scratch anvil This file system's quotas are currently inaccessible. projects x-mcb130189 This file system's quotas are currently inaccessible. (miniconda3)\\*x-name@login03\\* \\*~\\* \\*»\\* Could you please check and help me get back to the $PROJECTS directory? Since we are at a very critical phase of the projects, if we have indeed used all the allocated quota, I request you to kindly provide an additional 20T in the $PROJECTS partition so that we can complete the project. As soon as we are done on this project we can move out the data to archival storage. Thanks, name. ; Hi name, Thanks for reaching out Regards, name ;",manojh@access-ci.org,Manoj Hariharan,Nannan Shan,Purdue University,Anvil,19,115,24,2024,2024-06-10
ATS-11672,Purdue Anvil Freezing,2024-10-24,2024-11-21,"Hello, Lately when I am using ANVIL it seems to freeze. I am trying to run code and one minute it will run fine and the other it just hangs until it times out. I occasionally get errors such as ""slurmstepd: error: \\*\\*\\* JOB 8090530 STEPD TERMINATED ON a242 AT 2024-10-17T17:59:21 DUE TO JOB NOT ENDING WITH SIGNALS \\*\\*\\*"" in my output files or ""sbatch: error: Batch job submission failed: Socket timed out on send/recv name"" when submitting jobs. I am using WINSPC and PuTTY to connect to Purdue ANVIL, and this has worked in the past. The code I am using has worked on Purdue ANVIL in the past, until recently where it has occasionally had issues with freezing. Is this a known Issue with ANVIL? I don't think the issue is on my end because I am using code that has worked on ANVIL before, and it still usually runs fine. Maybe one day a week my jobs seem to freeze though. Sincerely, name ; Hi name, Thank you for contacting us. We're aware of the issue, and our engineers are actively addressing it. The load on Anvil has been lowered, so you should notice improved performance. Our team is working on getting Anvil back to full capacity. Thank you for your patience. Best, name K ; Hi name, The issue should've been resolved. Could you please check and let me know it you still have an issue? Best, name K ; Hello, I haven't had the issue the past few weeks since about the time I submitted the help request. Sincerely, name ; Thanks for letting me know. I will mark this ticket as resolved now, but feel free to reach out again with any questions or concerns. Best, name K ;",amannion@access-ci.org,Anthony Mannion,Haniye Kashgarani,Purdue University,Anvil,5,21,43,2024,2024-10-21
ATS-11764,Extended work hours for jobs ,2024-10-28,2024-11-20,"Hi, I am trying to run a phonon job using VASP software on Anvil. However, the job does not finish after 96 hours on 1 node. there is no possibility to continue the job after time out and using more than 1 node did not affect the speed, actually, sometimes it causes crashing to the job. I need the job to run for 240 hrs using one node and I will need this exception for one month only. Thank you, Basant ; \\*\\*PRIVATE NOTE\\*\\* Hi, ~accountid:id] Could you please work with this user to figure out a best solution for them? Thanks Regards, name ;",belshoky@access-ci.org,Basant Elshoky,Nannan Shan,Purdue University,Anvil,9,18,44,2024,2024-10-28
ATS-11904,ABAQUS installation on anvil,2024-11-04,2024-11-20,"I attended the support hour last week for Anvil. I need to get Abaqus installed on Anvil to run jobs using an access allocation. I reached out to ECN on information for install. See below for their response. They believe RCAC should have all necessary info to install abaqus on anvil as well as all information for the licensing ---- ""Hey name, Thanks for reaching out. We believe that RCAC already has access to our Abaqus image, and the necessary licensing information for the product. Please reach back out to RCAC, make sure that this information is correct, and let us know what they say. Cheers, name Purdue IT"" ---- ; Hello, Thank you for reaching out to RCAC Support! We're working on your request and will get back to you as soon as we have a solution. Please allow up to one business day for our response. Best regards, name Purdue IT https://service.purdue.edu: https://service.purdue.edu/ ; Hello, Is there any update on my request about installing abaqus on anvil? Thanks, name ; Hi name, Thanks for reaching out! Let me talk to ECN people to see how we deal with your request. We will share the updates later. Thanks for your patience. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Hi name, Please allow me to chime in and assist on this request. We can help the installation under your project space so all group members in that project could use it (looks like you are the PI and only user at the moment). Can you confirm if it's your project {{mch240064}} that requires Abaqus? Another question is which Abaqus version do you want to use. We have had Abaqus 2023 and 2024 installed on different campus clusters but don't have one on Anvil yet. Best regards, name Senior Computational Scientist Purdue Information Technology ; Hello, Yes, that is the correct project number. I currently run Abaqus 2022, and would prefer that if available. If not 2023 is also fine. Thanks, name ; Roger that. I will work on the installation and share updates when it's done. name ; Hi name, I have done a test installation with my account and looks like Abaqus 2023 or older does not support our ""new"" Anvil OS (i.e. Rocky Linux 8) so we might only get Abaqus 2024 installed for you (the installation and test case were smooth for me). Does it sound like a plan for you too? There are some tricks we can do to install previous Abaqus versions but I am not sure about the compatibility for actual simulations. If you would like to go with this plan, would you mind if I temporally add myself into your allocation and finish the installation into your project space? Best, name ; Yes, that sounds good. Please let me know how I can add you to the allocation Thanks, name ; Hi, You don't have to. I can add myself in your allocation (admin privilege : ) ). I just need your permission to do so. Let me try the installation into your project space and update with you when it's done. name ; Hi, The installation is done. I also made a module for your group to allow easy access. In order to use it, you can follow the steps below: module use /anvil/projects/x-mch240064/etc/modules module load abaqus # You may check the availability with : which abaqus The license server has been setup so as long as you have been added to ECN's license pool (if you are not sure, please contact ECN), you can start using abaqus. Let me know how it works for you. Note: if you want to open the Abaqus CAE GUI, try {{abaqus can -mesa}}. Best, name ; Hi, Since we haven't heard back from you for a while, I will temporally resolve the ticket. Feel free to let me know if you need more assistance. name ;",gallaway@access-ci.org,Glynn Gallaway,Guangzhen Jin,Purdue University,Anvil,12,13,45,2024,2024-11-04
ATS-12183,Access to multiple highmem nodes on Anvil,2024-11-15,2024-11-18,"Hello Anvil support. I am running very large and highly memory-intensive jobs, which run best on the highmem partition of Anvil. I have successfully used the ""Wide-Highmem"" partition for previous works - mch220029 and PHY230172. I am curious if I could get access to this partition for my most recent allocation allotment (MCH240084). This is an extension of the project MCH220029, which only has 10% of the allocation left. It would be very helpful to receive access to multiple highmem nodes so that I can continue my work seamlessly when the previous project allocation runs out. I am currently using 10 of these nodes and see that 19 still remain idle, so I believe my access will not interfere with other works significantly. Thank you in advance for your consideration. ; Hello, I hope you are doing well. Thank you for reaching out to RC Support with your question! We are actively working on addressing the issue. Rest assured, we will provide you with a response as soon as possible. Best regards, name RC Support ; Hi, Thank you for sharing the details. We have just applied the {{wide-highmem}} QOS to your new allocation {{mch240084}}. You can use the this QOS by adding option {{-q wide-highmem}} to your job submission (similar to what you have done with your other allocations). Please give it a try and see how it works. Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi name, Thank you for getting back to me so quickly. I very much appreciate your help with this. I am getting a QOSMaxJobsPerUserLimit. What is the node-limit for this? I am trying to run a job on 8 nodes (1024 cpus). Thanks in advance. Brendan ---- ; Hi Brendan, The current limitation on {{wide-highemem}} QOS is 16 nodes max per user, which means you cannot use more than 16 highmem nodes with all your jobs. And currently all your running jobs based on this QOS have used 15 nodes so that's the reason you cannot start another 3-node job on {{wide-highmem}}. You can check the QOS limit with the following command: $ sacctmgr show qos wide-highmem format=Name%20,MaxTRES%20,MaxWall,MaxTRESPU%20,MaxJobsPU,MaxSubmitPU Name MaxTRES MaxWall MaxTRESPU MaxJobsPU MaxSubmitPU ; wide-highmem cpu=2048,node=16 2-00:00:00 cpu=2048,node=16 16 32 Hope it helps. name ; Thanks for the update, name. That makes sense. I appreciate your help with this. ---- ;",bchristensen,Brendan Christensen,Guangzhen Jin,Purdue University,Anvil,6,2,46,2024,2024-11-11
ATS-12191,AnvilGPT Access Request,2024-11-15,2024-11-22,"Dear Anvil team, I'd like to request access to AnvilGPT under allocation CIE170004 (Globus Staff). Not planning anything large - mostly just for experimentation. Most likely just UI-based stuff for now, maybe some API tests at later on. Thanks (and looking forward to seeing some of you at SC) 🙂 ; name, Thank you for reaching out to RCAC for support. I believe that I have granted you access to AnvilGPT, but please test it out and let me know if it worked. Thanks, name ; Excellent, thanks! Confirming that I can login to AnvilGPT successfully. name ;",pentium@access-ci.org,Lev Gorenstein,Michael Carlson,Purdue University,Anvil,3,6,46,2024,2024-11-11
ATS-10097,Inquiries about requesting more storage ,2024-08-23,2024-12-04,"Hello, I have been using ACCESS credits to use the Purdue ANVIL GPU to analyze super-resolution Cryo-EM data for my PhD project. I am having trouble transferring my latest dataset to my ANVIL project folder (x-bio240106). When I try to transfer the files using Globus, it gives back the error ""storage quota exceeded"". I wanted to ask if I can request more storage using ACCESS credits for ANVIL at Purdue, or do I have to transfer my data to scratch first and then transfer it to my project folder? Thank you for your time, -name ; Hi name, Thanks for reaching out | \\* \\*name\\*\\* Cancer Chemical name PhD Candidate Binning Lab \\* \\*name Cancer Center\\*\\* | | 12902 Magnolia Drive, Tampa, FL 33612 : \\* \\*tel:\\*\\* : \\* \\*email:\\*\\*\\* \\*: mailto: | ; Hi name, I think we might need to schedule a meeting to talk about your data. We can have a ZOOM meeting next week. Does 10:30am-11am EST on Friday (9/6/2024) works for you? I will be traveling on Wed and Thurs, the earliest time to have a meeting is Friday. Let me know. Regards, name ; Hi name, I apologize for the late reply. I am available to meet this Friday at the time you proposed. Does this still work for you? Thank you for your time, -name ; Hi name, Is it possible for us to meet this week over zoom to discuss my data? Thank you, -name ---- ; Hi name, I missed you message last time. Let's schedule our meeting to talk about your data. How about Friday morning (9/27/2024), say sometime between 10am-12pm EST? Regards, name ; Hi name, Thank you for your email. Tomorrow between 10-12pm sounds good to me. Will you be sending the meeting invite? Thank you for your time, -name ---- ; Hi name, I send the link to this email : mailto: If you did not receive it, here is the Zoom link, https://purdue-edu.zoom.us/j/93895887627?pwd=0OeAgWPXYL5Ju8fwJ9bdW8nnNpEQbz.1&from=addon: https://purdue-edu.zoom.us/j/93895887627?pwd=0OeAgWPXYL5Ju8fwJ9bdW8nnNpEQbz.1&from=addon|smart-link Regards, name ; Hi name, I received it. Thank you for the link. -name ---- ; Hi name, I know we had a meeting on Sept 27, but I forgot what issues we were trying to address, sorry I lost my notes about our meeting. Can you remind me what issue we should work on? Regards, name ; Hi name, No worries. Our meeting was about me not being able to process my cryo-em dataset on scratch. I had two datasets, and the first one I was able to run and process it on my project folder. My second dataset was bigger than my first one, and that one I stored on the scratch folder. I was able to import the micrographs to cryosparc, but I was not able to do the CTF correction. I have not been able to run it again, I will try to run it again next week because I am currently evacuating due to a hurricane coming directly to Tampa. So, I will get back to you regarding any errors I get next week. Thank you for your time, -name ---- ; Hi name, Did you get a chance to try other dataset? Regards, name ; Hi name, I have tried to analyze my data, but now I have a new problem: when I request cluster access for CryoSPARC, the request goes through but I am not able to sign in to CryoSPARC. The screen goes name for about 2 minutes and I get the message ""No VNC"". Then, my session on anvil suddenly stops. Do you know what could be happening? Thank you, -name ---- ; Hi name, Can you let me know how you request to run CryoSPARC on Anvil? Are you using shared partition? We had issues with shared partition in the past weeks, and I am not sure if that would affect your job. Please share more details. Regards, name ; Hi name, Here are the settings I have always used to log onto the cryosparc VPN: I usually request between 4 and 8 hours depending on how much time I have at work to analyze data. After about two minutes, I get this message: And my session goes from this: To this: -name\\*\\* Cancer Chemical name PhD Candidate Binning Lab \\* \\*name Cancer Center\\*\\* | | 12902 Magnolia Drive, Tampa, FL 33612 : \\* \\*tel:\\*\\* : \\* \\*email:\\*\\*\\* \\*|mailto: | ; Hi name, I wanted to follow up on my previous email. We're you able to check on my problem accessing CryoSPARC? Thank you for your time, -name ---- ; Hi name, I think I can reproduce the error you mentioned. Can you try the following and see if this works for you? Rename the cryosparc\\_hpc directory (to like cryosparc\\_hpc.bak1) and restart the program Regards, name ; Hello, It has been a while since last time we hear from you. This ticket would be tentatively marked as resolved. Replying to this ticket within 7 days will re-open this ticket. After 7 days, feel free to submit a new ticket to [https://support.access-ci.org/user/login?destination=/open-a-ticket: https://support.access-ci.org/user/login?destination=/open-a-ticket if you have questions in the future. Thanks! Regards, name ;",anicolaci@access-ci.org,Angelo Nicolaci,Nannan Shan,Purdue University,Anvil,19,74,34,2024,2024-08-19
ATS-11172,AnvilGPT Access Request,2024-10-06,2024-11-26,"Dear Sir or Madam, I am reaching out to request access to both the UI and API of AnvilGPT, as I intend to utilize LLMs for coding and data analysis. I am particularly interested in comparing the performance of these open-source models with ChatGPT. Currently, I am unsure where to find my allocation number, and my ACCESS account is still pending activation (Please see the attachment below). My ACCESS account is linked to my Purdue email (: mailto:). Please let me know if any additional information is required. Thank you for your assistance. Best regards, Yiming name ; Dear Anvil User, Thank you for contacting the user support team. I'll look into the status of your request and get back to you as soon as possible. Best, I.name Anvil support team ; \\*\\*PRIVATE NOTE\\*\\* Checking with name and others on the policy here. Since they are a Purdue student with no prior ACCESS allocations, we may want to have them wait for PurdueGPT instead. ; Hi name, Just wanted to inform you that your AnvilGPT access request will remain pending until our official launch in the coming few weeks, at which point we can consider approval. We appreciate your patience and will notify you once access is available. Best, I.name: http://I.name Anvil support team ; No problem. Please feel free to notify me when you are ready to go ---- \\*发件人:\\* name \\*发送时间:\\* Thursday, October 10, 2024 11:44:17 AM \\*收件人:\\* name, Yiming \\*主题:\\* ATS-11172 AnvilGPT Access Request | | You don't often get email from . Learn why this is important: https://aka.ms/LearnAboutSenderIdentification | | |---- \\*External Email\\*: Use caution with attachments, links, or sharing data ---- | ; Hi , I was informed that we have PurdueGPT ready for beta users so you can login using this link: https://purduegpt.rcac.purdue.edu/: https://purduegpt.rcac.purdue.edu/ accessing that will create a pending access request which we can review and approve. Best, I.name: http://I.name RCAC support team ; \\*\\*PRIVATE NOTE\\*\\* [~accountid:id:id-248a-43b5-a841-66499835a741 should this be marked as resolved after informing the user to sign in into PurdueGPT instead ? ;",yim996@access-ci.org,Yiming Liu,Ashish Malik,Purdue University,Anvil,8,37,40,2024,2024-09-30
ATS-11482,cannot install Dedalus on Anvil,2024-10-17,2024-11-25,"Hi, I need to install the Dedalus python package for my research project. Installation instructions are located here: https://dedalus-project.readthedocs.io/en/latest/pages/installation.html. I've tried installing using the pre-compiled MPI and FFTW libraries (I've tried using gcc-compiled and intel-compiled separately). I have also submitted a post to the Dedalus Users google group, which I can link once it gets through their approval system. Attached are two installation scripts with associated outputs (one pair is for gcc, the other is intel-compiled). I'm getting the same issue in both cases. I also get the same issue when fresh installing FFTW as opposed to using the pre-compiled libraries. Specifics about which libraries and which modules are being implemented can be found in the installation scripts. Please let me know if more details would be useful. Thank you in advance. ; ^gcc\\_output.txt] ^install\\_gcc.sh ^install\\_intel.sh ^intel\\_output.txt ; Hello, I hope you are doing well. Thank you for reaching out to RC Support with your question! We are actively working on addressing the issue. Rest assured, we will provide you with a response as soon as possible. Sincerely, name ; Hi, I can confirm it's not working properly with openmpi/4.1.6 with the same error on Anvil. It should be related to the incompatibility between mpi library and dedalus. I tried the building with gcc/11.2 + openmpi/3.1.6 and it was successfully installed: # Inside of install\\_gcc.sh change the following lines: ... module load gcc/11.2.0 module load openmpi/3.1.6 ... # It will install successfully: ... Successfully built dedalus Installing collected packages: pytz, py-cpuinfo, tzdata, tblib, py, pluggy, numexpr, iniconfig, coverage, pytest, pandas, xarray, pytest-parallel, pytest-cov, pytest-benchmark, dedalus Successfully installed coverage-7.6.3 dedalus-3.0.3 iniconfig-2.0.0 numexpr-2.10.1 pandas-2.2.3 pluggy-1.5.0 py-1.11.0 py-cpuinfo-9.0.0 pytest-8.3.3 pytest-benchmark-4.0.0 pytest-cov-5.0.0 pytest-parallel-0.1.1 pytz-2024.2 tblib-3.0.0 tzdata-2024.2 xarray-2024.9.0 Disabled threading by default in the environment To make your changes take effect please reactivate your environment To make your changes take effect please reactivate your environment Installation complete in conda environment 'dedalus3' ... Give it another try and let me know how it works for you. Best regards, name Senior Computational Scientist Purdue Information Technology ; Hi name, Thank you for your quick reply. I also received a successful installation message after submitting the original ticket. Now I am encountering an issue which is limiting the software's functionality. Specifically, I am unable to output data when running Dedalus on >1 node. Since you have a working installation, would it be possible to check if you have this issue as well? If it's preferable, I can also open a separate ticket for this issue. Thank you, -name O. ; Hi, I can do the test. Could you share your script to run the workflow (including job submission and Dedalus commands) so I can follow the same process? name ; Hi name, I get the following output when trying to import dedalus during an interactive job. Could you investigate? Here's a snippet from my bash terminal including the commands I ran. Like I said, this is only happening during interactive jobs (dedalus3) x-loconnor@a865:~/adjop/mri$ python3 Python 3.12.7 : packaged by conda-forge | (main, Oct 4 2024, 16:05:46) GCC 13.3.0 on linux Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import dedalus.public as d3 python3: error: plugin\\_load\\_from\\_file: dlopen(/usr/lib64/slurm/auth\\_munge.so): /usr/lib64/slurm/auth\\_munge.so: undefined symbol: slurm\\_conf python3: error: Couldn't load specified plugin name for auth/munge: Dlopen of plugin file failed python3: error: cannot create auth context for auth/munge python3: fatal: failed to initialize auth plugin (dedalus3) x-loconnor@a865:~/adjop/mri$ ; Hi, Looks like it's a reproducible error from my end as well. I will need to discuss this issue internally and see what we can do to fix it. Will keep you updated. name ; I think running the command {{export LD\\_PRELOAD=/usr/lib64/libslurm.so}} (in your terminal) before you actually enter Python IDE and run the python command will solve this issue but I was running into another error ""libmpi.so.12: cannot open shared object file"". Will try to investigate more and let you know. name ; Hi name, Thank you for your attention to detail. I was receiving the same secondary error (""libmpi.so.12: cannot open shared object file"".) intermittently. I was worried that these unfamiliar errors would be difficult to discover/reproduce. This is phenomenal. Please let me know if you can resolve the problem (not urgent). I will also relay your solutions to the Dedalus User group: https://groups.google.com/g/dedalus-users so that future users will have more resources. Thanks again, -name O. ; Hi name, I've done some tests and finally make it work (at least the {{import}} succeeded without any errors). I assume the crux is the dedalus version for which I used 3.0.2. For your reference, I have exported my conda env so you can test with {{conda env create -f dedalus3\\_env.yml}}. Give it a try and see how it works for you. name [^dedalus3\\_env.yml ; Hi, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name ;",loconnor@access-ci.org,Liam O'Connor,Guangzhen Jin,Purdue University,Anvil,12,28,42,2024,2024-10-14
ATS-11893,My issue for submitting new job,2024-11-02,2024-12-04,"Hello, I cannot submit any job in Anvil cluster, please help me. I asked you for that last week and your changed the status to resolved but I cannot submit my simulations. Enclosed is what I can see as an ERROR in run file. Appreciate your help. Best, Javad ; ^slurm-8269659.out] ; Javad, Thank you for reaching out to RCAC for support. Did you change anything else about the jobs (e.g. input conditions, versions of softwares) since they were last running to completion? It looks like the script that is running builds MFIX and then fails on something. Could you attach the job script that you are submitting the jobs with so I can try to narrow down what is going on? I am also curious how you originally installed MFIX, it looks like it's through anaconda? If you could describe that process to me as well, it could be helpful. Thanks, name ; Hello, Thank you for your reply. No, I have not changed anything, all are the same. Exactly after maintenance of Anvil, this issue showed itself and I could not submit any more jobs. Enclosed are what I have in a folder of run, when I submit my job. Yes, this software is installed on Anaconda, I think, I am not very familiar with its process but if you need I can provide more information from the MFiX website. Appreciate your help. Best, Javad ^usr1\\_des.f \\_(2 kB)\\_ ^mfix.slurm \\_(0.4 kB)\\_ ^sbtrans.mfx \\_(14 kB)\\_ ; Javad, One error that I see is that './configure' cannot be found in the working directory of the script. In previous jobs, was that error still there? Does MFiX have any output before it crashes or does it crash on the first iteration? Actually, in looking at the error, it looks like it's crashing when MPI is being initialized. Additionally, something I can do is poke around the code on your account. I wouldn't change anything, just looking at code, so all your data would be safe. But you may see some extra commands appear in your bash history. I just want your permission before I do any digging in your account. Thanks, name ; Hello, Thanks for your email. No, I have not changed my setup in my new cases and I have not seen any similar errors before in my previous cases. Of course, you can try some cases in my account to see what is happening there. Appreciate your help. Best, Javad ; Javad, I did some digging and it looks like MFiX doesn't use the './configure' process to change the build flags. I don't think that line is needed. I looked in the code to see where it was failing and it seems to be failing right during the MPI initialization. Are you planning on using multiple nodes for your simulations, or will you be sticking to a single node? If you'll stick to a single node, you could try using 'SMP' instead of 'DMP' (SMP stands for 'shared memory parallelism' and DMP is 'distributed memory parallelism'). It sets up the memory in a different way and that might fix the error that you see. I am also talking with my coworkers to see if anything might have changed during the maintenance that would cause this issue. Thank you for your patience, name ; Hello, Appreciate your support. I do think that one node is good. This is really weird because I was doing my submission before the maintenance but after that this happened. I can wait for you to discuss this with your coworkers as well. Thanks. Best, Javad ; Javad, Something else you can try is to load in a different version of openMPI. It shouldn't change anything, since I think that MFiX ships with its own version of MPI, but it doesn't hurt to try. To do this, simply replace the line that says: module load openmpi with a line that says: module load openmpi/4.0.6 Again, it shouldn't change anything, but we can always try it. I am also still discussing with my coworkers about other possible solutions. Thanks, name ; Hello, I have tried that but I have the same errors, as you can find in enclosed file. Best, Javad ^slurm-8357503.out \\_(58 kB)\\_ ; Javad, I am working on reproducing your error on my end, but it may take some time. In the mean time, there are a couple additional things you can try: 1.) Re-create your MFiX environment and see if a re-download can fix your problems. 2.) Use pip instead of conda to install MFiX. 3.) Build MFiX from source (I'm not sure this one is viable, because I can't see what the available downloads for MFiX are yet). I'll let you know when I am able to reproduce your error myself. Thanks, name ; Hello, Thank you for your suggestions, I will test them. Please let me know if you could fix it. Thanks, Javad ; Javad, I was able to reproduce your error with the same version of MFiX. I was able to make MFiX run, however. I ran it in SMP mode (instead of DMP) and it seems to be working fine. I'm not sure what the implications for performance it has, so you'll have to test that out and let me know. To implement SMP, simply change the last two lines of your submit script to be: build\\_mfixsolver FCFLAGS=""-march=znver3"" --smp --batch env OMP\\_NUM\\_THREADS=12 ./mfixsolver -f sbtrans.mfx Where the number 12 should match with the number cores you are running with. Let me know if this works for you. Thanks, name ; Hi name, Appreciate your efforts to fix it. Yes, that is working now but this is really slow. How can I fix this issue? Thanks, Javad ; Javad, I'm glad it's working now. Could you describe a little about how you know that it's going slowly (just so I know what to look for in my testing)? I'm still working to fix the original issue using MPI. Thanks, name ; Hello, Thank you for your response. You know, this is based on my experience, for instance for one of my basic cases in TFM modeling, which is a fluid model, after 12 hours I had my run completed but now after 24 hours the results are less than 10% of completion. So, I can see that this is very slow. Best, Javad ; Hi name This issue is really urgent to me. and I need to do my research as soon as possible. Do you think it may be helpful that I want to close this ticket and open another ticket with urgent priority? Appreciate it. Best, Javad ; Javad, I think I have found a workaround to get your work going again. Essentially, we're going to turn off FPEs during MPI\\_INIT, and then turn them back on, so that if your code has an FPE it will still be caught. It does involve some file editing, but it is relatively minor. I could tell you what lines of code you need to add and where, or we could meet and go through it together. Which would you prefer? I am available now until 5 PM EST today, but tomorrow I will be helping to deliver a training all day and then I'll be gone to a conference for a week. Thanks, name ; Javad, The fix is as follows: In the file ~/.conda/envs/2024.02-py311/mfix-22.2.2/share/mfix/src/model/mfix.f under where it says 'PROGRAM MFIX', and under all the 'use' statements (around line 276) add the line: use ieee\\_exceptions Around line 282, add the lines: logical :: saved\\_fpe\\_mode(size(ieee\\_all)) call ieee\\_set\\_halting\\_mode(ieee\\_overflow, .true.) call ieee\\_set\\_halting\\_mode(ieee\\_invalid, .true.) call ieee\\_set\\_halting\\_mode(ieee\\_divide\\_by\\_zero, .true.) It should be after a line that says: INTEGER :: II Then, on line 301, right before the lines that say: -\\*- f90 -\\*- there is difficulties opening it. OPEN(UNIT=UNIT\\_DAT, FILE=mfix\\_dat\\_filename, STATUS='OLD', IOSTAT=IOS, & FORM=""UNFORMATTED"", ACCESS=""STREAM"", ACTION=""READ"") IF(IOS /= 0) THEN IF(myPE == PE\\_IO) WRITE (\\*,1001) mfix\\_dat\\_FILENAME ERROR\\_STOP 1001 FORMAT(2/,1X,70('\\*')/' From: RUN\\_MFIX',/' Error 1001: ', & 'Unable to open input data file: ',A/,'Aborting.',/1x,70('\\*'),2/) ENDIF READ(UNIT\\_DAT) MFIX\\_DAT CLOSE(UNIT\\_DAT) ! Read input data, check data, do computations for IC and BC locations ! and flows, and set geometry parameters such as X, X\\_E, DToDX, etc. CALL GET\\_DATA(MFIX\\_DAT) IF (CHECK\\_EXIT\\_FLAG()) RETURN ! Initialize the simulation CALL INITIALIZE(MFIX\\_DAT) IF (CHECK\\_EXIT\\_FLAG()) RETURN ! Time march loop. dt\\_loop: DO WHILE (TIME + 0.1\\*DT < TSTOP) CALL WAIT\\_WHILE\\_PAUSED IF(DES\\_CONTINUUM\\_COUPLED .OR. .NOT.DISCRETE\\_ELEMENT) THEN call run\\_fluid ENDIF IF (DEM\\_SOLIDS) THEN call run\\_dem IF(.NOT.DES\\_CONTINUUM\\_COUPLED) EXIT IF (CHECK\\_EXIT\\_FLAG()) THEN CALL TIME\\_STEP\\_END EXIT ENDIF ENDIF IF (PIC\\_SOLIDS) THEN call run\\_pic IF(.NOT.DES\\_CONTINUUM\\_COUPLED) EXIT IF (CHECK\\_EXIT\\_FLAG()) THEN CALL TIME\\_STEP\\_END EXIT ENDIF ENDIF ! Terminate MFIX normally before batch queue terminates. CALL CHECK\\_BATCH\\_QUEUE\\_END(EXIT\\_FLAG) CALL TIME\\_STEP\\_END ! Transient or steady state simulation IF (STEADY\\_STATE .OR. ADJUST\\_PARTITION) EXIT IF (CHECK\\_EXIT\\_FLAG()) EXIT ENDDO dt\\_loop CALL FINALIZE IF(.NOT.ADJUST\\_PARTITION) EXIT ENDDO CONTAINS subroutine run\\_fluid STARTTIME = WALL\\_TIME() CALL TIME\\_STEP\\_INIT(MFIX\\_DAT) DO CALL ITERATE\\_INIT DO WHILE (NIT] = ..."" print \\*, "" -h,--help: display this help message"" print \\*, "" -p,--print-flags: print flags solver was & &built with, such as: dmp mkl python smp"" print \\*, "" -f,--file : & &specify filename of input file (Default: mfix.dat)"" print \\*, "" =: specify keyword on & &command line, overrides values in input desk (mfix.dat or .mfx)"" print \\*, "" -l,--log : log message level, one of {ERROR, WARNING, STATUS, INFO}, default INFO"" print \\*, "" -v,--version: print version info"" END SUBROUTINE PRINT\\_USAGE END PROGRAM MFIX Here is the whole file that I modified (note that it has no empty lines, which is different from your file, just a quirk of the way I copied it). I am unsure of how to attach it other than the way I attached it before. The lines that I added are 232, 237-240, 250-251, and 254. These lines will not match up exactly with your file (because of the no empty lines problem), so be sure to match the context/surroundings of the lines. I hope this helps. Thanks, name ; Hello name Thanks for that and happy Thanksgiving. I did that but I have two separate results: in one of my simulations that is working but for another, I have this error: \\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\* From: mfix.f Error 1000: Input data file does not exist: rb\\_1.mfx Aborting. \\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\* \\*\\*\\* The MPI\\_Comm\\_f2c() function was called before MPI\\_INIT was invoked. \\*\\*\\* This is disallowed by the MPI standard. \\*\\*\\* Your MPI job will now abort. a048.anvil.rcac.purdue.edu:4124591: http://a048.anvil.rcac.purdue.edu:4124591 Local abort before MPI\\_INIT completed completed successfully, but am not able to aggregate error messages, and not able to guarantee that all other processes were killed! ; Primary job terminated normally, but 1 process returned a non-zero exit code. Per user-direction, the job has been aborted. ; mpirun detected that one or more processes exited with non-zero status, thus causing the job to be terminated. The first process to do so was: Process name: [62423,1,2 Exit code: 1 ; Appreciate your help. Best, Javad ; Javad, I spoke with my coworkers and they came up with a separate solution, that I tested and it seems to work. This one is much simpler and doesn't require you to modify your source code. Simply add the line: export UCX\\_PROTO\\_ENABLE=n to your submit script after activating the MFiX environment, but before you call 'build\\_mfixsolver'. As for the new error that you are experiencing, could you attach a picture of what it looks like? It appears as though maybe you are missing an input data file that it is expecting? Thanks, name ; Hello, Thank you for your email. Sorry, but I cannot understand exactly where I should put this line: Actually, I cannot understand what you said:id\\*"" \\*to your submit script after activating the MFiX environment, but before you call 'build\\_mfixsolver'.\\*""\\* Appreciate it. Best, Javad ; Javad, Your mfix.slurm file looks like this (as you sent it to me): #!/bin/bash #SBATCH --account=chm230034 #SBATCH --job-name=oneLSB #SBATCH --nodes=1 #SBATCH --ntasks-per-node=12 #SBATCH -n 12 #SBATCH --time=71:59:59 module load anaconda/2021.05-py38 module load openmpi module load gcc source activate mfix-22.2.2 ./configure FC=gcc FCFLAGS=""-march=znver3"" build\\_mfixsolver --dmp --batch mpirun -n 12 --map-by core ./mfixsolver -f sbtrans.mfx NODESI=3 NODESJ=4 NODESK=1 In this case, you would add the line: export UCX\\_PROTO\\_ENABLE=n between lines 14 and 15. So, it should look like this: #!/bin/bash #SBATCH --account=chm230034 #SBATCH --job-name=oneLSB #SBATCH --nodes=1 #SBATCH --ntasks-per-node=12 #SBATCH -n 12 #SBATCH --time=71:59:59 module load anaconda/2021.05-py38 module load openmpi module load gcc source activate mfix-22.2.2 export UCX\\_PROTO\\_ENABLE=n build\\_mfixsolver --dmp --batch mpirun -n 12 --map-by core ./mfixsolver -f sbtrans.mfx NODESI=3 NODESJ=4 NODESK=1 Does this help? If you do this, there is no need to disable FPEs during MPI\\_INIT (but it will work alongside it if you have already made that change). Thanks, name ; Thank you, name; that is working. I really appreciate your help and your solutions. Best, Javad ; Javad, I am glad that things are now working for you. I apologize for the time that it took to arrive to a solution. I am going to mark your two tickets as resolved. But if you run into problems with submission, please respond to this ticket within 7 days to reopen it. Otherwise, you will need to submit a new ticket. Thanks, name ;",jomidi@access-ci.org,Javad Omidi,Michael Carlson,Purdue University,Anvil,29,23,44,2024,2024-10-28
ATS-12172,My issue for submitting new job,2024-11-15,2024-12-04,"Hello, I hope this message finds you well. Following the maintenance performed on Anvil approximately 15 days ago, I have been unable to submit any jobs to the cluster. Despite my setup and configurations remaining unchanged, I am encountering the attached error, which appears to be unknown. I have previously reached out for assistance here and I opened two tickets, and while two name support teams have worked on this issue for over two weeks, the problem remains unresolved. This situation is significantly impacting my PhD research, and I urgently require access to the cluster. I would greatly appreciate your support in resolving this matter as soon as possible. Thank you for your time and assistance. Best regards, Javad Omidi ; ^slurm-8124331.out] ; Hello, I hope you are doing well. Thank you for reaching out to RC Support with your question! We are actively working on addressing the issue. Rest assured, we will provide you with a response as soon as possible. Best regards, name RC Support ; Hello, Thank you for your kind consideration and your email. Could you please let me know any progress you had on resolving the issue? Appreciate your help. Best, Javad Omidi ; \\*\\*PRIVATE NOTE\\*\\* It's a duplicate issue with their previous ticket ATS-11893: https://access-ci.atlassian.net/browse/ATS-11893 (handled by name). ; Hello, We apologize for the delayed response. Your ticket is being escalated and assigned to the right expert. We will get back to you as soon as possible. Best, name RC Support ; Javad, Are you able to meet with me regarding this issue next week on Monday (12/2/24) at 11 AM EST? I think that meeting then would be the quickest way to move forward with resolving your MPI\\_INIT problems. Thanks, name ; Hi, I sent you a separate email regarding the modifications you sent me before. Could you please reply to that? I am very confused, and I need your assistance. My projects have been delayed during the last month. Best, Javad ; Javad, I am resolving this ticket as mentioned in the other ticket. Thanks, name ;",jomidi@access-ci.org,Javad Omidi,Michael Carlson,Purdue University,Anvil,9,14,46,2024,2024-11-11
ATS-12252,Installing BerkleyGW and Yambo,2024-11-19,2024-11-26,"I would like to request the installation of the following two software being BerkleyGW (https://berkeleygw.org/: https://berkeleygw.org/|smart-link) and Yambo (https://www.yambo-code.org/: https://www.yambo-code.org/|smart-link ) ; Hi Brody, Thanks for reaching out! Please check Anvil software request policy at https://www.rcac.purdue.edu/knowledge/anvil/policies/software\\_installation\\_request\\_policy: https://www.rcac.purdue.edu/knowledge/anvil/policies/software\\_installation\\_request\\_policy|smart-link In your case, we would recommend your group to install BerkleyGW and Yambo to your project space. If you encounter any issues, please feel free to let us know. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Hi, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name Purdue RCAC Support ;",bbrogdon@access-ci.org,Brody Brogdon,yang2383,Purdue University,Anvil,3,6,47,2024,2024-11-18
ATS-12353,problem with job submission script,2024-11-22,2024-12-05,"In my job submission script, I have : #SBATCH -A che240192-gpu #SBATCH --job-name myjob #SBATCH -o %x-%j.out #SBATCH --time=00:10:00 #SBATCH --nodes=1 #SBATCH -p gpu-debug I got the following error: ""sbatch: error: QOSMinGRES sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)"" If I change to #SBATCH -A che240192 #SBATCH --job-name myjob #SBATCH -o %x-%j.out #SBATCH --time=00:10:00 #SBATCH --nodes=1 #SBATCH -p debug I got the following error: ""sbatch: error: Batch job submission failed: Invalid account or account/partition combination specified"" ; Hello! For the gpu partitions, you'll need to specify the number of GPU's per node by using this SBATCH argument: `--gres=gpu:1`. For the second script, I see that you are only a member of `CHE240192-gpu` queue and not the `CHE240192` queue which is why the associated error is received. Thanks, name ;",pxu2@access-ci.org,Peng Xu,Sean Lee,Purdue University,Anvil,2,10,47,2024,2024-11-18
ATS-12393,anvil home directory quota,2024-11-25,2024-12-02,"Hi, Currently, the quota limit on Anvil/home/x-snajafi/ is set to 25GB. I need to install a few programs that require at least 15GB of additional space. Would it be possible to increase my home directory quota? ; Hello. I have set your home directory quota to 40GB. name Senior Research Solutions Engineer ;",snajafi@access-ci.org,Saeed Najafi,ramonw,Purdue University,Anvil,2,6,48,2024,2024-11-25
ATS-12398,Anvilgpt access request,2024-11-25,2024-11-26,"Upon our discussion (name and name) this morning on possible use for teaching. ; Hi Dongling, Your request has been approved for ANVILGPT. Feel free to use it, and let us know if you have any questions. ; Hi name, Thank you so much! I have access now and the interface is nice and intuitive. You mentioned that you could share some python notebook examples for using these LLM's including the RAG part. Would you please send them at your earliest convenience? I appreciate your help very much. Best, Dongling ;",dhuang5,Dongling Huang,Ashish Malik,I do not know the RP,Anvil,3,2,48,2024,2024-11-25
ATS-12636,Home Directory not found when accesing through open-demand.,2024-12-09,2024-12-12,"Hi, I get the following error when i access anvil through open demand. h1. Home directory not found Your home directory appears to be missing. The home directory mount may be unavailable, or your home directory may need to still be created. Please contact support for help and attempt to restart your web server by clicking below when the problem has been fixed I can access through ubuntu ssh, but not open-demand. What should I do? Best, Moaz. ; Hi Moaz, Thank you for reaching out. There was an issue with Anvil OOD yesterday, but it should now be resolved. Could you please try again and let me know if you still encounter any issues? Best, name, PhD (she/her) Senior Computational Scientist RCAC - Purdue University ;",mbilto@access-ci.org,Moaz Bilto,Haniye Kashgarani,Purdue University,Anvil,3,4,50,2024,2024-12-09
ATS-11540,I have issue with queue waiting time for interactive session for about 30 minutes or more for each time . can you please help me to fix it?,2024-10-21,2024-12-09,"I have issue with queue waiting time for interactive session for about 30 minutes or more for each time . can you please help me to fix it? ; Hi , Our team are currently working on resolving the issue. I'll keep you updated as soon as possible! Best, I.name Anvil support team ; \\*\\*PRIVATE NOTE\\*\\* the team are working on the issue. ; Hi , I am following up on the status of the issue. Are you still facing the issue ? Please let me know as soon as possible. Best, I.name Anvil support team ; Hello name, It was okay if i request for more hour .In case if i request for 30-2 hours ,the waiting times is still long . Regards, Madhu ---- ; Hi, Just following up on the issue, I know we had this issue reported before but right now all the scheduling/waiting periods of the jobs works normally. I'm not sure if you're observing very significant long waiting times? How long ? Best, I.name Anvil support team ; Hi, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, I.name Anvil support team ;",mponusamy@access-ci.org,Madhumathi Ponusamy,Ibrahem Alshybani,Purdue University,Anvil,7,36,43,2024,2024-10-21
ATS-12208,Invalid qos specification in Job Composer,2024-11-17,2024-12-12,"When I run my code in Job Composer, I get a message that says, ""An error occurred when submitting jobs for simulation 2: sbatch: error: Batch job submission failed: Invalid qos specification"". Here is the code: #!/bin/bash # JOB HEADERS HERE #SBATCH --qos=part-stand echo ""Hello World"" ; Ricky, Thank you for reaching out to RCAC for support. Currently, many of our staff are at a conference, so responses will be delayed. Thank you for your patience in this matter. You will need to specify some more things in your job submission script, specifically the allocation that you want to submit to. See the example below: #!/bin/bash # FILENAME: myjobsubmissionfile #SBATCH -A myallocation # change this to be your allocation number #SBATCH --qos=part-stand #SBATCH -p=shared #SBATCH --nodes=1 #SBATCH --ntasks=1 #SBATCH --time=00:10:00 #SBATCH --job-name myjobname echo ""Hello World"" Thanks, name ; Ricky, Since it's been a while since I've heard from you, I'm tentatively marking this ticket as resolved. If you're still encountering problems, please let me know within 7 days to reopen the ticket. Otherwise, you will need to submit a new ticket. Thanks, name ;",rsteinel@access-ci.org,Ricky Steinel,Michael Carlson,Purdue University,Anvil,3,19,46,2024,2024-11-11
ATS-12567,Different Version of Julia,2024-12-05,2024-12-13,"Right now, I am running into some issues with implementing my code. I think it stems from having to run a different version of name on the cluster versus the name that I run on my own personal computer. Is there an easy way to add name 1.7.3 onto Anvil? If not, I can try to alter my code so that it runs on one the versions that Anvil currently supports. ; Hi name, Thank you for contacting Anvil support. If code modification is not significant that would be ok at least in the meantime. Regarding installing specific version for you on anvil, I believe it's possible as long as you have a valid license. I need to double check with my group though. Best, I.name Anvil support team ; Ok, I believe that getting it to work on a different version should be straightforward enough. I do have another question however regarding running name on the cluster. So, I've been trying to download on use packages from name, but after using about 4 to 5 packages on a specific run, the run will quit with an oom (out of memory issue). There are two reasons why I believe this might be happening. The first is that when I am currently running a run.slurm file, I am not requesting any amount of memory and so I may just be receiving too little memory to properly download the packages. I cannot figure out how to properly request more memory for a specific slurm run, I have tried ""--l mem=mem]"" along with just ""--mem=memM: G|T"" or ""--mem-per-cpu=mem[M: G|T"" and the errors I receive are either invalid license specification or invalid --mem specification. The other reason I think I could be receiving this error which I don't think is the case is that the .name file that stores the packages is located in my home mount point as opposed to in my projects mount point. Any help is appreciated here. ; I've actually figured out all these issues in the past 2 hours and everything works on the current downloaded version of name 1.6.2. However, I still do have one question, which appears when I try running on name 1.9.3. When trying to install packages on name 1.9.3, I continuously get the following error message: ERROR: LoadError: SystemError: opening file ""/apps/anvil/external/apps/name/1.9.3/share/name/environments/v1.9/Project.toml"": Permission denied And so I'm unable to run anything on name 1.9.3. This issue is more of a question that I might need answered in the future, as I can do everything that I want on name 1.6.2. Thanks, name ; And I have now figured out this issue as well, so I am all set. Thank you. ; \\*\\*PRIVATE NOTE\\*\\* Hi name, I am glad you're able to resolve the issue yourself. I'll mark this ticket as resolved now. Best, I.name: http://I.name Anvil support team ;",elowe1@access-ci.org,Eric Lowe,Ibrahem Alshybani,Purdue University,Anvil,6,7,49,2024,2024-12-02
ATS-12600,Home directory not found Your home directory appears to be missing. ,2024-12-07,2024-12-10,"Hi I got this error while login in the ondemand, the terminal login is fine. ""The home directory mount may be unavailable, or your home directory may need to still be created. Please contact support for help and attempt to restart your web server by clicking below when the problem has been fixed."" Best, Wenliang ; Wenliang, Thank you for reaching RCAC for support. Thank you for bringing this to our attention. It looks like this problem is affecting some users (but not all). We are doing our best to bring back OnDemand functionality as soon as possible. Thank you for your patience in this matter, name ; Thank you, name. It's back now. ; Wenliang, We have deployed a patch that should resolve this issue for users. I'm marking this ticket as solved, but if you do run into issues, please respond to this ticket within 7 days to reopen it. Otherwise, you will need to submit a new ticket. Thanks, name ;",wangwl@access-ci.org,Wenliang Wang,Michael Carlson,Purdue University,Anvil,4,2,49,2024,2024-12-02
ATS-13109,AnvilGPT ACCESS Request,2025-01-09,2025-01-10,"Hi, I'd like to try out AnvilGPT, having also built a similar service for Jetstream2 (https://docs.jetstream-cloud.org/general/inference-service/: https://docs.jetstream-cloud.org/general/inference-service/|smart-link ), curious how a different group approached a similar goal. I'll try both the UI and API. I'm name, several ACCESS allocations, TRA160003, CCR190024, etc. ; Hi name, Your request has been approved, and you have been given access to both the UI and the API for AnvilGPT. Feel free to start exploring the service, and let us know if you have any questions or need further assistance. ;",cmart,Chris Martin,Ashish Malik,Purdue University,Anvil,2,2,2,2025,2025-01-06
ATS-12606,Could not access to ondemand of Anvil Purdue,2024-12-07,2024-12-10,"I am unable to access Ondemand for reasons that I do not understand, but I can still log in to my account on the Anvil server. I need access to Ondemand to use the Jupyter Notebook for my data analysis. ; name, Thank you for reaching RCAC for support. Thank you for bringing this to our attention. It looks like this problem is affecting some users (but not all). We are doing our best to bring back OnDemand functionality as soon as possible. Thank you for your patience in this matter, name, We have deployed a patch that should resolve this issue for users. I'm marking this ticket as solved, but if you do run into issues, please respond to this ticket within 7 days to reopen it. Otherwise, you will need to submit a new ticket. Thanks, name ; Hi name, I have access to Anvil OnDemand, and it is working. I believe the bug has been resolved. Thanks. Best, name. ;",ellanguyen@access-ci.org,Thi Hong Ha Nguyen,Michael Carlson,Purdue University,Anvil,5,2,49,2024,2024-12-02
ATS-12616,Home Directory not found,2024-12-07,2024-12-10,"I couldn't get access to https://ondeomehmand.anvil.rcac.purdue.edu/: https://ondemand.anvil.rcac.purdue.edu/pun/name/dashboard. It keep getting \\*Home directory not found error.\\* I logged in to Access and did all I could but still not working. ; name, Thank you for reaching RCAC for support. Thank you for bringing this to our attention. It looks like this problem is affecting some users (but not all). We are doing our best to bring back OnDemand functionality as soon as possible. Thank you for your patience in this matter, name, We have deployed a patch that should resolve this issue for users. I'm marking this ticket as solved, but if you do run into issues, please respond to this ticket within 7 days to reopen it. Otherwise, you will need to submit a new ticket. Thanks, name ;",moyelakin@access-ci.org,Michael Oyekunle Oyelakin,Michael Carlson,Purdue University,Anvil,3,2,49,2024,2024-12-02
ATS-12333,Purdue Anvil BioContainer Help - Purge_dups,2024-11-21,2025-01-21,"Good afternoon, I am having issues with one of the Purdue Anvil biocontainer modules: purge\\_dups. Per https://github.com/dfguan/purge\\_dups: https://github.com/dfguan/purge\\_dups|smart-link I am trying to run the script/executables below, but they do not appear to be precompiled on Anvil; the files on github are '.c' files and have associated '.h' files. They can be accessed at: https://github.com/dfguan/purge\\_dups/tree/master/src: https://github.com/dfguan/purge\\_dups/tree/master/src|smart-link pbcstat calcuts split\\_fa purge\\_dups get\\_seqs etc. These executables are not currently listed as available commands for the container 'purge\\_dups' on Anvil. Would it be possible to get some help turning these source files into executables to be run on Anvil? Any help you could provide would be greatly appreciated. Thanks, name ; \\*\\*PRIVATE NOTE\\*\\* Hi ~accountid:id:id-0296-44c2-8aaa-9a36b2662a58 , Could you check this Jira ticket and let me know if it's something you can help with. ; Hi name, The module for {{purge\\_dups}} has been fixed. Please load the updated module using the following commands: ml biocontainers ml purge\\_dups/1.2.6\\_fixed These changes should take effect by tomorrow. If you still cannot find the executables after that, please let us know, and we will check it again for you. Thanks, name Lead Bioinformatics Scientist, RCAC Purdue University ; Hi name, Thank you so much for your help. I've run the complete pipeline once and all of the executables and scripts seem to be working properly. Many thanks, name ---- ;",abernard@access-ci.org,Andrea Bernard,Arun Seetharam,Purdue University,Anvil,4,44,47,2024,2024-11-18
ATS-12625,Could not connect to the Anvil cluster,2024-12-08,2024-12-10,"h1. Home directory not found Your home directory appears to be missing. The home directory mount may be unavailable, or your home directory may need to still be created. Please contact support for help and attempt to restart your web server by clicking below when the problem has been fixed. ; Hi name, It is Anvil at Purdue. Thank you. ---- ; Hi name, Thank you for reaching out. There was an issue with Anvil OOD yesterday, but it should now be resolved. Could you please try again and let me know if you still encounter any issues? Best, name, PhD (she/her) Senior Computational Scientist RCAC - Purdue University ; Hi name, Thanks so much for your reply. It works now. Best regards, name ---- ; Thanks for letting me know. Best, name K ;",wliu1@access-ci.org,Wei Liu,Haniye Kashgarani,Purdue University,Anvil,5,2,49,2024,2024-12-02
ATS-12632,Unable to Access home directory on Purdue University Anvil account.,2024-12-09,2024-12-10,"I provided a photo below of the issue I am continually running into when I attempt to login and start a session. This has been happening since Friday 12/6/24. ; Hi Eli, Thank you for reaching out. There was an issue with Anvil OOD yesterday, but it should now be resolved. Could you please try again and let me know if you still encounter any issues? Best, name, PhD (she/her) Senior Computational Scientist RCAC - Purdue University ; Ms. name, The issue seems to be resolved, as it is now working. Thank you so much for your help\! Have a great day! Eli name ---- ; Thanks for letting me know. I will mark this ticket as resolved, but feel free to reach out again with any questions. Best, name K ;",echandler@access-ci.org,Eli Chandler,Haniye Kashgarani,Purdue University,Anvil,5,2,50,2024,2024-12-09
ATS-12816,Install bioinformatics tools for upcoming workshop in early Jan 2025,2024-12-18,2025-01-21,"Raising this request on behalf of instructors for an upcoming workshop (allocation BIO240351). I see some bioinformatic tools that we'll need, which I don't see listed on the Anvil website are: \\* \\*Admixture\\* (https://dalexander.github.io/admixture/: https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdalexander.github.io%2Fadmixture%2F&data=05%7C02%7Crkalyana%40purdue.edu%7Cc97ec4de98f8484b58e208dd1f970592%7C4130bd397c53419cb1e58758d6d63f21%7C0%7C0%7C638701455711463909%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=UpqWNG%2FyisA%2BPqABzn%2BVMQpOmlpxyYqDbv%2BlY1hZjEw%3D&reserved=0) \\* \\*PSMC\\* (https://github.com/lh3/psmc: https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Flh3%2Fpsmc&data=05%7C02%7Crkalyana%40purdue.edu%7Cc97ec4de98f8484b58e208dd1f970592%7C4130bd397c53419cb1e58758d6d63f21%7C0%7C0%7C638701455711485319%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=FszFqmWBcUaGXb8q5uS0pRM22zzobYVO6jmVzyP1Xk0%3D&reserved=0) \\* \\*feems\\* (https://github.com/NovembreLab/feems: https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2FNovembreLab%2Ffeems&data=05%7C02%7Crkalyana%40purdue.edu%7Cc97ec4de98f8484b58e208dd1f970592%7C4130bd397c53419cb1e58758d6d63f21%7C0%7C0%7C638701455711495705%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=8aeksHwtA1bBUsJG2s0DYi%2FEbiVrciapCzSW63M%2BFeE%3D&reserved=0). I know feems can be quite difficult to install, so no worries if you aren't able to install it. The other instructors and I may reach out with additional software to install in the next couple hours or tomorrow. ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id:id-0296-44c2-8aaa-9a36b2662a58] assigning to you for follow up. thanks Thanks, name Lead Bioinformatics Scientist RCAC, Purdue University. ; Hi name, Thanks so much Thanks so much, ---name ; Hi name, Thanks for the scripts and information! I've set up {{feems}} in a biocontainers, and you can now load it as follows: $ ml biocontainers User guides for each biocontainer module can be found at https://www.rcac.purdue.edu/knowledge/biocontainers $ ml feems $ python Once inside Python, you can use: # base import numpy as np import pkg\\_resources from sklearn.impute import SimpleImputer from pandas\\_plink import read\\_plink # viz import matplotlib.pyplot as plt import cartopy.crs as ccrs # feems from feems.utils import prepare\\_graph\\_inputs from feems import SpatialGraph, Viz # change matplotlib fonts plt.rcParams[""font.family"" = ""Arial"" plt.rcParams""font.sans-serif"" = ""Arial"" Alternatively, you can use {{https://ondemand.anvil.rcac.purdue.edu}} to access a desktop environment and start a notebook session ({{jupyter notebook}} or {{jupyter lab}}). If you need additional packages in the same container, let me know, and I'll be happy to add them. Thanks, name Lead Bioinformatics Scientist RCAC, Purdue University. ;",rkalyana@access-ci.org,Rajesh Kalyanam,Arun Seetharam,,Anvil,5,25,51,2024,2024-12-16
ATS-12648,I cannot submit a job on Anvil using the sbatch command. Error says command not found,2024-12-09,2024-12-12,"Dear Support team, I'm struggling with submitting a job on Anvil. I am following the user guide(https://www.rcac.purdue.edu/knowledge/anvil/run/batch: https://www.rcac.purdue.edu/knowledge/anvil/run/batch|smart-link ) and trying to run a test.m matlab file using Anvil. The first image shows the myjobsubmissionfile run code. The second image is a snapshot of the folder. I clicked on the ""open in Terminal"" button in the second picture and typed {{$ sbatch --nodes=1 --ntasks=1 myjobsubmissionfile}} and got an error message saying ""command not found"" (3rd image) I was confused because when I run commands such as ""ls"" it seems that the files are uploaded properly in the folder. (4th image) I feel like I'm missing something. Is this problem related to permission? Thank you. Sincerely, name ; Hi name, Thank you for reaching out. When submitting your job, you are currently using ""$ sbatch"" at the beginning of the command line. However, you need to remove the ""$"" symbol and start the command directly with sbatch. Let me know if you have any other questions. Best, name, PhD (she/her) Senior Computational Scientist RCAC - Purdue University ; Hi name, Thank you for your response. Although removed the ""$"" It didn't work. The message says ""{{Unable to open file myjobsubmissionfile}}"". The files are in the folder. I know something is wrong but I'm not sure. Thank you. Sincerely, name ; Hi name, Your filename has a '.txt' extension and you need to add it at end of your filename. Best, name K ; Hi name, Oh I see. Thank you. Sincerely, name, If you have no further questions, I will proceed to mark this ticket as resolved. Let me know if you have another question. Best, name K ;",akim5@access-ci.org,Anthony Kim,Haniye Kashgarani,,Anvil,7,4,50,2024,2024-12-09
ATS-12673,"""Floating-point exception"" error codes for simulations which worked previously",2024-12-10,2024-12-12,"Simulations which previously ran without error on Anvil now return mysterious ""Floating-point exception"" error codes and crash. The simulations use the software package MFiX which currently runs using a Conda environment installed to the Anvil cluster. The directory where one of these simulations was being run from is ""/anvil/projects/x-chm230046/MFiX/CFD-DEM/SpoutedBed/VaryingCases/Dry/DecemberTest"" ; \\*\\*PRIVATE NOTE\\*\\* Hi name, Thank you for reaching out. There was an issue with the deployed MPI and UCX on Anvil, but one of my colleagues has deployed a fix. Please try again and let me know if you encounter any further issues. Best, name K ; This issue has been resolved. Thank you, ; Thanks for letting me know. I will mark this ticket as resolved now. Best, name K ;",cspitler@access-ci.org,Christopher Spitler,Haniye Kashgarani,,Anvil,5,3,50,2024,2024-12-09
ATS-12678,VASP access on Anvil,2024-12-10,2024-12-13,"I am name Kethamukkala, a PhD student in Prof. name's group at Arizona State University. I am a part of Prof. name's Anvil ACCESS project MAT210034 and my username is ""x-kkethamukkal"". I need to use VASP on Anvil and request access for the same. Please let me know if I can provide any further information and my email ID is """". Thank you. ; Hi, Thank you for contacting us. We will get back to you as soon as we have the answer. Best regards, name ; Hi, We've added your license. You should be good to use VASP on Anvil now. Let us know if you need more help. Best, name ;",x-kkethamukkal,Kaushik Kethamukkala,Xiao Liu,Purdue University,Anvil,4,4,50,2024,2024-12-09
ATS-11913,Extended work hours for jobs,2024-11-04,2024-12-18,"Hi, I want to extend the job hours for 10 days instead of 4 for one month. I ran the same exact job on 1 node and 4 nodes for 24 hrs. Job on \\*4 nodes\\* finished 24 steps out of 234 in 24 hrs \\*(job ID 8246834)\\* Linear response progress: Degree of freedom: 24/234 Job on \\*1 node\\* finished 25 steps out of 234 in 24 hrs \\*(Job ID 8247738)\\* Linear response progress: Degree of freedom: 25/234 So, could you please, extend the allocated time for running the jobs? I think those kinds of jobs can be finished within 10 days on 1 node. Thank you, Basant ; Hi Basant, Thank you for reaching out. We will get back to you about increasing walltime for these jobs as soon as possible. Eli name Purdue IT https://service.purdue.edu ; Hi Basant, After reviewing your request, it would be possible to extend this. Is it possible to hold a quick meeting on Teams or Outlook or send me your jobid as soon as you run it so I can manually extend your walltime for that specific job? Best Regards, Eli name Purdue IT http://service.purdue.edu ; Hi name, Thank you for your reply. I can meet you at any time. For the jobs, I will need this extension for almost 20 jobs of the same kind, not only one. Thank you, Basant ; Hi Basant, In this case, it would be more beneficial if you could send me your jobids as soon as you have ran those jobs as this would be more efficient if I manually changed their walltimes if they were the same kind of jobs. You can book a meeting with me here: https://outlook.office.com/bookwithme/user//meetingtype/Ze4nWNmz10ChTtEOtbWU8g2?bookingcode=09da7919-f89d-4541-be3c-1e987c4030e4&anonymous&ep=mlink. Best Regards, Eli name Purdue IT https://service.purdue.edu: https://service.purdue.edu/ ; Hi Basant, I'd like to follow up on this ticket. Let me know if you have any more jobs you will release this week and you should book a meeting with me here: https://outlook.office.com/bookwithme/user//meetingtype/Ze4nWNmz10ChTtEOtbWU8g2?bookingcode=09da7919-f89d-4541-be3c-1e987c4030e4&anonymous&ep=mlink accordingly. Best Regards, Eli name Purdue IT https://service.purdue.edu: https://service.purdue.edu ; Hi name, Thank you so much for following up. I booked another meeting for the second set of jobs. Thank you, Basant ; Hi name, As a follow-up to our previous meeting. All the jobs are at a great rate and most are already finished in the allocated time. However, the job number (8384487) working on one node is a little bit slow and will need up to 16 days to finish. Thank you, Basant ; Hi Basant, Thank you for letting me know. I have updated job 8384487 and will now finish within 16 days. Best Regards, Eli name Purdue IT https://service.purdue.edu: https://service.purdue.edu/ ; Thank you so much. ; Hi Basant, Could I follow up on the status of the jobs we extended on call? Best Regards, Eli name Purdue IT https://service.purdue.edu ; Hi name, Thank you for your follow-up. The jobs finished successfully and we are analyzing data and preparing the manuscript for submission. Thank you so much for your help and support. Best Regards, Basant ; Hi Basant, Glad to hear this. I will now close this ticket. Let us know if you have any futher issues. Best Regards, Eli name Purdue IT https://service.purdue.edu ;",belshoky@access-ci.org,Basant Elshoky,Elian Rieza,Purdue University,Anvil,13,33,45,2024,2024-11-04
ATS-12063,Increase the file number quota on Anvil,2024-11-11,2024-12-18,"Hello, our group is running a suite of 32 simulations in Enzo on Anvil. All should run to 100 frames, using 4 nodes and total of 512 cores. This amounts to about 1.6 million files written to the disk (one per each core, frame and simulation). The initial run has to be followed by statistical analysis, yielding about 10 files per simulation and frame, so about 300,000 files. Can you please increase the file number limit (to 5 million files, just to be on the safe side) so we can finish the suite? Thank you. ; Hi Branislav, Thank you for reaching out. We will get back to you about this request as soon as possible. Eli name Purdue IT https://service.purdue.edu ; Dear Eli, I was wondering what's the status of my file number quota increase request. Please let me know if I can be of any help with moving this along. Best, Branislav Rabatin ; Hi Branislav, We are still reviewing your increase request. We will get back to you from later today at the earliest up to Friday evening at the latest. Best Regards, Eli name Purdue IT https://service.purdue.edu: https://service.purdue.edu/ ; Hi Branislav, Please ask your project PI to fill out this form: https://forms.office.com/pages/responsepage.aspx?id=Ob0wQVN8nEGx5YdY1tY\\_ITl1stL7IvdDuW31KFR1mwlUMlFUQVdFSVdEUTJJOTdMSEhSOElKTTdZWiQlQCN0PWcu&route=shorturl. I will soon escalate this request to the operations team and we will be able to see if operations will increase your file quota. Best Regards, Eli name Purdue IT https://service.purdue.edu ; Dear Eli, my PI says he doesn't have the permission to view the form. Best, -BR ; Hi Branislav, Apologies, It seems that we have changed the process for file quota increases. Could I get the directory where you would like the quota increase and the project ID instead? Best Regards, Eli name Purdue IT https://service.purdue.edu ; Hello, the directory is my scratch (/anvil/scratch/x-rabatinb). Not sure what the project ID is, but my PI's name is Prof. name Collins. -BR ; Hi again, my PI got to me, he says the ID is either ast140008 or phy240036 ; Hi Branislav, The file quota has now been increased to 5 million files. Let us know if you have any further issues. Best Regards, Eli name Purdue IT https://service.purdue.edu: https://service.purdue.edu|smart-link ; \\*\\*PRIVATE NOTE\\*\\* Has been resolved. Confirmed with name. ;",rabatinb@access-ci.org,Branislav Rabatin,Elian Rieza,Purdue University,Anvil,11,28,46,2024,2024-11-11
ATS-12986,SU balance mismatch,2025-01-03,2025-02-06,"My PI is saying that our name balance is 1,473,198 but when I do mybalance is 73441.4 left. There's some mismatch here and thus I can't land my job because of it? Could you guys please confirm? Thank you We are actively working on addressing the issue. Rest assured, we will provide you with a response as soon as possible. Best regards, name RC Support ; Hello, Thank you for your patience! From what we see, your allocation balance for {{ees240013}} is 9786. Can you please share more details on where your PI checked the name balance and if possible ask your PI to confirm it. Best, name RCAC Support ;",tim48@access-ci.org,Ting-Hsuan Ma,Ankitha Mallekav,Pittsburgh Supercomputing Center (PSC),Anvil,3,25,1,2025,2024-12-30
ATS-12201,Anvil: Seg Fault when running job on >1 node,2024-11-16,2024-12-17,"Dear Support I am trying to run the Parallel Ice Sheet Model (PISM, www.pism.io: http://www.pism.io) on Anvil. PISM is MPI based and requires recent versions of PETSc, hdf5, netCDF, YAXT/YAC, PROJ, GSL, UDUNITS and a few more. Due to the old software stack on Anvil, we had to compile I had to compile HDF5, netCDF, and PETSc myself, using the Intel 2024 compiler and impi/2021. Libraries were first compiled on the login nodes, later on the compute nodes, my problem occurs in both cases. Note that we can run PISM successfully with the same setup on other systems such as NASA's Pleiades cluster. When I run PISM requisition 1 node (wholenode queue), PISM runs successfully. However, when I try to use 2 nodes instead, I am running into the seg fault below. PETSc catches a memory problem and from what I can tell, it happens when the external library YAC (https://dkrz-sw.gitlab-pages.dkrz.name/yac/: https://dkrz-sw.gitlab-pages.dkrz.name/yac/|smart-link ), but it appears to be triggered by the MPI library. I don't really know how to go about this. From my experience with Pleiades, HPC systems are very fragile when it comes to compilers and MPI stacks, often requiring trial and error to find a combination that magically works. Unfortunately, options on Anvil appear limited, as YAC only compiles on newer versions of MPI and the Intel Compiler due to their Fortran dependency, thus I'm using the latest 2024 Intel Compiler. Do you have any thoughts? Thanks, name Reading configuration parameters (pism\\_overrides) from file '/anvil/projects/x-ees240003/pism-ragis/calibration/2024\\_11\\_grimp\\_tw/pism.nc'. Reading configuration parameters (pism\\_config) from file '/home/x-aaschwanden/local/pism/share/pism/pism\\_config.nc'. Setting time from '/anvil/projects/x-ees240003/pism-ragis/calibration/2024\\_11\\_grimp\\_tw/time\\_forcing/timefile\\_1980-1-1\\_1984-12-31.nc'... PISM (basic evolution run mode) 2.1.99-b3346b65c committed by Constantine Khrulev on 2024-11-06 setting computational box for ice from variable 'domain' in grid definition file '/anvil/projects/x-ees240003/pism-ragis/data/grids/pism-bedmachine-greenland.nc' and user options: -660.65 km, 887.35 km x -3376.55 km, -640.55 km x 0 m, 4000.00 m Reading boundary conditions from '/anvil/projects/x-ees240003/pism-ragis/data/climate/HIRHAM5-monthly-ERA5\\_1975\\_2021.nc'... Run time: 1980-01-01 00.000h, 1984-12-31 00.000h (4.999 years, using the 'standard' calendar) # Allocating the geometry evolution model... # Allocating an iceberg remover (part of a calving model)... # Allocating a stress balance model... Initializing bed smoother object with 0.900 km half-width ... # Allocating an energy balance model... # Allocating a subglacial hydrology model... # Allocating a basal yield stress model... # Allocating a bedrock thermal layer model... # Allocating a bed deformation model... # Allocating a surface process model or coupler... Reading boundary conditions from '/anvil/projects/x-ees240003/pism-ragis/data/climate/HIRHAM5-monthly-ERA5\\_1975\\_2021.nc'... Reading boundary conditions from '/anvil/projects/x-ees240003/pism-ragis/data/climate/HIRHAM5-monthly-ERA5\\_1975\\_2021.nc'... # Allocating sea level forcing... # Allocating an ocean model or coupler... Computing longitude and latitude using projection parameters... bootstrapping from file '/anvil/projects/x-ees240003/pism-ragis/data/dem/BedMachineGreenland-v5\\_0.nc'... WARNING: 'mask' found; IGNORING IT! WARNING: surface elevation 'usurf' found; IGNORING IT! reading 2D model state variables by regridding ... Initializing 2D interpolation on the sphere from 'BedMachineGreenland-v5\\_0.nc:y:x' to the internal grid... Input grid:id mapping: polar\\_stereographic PROJ string: 'PROJCS""WGS 84 / NSIDC Sea Ice Polar Stereographic North"",GEOGCS""WGS 84"",DATUM[""WGS\\_1984"",SPHEROID[""WGS 84"",6378137,298.257223563,AUTHORITY[""EPSG"",""7030"",AUTHORITY""EPSG"",""6326""],PRIMEM""Greenwich"",0,AUTHORITY""EPSG"",""8901"",UNIT""degree"",0.0174532925199433,AUTHORITY""EPSG"",""9122"",AUTHORITY""EPSG"",""4326""],PROJECTION""Polar\\_Stereographic"",PARAMETER""latitude\\_of\\_origin"",70,PARAMETER""central\\_meridian"",-45,PARAMETER""scale\\_factor"",1,PARAMETER""false\\_easting"",0,PARAMETER""false\\_northing"",0,UNIT""metre"",1,AUTHORITY""EPSG"",""9001"",AXIS""X"",EAST,AXIS""Y"",NORTH,AUTHORITY""EPSG"",""3413""]' x: 10218 points, -653.000, 879.700 km, x0 = 113.350 km, Lx = 766.350 km y: 18346 points, -3384.500, -632.600 km, y0 = -2008.550 km, Ly = 1375.950 km t: 0 records Defining the source grid (BedMachineGreenland-v5\\_0.nc:y:x)... Source grid resolution: ~150.000 m Defining the target grid (internal for BedMachineGreenland-v5\\_0.nc:y:x)... Target grid resolution: 900.000 m Interpolation method: 1st order conservative 64PETSC ERROR: ; 64PETSC ERROR: Caught signal number 11 SEGV: Segmentation Violation, probably memory access out of range 64PETSC ERROR: Try option -start\\_in\\_debugger or -on\\_error\\_attach\\_debugger 64PETSC ERROR: or see https://petsc.org/release/faq/#valgrind and https://petsc.org/release/faq/ 64PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 64PETSC ERROR: to get more information on the crash. 64PETSC ERROR: Run with -malloc\\_debug to check if memory corruption is causing the crash. Abort(59) on node 64 (rank 64 in comm 0): application called MPI\\_Abort(MPI\\_COMM\\_WORLD, 59) - process 64 Assertion failed in file ../../src/mpid/ch4/shm/posix/eager/include/intel\\_transport\\_recv.h at line 1202: cma\\_read\\_nbytes == size Assertion failed in file ../../src/mpid/ch4/shm/posix/eager/include/intel\\_transport\\_recv.h at line 1202: cma\\_read\\_nbytes == size Assertion failed in file ../../src/mpid/ch4/shm/posix/eager/include/intel\\_transport\\_recv.h at line 1202: cma\\_read\\_nbytes == size Assertion failed in file ../../src/mpid/ch4/shm/posix/eager/include/intel\\_transport\\_recv.h at line 1202: cma\\_read\\_nbytes == size Assertion failed in file ../../src/mpid/ch4/shm/posix/eager/include/intel\\_transport\\_recv.h at line 1202: cma\\_read\\_nbytes == size Assertion failed in file ../../src/mpid/ch4/shm/posix/eager/include/intel\\_transport\\_recv.h at line 1202: cma\\_read\\_nbytes == size Assertion failed in file ../../src/mpid/ch4/shm/posix/eager/include/intel\\_transport\\_recv.h at line 1202: cma\\_read\\_nbytes == size Assertion failed in file ../../src/mpid/ch4/shm/posix/eager/include/intel\\_transport\\_recv.h at line 1202: cma\\_read\\_nbytes == size Assertion failed in file ../../src/mpid/ch4/shm/posix/eager/include/intel\\_transport\\_recv.h at line 1202: cma\\_read\\_nbytes == size \\*:hindcasts\\* $ module list Currently Loaded Modules: # xalt/2.10.45 (\\*S\\*) 5) impi/2021.12 9) anaconda/2024.02-py311 13) curl/7.76.1 17) expat/2.4.1 # tbb/2021.12 6) intel-rt/2024.1.0 10) gsl/2.4 14) proj/6.2.0 18) udunits/2.2.28 # oclfpga/2024.1.0 7) cmake/3.20.0 11) libiconv/1.16 15) libmd/1.0.3 19) zlib/1.2.11 # intel/2024.1 8) fftw/3.3.8 12) libxml2/2.9.10 16) libbsd/0.11.3 20) libszip/2.1.1 ; name, Thank you for reaching out to RCAC for support. Many of us on the support team are at a conference, so responses will be delayed. Thank you for your patience in this matter. Have you tried configuring PetSc with '--with-debugging=yes' to see if that gives more information about the crash? Or since it's in a different package, will that not help? Thanks, name, Since we haven't heard from you in a while, I'm tentatively marking this ticket as resolved. If you have further questions, please respond to this ticket within 7 days to reopen it. Otherwise, you will need to submit a new ticket. Thanks, name, Since we haven't heard from you in a while, I'm tentatively marking this ticket as resolved. If you have further questions, please respond to this ticket within 7 days to reopen it. Otherwise, you will need to submit a new ticket. Thanks, name ; Hi name I've been traveling for the past two weeks and haven't had a chance to follow up. Feel free to close the ticket for now, it's probably gonna be new year before I'll be able to get back to it. Best, name Dr. name Aschwanden Research Professor Geophysical Institute University of Alaska Fairbanks ^smime.p7s \\_(1 kB)\\_ ;",aaschwanden@access-ci.org,Andy Aschwanden,Michael Carlson,Purdue University,Anvil,5,22,46,2024,2024-11-11
ATS-12270,VASP job randomly killed,2024-11-19,2024-12-18,"I was submitting VASP relaxation jobs, but some jobs are killed in the middle without a clear error messages. I submitted the same jobs (same inputs) in other HPC clusters, and no errors appeared there. I am wondering if this is a VASP compilation issue, or something related to the nodes. Here is an example of error outputted ""Backtrace for this error: #0 0x14fb9d0015af in ??? #1 0x14fb9d00152f in ??? #2 0x14fb9cfd4e64 in ??? #3 0x14fb9d042726 in ??? #4 0x14fb9d049a2b in ??? #5 0x14fb9d04bccc in ??? #6 0x14fb9b2d3f40 in ??? #7 0x14fb9b2d5455 in ??? #8 0x14fb9b2e13d5 in ??? #9 0x14fb9b2d564b in ??? #10 0x14fb93570d48 in ??? #11 0x14fb93570f97 in ??? #12 0x14fb9357135f in ??? #13 0x14fb9bab1a71 in ??? #14 0x14fb9bab14da in ??? #15 0x14fb9bad83a7 in ??? #16 0x14fb9bad8646 in ??? #17 0x14fb9bafe91c in ??? #18 0x14fb9b847ba4 in ??? #19 0x14fb9bab8b39 in ??? #20 0x14fb9bdb23f2 in ??? #21 0x14fb9d866634 in ??? #22 0x14fb9d8c6eb6 in ??? #23 0x14fb9d8c7308 in ??? #24 0x14fb9d8dbafa in ??? #25 0x14fb9d87e297 in ??? #26 0x14fb9f462f79 in ??? #27 0x14fb9f455c20 in ??? #28 0x14fb9fb45328 in ??? #29 0x14fb9fb7ce6d in ??? #30 0x14fb9fc17902 in ??? #31 0x14fb9f93460f in ??? #32 0x14fb9f92da1a in ??? #33 0x14fb9f929b56 in ??? #34 0x47e858 in ??? #35 0xa58d57 in ??? #36 0xb04d10 in ??? #37 0x1139a66 in ??? #38 0x111caab in ??? #39 0x113a0a5 in ??? #40 0x14fb9cfed7e4 in ??? #41 0x41299d in ??? #42 0xffffffffffffffff in ??? srun: error: a301: task 96: Aborted srun: Job step aborted: Waiting up to 32 seconds for job step to finish. slurmstepd: error: \\*\\*\\* STEP 8364060.0 ON a301 CANCELLED AT 2024-11-08T17:54:18 \\*\\*\\* slurmstepd: error: \\*\\*\\* JOB 8364060 ON a301 CANCELLED AT 2024-11-08T17:54:18 \\*\\*\\*"" ; Hi Zhuohan, Thanks for reaching out! Can you share your job ID or job submit script for me to take a look? Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Hi name, Sorry for a late reply. Here are some job IDs that are killed randomly. I also attached the submit script that I used to submit these jobs. Job IDs: 8364060, 8364061, 8388486, 8364185, 8364187. Best, Zhuohan #!/bin/bash # FILENAME: myjobsubmissionfile #SBATCH -A dmr970008 #yallocation # Allocation name #SBATCH --nodes=1 # Total # of nodes #SBATCH --ntasks=128 # Total # of MPI tasks #SBATCH --\\*time\\*=48:00:00 # Total run \\*time\\* limit (hh:mm:ss) #SBATCH -J vasptest # Job name #SBATCH -o myjob.o \\*%j\\* # Name of stdout output file #SBATCH -e myjob.e \\*%j\\* # Name of stderr error file #SBATCH -p wholenode # Queue (partition) name ###SBATCH --mail-user=#useremailaddress ###SBATCH--mail-\\*type\\*=all # Send email to above address \\*at\\* begin and end of job # Manage processing environment, load compilers and applications. module purge #module load compilername #module load mpilibrary #module load applicationname module load gcc/11.2.0 openmpi/4.0.6 hdf5/1.10.7 module load intel-mkl module list export \\*I\\_MPI\\_FABRICS\\*=shm export \\*OMP\\_NUM\\_THREADS\\*=1 export \\*PATH\\*=$PATH:/home/x-johan28/bin/VASP\\_binaries/distribution\\_gnu\\_recommended ##srun -n $SLURM\\_NTASKS vasp\\_std > vasp.out ##srun -n $NTASKS vasp\\_std > vasp.out ##srun -n $SLURM\\_NTASKS vasp\\_std srun -n $SLURM\\_NTASKS vasp\\_std > vasp.out rm CHG ; Hi name, I just wanted to follow up on my last email. Best, Zhuohan ; Hi Zhuohan, I am sorry for the delay. I was on sick leave and did not get back to you. Looks like you are using your own compiled VASP for your jobs and you used openmpi/4.0.6 for your compilation. It has been proved that the version of 4.0 of openmpi will lead some memory issues, so we had changed to openmpi/4.1.6 for our central VASP compilation on Anvil. Can you try re-compile your VASP with openmpi/4.1.6 module on Anvil and see if you can run your optimization? Regards, name ; Hi name, Thank you so much for the reply. I hope you are feeling better now. I will try the recompilation. Best, Zhuohan ;",johan28@access-ci.org,Zhuohan Li,Nannan Shan,Purdue University,Anvil,6,22,47,2024,2024-11-18
ATS-12555,"File count limit in project repo, using a large dataset.",2024-12-05,2024-12-18,"To whom it may concern, I have been using a variety of datasets to test my research on adversarial machine learning defense frameworks but have run into an issue when using larger datasets. For example, I have recently tried to download and use the 'Places365' dataset on Purdue's Anvil GPU cluster. However, the download failed about half way. Upon checking some of the account distinctions and repo limits with the ""myquota"" command, I saw that I reached the file limit count of 1,048k. The 'Places365' dataset has over 1.8 million files, so it already exceeds the limit on the Anvil GPU clusters. The research I am currently doing necessitates larger datasets to generalize better, so essentially is there anyway to increase that limit, or should I search for more limited datasets of smaller size? Thank you. ; Hi name Del Tufo, Thank you for contacting Anvil support. I need to double check with the team to see the right resolution for this issue. I'll be back should I have an update. Appreciate your patience in the meantime. Best, I.name Anvil support team ; name, Thank you for looking into this issue, I will patiently await your response. name ; Hi , I have discussed the situation with my team and we're wondering if the dataset you mentioned is so popular and widely used! Let me know so we can propose some steps to resolve this issue. Best, I.name: http://I.name Anvil support team ; Hi, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, I.name: http://i.name/ Anvil support team ; name, Sorry for the late reply, with finals this week it has been quite difficult to manage time effectively. To answer your question, yes, the Places365 is a popular dataset that is used in a variety of scene classification training. While the intent of using this dataset in my experiments is not direct scene classification accuracy rate, (mostly focusing on the robustness of the proposed experimental framework against adversarial attacks on a large, many class dataset, hence via the Places365 dataset), I do believe that the dataset can be used to provide salient experimental data for my research. Provided are some links regarding the dataset if you seek more information: http://places.csail.mit.edu/: http://places.csail.mit.edu/ https://github.com/CSAILVision/places365: https://github.com/CSAILVision/places365 Thank you, and I hope to hear back again. name Del Tufo, : mailto: name M. Rowan College of Engineering, Rowan University BS - Electrical and Computer Engineering Major, CS Minor ;",vdeltufo@access-ci.org,Vincent Del Tufo,Ibrahem Alshybani,Purdue University,Anvil,6,10,49,2024,2024-12-02
ATS-12853, Requested node configuration is not available,2024-12-19,2024-12-20,"Hi. Thank you so much for your help. I am attempting to run a job with 250GB of memory for 96 hours on the wholenode partition. Accoridng to https://www.rcac.purdue.edu/knowledge/anvil/run/partitions?all=true: https://www.rcac.purdue.edu/knowledge/anvil/run/partitions?all=true|smart-link this should be possible. However I keep getting: sbatch: error: Batch job submission failed: Requested node configuration is not available. I must be missing something. Could you help me identify what is wrong with the following batch file specifications? Thank you! #!/bin/bash #SBATCH -A mth240010 #SBATCH --nodes=1 #SBATCH --ntasks=1 #SBATCH --mem=250G #SBATCH --time=96:00:00 ; Hi, Thank you for contacting us. The total RAM you can get from one compute node on {{wholenode}} would be slightly less than the total amount of node RAM because there will be some RAM reserved for basic processes on the node. i.e. you will get ~245 G RAM from one single node. Please try to remove {{#SBATCH --mem=250G}} option from your job submission and let Slurm arrange the RAM for you job. Best regards, name Senior Computational Scientist Purdue Information Technology ;",bbarthel@access-ci.org,Benedikt Barthel,Guangzhen Jin,,Anvil,2,2,51,2024,2024-12-16
ATS-11747,Anvil Directory Access,2024-10-28,2025-01-03,"I am trying to get access to data in anvil using this command: cp -r /anvil/projects/tdm/corporate/isac-space-weather/ ~/isac-space-weather. When I run this, I receive a 'Permission Denied' note. Can you help me get access to this? ; Hi name, You currently don't have access to the TDM group on Anvil. It's recommended that you contact The Data Mine group to request for your account to be granted access to the group. Their contact is mailto:]. I hope this helps. Please feel free to contact us back if you have any further inquries. Best Regards, Eli name Purdue IT [https://service.purdue.edu: https://service.purdue.edu ; Hi name, Could I get confirmation that you were given access to the TDM group on Anvil? It seems as if you were given access two weeks ago. Best Regards, Eli name Purdue IT https://service.purdue.edu ; \\*\\*PRIVATE NOTE\\*\\* Closed. User was given access to the queue. ;",ajossi@access-ci.org,Andrew Jossi,Elian Rieza,Purdue University,Anvil,4,50,44,2024,2024-10-28
ATS-12974,myquota is broken on Anvil and says quotas are currently inaccessible,2025-01-03,2025-01-03,"It looks like myquota is currently broken: login01.anvil ~ : myquota Type Location Size Limit Use Files Limit Use ============================================================================== home x-dgc Home directory quotas are currently inaccessible. - - scratch anvil This file system's quotas are currently inaccessible. projects x-cis220051 This file system's quotas are currently inaccessible. Regards, Doug ; \\*\\*PRIVATE NOTE\\*\\* Hello, I hope you are doing well. Thank you for reaching out to RC Support with your question! We are actively working on addressing the issue. Rest assured, we will provide you with a response as soon as possible. Best regards, name RCAC Support ; Hello Doug, I spoke with the team and the issue should be fixed now. Can you please test and let me know if any issues persist? Best, name ; Hi name, Yes, it's working again now, thanks! Regards, Doug ; Hello Doug, Thanks for letting me know! Best, name ;",dgc,Doug Crabill,Ankitha Mallekav,Purdue University,Anvil,5,1,1,2025,2024-12-30
ATS-12979,"Anvil general filesystem issues, programs hang device wait",2025-01-03,2025-01-03,"I think the ""myquota"" issue reported on ATS-12974 is a symptom of a more serious issue with the filesystems on Anvil. I'm finding I cannot launch certain ondemand applications, and other programs, like Firefox, enter device wait and never fully launch. Regards, Doug ; Anvil is completely unusable now. All commands hang and new logins cannot be made. Regards, Doug ;",dgc@access-ci.org,Doug Crabill,Ankitha Mallekav,Purdue University,Anvil,2,1,1,2025,2024-12-30
ATS-9549,"Anvil: no free nodes, fix ""comp"" nodes, make SLURM QOS changes?",2024-07-26,2025-01-07,"A couple of times in the last two weeks, including today, we have seen periods were there were zero idle nodes in the shared and wholenode partitions of Anvil. We make heavy use of the shared partition and rarely use the wholenode partition. As described on https://access-ci.atlassian.net/browse/ATS-9184: https://access-ci.atlassian.net/browse/ATS-9184|smart-link, there are once again many nodes in the ""comp"" state (""sinfo -p shared"" currently shows 66), where they seem to be stuck and unusable. This number was in the 30s a couple of days ago but has steadily grown. A good first step would be to reset these nodes so they can be used again. Hopefully the core reason for why they are entering this ""comp"" state state can be determined and corrected. I have two other suggestions as well: Maybe consider widening the shared partition from 250 nodes to 500? The use of this partition seems to have gone up considerably in recent months. The second suggestion is to apply QOS caps on all partitions so we don't have individual users dominating the cluster as much. The current limit is 6400 cores on the shared partition, which may have been fine in Anvil's infancy, but maybe is too generous now? There don't appear to be any QOS limits at all on the wholenode partition other than walltime We are actively working on addressing the issue. Rest assured, we will provide you with a response as soon as possible. Sincerely, name ; Hello Doug Is the current 6400 cores limit reasonable for the shared partition? It seems quite high. Bottom line: at a time when we had just a handful of students using the cluster over the name, there were 0 free cores on the shared partition, which is a little scary with the semester about to start name ;",dgc,Doug Crabill,rderue,Purdue University,Anvil,6,118,30,2024,2024-07-22
ATS-12709,Issues with installing packages in R,2024-12-12,2025-01-07,"I couldn't install packages in R ; \\*\\*PRIVATE NOTE\\*\\* User joined Anvil Support Hour and he has issue installing Terra, SF, and raster packages in R. ; Hi name, Thank you for joining Anvil Support hour yesterday. Were you able to install the packages as I mentioned with R 4.1.0? Do you still have any issues? Best, name K ; Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name K ;",moyelakin@access-ci.org,Michael Oyekunle Oyelakin,Haniye Kashgarani,,Anvil,4,19,50,2024,2024-12-09
ATS-12832,Permission to access another user's files,2024-12-18,2025-01-08,"Dear Anvil team, I have two requests regarding accessing the files created by another member of our group: # Remove the all the files under /anvil/projects/x-mth240010/MW\\_nudging/ERA5/ERA5\\_Struct/ They were created by Dr. name Barthel of our group, but when he tried to remove the files, he got permission problems. # Access the files under /anvil/scratch/x-bbarthel/climatedata/30yeartrain/ Is there any way that I can get the permission to access files under this path? Thanks so much for your help Best, I.name: http://i.name/ Anvil support team ; Hi name, We do have the permission from the PI (Prof. Sapsis, cc'd) to remove/access the files on Anvil: 1. Remove the all the files under /anvil/projects/x-mth240010/MW\\_nudging/ERA5/ERA5\\_Struct/. We tried removing the files by ourselves but got permission problem. 2. I would like to request access the files under /anvil/scratch/x-bbarthel/climatedata/30yeartrain/ Thanks for your help Best, Mengze ; Thank you for the update. You should have access to the intended folder now. Let me know if otherwise. Best, I.name: http://I.name Anvil support team ; Hi, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, I.name: http://I.name Anvil support team ; The issue has been resolved. Thank you very much for your help. ---- ;",x-mwang8,Mengze Wang,Ibrahem Alshybani,Purdue University,Anvil,8,16,51,2024,2024-12-16
ATS-12903,VASP Module Not Found on Anvil CPU System,2024-12-26,2025-01-08,"I recently received an ACCESS allocation and exchanged part of my credits for use on Anvil CPU. While preparing to run simulations on Anvil, I searched for the VASP module using the module avail vasp command but could not find it installed on the system. VASP is critical for my research, and I would appreciate it if the module could be made available on Anvil. Please let me know if this can be installed or if further steps are required from my side. I'm happy to provide additional details if needed. ; Hello, The Anvil support staff will be out of office from Monday, December 23rd, 2024 to Wednesday, January 1st, 2025. During this time, Anvil computing services will continue to be available, but all staff will be on leave. Our staff members will monitor the status of all computing and data resources in an effort to ensure continuous availability. We will also monitor the ticketing system throughout the holiday period and answer critical issues and problems. Non-critical user issues and questions will be addressed beginning Thursday, January 2nd, 2025. There will also be no Anvil Support Hour consultations during this break. Scratch file purging on Anvil will continue as normal during the break, so be sure to archive your files in scratch storage during the break. This does not apply to Projects or home directories -- only scratch storage. Have a wonderful break, and we look forward to great things in the new year Best, I.name: http://I.name Anvil support team ; Thank you. : mailto: ; Just verified your VASP associated email and got you access to both vasp5 and vasp6. You should try verifying that and let me know if you still cannot access these modules. Best, I.name: http://I.name Anvil support team ; Great. Thank you, name. It took a bit of time, but I see the VASP calculation running. Thank you. Do you have any tips or best practices to request resources on Anvil CPU? ; Great. We have a user guide about Anvil, and I recommend going through it as it gives you all the information you need while using Anvil: https://www.rcac.purdue.edu/knowledge/anvil: https://www.rcac.purdue.edu/knowledge/anvil|smart-link I'll mark this ticket as resolved and you're welcome to respond if you have further questions. Best, I.name: http://I.name Anvil support team ;",vpasumarthi1@access-ci.org,Viswanath Pasumarthi,Ibrahem Alshybani,Purdue University,Anvil,10,10,52,2024,2024-12-23
ATS-12798,AnvilGPT Access Request,2024-12-17,2025-01-14,"I intent to use the service for research queries and testing the mathematical reasoning capability of LLM models. I intend to use both the UI and API. ; Hi, would you please also provide ACCESS Allocation number? Best, name ; Thank you for sharing your intent to use the service for research queries and testing the mathematical reasoning capabilities of LLM models. Please note that to continue using ANVILGPT, an access allocation number is now mandatory. However, we strongly encourage you to transition to \\*PurdueGENAI Studio\\*, which provides similar capabilities and is specifically designed for Purdue users. You can access the platform using your Purdue credentials at this link: https://genai.rcac.purdue.edu/: https://genai.rcac.purdue.edu/. ;",glin4,anonymous,Ashish Malik,Purdue University,Anvil,3,21,51,2024,2024-12-16
ATS-13042,Miss,2025-01-07,2025-01-15,"I don't have a Bypass code for my Access ID. ; \\*\\*PRIVATE NOTE\\*\\* logging in ACCESS issue, please pick it up ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id:id-9b93-4140-a425-2434ebab7596] I don't know what ""I don't have a Bypass code for my Access ID"" means, but the other note says it is a login issue so I'll give it to you and you can assign it in operations as needed. ; Hi Lapaka, ACCESS does not provide bypass codes for DUO authentication. You need to enroll in DUO with a mobile device or computer, install the DUO App, and configure authentication to use DUO Push. The steps to do so are described at [https://operations.access-ci.org/identity/manage-mfa: https://operations.access-ci.org/identity/manage-mfa . \\* Derek ; \\*\\*PRIVATE NOTE\\*\\* No enrollment in ACCESS DUO found for lpetrus as of 2025-01-15. ; Hi Derek My issue was resolved. Thank you very much. ;",lpetrus,Lapaka,Derek Simmel,,Anvil,6,7,2,2025,2025-01-06
ATS-13214,Need access to VASP on Anvil,2025-01-15,2025-01-16,"I was recently granted access to Anvil and I wish to use VASP on it. I tried emailing : mailto: about it, bet never received a reply. If I need to contact them regarding access to VASP on anvil. ; Hi, Yes, you should reach RCAC here with Anvil problem, instead of rcac-help. I will work on adding your license tomorrow and let you know. Best, name ; Thank you so much. Kind regards, name ---- ; Hi name, Now I've added you to the license. Let us know if you need more help. Best, name ;",evarghese@access-ci.org,Emin Varghese,Xiao Liu,Purdue University,Anvil,5,2,3,2025,2025-01-13
ATS-16702,Access to $PROJECT on Anvil CPU,2025-05-21,2025-05-21,"I recently got an allocation on Anvil CPU, and I am unable to access the $PROJECT directory: :~ $ ls $PROJECT ls: cannot open directory '/anvil/projects/x-phy250136': Permission denied Can you please ensure that I have full access to this folder, and that my Co-PI (username x-scheng7) also has access to this folder? Thanks very much! ; name, There was an issue of project group associated that was preventing you from accessing the project directory. This should be resolved now. Please try it and let me know if it works. Thanks, name ; All good now! Thanks so much!! ;",dhyde@access-ci.org,David Hyde,Xiao Liu,,Anvil,3,1,21,2025,2025-05-19
ATS-13222,Where to submit the progress report to get the remaining SUs from explore project?,2025-01-15,2025-01-16,"Dear Sir/Madam, I am running simulations using SUs on Anvil from the Explore project. The first half of SUs from explore project are almost used up. Where could I submit the progress report to get the remaining SUs from Explore project? Thank you in advance! Libo name ; Hello, I hope your Thursday is going well. You can submit a Supplement for the second half of your ACCESS Credits for the Explore Allocation (EES240132). When you submit the Supplement, please add a Progress Report. The Progress Report should describe how the PI's current/previous allocation was used and summarize the findings or results. You can read how to submit a Supplement here: ( https://allocations.access-ci.org/how-to#request-more-credits: https://allocations.access-ci.org/how-to#request-more-credits|smart-link ). We have also added the steps here: h3. \\*Request more Credits\\* # First, login to \\*allocations.access-ci.org\\*: http://allocations.access-ci.org/ #\\* You'll see your project information, or a list of your projects if you have multiple. # Click on the ""\\*Credits + Resources\\*"" tab. # Click ""\\*Request More Credits\\*."" # A ""\\*Manage Your Project\\*"" box will then appear. # Click ""\\*Request a Supplement\\*."" # Provide the reason you need additional credits. # Select ""\\*ACCESS Credits\\*"" as the available resource. # Upload your progress report. # Submit the form. # You will receive an email notification confirming your successful request. Once a decision has been made, you will receive a separate notification. Let us know if you have any questions along the way. If you have any questions in the future, please visit this site (https://support.access-ci.org/help-ticket: https://support.access-ci.org/help-ticket|smart-link ) and submit a ticket. name Pusateri ACCESS Allocations ;",zhanglib@access-ci.org,Libo Zhang,brandonp,,Anvil,2,2,3,2025,2025-01-13
ATS-13227,Invoking samtools module in a perl script - Purdue Anvil,2025-01-16,2025-01-17,"Hello ACCESS support, I am attempting to run attached perl script ('two\\_read\\_bam\\_combiner.pl') on Purdue Anvil. As input, the script requires the path to the program 'samtools'; however, I am unsure of the samtools module pathway, or how to assign it as a variable, to ultimately pass it on to the perl script. Is it possible to assign a module to a variable? Also attached is the .slurm script (arima\\_mapping\\_3A.sh) containing the use of the perl script. The issue seems to be the command (in red): perl $COMBINER $FILT\\_DIR/${SRA}\\_R1.bam $FILT\\_DIR/${SRA}\\_R2.bam \\*$SAMTOOLS\\* $MAPQ\\_FILTER Any help you could provide as to how to invoke the module samtools in this script would be greatly appreciated. Thanks, name ; ^arima\\_mapping\\_3A.sh] ^two\\_read\\_bam\\_combiner.pl ; Hi name, Thank you for contacting Anvil support. I'm not an expert in bio containers but have some thoughts though. The samtools is run by the singularity which means its location is not in the system rather is containerized. So could you try this in your bash script: SAMTOOLS=""/usr/bin/singularity run /apps/biocontainers/images/staphb\\_samtools:1.9.sif samtools"" and update your perl command to: perl $COMBINER $FILT\\_DIR/${SRA}\\_R1.bam $FILT\\_DIR/${SRA}\\_R2.bam ""$SAMTOOLS"" $MAPQ\\_FILTER also in your script after loading the modules put these commands: shopt -s expand\\_aliases source ~/.bashrc Also, I refer you to our userguide about samtools: https://www.rcac.purdue.edu/knowledge/biocontainers/samtools: https://www.rcac.purdue.edu/knowledge/biocontainers/samtools|smart-link I'll contact one of our experts to provide his feedback on your ticket but in the meantime, I expect you to do what I mentioned earlier. Best, I.name: http://i.name/ Anvil support team ; \\*\\*PRIVATE NOTE\\*\\* [~accountid:id:id-0296-44c2-8aaa-9a36b2662a58 , I have given the user some feedback about using samtools. Please correct me if wrong . ; Hello name, Thank you for reaching out to ACCESS support Thanks, name Lead Bioinformatics Scientist, RCAC Purdue University ; Hi name, I can't thank you enough for your help. I ran the script this morning with the wrapper and paths you provided along with your advice concerning how to partition threads. The script ran perfectly. Will the wrapper continue to be available in the future? I'm sure I'll be running this analysis many times on my different assemblies and species. Thanks again - and have a great weekend. name ---- ; Hi name, You're very welcome - glad to hear that it worked perfectly. The wrapper will be permanently available for your future use. If you ever need more such apps for any other analysis, please don't hesitate to reach out. Good luck with your analyses and have a great weekend as well! Thanks, ;",abernard@access-ci.org,Andrea Bernard,Ibrahem Alshybani,Purdue University,Anvil,7,2,3,2025,2025-01-13
ATS-13379,SU Balance Discrepancy on Purdue Anvil Cluster,2025-01-22,2025-01-22,"My request for 90,000 exchange credits was approved on January 20, and the total balance on Purdue Anvil CPU now shows 90,383. However, this is not yet reflected on the cluster, where the name balance still shows 383.5. Please check and update the balance accordingly. ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id:id-248a-43b5-a841-66499835a741 ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id who is our ticket triage person now? we may need to let name know to tag them instead of name ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id:id-248a-43b5-a841-66499835a741 - My Apologizes. I wish there was a page that we had to know the specific person to assign everything to so this didn't happen. Please let me know who the correct person is and I will update my notes. Sorry again. ; \\*\\*PRIVATE NOTE\\*\\* no worries ~accountid:id feel free to tag any of us and we can get it to the right person. FYI, name has left Purdue, so we may need to get her removed from Jira. ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id:id-ae32-498d-af6a-966ed0fbac97 I have resent the allocation AMIE package to Halcyon. You may check it later and see if it gets updated. Let me know if not. ; Hi name, This has now been fixed, as far as we can tell. Please let us know if you still any issues. Thanks! name ; Hi name, I saw your updated allocation: Recent login: Tue Jan 21 12:49 - 15:04 (02:14) from 106.0.39.174 Allocation Type name Limit name Usage name Usage name Balance Account (account) (user) ============= ==== ========== ========== ========== ========== che240218 CPU 100000.0 9616.5 9616.5 90383.5 Could you see them too? Please let us know if you need more help. Best, name ; Thank you, it's been fixed now. ; Thank you, it's been fixed now. ;",vpasumarthi1@access-ci.org,Viswanath Pasumarthi,Xiao Liu,Purdue University,Anvil,11,1,4,2025,2025-01-20
ATS-4461,Disk quota on scratch,2023-11-14,2025-01-27,"Hello, I'm working on Anvil. For the last week, I have received numerous errors regarding my disk quota. As an example, just today I got the following error: Traceback (most recent call last): ... OSError: Errno 122] Disk quota exceeded: 'outputSynths/157\\_specfem\\_C101202H' :submit-jobs-specfem $ myquota Type Location Size Limit Use Files Limit Use ============================================================================== /usr/local/bin/myquota: line 367: printf: 6.: invalid number /usr/local/bin/myquota: line 547: printf: .: invalid number /usr/local/bin/myquota: line 598: printf: 99.: invalid number /usr/local/bin/myquota: line 1121: printf: 92.: invalid number /usr/local/bin/myquota: line 1147: printf: 96.: invalid number home x-dsoergel 1.5GB 25.0GB 0% - - - scratch anvil 812.2GB 100.0TB 0,00% 999k 1,000k 0% projects x-ear170001 4.6TB 5.0TB 0% 1,016k 1,048k 0% As can be seen, I still have plenty of place on scratch (where this code is running), I use less than half my allocation. I get an error of disk quota exceeded anyway. The code doesn't generate new files, it copies existing files around (files that are much smaller than the free disk space). Has the disk quota on anvil scratch changed? Is it by project (I thought it was by User)? By the way, myquota shows warnings, is it supposed to? The number is similar to the output of name -h $SCRATCH anyway. Regards, Dorian Soergel ; Hi Dorian, Thank you for reaching out. Your personal scratch directory should not be affected by other users and there are no changes to its quota. Based on the error message and the report of {{myquota}}, it seems your scratch directory was reaching its inode limit (aka file number limit). For the moment, I can see that you only have 630k files (63% of the limit) in your scratch directory, which should resolve the issue. $ myquota x-dsoergel Type Location Size Limit Use Files Limit Use ============================================================================== home x-dsoergel 1.5GB 25.0GB 6% - - - scratch anvil 496.7GB 100.0TB 0.49% 630k 1,000k 63% projects x-ear170001 4.6TB 5.0TB 92% 1,016k 1,048k 97% Regarding the output of {{myquota}} you received, it looks odd. I would ask our experts to take a look at the issue and get back to you. A side note, if you were copying existing files around in your scratch directory to circumvent the periodical purge, that would be highly discouraged. To maintain its high performance, the scratch filesystem is intended for temporary storage of your working files. Please consider moving your files to a long-term storage space if that is the case. Thanks, name ; <\ Dorian ; Hi Dorian, Thanks for letting me know that Regards, Dorian Soergel ; Hi name, Ah and I'm not sure I understand: for what I remember, the ticket is about the strange error messages I get when I do 'myquota' not the number of files I have. Could it be related? Did I misunderstand something? As a reminder, here is what I get: |mailto::[~ $ myquota Type Location Size Limit Use Files Limit Use ============================================================================== /usr/local/bin/myquota: line 367: printf: 6.: invalid number /usr/local/bin/myquota: line 547: printf: .: invalid number /usr/local/bin/myquota: line 598: printf: 85.: invalid number /usr/local/bin/myquota: line 1121: printf: 74.: invalid number /usr/local/bin/myquota: line 1147: printf: 96.: invalid number home x-dsoergel 1.5GB 25.0GB 0% - - - scratch anvil 696.0GB 100.0TB 0,00% 850k 1,000k 0% projects x-ear170001 3.7TB 5.0TB 0% 1,013k 1,048k 0% Regards, Dorian Soergel ; Hi Dorian, I suspect that error message is due to some module/environment that you have loaded. I just tried running myquota as your account, but cannot recreate the error. $ myquota Type Location Size Limit Use Files Limit Use ============================================================================== home x-dsoergel 1.5GB 25.0GB 6% - - - scratch anvil 696.0GB 100.0TB 0.68% 850k 1,000k 85% projects x-ear170001 3.7TB 5.0TB 75% 1,013k 1,048k 97% Glad to hear that you were able to find a way around the file quotas. Let us know if we can help with something else. Best regards, name. ; Hi name, I just discussed the issue with my PI and the rest of the group. We would very much like to increase our quota, particularly in terms of file number. How does it work? Is there a procedure for this? Regards, Dorian Soergel ; Let's have a quick chat sometime next week. I am mostly available on Tue/Fri. We usually try to understand your workflow, how much quota bump you need, and for how long. Best regards, name. ; Hi name, Sorry for my lack of reply. I have been reaching out to the members of my group to find out who uses so many files and why, so that I have a case for you to explain what we need and why we need it. They still haven't all replied. I will recontact you again if they reply, else I will try do make do with the file quota I have (which is still doable). Regards, Dorian ; Hi Dorian, I am reviewing old tickets on Anvil. I'll mark this closed. Please feel free to open a new ticket if you need assistance with file quotas. Regards, name. ;",dsoergel@access-ci.org,Dorian Soergel,Amiya Maji,Purdue University,Anvil,14,315,46,2023,2023-11-13
ATS-5049,Discrepancy between SU balance on ACCESS vs Anvil,2023-12-21,2025-01-31,"Raising this ticket on behalf of allocation: OTH220004 There is a discrepancy between the name balance reported by mybalance on Anvil versus the balance on the ACCESS websites (xacct-admin & review-access). mybalance reports the following: oth220004: limit (8333), balance (223.4) oth220004-gpu: limit (7279), balance (2213.2) while the ACCESS websites report: oth220004: limit (8333), balance (7649.9) oth220004-gpu: limit (7279), balance (-302.7) Could we look into it to see which one is correct? Thanks, name ; Hi name, Thank you for sending the ticket. I've reported the issue to our experts. They are currently investigating. We would keep you updated. Thanks, name ; Hi name, Apologies for the delayed follow-up. name has been investigating the issue and he noticed a bug in the usage reporting process. Please see the related communications in https://access-ci.atlassian.net/browse/ATS-5527: https://access-ci.atlassian.net/browse/ATS-5527|smart-link. The name usage reported by the local command {{mybalance}} should be correct. Thanks, name ;",rkalyana@access-ci.org,Rajesh Kalyanam,Kevin Colby,,Anvil,3,292,51,2023,2023-12-18
ATS-6992,CAMx model not running ,2024-03-21,2025-01-27,"Hi, I have compile the CAMx model, yet when running it I am facing some errors that I need help with. I have compiled it on the following path: /anvil/projects/x-atm130003/kiarash/camx/camxv7.2/built/CAMx.v7.20.openMPI.NCF4.ifort and the run script is on the following path: /anvil/projects/x-atm130003/kiarash/camx/camxv7.2/bench\\_inp/runfiles/CAMx\\_v7.20.36.12.20160610-11.MPICH3.job\\_v2 Here is the run log: /anvil/projects/x-atm130003/kiarash/camx/camxv7.2/bench\\_inp/runfiles/slurm-4654227.out and the error is: zrates ......malloc(): unaligned tcache chunk detected malloc(): unaligned tcache chunk detected malloc(): unaligned tcache chunk detected malloc(): unaligned tcache chunk detected free(): invalid pointer malloc(): unaligned tcache chunk detected malloc(): unaligned tcache chunk detected malloc(): unaligned tcache chunk detected malloc(): unaligned tcache chunk detected forrtl: severe (174): SIGSEGV, segmentation fault occurred Image PC Routine Line Source libifcoremt.so.5 0000148A65DEF5C1 for\\_\\_signal\\_handl Unknown Unknown libpthread-2.28.s 0000148A63E8BCF0 Unknown Unknown Unknown libc-2.28.so: http://libc-2.28.so 0000148A63B4F8C6 \\_\\_libc\\_malloc Unknown Unknown libifcoremt.so.5 0000148A65E305D2 for\\_\\_get\\_vm Unknown Unknown libifcoremt.so.5 0000148A65DDC673 Unknown Unknown Unknown libifcoremt.so.5 0000148A65DDB34C for\\_\\_issue\\_diagno Unknown Unknown libifcoremt.so.5 0000148A65DEF555 for\\_\\_signal\\_handl Unknown Unknown libpthread-2.28.s 0000148A63E8BCF0 Unknown Unknown Unknown libc-2.28.so: http://libc-2.28.so 0000148A63B02ACF gsignal Unknown Unknown libc-2.28.so: http://libc-2.28.so 0000148A63AD5EA5 abort Unknown Unknown libc-2.28.so: http://libc-2.28.so 0000148A63B43CC7 Unknown Unknown Unknown libc-2.28.so: http://libc-2.28.so 0000148A63B4AFCC Unknown Unknown Unknown libc-2.28.so: http://libc-2.28.so 0000148A63B4CB54 Unknown Unknown Unknown libuct\\_xpmem.so.0 0000148A57BF716B Unknown Unknown Unknown libuct.so.0.0.0 0000148A6132A910 uct\\_md\\_mem\\_dereg Unknown Unknown libucp.so.0.0.0 0000148A6158D7B5 ucp\\_mem\\_rereg\\_mds Unknown Unknown libucp.so.0.0.0 0000148A61591FD2 Unknown Unknown Unknown Thanks, Kiarash Farzad ; Hi Kiarash, Apologies that this ticket slipped through. I've escalated it to our scientists. They would look into the issue and contact you later. Thanks, name ; Hi, This ticket was opened 2 months ago, and I got my problem solved few days back. I was expecting a faster response and help, this was not a very good experience. Could we please close this ticket? Thanks, ;",kiarash1994@access-ci.org,Kiarash Farzad,Amiya Maji,Purdue University,Anvil,3,223,12,2024,2024-03-18
ATS-7132,"I'm having issues with installation of OpenFOAM on Anvil. My understanding is that the gcc module is out of date, i.e. 11.2. Is it possible to install newer versions  13.2 or newer? I'm adding details in the description. Thank you.",2024-03-28,2025-01-27,"wmake foamyHexMesh Making dependencies: foamyHexMesh.C g++ -std=c++11 -m64 -pthread -DOPENFOAM=2306 -DWM\\_DP -DWM\\_LABEL\\_SIZE=32 -Wall -Wextra -Wold-style-cast -Wnon-virtual-dtor -Wno-unused-parameter -Wno-invalid-offsetof -Wno-attributes -Wno-unknown-pragmas -O3 -DNoRepository -ftemplate-depth-100 -frounding-math -DNDEBUG -DCGAL\\_INEXACT -DCGAL\\_HEADER\\_ONLY -I/home/x-otumuklu/OpenFOAM/ThirdParty-v2306/platforms/linux64Gcc/boost\\_1\\_74\\_0/include -I/home/x-otumuklu/OpenFOAM/ThirdParty-v2306/platforms/linux64Gcc/CGAL-4.14.3/include -Wno-old-style-cast -Wno-unused-local-typedefs -Wno-array-bounds -Wno-deprecated-declarations -fpermissive -I../conformalVoronoiMesh/lnInclude -I/home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/src/finiteVolume/lnInclude -I/home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/src/fileFormats/lnInclude -I/home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/src/surfMesh/lnInclude -I/home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/src/meshTools/lnInclude -I/home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/src/dynamicMesh/lnInclude -I/home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/src/parallel/decompose/decompositionMethods/lnInclude -I/home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/src/mesh/snappyHexMesh/lnInclude -IvectorTools -iquote. -IlnInclude -I/home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/src/OpenFOAM/lnInclude -I/home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/src/OSspecific/POSIX/lnInclude -fPIC -c foamyHexMesh.C -o /home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/build/linux64GccDPInt32Opt/applications/utilities/mesh/generation/foamyMesh/foamyHexMesh/foamyHexMesh.o g++ -std=c++11 -m64 -pthread -DOPENFOAM=2306 -DWM\\_DP -DWM\\_LABEL\\_SIZE=32 -Wall -Wextra -Wold-style-cast -Wnon-virtual-dtor -Wno-unused-parameter -Wno-invalid-offsetof -Wno-attributes -Wno-unknown-pragmas -O3 -DNoRepository -ftemplate-depth-100 -frounding-math -DNDEBUG -DCGAL\\_INEXACT -DCGAL\\_HEADER\\_ONLY -I/home/x-otumuklu/OpenFOAM/ThirdParty-v2306/platforms/linux64Gcc/boost\\_1\\_74\\_0/include -I/home/x-otumuklu/OpenFOAM/ThirdParty-v2306/platforms/linux64Gcc/CGAL-4.14.3/include -Wno-old-style-cast -Wno-unused-local-typedefs -Wno-array-bounds -Wno-deprecated-declarations -fpermissive -I../conformalVoronoiMesh/lnInclude -I/home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/src/finiteVolume/lnInclude -I/home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/src/fileFormats/lnInclude -I/home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/src/surfMesh/lnInclude -I/home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/src/meshTools/lnInclude -I/home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/src/dynamicMesh/lnInclude -I/home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/src/parallel/decompose/decompositionMethods/lnInclude -I/home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/src/mesh/snappyHexMesh/lnInclude -IvectorTools -iquote. -IlnInclude -I/home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/src/OpenFOAM/lnInclude -I/home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/src/OSspecific/POSIX/lnInclude -fPIC -Xlinker --add-needed -Xlinker --no-as-needed /home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/build/linux64GccDPInt32Opt/applications/utilities/mesh/generation/foamyMesh/foamyHexMesh/foamyHexMesh.o -L/home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/platforms/linux64GccDPInt32Opt/lib \ -L/home/x-otumuklu/OpenFOAM/ThirdParty-v2306/platforms/linux64Gcc/boost\\_1\\_74\\_0/lib64 -lconformalVoronoiMesh -lfileFormats -lsurfMesh -lmeshTools -ldecompositionMethods -ldecompose -L/home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/platforms/linux64GccDPInt32Opt/lib/dummy -lkahipDecomp -lmetisDecomp -lptscotchDecomp -lscotchDecomp -ldynamicMesh -lOpenFOAM -ldl \ -lm -o /home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/platforms/linux64GccDPInt32Opt/bin/foamyHexMesh /home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/platforms/linux64GccDPInt32Opt/lib/libconformalVoronoiMesh.so: undefined reference to {{mpfr\\_get\\_name' /home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/platforms/linux64GccDPInt32Opt/lib/libconformalVoronoiMesh.so: undefined reference to }}\\_\\_gmpn\\_com' /home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/platforms/linux64GccDPInt32Opt/lib/libconformalVoronoiMesh.so: undefined reference to {{\\_\\_gmpq\\_swap' /home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/platforms/linux64GccDPInt32Opt/lib/libconformalVoronoiMesh.so: undefined reference to }}\\_\\_gmpq\\_init' /home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/platforms/linux64GccDPInt32Opt/lib/libconformalVoronoiMesh.so: undefined reference to {{\\_\\_gmpn\\_copyi' /home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/platforms/linux64GccDPInt32Opt/lib/libconformalVoronoiMesh.so: undefined reference to }}\\_\\_gmpq\\_set\\_si' /home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/platforms/linux64GccDPInt32Opt/lib/libconformalVoronoiMesh.so: undefined reference to {{mpfr\\_set\\_q' /home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/platforms/linux64GccDPInt32Opt/lib/libconformalVoronoiMesh.so: undefined reference to }}\\_\\_gmpn\\_add\\_n' /home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/platforms/linux64GccDPInt32Opt/lib/libconformalVoronoiMesh.so: undefined reference to {{\\_\\_gmpq\\_set\\_d' /home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/platforms/linux64GccDPInt32Opt/lib/libconformalVoronoiMesh.so: undefined reference to }}mpfr\\_get\\_d' /home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/platforms/linux64GccDPInt32Opt/lib/libconformalVoronoiMesh.so: undefined reference to {{\\_\\_gmpq\\_sub' /home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/platforms/linux64GccDPInt32Opt/lib/libconformalVoronoiMesh.so: undefined reference to }}\\_\\_gmpq\\_clear' /home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/platforms/linux64GccDPInt32Opt/lib/libconformalVoronoiMesh.so: undefined reference to {{\\_\\_gmpn\\_sqr' /home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/platforms/linux64GccDPInt32Opt/lib/libconformalVoronoiMesh.so: undefined reference to }}mpfr\\_set\\_name' /home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/platforms/linux64GccDPInt32Opt/lib/libconformalVoronoiMesh.so: undefined reference to {{\\_\\_gmpn\\_sub\\_n' /home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/platforms/linux64GccDPInt32Opt/lib/libconformalVoronoiMesh.so: undefined reference to }}\\_\\_gmpq\\_mul' /home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/platforms/linux64GccDPInt32Opt/lib/libconformalVoronoiMesh.so: undefined reference to {{\\_\\_gmpq\\_div' /home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/platforms/linux64GccDPInt32Opt/lib/libconformalVoronoiMesh.so: undefined reference to }}mpfr\\_subnormalize' /home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/platforms/linux64GccDPInt32Opt/lib/libconformalVoronoiMesh.so: undefined reference to {{\\_\\_gmpq\\_set' /home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/platforms/linux64GccDPInt32Opt/lib/libconformalVoronoiMesh.so: undefined reference to }}\\_\\_gmpn\\_mul' /home/x-otumuklu/OpenFOAM/OpenFOAM-v2306/platforms/linux64GccDPInt32Opt/lib/libconformalVoronoiMesh.so: undefined reference to `\\_\\_gmpq\\_add' collect2: error: ld returned 1 exit status ; Hi Ozgur, Thank you for reaching out. We have OpenFoam preinstalled as a module on Anvil. You can get access to it using the command {{module load openfoam/8-20210316}}. Would you please let us know if it meets your needs? Warm regards, name ; Hi name, Thank you for the reply. I made changes in the source code, and I saw the installed version. Unfortunately, it is not working even with my original test case as it is an old version. Is it possible to install a new version of GCC or should I try to install it myself? Kind regards, ---- ; Hi Ozgur, Apologies for the delayed response. I would escalate your ticket to our scientists. They'll take a look at the issue and contact you later. Thanks, name ; Hi, I am reviewing old tickets on Anvil. Do you still need assistance with this? Regards, name. ; Hi name, I've resolved the issue. Sincerely, ---- ;",otumuklu@access-ci.org,Ozgur Tumuklu,Amiya Maji,Purdue University,Anvil,6,218,13,2024,2024-03-25
ATS-12996,How to install R packages,2025-01-04,2025-01-31,"Hi Anvil staff, I was just wondering how to install specific packages in R, where I can install them into a specific directory? For example, I was trying: install.packages(""scatterpie"", lib = ""/home/x-lhennelly/Rpackages"") with making the directory {{/home/x-lhennelly/Rpackages}} beforehand, but I can't seem to get scatterpie to download, as it says ""Error in library(scatterpie, lib.loc = ""/home/x-lhennelly/Rpackages"") there is no package called 'scatterpie'"". Otherwise, I wanted to install the packages: library(maps), library(mapdata), and library(rworldmap). Thanks! --name, Thank you for reaching RCAC for support. I tried installing ""scatterpie"" in my own space and it gave me some errors, which I am now trying to resolve. It looks like the way that you are installing the packages is correct, with the lib and the lib.loc specified. However, it seems as though Anvil is missing some system packages that is making the installation of ""scatterpie"" fail. Thank you for your patience, name, Thank you for reaching RCAC for support. I tried installing ""scatterpie"" in my own space and it gave me some errors, which I am now trying to resolve. It looks like the way that you are installing the packages is correct, with the lib and the lib.loc specified. Are you tied to the 4.1.0 version of R? Or would you be ok with using the 4.4.1 version of R. I was able to install ""scatterpie"" on 4.4.1, but ran into errors on the 4.1.0 version. To use the 4.4.1 version of R, you just use the command 'module load r/4.4.1'. Thank you for your patience, name, Since I haven't heard from you in a while, I am tentatively marking this ticket as resolved. If you are still running into issues, please respond to this ticket within 7 days. Otherwise, you can always open a new ticket. Thanks, name ;",lhennelly@access-ci.org,Lauren Hennelly,Michael Carlson,Purdue University,Anvil,4,20,1,2025,2024-12-30
ATS-7607,WARNING: There was an error initializing an OpenFabrics device.,2024-04-18,2025-01-27,"I am getting WARNING: There was an error initializing an OpenFabrics device and the runs are becoming very slow. I'm also getting this suggestion ""a377.anvil.rcac.purdue.edu:3279285 common\\_ucx.c:364 Warning: UCX is unable to handle VM\\_UNMAP event. This may cause performance degradation or data corruption. Pls try adding --mca opal\\_common\\_ucx\\_opal\\_mem\\_hooks 1 to mpirun/oshrun command line to resolve this issue."" This is occurring when i load openmpi/4.0.6 and intel modules and submit a job using ""srun -n $SLURM\\_NTASKS exe"" ; Hi name, Thank you for reaching out. To help us investigate, would you please share the ID of the problematic job? Warm regards, name ; Hello name, This is the job ID: 4864168 Thanks, name. ; Hi name, Thanks for the info ;",x-vpulleti@access-ci.org,Venkatesh pulletikurthi,Amiya Maji,Purdue University,Anvil,8,203,16,2024,2024-04-15
ATS-13070,Anvil Black Hole Node,2025-01-08,2025-01-31,"I tried canceling a job when it unexplainedly failed after about 20 minutes of running and noticed that it was stuck on CG status, showing one node still in use. I ran the following, scontrol show job and it says that the job is stuck on, NodeList=a343 I believe this is a name hole node that needs attention. Thank you! ; Hi, Thank you for reporting the issue. Yes it may take a good while to terminate the process on one node especially when the node is busy. From what I can see now, this should have been resolved. Best regards, name Senior Computational Scientist Purdue Information Technology ;",aniemiera@access-ci.org,Alexis NieMiera,Guangzhen Jin,Purdue University,Anvil,2,18,2,2025,2025-01-06
ATS-13338,myquota on Anvil does not work properly,2025-01-21,2025-01-30,"The {{myquota}} command on Anvil does not print the relevant information properly. Here is an example: :tests $ myquota Type Location Size Limit Use Files Limit Use ============================================================================== (standard\\_in) 1: syntax error FILEH (standard\\_in) 1: syntax error FILELIMITH (standard\\_in) 1: syntax error FILEH (standard\\_in) 1: syntax error FILELIMITH (standard\\_in) 1: syntax error FILEH (standard\\_in) 1: syntax error FILELIMITH (standard\\_in) 1: syntax error FILEH (standard\\_in) 1: syntax error FILELIMITH home x-kkeshavarz 2.2MB 0KB % - - - scratch anvil idKBblockUsageKB 0% k k 0% projects x-cis240640 idKBblockUsageKB 0% k k 0% projects x-ees240058 idKBblockUsageKB 0% k k 0% projects x-ees240082 idKBblockUsageKB 0% k k 0% ; Hi name, I am not able to recreate this issue as myquota is working for me. Maybe there is something in the tests directory you are in that is causing myquota to not work? There has been a known issue with myquota recently but it was supposedly resolved. I'll reach out and see what the status is so I can get that information to you. Also, if you wanted to know your current quotas, I was able to check from my machine: {{myquota x-kkeshavarz}} {{Type Location Size Limit Use Files Limit Use}} {{==============================================================================}} {{home x-kkeshavarz 221.6MB 25.0GB 0.87% - - - }} {{scratch anvil 0KB 100.0TB 0% 0k 1,000k 0.00%}} {{projects x-cis240640 0KB 5.0TB 0% 0k 1,048k 0.00%}} {{projects x-ees240058 4.9TB 5.0TB 99% 0k 1,048k 0.04%}} {{projects x-ees240082 16.6TB 160.0TB 10% 276k 1,048k 26%}} Hope this helps! Best regards, name Purdue RCAC Support ; Hi name, Thank you for the information. I checked the command in other directories (home amongst others) and still facing the same problem; not sure where the issue is. My .bashrc and .bash\\_profile do not contain anything out of ordinary either. Cheers, name ; Hi, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name Purdue RCAC Support ;",kkeshavarz,Kasra,yang2383,Purdue University,Anvil,4,8,4,2025,2025-01-20
ATS-13456,"Request access to VASP, license for verification provided by my advisor Emmanouil Kioupakis",2025-01-24,2025-01-31,"Hi, I need to request access to all available VASP5 and 6, the license for verification provided by my advisor Emmanouil Kioupakis (: mailto:) who should have all the licenses. ; Hello, I hope you are doing well. Thank you for reaching out to RC Support with your question! We are actively working on addressing the issue. Rest assured, we will provide you with a response as soon as possible. Best regards, name RCAC Support ; Hi name, Thanks for reaching out! In order to add you to our VASP group. I would need to know your email address associated with your VASP license. I do not need your supervisor's info unless we need to add your supervisor as well. Your supervisor should already add you to your VASP license, and I need your email which you used for VASP license. Your email will be used to validate your VASP license on our end. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; My email: ; Hi name, Thank you for your reply! My email with the VASP license should be: : mailto:. ; Hi name, You have been added to vasp5 and vasp6 groups on Anvil. Your membership will be ready within a few hours. Please check our user guide for VASP calculations on Anvil. https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/vasp: https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/vasp|smart-link Regards, name ;",yliu10,Yujie Liu,Nannan Shan,Purdue University,Anvil,6,6,4,2025,2025-01-20
ATS-13637,Apply for Resouces on Purdue Anvil,2025-01-31,2025-01-31,"Dear there, I am writing to apply for resources on Purdue Anvil. Would you please help to add the Anvil resource to our allocation under Project EES210015? We propose to use \\*anvi'o\\* for microbiome research and recognized it has been installed and well-documented on Purdue Anvil (https://access-sds.ccs.uky.edu:8080/?software=anvio: https://access-sds.ccs.uky.edu:8080/?software=anvio). If we can directly run anvi'o on Anvil, it will avoid compiling the program on Expanse, which is the main resource we are using. Please find the project description: We are assembling MAGs (metagenome assembled genomes) from a 6x coverage metagenomic dataset of water and sediment samples from Mobile name, Alabama. These samples are part of a microbial source tracking project to improve community and ecosystem health in coastal Alabama. Thanks, Zhilong ; Hello, I hope your Friday is going well. An Exchange Request is where you exchange your ACCESS Credits for time on a resource. You can read how to submit an Exchange Request here: ( https://allocations.access-ci.org/how-to#exchange-credits: https://allocations.access-ci.org/how-to#exchange-credits|smart-link ). We have also added how to submit an Exchange Request here: \\_Exchange Credits for Resources\\_ # First, login to \\*allocations.access-ci.org\\*: http://allocations.access-ci.org/ #\\* You'll see your project information, or a list of your projects if you have multiple. # Click on the ""\\*Credits + Resources\\*"" tab. #\\* You can request multiple resources within one exchange. # Click ""\\*Add a resource to your exchange.\\*"" #\\* The list of available resources will then populate. # Select a resource. #\\* A required resource (oftentimes a storage resource) will automatically populate along with your selection. # Enter the amount of units you'd like to request. # Enter a brief justification of why you're requesting the resource(s). # Click ""\\*Submit for Approval\\*."" # A pop-up will then appear to ""\\*Complete Your Exchange\\*."" # Confirm the amounts being requested are correct, then click ""\\*Submit.\\*"" # You will receive an email notification confirming your successful request. Once a decision has been made, you will receive a separate notification. Let us know if you have any questions along the way. If you have any questions in the future, please visit this site (https://support.access-ci.org/help-ticket: https://support.access-ci.org/help-ticket|smart-link ) and submit a ticket. name Pusateri ACCESS Allocations ; Thank you. I have added the resource and submitted the exchange request. Thanks! ;",liuz@access-ci.org,Zhilong Liu,brandonp,Purdue University,Anvil,3,1,5,2025,2025-01-27
ATS-6987,Open Fabrics Error when running NEK5000,2024-03-21,2025-02-04,"We have run on another machine that has and openMPI installed and we do not get the OpenFabrics Error below, but on Anvil we are getting the following errors Loading the following modules: module load intel/19.1.3.304 module load openmpi module load cmake Below is a sample of the error I am getting when running the case: WARNING: There was an error initializing an OpenFabrics device. h2. Local host: a380 Local device: mlx5\\_0 ---- WARNING: There was an error initializing an OpenFabrics device. h2. Local host: a384 Local device: mlx5\\_0 ---- WARNING: There was an error initializing an OpenFabrics device. h2. Local host: a384 Local device: mlx5\\_0 ---- WARNING: There was an error initializing an OpenFabrics device. h2. Local host: a384 Local device: mlx5\\_0 ---- WARNING: There was an error initializing an OpenFabrics device. h2. Local host: a384 Local device: mlx5\\_0 ---- WARNING: There was an error initializing an OpenFabrics device. h2. Local host: a384 Local device: mlx5\\_0 ---- WARNING: There was an error initializing an OpenFabrics device. h2. Local host: a384 Local device: mlx5\\_0 ---- WARNING: There was an error initializing an OpenFabrics name ; Hi name, Thank you for reaching out. To help us investigate the issue, would you please share the IDs of the problematic jobs? Did you see the error in all of your jobs or some of them? Warm regards, name ; Hi name, I am so sorry for the delay. Below are some IDs from jobs that have had the OpenFabrics error. So far, this error has occurred on every job for this project. I tried to view the job history in slurm using sacct, but nothing showed up. I looked at the logfile for the jobs but couldn't find any specifics about the job ID there either. In my javascript.sh, I have the --mail flag for my email account, but I haven't gotten slurm emails since March 10. I have run several jobs since then. I'm sorry I couldn't be more helpful Best regards, name ; I just started a new job and got the same errors. The job ID is: 4738003 ; Hi name, Thanks for sharing the information. I've escalated your ticket to our experts. They would look into the issue and contact you later. Warm regards, name ; Hi, name. Would you please take a look at this ticket? Thanks -name compile\\_script https://ssl.gstatic.com/docs/doclist/images/icon\\_10\\_generic\\_list.png ; Hi name, Thank you for sharing these. I did not see any module loads in the compile script. Which modules did you load to build the application? Can you please share how I can reproduce the run? Best regards, name. ; Hi name, Maybe I am misunderstanding, but I don't believe I needed to load any additional modules to build the application. To run a job, this is the script I use: #!/bin/bash -l #SBATCH --nodes=16 #SBATCH --ntasks-per-node=128 #SBATCH --time=24:00:00 #SBATCH --export=NONE #SBATCH --mail-user=[: mailto: #SBATCH --mail-type=ALL #SBATCH -e error\\_file\\_%j.e #SBATCH -o logfile #SBATCH -A PHY240099 #SBATCH -p wholenode module purge module load intel/19.1.3.304 module load openmpi module load cmake module list srun -n $SLURM\\_NTASKS ./nek5000 > logfile 2>&1 This uses openmpi 4.1.6 ; name, You need to load the same set of modules as in your job script when compiling the application. If you did not load the modules during compilation, that may explain the error messages. Please try loading the same set of modules, recompile your application from a fresh copy, then try running again. Best regards, name. ; Hi name, I am sorry for the confusion. I did load the modules manually when I compiled the application. Best, name ; Hi name, I am reviewing old tickets on Anvil. Do you still need assistance with this issue? Regards, name. ; Closing stale ticket. Please submit a new issue if the problem persists. Regards, name. ;",nziems@access-ci.org,Nathan Ziems,Amiya Maji,Purdue University,Anvil,18,229,12,2024,2024-03-18
ATS-11864,Job submission errors on Anvil,2024-10-31,2025-02-06,"I got errors for submitting jobs on Anvil from time to time. The error message is ""sbatch: error: Batch job submission failed: Socket timed out on send/recv name"". ; Hello, I hope you are doing well. Thank you for reaching out to RC Support with your question Now I have a new problem of the job not continuing (no output), while it is also not killed. Here is the details of the job that I have the problem: ""JobId=8364055 JobName=vasptest UserId=x-johan28(7940462) GroupId=x-dmr970008(7001336) MCS\\_label=N/A Priority=33819 Nice=0 Account=dmr970008 QOS=cpu JobState=RUNNING Reason=None Dependency=(null) Requeue=1 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0 RunTime=00:53:25 TimeLimit=2-00:00:00 TimeMin=N/A SubmitTime=2024-11-07T14:00:15 EligibleTime=2024-11-07T14:00:15 AccrueTime=2024-11-07T14:00:15 StartTime=2024-11-07T14:00:36 EndTime=2024-11-09T14:00:36 Deadline=N/A PreemptEligibleTime=2024-11-07T14:00:36 PreemptTime=None SuspendTime=None SecsPreSuspend=0 LastSchedEval=2024-11-07T14:00:36 Scheduler=Backfill Partition=wholenode AllocNode:Sid=login05:2262667 ReqNodeList=(null) ExcNodeList=(null) NodeList=a731 BatchHost=a731 NumNodes=1 NumCPUs=128 NumTasks=128 CPUs/Task=1 ReqB:S:C:T=0:0:\\*:\\* ReqTRES=cpu=128,mem=245400M,node=1,billing=128 AllocTRES=cpu=128,mem=245400M,node=1,billing=128 Socks/Node=\\* NtasksPerN:B:S:C=0:0:\\*:\\* CoreSpec=\\* MinCPUsNode=1 MinMemoryNode=0 MinTmpDiskNode=0 Features=(null) DelayBoot=00:00:00 OverSubscribe=NO Contiguous=0 Licenses=(null) Network=(null) Command=/anvil/projects/x-dmr970008/johan28/ACCESS\\_benchmark\\_test/PBE\\_relaxation/Li7La3Zr2O12/enum\\_0/step-1/job.cmd WorkDir=/anvil/projects/x-dmr970008/johan28/ACCESS\\_benchmark\\_test/PBE\\_relaxation/Li7La3Zr2O12/enum\\_0/step-1 StdErr=/anvil/projects/x-dmr970008/johan28/ACCESS\\_benchmark\\_test/PBE\\_relaxation/Li7La3Zr2O12/enum\\_0/step-1/myjob.e8364055 StdIn=/dev/null StdOut=/anvil/projects/x-dmr970008/johan28/ACCESS\\_benchmark\\_test/PBE\\_relaxation/Li7La3Zr2O12/enum\\_0/step-1/myjob.o8364055"" Best, Zhuohan ;",johan28@access-ci.org,Zhuohan Li,Ankitha Mallekav,Purdue University,Anvil,4,71,44,2024,2024-10-28
ATS-13178,Access to Anvil (Purdue),2025-01-13,2025-02-13,"Hi ACCESS and Purdue, Can you tell me how to set up an account on RCAC, Purdue? I just transfer some credits to Anvil for scaling tests. I may have an username ``x-pxdaniel'' at RCAC, but I never used it before. Thanks, name ; Hi ACCESS, is there any update on this ticket? Thanks, ; \\*\\*PRIVATE NOTE\\*\\* Hi name, Thank you for contacting RCAC Support ; Thank you, name, No worries, I appreciate your information and the response. I think the ticket can be closed now. ---- ;",pxdaniel@access-ci.org,Chang Hsin Chen,yang2383,Purdue University,Anvil,5,24,3,2025,2025-01-13
ATS-13245,Help with installing a program through apptainer  on Anvil,2025-01-16,2025-02-03,"I had a very helpful session but I'm still running into an issue trying to install a program through an apptainer. I've included screenshots of the error I got. It seems to be having an issue finding a specific file. I searched for it but that file does not pop up. Do I clean out everything and start the installation process over? ; Hi Sedinam, Thank you for reaching out. I'll take some time to look into this issue and will get back to you by Tuesday, or sooner if possible. Thank you for your patience. Best, h6. name, PhD (she/her) h6. Senior Computational Scientist h6. RCAC - Purdue University ; Hi Sedinam, Thank you for your patience while I look into this issue. I have tried a few things on my end using the Aspect documentation, and what you can do is pull the Aspect Docker image as a Singularity/apptainer image: git clone https://github.com/geodynamics/aspect.git cd aspect singularity pull docker://geodynamics/aspect Then, you will have {{aspect\\_latest.sif}} in your Aspect directory, and you will need to do the following: mkdir build cd build singularity exec -e ../aspect\\_latest.sif cmake .. singularity exec -e ../../aspect\\_latest.sif make I was able to compile Aspect without any issues, and you should be able to install it without any problems. When working with aspect, you will need to use ""{{singularity exec -e ../aspect\\_latest.sif }}"" instead of {{docker run -it }} which is mentioned in aspect documentation. You cannot run docker on clusters (as you need to be admin on the machine to be able to use docker) instead you will need to use singularity/apptainer. Let me know if you need any further assistance. Best, name K ; Hi name, Thank you for the instructions. I will try that in the next day or two and reach out if I have any questions! Best, Sedinam ---- ; Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name K ;",sbiasseybogart@access-ci.org,Sedinam Biassey-Bogart,Haniye Kashgarani,Purdue University,Anvil,6,13,3,2025,2025-01-13
ATS-13296,error when start rstudio session vio openon demand,2025-01-18,2025-02-05,"First apologies, I am just starting to learn all of this so this is probably my fault but since it started after the maintenance yesterday… I was able to access RStudio earlier this week but today I am receiving a error when I try to start a session: Could not connect to the R studio session on RStudio Server. Unable to connect to service (1) I looked at the file rsession.log and see this: Launching rsession... + exec rsession --r-libs-user '' -u x-dtatem --session-use-secure-cookies 1 --session-root-path / --session-same-site 0 --session-use-file-storage 1 --launcher-token BA833A09 --r-restore-workspace 2 --r-run-rprofile 2 rsession: /apps/spack/anvil/apps/gcc/11.2.0-gcc-8.4.1-qjtdkvs/lib64/libstdc++.so.6: version `GLIBCXX\\_3.4.30' not found (required by /home/x-dtatem/miniconda3/lib/R/lib/../../libicuuc.so.73) ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id:id-4225-4671-baf9-1f68f6590d0c] Please take a look. ; I have been able to solve this issue but have many more…. I am not certain but i believe this may have been caused by some of the updates performed last week. I reinstalled a few things and i can now run rstudio. I have a zoom appointment this afternoon 1`/23/25. I am not sure if you are able to help with specific issues but I am trying to install the rethinking library in Rstudio which requires cmdstanr and rstan and have not been able to succeed. If you could provide any guidance I would appreciate it. ; Hi name, Nice talking to you during Anvil support hour. Please share any other issues you might have. Best, name, PhD (she/her) Senior Computational Scientist RCAC - Purdue University ; Hi name, Thank you so much for your help and patience! While I made progress I am now stuck again. In the process of installing the rethinking package in rstudio it gets stuck with the following error regarding the fontconfig freetype2 library I am not sure if these are things i can install or not. any guidance would be appreciated. Output: \\* installing \\*source\\* package 'systemfonts' ... \\*\\* package 'systemfonts' successfully unpacked and MD5 sums checked \\*\\* using staged installation Package fontconfig was not found in the pkg-config search path. Perhaps you should add the directory containing `fontconfig.pc' to the PKG\\_CONFIG\\_PATH environment variable Package 'fontconfig', required by 'virtual:world', not found Package 'freetype2', required by 'virtual:world', not found Using PKG\\_CFLAGS= Using PKG\\_LIBS=-lfontconfig -lfreetype ; ANTICONF ; Configuration failed to find the fontconfig freetype2 library. Try installing: \\* deb: libfontconfig1-dev (Debian, Ubuntu, etc) \\* rpm: fontconfig-devel (Fedora, EPEL) \\* csw: fontconfig\\_dev (Solaris) \\* brew: freetype (OSX) If fontconfig freetype2 is already installed, check that 'pkg-config' is in your PATH and PKG\\_CONFIG\\_PATH contains a fontconfig freetype2.pc file. If pkg-config is unavailable you can set INCLUDE\\_DIR and LIB\\_DIR manually via: R CMD INSTALL --configure-vars='INCLUDE\\_DIR=... LIB\\_DIR=...' ; ERROR MESSAGE ; :1:10: fatal error: fontconfig/fontconfig.h: No such file or directory compilation terminated. ; ERROR: configuration failed for package 'systemfonts' \\* removing '/home/x-dtatem/R/x86\\_64-pc-linux-gnu-library/4.1/systemfonts' Warning in install.packages : installation of package 'systemfonts' had non-zero exit status The downloaded source packages are in '/tmp/Rtmpl0pHVu/downloaded\\_packages' ---- ; Hi name, Thank you for reaching out. I tried the installation on my side, and the issue you're encountering is because of the ""devtools"" package you're installing. Devtools is installed globally on Anvil, so you don't need to reinstall it. If you retry the installation with the following lines, it should work: remotes::install\\_github(""stan-dev/cmdstanr"") cmdstanr::install\\_cmdstan() install.packages(c(""coda"",""mvtnorm"",""loo"",""dagitty"",""shape"")) devtools::install\\_github(""rmcelreath/rethinking"") If you still encounter the systemfonts error, try loading the freetype, fontconfig, and font-util modules by: name.setenv(MODULESHOME = ""/opt/lmod/lmod"") source(file.path(name.getenv(""MODULESHOME""), ""init/R"")) module(""use"", ""/opt/spack/cpu/Core/"") module(""load"",""freetype"") module(""load"",""fontconfig"") module(""load"",""font-util"") Then retry the installation. remotes::install\\_github(""stan-dev/cmdstanr"") cmdstanr::install\\_cmdstan() install.packages(c(""coda"",""mvtnorm"",""loo"",""dagitty"",""shape"")) devtools::install\\_github(""rmcelreath/rethinking"") Let me know if you need any further assistance. Best, name K ; Thank you that worked! But today I can't access rstudio server. when i launch the server from the ondemand interface i get \\*Not Found\\* The requested URL was not found on this server. URL [https://ondemand.anvil.rcac.purdue.edu/rnode/a923/6315/auth-do-sign-in: https://ondemand.anvil.rcac.purdue.edu/rnode/a923/6315/auth-do-sign-in session ID \\*Session ID:\\* e7241653-bbbf-42e0-bc75-17cd781e9645: https://ondemand.anvil.rcac.purdue.edu/pun/name/dashboard/files/fs/home/x-dtatem/ondemand/data/name/dashboard/batch\\_connect/name/rstudio/output/e7241653-bbbf-42e0-bc75-17cd781e9645 \\*Host:\\* >\\_a923 any thoughts? name ---- ; Hi name, Do you still have issue accessing rstudio? One thing you can do when this happens is to remove ~/.cache directory and start a new session. Let me know if the issue persists. Best, name K ; Thanks, it seems to have resolved itself. name ---- ; Thanks for letting me know. I will mark the ticket as resolved now. Best, name K ;",dtatem@access-ci.org,David Tatem,Haniye Kashgarani,Purdue University,Anvil,10,13,3,2025,2025-01-13
ATS-13772,Request to Add VASP License to ANVIL Cluster,2025-02-05,2025-02-06,"Dear Sir/Madam, I am name, a visiting scholar at Purdue University under the Purdue-India Overseas Visiting Doctoral Fellowship program. I am working in the School of Materials Engineering under the supervision of Professor name. I hold a VASP license through my parent institute in India, with license number 23-0006 (\\*email address:\\* \\*\\*: mailto:). I kindly request that this license be added to the \\*ANVIL\\* clusters. Thank you for your assistance. Best regards, name Username: x-ksamanta1 ; Hi name, I just added your license to x-ksamanta1, and it may take some time to come into effect. Please try it later and let us know if you need more help. Best, name ;",ksamanta1@access-ci.org,Kushal Samanta,Xiao Liu,Purdue University,Anvil,2,2,6,2025,2025-02-03
ATS-13547,“AnvilGPT Access Request”,2025-01-28,2025-02-11,"I'm hoping to do some comparisons between this inference service and the JS2 one and the system we are setting up at the University of Arizona. I also am in conversations with the group at my institution known as AI core and would like to test it out before referring some of their staff to take a look here for inspiration. The last point is I'm hoping to participate in the NAIRR EAGER award which aims to skill up Campus Champions in various AI topics, so having access to several inference systems would be useful for that. TRA220030 is my ACCESS allocation ; \\*\\*PRIVATE NOTE\\*\\* This somehow ended up with IU set as the RP. Changing to Purdue. ; \\*\\*PRIVATE NOTE\\*\\* Hi, Thank you for contacting us. We will get back to you as soon as we have the answer. Best regards, name Purdue RCAC Support ; Just let me know if I can provide more information. ; Hi name, Just waiting on conformation from the AnvilGPT team. I will let you know the status and if you have access, as soon as I get it Best regards, name Purdue RCAC Support ; Hi, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name Purdue RCAC Support ;",baylyd,Devin Bayly,yang2383,Purdue University,Anvil,8,11,5,2025,2025-01-27
ATS-13777,Simulation runs are failing with common error,2025-02-05,2025-02-07,"I have been running simulations on Anvil with a parallelized code. I compile this in my directory /home/x-jsullivan1/WORK2/arepo. I am currently getting an error in my runs (directory /anvil/scratch/x-jsullivan1/CosmoArkABHRuns/Run\\_02\\_05\\_25\\_1) that seem related to the system architecture. These are in the output\\_run\\_01\\_31\\_3 and error\\_run\\_01\\_31\\_3 files. To expand on what I have been running in case it will help, the code that produced this error has a slightly different configuration that of other recent runs (i.e. the run in /anvil/scratch/x-jsullivan1/CosmoArkABHRuns/Run\\_01\\_31\\_25\\_1). However, I had previously successfully compiled and ran the code (in October of last year) that is now failing so I know the issue is not the configuration or parameter files themselves. ; Hi, I checked the error file which seems difficult to understand what went error. Could you please also share your workflow? Best, name ; Hello, I recompiled and re-ran today (with the same method) and it seems to be running smoothly. I am not sure if this was related to maintenance or something with the machine but it is resolved. Thank you. Best, name ; Great! Let us know if you need more help. Best, name ;",jsullivan1@access-ci.org,James Sullivan,Xiao Liu,,Anvil,4,3,6,2025,2025-02-03
ATS-9437,Installation Request for NVIDIA Peer Memory (peermem) and GDRCopy Packages on Purdue Anvil,2024-07-21,2025-02-11,"Dear Support Team, I am requesting the installation of the NVIDIA Peer Memory (peermem) and GDRCopy packages on the Purdue Anvil system. These packages are required for my research work. Thank you for your assistance. ; Hello name ; Hi name, This will entail some validation of the relevant kernel module with Anvil. We will have get back to you following that. Best, -name ; Hi name, Sure. Thanks for looking into this. Best -name ; Hi name, I've just taken over this ticket again and wanted to ask if you still require assistance with the issue you described here. Best, -name ; Hi name, I still require NVIDIA Peer Memory (peermem) and GDRCopy packages on the Purdue Anvil system. Please let me know if you have already installed them. Thanks -name ; Hello name, Could you please provide some updates on the ticket? Thanks -name ; Hi name, Thank you for your patience. Our engineering team has determined that {{peermem}} and {{GDRcopy}} can go into service on Anvil {{g}} nodes during upcoming maintenance. Anvil {{h}} nodes currently have both installed already, and they will be immediately available when those nodes go into service. I will go ahead and tentatively mark this ticket as resolved, but please let me know if you have any additional questions or concerns. Best, -name ; \\*\\*PRIVATE NOTE\\*\\* These modules are already on {{h}} nodes and will be set up on {{g}} nodes at least in the next maint. ;",gkuncham@access-ci.org,Goutham Kalikrishna Reddy Kuncham,Charles Christoffer,Purdue University,Anvil,9,147,29,2024,2024-07-15
ATS-13431, Issue with a job I submitted to Anvil,2025-01-23,2025-02-13,"I'm experiencing an issue with a job I submitted to Anvil. The job runs for a few hours but consistently fails with the error message, \\_""couldn't find connection.""\\_ Upon resubmission, it runs again for a few hours but ultimately returns the same error. This has happened more than ten times for the same job. I have attended the office hour and I requested to submit a ticket regarding my issue. ; Hi name, Thank you for reaching out and thanks for joining Anvil Support Hour. I will spend some time on this issue and will keep you updated when I found a solution. Thanks for your patience. Best, name K ; Hi name, As you might know from name, I am still trying to figure out the issue and haven't been able to understand what's going on. I will get back to you once I find out. In the meantime, can I ask where I can find your Gilbreth script? Since everything on Gilbreth is fine, this might give me some insights. Best, name K ; Hi name, Since we were able to resolve your script's issue with name, I will mark this ticket as resolved. But feel free to reach out again if there is any other issues. Best, name K ;",moyelakin@access-ci.org,Michael Oyekunle Oyelakin,Haniye Kashgarani,Purdue University,Anvil,4,16,4,2025,2025-01-20
ATS-13465,User removed from resource yet still running jobs against allocation,2025-01-24,2025-02-11,"Hello, I am an allocation manager of ACCESS project CIS230083. We have removed one of our users, name Chapparapu, from our ACCESS project, as he has applied for and received his own, CIS240662. Despite removing him from our ACCESS project, name has been able to consume ~150 of our allocation's (cis230083-gpu) SUs at Purdue's Anvil GPU cluster, which has now twice depleted the balance we maintain for research facilitation. Could you please take a look and check why he still has access to our allocation? This is preventing us from replenishing our balance on Anvil GPU out of fear of it being misallocated. ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id:id-248a-43b5-a841-66499835a741 - I am not seeing this person on their allocation. I am assuming this is an Anvil issue and not an ACCESS issue. ; Hello, I hope you are doing well. Thank you for reaching out to RC Support with your question! We are actively working on addressing the issue. Rest assured, we will provide you with a response as soon as possible. Best regards, name RCAC Support ; Hello name, Thank you for your patience. We are investigating the issue. Would you like us to try removing that user from our side? Best regards, name RCAC Support ; Hi name, Thank you for checking in, it would be helpful if you could remove the user from our allocation cis230083-gpu . It is my understanding that the user should have access to allocations cis240662 and cis240662-gpu tied to their own ACCESS project. Best, ---- ; Hi, Please allow me to chime in and assist. Yes we did notice something odd happened in the backend that after you removed user {{x-achapparapu}} out of your allocation {{cis230083-gpu}} but this user was still able to continue using the allocation SUs. We have fixed this issue for you allocation so now this user has been removed from allocation. I also went ahead and refunded the total 201 SUs consumed by this user after the removal happened. Please allow a couple of days to propagate those changes to the system. Let me know if you have other concerns. Best regards, name Senior Computational Scientist Purdue Information Technology ;",bkeene@access-ci.org,Benjamin Keene,Guangzhen Jin,Purdue University,Anvil,6,13,4,2025,2025-01-20
ATS-13487,Gromacs version on Anvil,2025-01-25,2025-02-12,"Hello, The Gromacs version installed on Anvil is an older gromacs/2021.2 version. Is there any plan for installing a newer version? I understand that I can always install any version of my choice on my home though. Thank you so much! Regards, Pritam ; Hi Pritam, Thanks for reaching RCAC. I don't aware an update for now. What version do you need? Is there a specific feature that the old version doesn't have? I will bring the installation up for group discussion, but it may need a while. Please don't hesitate to install for your own usage if you need in a hurry. Best, name ; Hi name, Thank you for your reply. There is no rush but it would be great to see a newer version installed eventually. The current version is 4 years old and there have been some major improvements in the last few releases. Thanks again for your help. Regards, Pritam ; Hi Pritam, The most recent version is 2024, which is only one year old. Please give it a try, and let us know if it can meet your requirements. Best, name ; Hi name, Version 2024 is good. I think they will have a new version coming soon in February. Regards, Pritam ; \\*\\*PRIVATE NOTE\\*\\* Thanks for the update. Please let us know if you need more help. Best, name ;",pganguly@access-ci.org,Pritam Ganguly,Xiao Liu,Purdue University,Anvil,6,13,4,2025,2025-01-20
ATS-13696,Unable to SSH into Purdue Anvil RCAC Cluster,2025-02-03,2025-02-10,"I'm an undergraduate student at the University of Illinois at Chicago. My ACCESS ID is cwilliams6. After perfectly following the instructions to generate SSH keys and everything according to the instructions in the following links, RCAC - Knowledge Base: Anvil User Guide: SSH Keys: https://www.rcac.purdue.edu/knowledge/anvil/access/login/sshkeys RCAC - Knowledge Base: Anvil User Guide: Logging In: All topics: https://www.rcac.purdue.edu/knowledge/anvil/access/login?all=true I am unfortunately still prompted to enter a password, and this is while the ""authorized\\_keys"" text file exists in the folder. Thus I am unable to SSH into the Anvil cluster even after following all of the instructions correctly. ; Hi name, Thank you for reaching out. Could you please let me know how you're setting up the SSH key? You need to create the SSH key using ssh-keygen in your local computer and them copy the content of key-name.pub file to your ~/.ssh/authorized\\_keys file. Let me know if there's an issue. Best, name K ; Hello there, I managed to get the issue resolved. Thanks a lot! Kind regards, name : mailto:于2025年2月7日 周五下午4:04写道: ; Awesome! Thanks for letting me know. I will now mark this ticket as resolved, but feel free to reach out again if you need further assistance. Best, name K ;",cwilliams6@access-ci.org,Caleb Williams,Haniye Kashgarani,Purdue University,Anvil,4,6,6,2025,2025-02-03
ATS-13716,Disk space full,2025-02-03,2025-02-13,"I tried copying files to my $HOME directory and got a message that I did not have enough space in the account. I did check {{myquota}}, and I do not understand why my space is full. When I checked {{myquota}} my dir was almost full (99%), but when I checked the data that I have, it is about 11G. Below are the responses I got from two commands to check my disk space: :\~] $ name -sh \\* : sort -hr 5.8G ls\\_stat\\_files 5.1G conda\\_env 3.5K privatemodules 512 first\\_jon.sub :[Anvil $ myquota h1. Type Location Size Limit Use Files Limit Use home x-hkyeremateng 24.6GB 25.0GB 99% - - - scratch anvil 0KB 100.0TB 0% 0k 1,000k 0.00% projects x-cis250013 0KB 5.0TB 0% 0k 1,048k 0.00% ; It seems that the {{tmp}} folder has a file called name and that is about 21G ; Hi Hubert, Thank you for reaching out. The directories which name start with a ""."" are hidden in your home directory. You can use \\*ls -name\\* or \\*ncdu\\* in your home directory to check the directory size. Here is \\*ncdu\\* output, your ~/.cache is taking ~ 5GB which you can remove safely. Your ~/.conda is also taking ~9GB, you can remove the environments you don't need to free up some space. Best, name K ; Is there a way for me to request to increase my disk size? ; Hi Hubert, Thank you for reaching out. We don't usually increase the disk size of home and scratch directories. Please try removing some data from your home directory. You can also move some files to your scratch or project folder to avoid maxing out your home directory. Removing you cache directory is safe and you can go ahead an remove it, also if you need your conda environments you can move them somewhere else and try activating the environment from the new path. Best, name K ; Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name K ;",hkyerematengboateng@access-ci.org,Hubert Kyeremateng-Boateng,Haniye Kashgarani,Purdue University,Anvil,6,9,6,2025,2025-02-03
ATS-14763,Interactive desktop usage in Anvil-PURDUE cluster,2025-03-11,2025-04-24,"Hi, I am using Anvil cluster. There was interactive desktop option but now there is no longer any option for interactive desktop. So, how can I use interactive desktop? ; Hi Abdul, Thanks for reaching out Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Hi: As it's been a week and we haven't heard back, we will mark this ticket as resolved. Again, apologies for the delay in initial response, but feel free to open another ticket if you have any other questions and we should get back within a day or two. Apologies for any inconveniences. name ;",ashuvo@access-ci.org,Abdul Aziz Shuvo,Ansen Shia,Purdue University,Anvil,3,33,11,2025,2025-03-10
ATS-13436,Installing MOPAC and ORCA on ANVIL,2025-01-23,2025-02-21,"Hello, I was wondering if I could get some help with installing MOPAC and ORCA on ANVIL. ; Hello, I hope you are doing well. Thank you for reaching out to RC Support with your question Regards, name ;",cugboh@purdue.edu,Chizaram Ugboh,Nannan Shan,Purdue University,Anvil,7,22,4,2025,2025-01-20
ATS-13628,I need access to log into  Purdue Anvil CPU	but I don't have my SSH key,2025-01-30,2025-02-19,"I need the SSH key for logging into Purdue Anvil CPU, MCB130189: Role of Epigenetic Modifications of DNA in Gene Regulation. My username: x-vrothenb I tried this command but it asks for a password: ssh -l x-vrothenb anvil.rcac.purdue.edu: http://anvil.rcac.purdue.edu ; Hello, I hope you are doing well. Thank you for reaching out to RC Support with your question! We are actively working on addressing the issue. Rest assured, we will provide you with a response as soon as possible. Best regards, name RCAC Support ; Hello Vince, Thank you for your patience. Are you still experiencing the issue? Anvil User Guide: https://www.rcac.purdue.edu/knowledge/anvil/access/login/sshkeys: https://www.rcac.purdue.edu/knowledge/anvil/access/login/sshkeys|smart-link Best regards, name RCAC Support ;",vrothenb@access-ci.org,Vince Rothenberg,Ankitha Mallekav,Purdue University,Anvil,3,15,5,2025,2025-01-27
ATS-14794,Project folder expansion,2025-03-12,2025-04-21,"Good day Anvil team, I am preparing for the FSU-SECM4 cryo-EM/ET data processing workshop later this year and plan to showcase processing of a large dataset. To thoroughly test my workflow, I kindly request an increase in my project folder allocation. My raw data is about 47 TB, which will likely grow during processing, and a 60 TB allocation would allow me to manage the dataset, preserve timepoints, and identify potential workflow pitfalls before the live workshop. I also cannot use the /scratch space, as frequent purges would risk losing valuable data and force me to restart. Since this data will be accessed randomly throughout processing, I would also appreciate any available SSD allocation to enhance relion and cryoSPARC performance. Thank you for your time and support. I look forward to your response. With kind regards, Nebojša Bogdanović, Ph.D. Cryo-EM | Specialized Research Faculty Southeastern Center for Macro-Molecular Machines SECM4 | Florida State University ; Hi, Could you please provide the information in the attachment. I will then submit the request for you. Best, name ; Hi name, Thank you very much. I filled and attached the form you sent. Please let me know if you need any more info. Best regards, Nash ---- ^Signed.pdf] \\_(105 kB)\\_ ; Hello name, I hope you are doing great. Do you maybe have an update on this request for expansion on disk quota? I have discussed this with name and I have added him here for the reference. Looking forward to hearing from you. Best regards, Nash ---- ; Hi Nash, I just check your myquota, which seems the new quota has came into effect. Let us know if this looks good for you or not, and how we could further help. \\*:\~]\\* $ myquota x-nbogdanovi Type Location Size Limit Use Files Limit Use =========================================================================== home x-nbogdanovi 4.9GB 25.0GB 19.8% - - - scratch x-nbogdanovi -38613504.0KB 100.0TB -0.0% 34.0K 1.0M 3.4% projects x-see230013 3.8TB 60.0TB 6.4% 944.4K 1.0M 90.1% Best, name ; Hi name, Thank you for the quota update. It means a lot. I have some remaining ACCESS credits that I have submitted to exchange for Anvil GPU. Can you maybe check if that can be approved today? I am in the process in requesting a second allocation of my ACCESS credits and will have to perform Anvil exchange again, if this software can work at your end. Please let me when it gets approved so I can dig into the data processing. Best regards, Nash ---- ; Hi Nash, Approving your exchange is something out of my control. But I could check the balance for you. \\*:\~\\* $ mybalance x-nbogdanovi Allocation Type name Limit name Usage name Usage name Balance Account (account) (user) ============= ==== ========== ========== ========== ========== see230013-gpu GPU 5984.4 4721.0 0.0 1263.4 Let us know if you have more questions. Best, name ; Hi, Since I have not heard back from you in a while, I'm tentatively marking this ticket resolved at this point. If you still need assistance, please feel free to reply to this email within the next 7 days to reopen the ticket. Best, name ;",nbogdanovi@access-ci.org,Nebojša Bogdanović,Xiao Liu,,Anvil,8,29,11,2025,2025-03-10
ATS-13826,ANVIL - Request to build new module for VASP 6.4.3,2025-02-07,2025-02-21,"Dear Anvil Staff, Would it be possible to build a new module for VASP 6.4.3? The most recent version on Anvil at the moment is 6.3.0 which is missing some helpful recent updates. I have placed the tarball for VASP 6.4.3 in my home directory at ""/home/x-jcappola/vasp.6.4.3.tgz"" if this is possible. Thank you We are actively working on addressing the issue. Rest assured, we will provide you with a response as soon as possible. Best regards, name RCAC Support ; \\*\\*PRIVATE NOTE\\*\\* Hi name, Thanks for reaching out Thank you. -name ; Thanks for letting me know. Glad everything goes well. Good luck to your research! --name ;",jcappola@access-ci.org,Jonathan Cappola,Nannan Shan,,Anvil,6,11,6,2025,2025-02-03
ATS-13635,Unable to write files to anvil,2025-01-31,2025-02-28,"\\*Dear Support Team,\\* I hope this message finds you well. I am a PhD student utilizing computational resources under the NAIRR program. Recently, I've encountered issues when attempting to create or save files in my home directory. Specifically, I receive the error message: Disk quota exceeded Despite this, both my disk usage and inode usage are well below the allocated limits, as confirmed by the {{df -h}} and {{quota -v}} commands. Upon inspecting the system logs using {{dmesg}}, I observed repeated entries indicating that the NFS server ({{zfs.anvil.rcac.purdue.edu}}) is intermittently not responding. Examples of these log entries include: nfs: server zfs.anvil.rcac.purdue.edu not responding, still trying These connectivity issues with the NFS server appear to be preventing successful write operations to my home directory. Could you please investigate this matter and assist in resolving the NFS server connectivity problems? Your prompt assistance would be greatly appreciated, as it is impacting my research activities. Thank you for your support. \\*My details:\\* \\* \\*Email: \\* \\* \\*Allocation account: ai240141-gpu\\* \\*Best regards,\\* Anay Mehrotra ;",amehrotra5@access-ci.org,Anay Mehrotra,Nannan Shan,Purdue University,Anvil,1,21,5,2025,2025-01-27
ATS-13666,Question regarding MPS on Purdue Anvil GPUs,2025-01-31,2025-02-24,"I, name Sonti, am a 3rd year PhD Candidate under Prof. Surl-Hee name at the UC name Department of Chemical Engineering. I am planning to test whether running molecular dynamics (MD) simulations with AMBER: https://ambermd.org/ can be enhanced using the multi-processing service (MPS) feature of NVIDIA GPUs (for versions V100 and up). Since Purdue Anvil has V100 GPUs and newly installed H100 GPU nodes, I wanted to ask if the MPS option (\\*""nvidia-cuda-mps-control""\\*) is supported on these GPUs. ; name, Thank you for reaching RCAC for support. Have you tried to enable the MPS daemon yourself? It looks like the ""{{nvidia-cuda-mps-control}}"" command is available on the GPU nodes. Thanks, name, Since I haven't heard from you in a while, I'm tentatively marking this ticket as resolved. If you are still encountering problems, please respond to this ticket within 7 days to reopen it. Otherwise, you can always submit a new ticket. Thanks, name ;",ssonti@access-ci.org,Siddharth Sonti,Michael Carlson,Purdue University,Anvil,3,17,5,2025,2025-01-27
ATS-15055,recent queue time become much higher on Anvil for wholenode,2025-03-21,2025-04-23,"Hi, I noticed that the recent queue time becomes much higher on Anvil for wholenode partition. Previous experience has always been quite smooth for a few nodes's jobs. But in these two weeks my jobs rarely run but keep waiting. Something I don't quite understand is, there seems to be more than enough nodes that are ""Idle"" but still my jobs are waiting due to priority. Below is an example of the current status of the wholenode partition: : grabnode (0321-16:52:19)$ showpartitions Partition statistics for cluster anvil at Fri name 21 16:52:21 EDT 2025 Partition #Nodes #CPU\\_cores Cores\\_pending Job\\_Nodes MaxJobTime Cores Mem/Node Name State Total Idle Total Idle Resorc Other name Max Day-hr:mn /node (GB) wholenode up 746 36 95488 19200 0 105544 1 infin infinite 128 257 standard up 746 36 95488 19200 0 16 1 infin infinite 128 257 shared:\\* up 250 1 32000 8936 0 1256 1 infin infinite 128 257 wide up 746 36 95488 19200 0 67072 1 infin infinite 128 257 highmem up 32 30 4096 3840 0 8 1 infin infinite 128 1031 debug up 17 0 2176 446 0 44 1 infin infinite 128 257 gpu up 16 0 2048 1085 0 10410 1 infin infinite 128 515 ai up 21 20 2016 1920 0 0 1 infin infinite 96 1031 gpu-debug up 16 0 2048 1085 0 0 1 infin infinite 128 515 profiling up 4 4 512 512 0 0 1 infin infinite 128 257 : grabnode (0321-16:52:22)$ sinfo -p wholenode PARTITION AVAIL TIMELIMIT NODES STATE NODELIST wholenode up infinite 3 comp a445,679,701 wholenode up infinite 109 plnd a300-336,338-356,359,433-444,446-464,466-470,472-479,755-760,790-791 wholenode up infinite 22 drain\\* a276,396,410,471,489,521,549-550,601,622,642,659,683,703,739,761,787,795,878,889,992-993 wholenode up infinite 16 down\\* a251,254,269,277,279,337,383,431,465,511,552,707,711,741,925,927 wholenode up infinite 2 resv a965-966 wholenode up infinite 558 alloc a250,252-253,255-268,270-275,278,280-299,357-358,360-382,384-395,397-409,411-417,420-430,432,480-488,490-508,510,512-513,515-520,522-548,551,553-597,600,602-621,623-641,643-658,660-675,677-678,680-681,688-692,694-700,702,706,708-710,712-719,721-732,740,742-750,762-786,788-789,792-794,796-838,847-877,879-888,890-924,926,928-951,953-964,968-991,994-995 wholenode up infinite 36 idle a418-419,509,514,598-599,676,682,684-687,693,704-705,720,733-738,751-754,839-846,952,967 and the status of my job: : grabnode (0321-16:52:21)$ sjobs JOBID PARTITION NAME USER ST TIME TIME\\_LEFT QOS NODES PRIORITY FEATURES NODELIST(REASON) 10064255 wholenode KBO\\_Z1RunC\\_FlowPar2Fill x-rixin PD 0:00 2-00:00:00 cpu 4 227 (null) (Priority) Is there a recent change on how jobs are assigned priority or what? Any information would be appreciated! Thanks, Rixin ; Hi Rixin, Thanks for reaching out! Thanks for your patience on this as this ticket was buried and we lost track of it. I am wondering if you still see issues on Anvil right now. Please feel free to let me know. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ;",rixin@access-ci.org,Rixin Li,Nannan Shan,Purdue University,Anvil,2,24,12,2025,2025-03-17
ATS-14029,Temporary increase in number of files in project space for SOC250007,2025-02-14,2025-02-27,"Hi, Raising this ticket on behalf of the users on SOC250007. Could you please increase the limit on the number of files in their project space to 10M for 6 months? They are trying to copy hourly tweet data for 10 years which runs into several million files. Thanks We are actively working on addressing the issue. Rest assured, we will provide you with a response as soon as possible. Best regards, name RCAC Support ; Thanks, name! Please let me know when our file number quota is increased so I can resume copying the data. Devika ; Hello Devika, Thank you for your patience. Can you please provide your detailed workflow and why the quota is necessary so we can report this to our storage experts. Best regards, name RCAC Support ; Hi name, Here's a refined version of your email with improved clarity and professionalism: ---- \\*Subject:\\* Request for Data Transfer Approval Hi name, We have hourly data files for each of the 56 census blocks in the U.S., totaling approximately 490,560 files per year (24 \\* 365 \\* 56) over 13 years. However, the actual number of files varies by year. Below is the exact count for each year: \\* \\*2010:\\* 4,029 \\* \\*2011:\\* 59,772 \\* \\*2012:\\* 358,938 \\* \\*2013:\\* 402,288 \\* \\*2014:\\* 446,403 \\* \\*2015:\\* 446,760 \\* \\*2016:\\* 447,984 \\* \\*2017:\\* 446,760 \\* \\*2018:\\* 446,760 \\* \\*2019:\\* 446,709 \\* \\*2020:\\* 436,407 \\* \\*2021:\\* 431,002 \\* \\*2022:\\* 433,704 \\* \\*2023:\\* 220,269 This is a temporary increase until July 2025. We would greatly appreciate your approval as soon as possible, as we are currently unable to proceed with the project until the data is moved. Please let me know if you need any further details. Thanks a lot, Devika Let me ; Hello Devika, Thank you for your patience. I have notified our team about your request and should get an answer tomorrow morning. I will get back to you as soon as I hear back. Best regards, name RCAC Support ; Hello Devika, The issue should be resolved now. If you have any other questions, feel free to let me know. Best Regards, name RCAC Support ;",rkalyana@access-ci.org,Rajesh Kalyanam,Ankitha Mallekav,,Anvil,7,10,7,2025,2025-02-10
ATS-14078,File upload to Anvil Workspace Document fails (error 403) ,2025-02-17,2025-02-26,"Hello name ; ^2022-10-17.rst] ; \\*\\*PRIVATE NOTE\\*\\* To clarify, name is trying to upload documents to AnvilGPT ; Hi name, Thanks for reaching out. We have identified the issue and are actively working on a fix. We expect to release an update within the next few days. I'll keep you posted on any further developments. Best, name ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id:id-8330-4926-8012-d8b114956413 any updates on this? ; \\*\\*PRIVATE NOTE\\*\\* [~accountid:id:id-248a-43b5-a841-66499835a741 I need to do a quick testing, and will push the changes by tomorrow. ; Hi name, The issue has now been fixed. Please check and let us know if you need any further assistance. Best, name ; I'm able to upload files without issue now. Thank you so much name! ;",joppenheimer@access-ci.org,Jonathan Oppenheimer,Mihir Ahlawat,,Anvil,8,8,8,2025,2025-02-17
ATS-14221,Job Submission/Initialization Keeps Failing,2025-02-21,2025-02-27,"Any job that I submit fails within 2 seconds of running, on demand says: 'The job terminated with a non-zero exit code and failed to execute' when I hover over the FAILED button. I'm not getting any output error or out files from this so I don't think this is an issue with my bash script in anyway. It seems it just wont initialize the run. Below is my bash submission script that I am using. # Joe ; I have now lost complete access to all of our allocation resources under x-dmr180108 and x-eve210010. I'm not sure what the reason for this is. According to my allocations on access, there is no change in my role as a user under both of these allocations. I would appreciate a timely response on this matter as I am fully locked out from all of my work. ; Correction: access says I am still on the x-dmr180108 allocation but executing id in my command line says I'm only in x-eve210010. I can access anything in the second allocation okay. But I am supposed to have my main group be x-dmr180108. I'm not sure why there is a mismatch between what access says and what anvil does. ; Hello, I hope you are doing well. Thank you for reaching out to RC Support with your question! We are actively working on addressing the issue. Rest assured, we will provide you with a response as soon as possible. Best regards, name RCAC Support ; Hello, Thank you for your patience. Can you please login again and re-try? Best regards, name RCAC Support ; Hello name, It works now, thank you so much for the timely help. I appreciate it. What exactly was the issue? Best, Joe ; Hello name, We were having an outage on Anvil this past weekend so it was a system wide issue. Best regards, name RCAC Support ;",jnicolas@access-ci.org,Joseph Nicolas,Ankitha Mallekav,,Anvil,9,5,8,2025,2025-02-17
ATS-14223,No access to /anvil/projects/x-ees240082 folder,2025-02-21,2025-02-27,"No access to /anvil/projects/x-ees240082 folder ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id:id-248a-43b5-a841-66499835a741 ; Hello, I hope you are doing well. Thank you for reaching out to RC Support with your question! We are actively working on addressing the issue. Rest assured, we will provide you with a response as soon as possible. Best regards, name RCAC Support ; Hello, Thank you for your patience. Can you please login again and re-try? Best regards, name RCAC Support ; Yes. It works now. Thanks. On Feb 24, 2025, at 2:15 PM, name wrote: || ;",jguo3@access-ci.org,Junwei Guo,Ankitha Mallekav,,Anvil,5,5,8,2025,2025-02-17
ATS-14238,Cannot see my project directory on Anvil,2025-02-22,2025-02-24,"Hi, I have several active projects on Anvil, but I am unable to access them. My access request has been denied, and when I use the command ""myquota,"" I can no longer see my projects. Please look into this issue, as all the important data for my thesis is stored on Anvil. Thank you for your support. Best, name, Thank you for contacting RCAC for support. Anvil had an unscheduled outage over the weekend, which may have caused the problems that you were seeing. Could you confirm that you are still unable to see all your active projects? I believe this should be fixed, but I want to make sure. Thanks, name ; Hi name, I have verified everything, and it is back to normal now. Thank you for your support. Best, name, I'm glad to hear that things are back to normal. I'm marking this ticket as resolved, but if you encounter any more issues, please let us know so that we can remedy them. Thanks, name ;",ellanguyen@access-ci.org,Thi Hong Ha Nguyen,Michael Carlson,,Anvil,5,1,8,2025,2025-02-17
ATS-14366,Unable to access projects directory,2025-02-25,2025-02-26,"Logging on the Anvil portal, I am unable to access my Projects Directory. I am getting the following error: ""Permission denied @ dir\\_initialize - /anvil/projects/x-chm240057"" ; Hi, Your problem has been fixed. I personalized as you and test as below: \\*:\~\\* $ cd /anvil/projects/x-chm240057/ \\*:x-chm240057\\* $ Please let us know if you need more help. Best, name ;",abhardwaj@access-ci.org,Apurva Bhardwaj,Xiao Liu,,Anvil,2,2,9,2025,2025-02-24
ATS-11469,JDFTx compilation,2024-10-17,2025-03-05,"We would like to use JDFTx to study grand canonical treatment on electrochemical systems. name and I have been discussing to compile JDFTx on Purdue Anvil. This ticket is to request the compilation of JDFTx on Purdue Anvil. ; Hi Jiayi, Thank you for reaching out. I will escalate this ticket to name since you've already had a discussion with her. Best, name K ; Hi name, I've tried to compile JDFTx with gcc compiler, but always got the header errors like below, which related to the source code. I would recommend to talk to the code developer about this. In file included from /anvil/scratch/nshan/apps/jdftx/jdftx-1.7.0/jdftx/core/ManagedMemory.h:25, from /anvil/scratch/nshan/apps/jdftx/jdftx-1.7.0/jdftx/core/ScalarField.h:33, from /anvil/scratch/nshan/apps/jdftx/jdftx-1.7.0/jdftx/core/Coulomb.h:23, from /anvil/scratch/nshan/apps/jdftx/jdftx-1.7.0/jdftx/electronic/Everything.h:26, from /anvil/scratch/nshan/apps/jdftx/jdftx-1.7.0/jdftx/commands/debug.cpp:21: /anvil/scratch/nshan/apps/jdftx/jdftx-1.7.0/jdftx/core/BlasExtra.h:36:1: note: 'DBL\\_MAX' is defined in header ''; did you forget to '#include '? 35 | #include +++ |+#include 36 | Good luck! name ;",jxu15@access-ci.org,Jiayi Xu,Nannan Shan,Purdue University,Anvil,3,100,42,2024,2024-10-14
ATS-13805,Re: Help with tesseract ocr installation,2025-02-06,2025-03-04,"Hi Team, I am working on a OCR project and i need {{tesseract}} as a command line software. Please help me installing the below software. {{sudo dnf install tesseract}} Thanks and regards, Uttam name P. ; Good evening what system are you running on? (Anvil, Expanse, Bridges, etc). Thanks I will route to Anvil team. ; Hi Uttam, Thank you for contacting Anvil support team. I'll be glad to assist you with that. I need to first look up the software and requirement and I'll get back to you if I questions or updates. I appreciate your patience in the mean time. Best, I.name Anvil support team ; Hi name, Thank you for the support. Please let me know in case of any update. Thank you, Uttam name P. ; Hi Uttam, Let me know if you have some availability so that I can help install that for you. Or, if you authorize me, I can do that on your behalf. Please let me know as you get time. Best, I.name: http://I.name RCAC support team ; Hi name, Please let me know how can i authorize you. Thanks, Uttam name P. ; You can just say I authorize you to access my home directory and do the software installation. Although I can access your account, however, we always respect the privacy of our users and the authorization is always required. Best, I.name: http://I.name Anvil support team ; Hi name, I authorize you to access my home directory and do the software installation. Thanks, Uttam ; Hi Uttam, I have created a local folder for the software installation and created a condo environment for this purpose. Now, as you login, the environment would be automatically be activated and you can check that by checking the installation using this command: tesseract -v Please try that and let me know if you need anything else. Best, I.name: http://I.name RCAC support team ; How can i activate this env. Can you make this env available to Jupiter notebook aswell ? ; \\*:\~]\\* $ tesseract -v -bash: tesseract: command not found I got this issue from Anvil Shell ; Hi name, I just figured out and It is working. Thank you so much for the support. Thanks and Regards, Uttam name P. ; Uttam, Just to let you know, I created a module for you hoping it would be much easier for you to use. You can simply use this command to load the module: module load tesseract/5.5.0 You can give it a try and let me know if everything works well. Best, [I.name: http://I.name Anvil support team ; Forgot to mention that I have also created Tesseract environment ,tesseract\\_env, which is now available as a Jupyter kernel that you can use in Open OnDemand. Best, I.name: http://I.name Anvil support team ; Hi name, The software is running as expected . Thanks, Uttam ;",upanasala@access-ci.org,Uttam Panasala,Ibrahem Alshybani,Purdue University,Anvil,17,19,6,2025,2025-02-03
ATS-13956,AnvilGPT Access Request,2025-02-12,2025-03-07,"I would like to request access to AnvilGPT for testing and comparison with some of the other services out there. Here is my allocation number: TRA120044. I just need access to the UI. ; Hi name, Apologies for the delay. I have approved your access request. Best, name ;",athota1@access-ci.org,Abhinav Thota,Sarah Rodenbeck,,Anvil,2,18,7,2025,2025-02-10
ATS-14011,job running limit,2025-02-14,2025-03-05,"Hi, I am trying to run a pytorch job on Anvil and running into the error below. sbatch: error: AssocGrpGRESMinutes sbatch: error: Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits) here is the script: # Zhigang ; Hello, I hope you are doing well. Thank you for reaching out to RC Support with your question! We are actively working on addressing the issue. Rest assured, we will provide you with a response as soon as possible. Best regards, name RCAC Support ; Hello Zhigang, Thank you for your patience. {{AssocGrpGRESMinutes}} means you don't have enough SUs for the job. $ mybalance x-zfeng2 Allocation Type name Limit name Usage name Usage name Balance Account (account) (user) ============= ==== ========== ========== ========== ========== soc230021 CPU 0.0 1052826.7 1052826.7 n/a soc230021-gpu GPU 0.0 3935.4 0.0 n/a soc250017-gpu GPU 1000.0 0.0 0.0 1000.0 The allocation you used for the job {{soc230021-gpu}} has expired. You might want to use {{soc250017-gpu}} instead. Best regards, name RCAC Support ; Thanks you so much for your help. This error is so obvious but I didn't get it in the first place. Zhigang On Feb 18, 2025, at 8:29 PM, name wrote: | | Caution: Non-NU Email | ; Thanks! Now I have a new issue. The job keeps running into memory error. Beside to optimize my code, what are the options do I have to let it running smoothly? This code was able to run last year while I was using the previous project resources. I have not made any changes to the codes yet. I am planning to expand the code. But I need to make sure that it runs well first. ############################################################### Traceback (most recent call last): File ""dashboard\\_mpe\\_agg\\_shk\\_v2.py"", line 139, in main() File ""dashboard\\_mpe\\_agg\\_shk\\_v2.py"", line 97, in main model, train\\_loss\\_value = decision\\_trainer.value\\_training(config.n\\_v\\_sim, dist\\_a\\_mid, dist\\_a\\_mesh, new\\_euler\\_scale, new\\_punish\\_scale) File ""/home/x-zfeng2/Project\\_2025/MPE\\_name/module\\_training\\_bellman\\_mpe\\_agg\\_shk\\_v2.py"", line 283, in value\\_training \\_, \\_, value\\_data\\_all\\_epochs = equm\\_updater.obj\\_sim\\_value(x\\_data\\_all\\_epochs, x\\_n\\_sim, dist\\_a\\_mid, File ""/home/x-zfeng2/Project\\_2025/MPE\\_name/module\\_obj\\_bellman\\_mpe\\_agg\\_shk\\_v2.py"", line 147, in obj\\_sim\\_value x\\_dist\\_g\\_all = self.calculate\\_G\\_batch(dist\\_a\\_mid, dist\\_a\\_mesh, x\\_dist0\\_expanded, 0, x\\_tfp0\\_expanded) # 1 is an indicator for simulation File ""/home/x-zfeng2/Project\\_2025/MPE\\_name/module\\_obj\\_bellman\\_mpe\\_agg\\_shk\\_v2.py"", line 383, in calculate\\_G\\_batch x\\_G / row\\_sums torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.96 GiB. GPU 0 has a total capacty of 39.50 GiB of which 434.12 MiB is free. Including non-PyTorch memory, this process has 39.06 GiB memory in use. Of the allocated memory 38.41 GiB is allocated by PyTorch, and 157.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max\\_split\\_size\\_mb to avoid fragmentation. See documentation for Memory Management and PYTORCH\\_CUDA\\_ALLOC\\_CONF ; Hello, Are you still experiencing this memory error? Best Regards, name RCAC Support ;",zfeng2@access-ci.org,Zhigang Feng,Ankitha Mallekav,Purdue University,Anvil,6,14,7,2025,2025-02-10
ATS-14159,Request to increase ANVIL projects storage space - cis220051,2025-02-20,2025-03-05,"The Data Mine is experiencing more data space usage lately. We would like to request an increase to our storage allocation for /anvil/projects/cis220051 by 50% from 20TB to 30TB. Is this request sufficient or is there other way you would like us to make this request? Thanks, Fulya Gokalp name, PhD Director of Data Science The Data Mine ; Hi Fulya, Apologies for the late reply. Do you still in need to increase your space storge? Best, I.name: http://I.name Anvil support team ; Hi name, Yes, please. We still need to increase the space storage. Thank you, Fulya Fulya Gokalp name The Director of Data Science, The Data Mine ; Hi Fulya, Your storage has been updated with an increase. Type Location Size Limit Use Files Limit Use home x-fgokalpyavuz 16.0MB 25.0GB 0.06% - - - scratch anvil 0KB 100.0TB 0% 0k 1,000k 0.00% projects x-cis220051 17.3TB 30.0TB 58% 5,116k 10,485k 49% Best, I.name: http://I.name Anvil support team ---- ; Hi name, Thank you. This is really helpful! Have a great day, Fulya ;",fgokalpyavuz,Fulya Gökalp Yavuz,Ibrahem Alshybani,,Anvil,5,10,8,2025,2025-02-17
ATS-14191,Request to get priority for job running,2025-02-21,2025-03-05,"Dear support staff, I am reaching out to inquire whether it would be at all possible for the batch jobs on the account cts190021 to gain some priority in running. There is a imminent program review for our aeroacoustic projects and we would like to run additional simulations to gather more results for the review. Both myself and another user with the User ID x-jyamasaki have submitted jobs earlier in the week that has been in the queue for more than 2 days, which has delayed our progress significantly. Please let me know if it is at all possible for you to accommodate this request. Thank you. Sincerely, name ; Hello, I hope you are doing well. Thank you for reaching out to RC Support with your question! We are actively working on addressing the issue. Rest assured, we will provide you with a response as soon as possible. Best regards, name RCAC Support ; Dear support staff, Is there any update you could offer me at this time regarding getting priority for job running? The program reviewing deadline would be next Monday, so we would really appreciate if this request can be accommodated. Please let me know as soon as possible. Thank you. Sincerely, name ; Dear name, Thank you for your patience. The request is for 56 nodes; however, all nodes in the \\*wholenode\\* queue are currently occupied. Unfortunately, there is nothing we can do at this time to allocate additional resources. Please let us know if you have any further questions or if we can assist in any other way. Best, name RCAC Support ;",sdai@access-ci.org,Steven Dai,Ankitha Mallekav,,Anvil,4,9,8,2025,2025-02-17
ATS-14219,Cannot access Purdue Anvil project directory: x-bio240060 and x-bio240291,2025-02-21,2025-03-05,"Hello, My username is x-hli16. I have three projects on Purdue Anvil: bio240060, bio240291, and bio240059. I am able to log in to Purdue Anvil, but I cannot access two of my three project folders \\* /anvil/projects/x-bio240060/ \\* /anvil/projects/x-bio240291/ When I try to access these folders, I receive the following error message: -bash: cd: /anvil/projects/x-bio240291/: Permission denied I have verified that I can log in to Anvil, but I do not have the permissions to enter these project directories. However, I can access my third project folder: /anvil/projects/x-bio240059/. Could you please check my access and permissions for projects bio240060 and bio240291? Thank you for your help. ; Hello, I hope you are doing well. Thank you for reaching out to RC Support with your question Best regards, name ;",x-hli16,Huiyu Li,Ankitha Mallekav,Purdue University,Anvil,5,9,8,2025,2025-02-17
ATS-14235,Node fail error for jobs,2025-02-21,2025-03-07,"Dear support staff, I have encountered an issue running batch job on the Anvil cluster. A recent job have repeated failed to start, with the email indicating NODE\\_FAIL and no output/error file generated in the scratch directory. Is there anyways to address this issue? Is there anything I can do to avoid this? Please let me know as soon as possible. ; name, As you know from your other two tickets, Anvil had an unscheduled outage that caused this 'NODE\\_FAIL' error. It should now be remedied, so let me know if you're still facing this issue. Thanks, name, Since I haven't heard from you in a while, I'm tentatively marking this ticket as resolved. If you are still facing problems, please respond to this ticket within 7 days to reopen it. Otherwise, you can always submit a new ticket. Thanks, name ;",sdai@access-ci.org,Steven Dai,Michael Carlson,,Anvil,4,11,8,2025,2025-02-17
ATS-14237,Job Re-queue'ing and NODE_FAIL,2025-02-22,2025-03-07,"Hello, I am facing an issue where my Slurm job keeps on getting re-queued, then failing immediately after (NODE\\_FAIL), then re-queue'ing again, and so on. From my email record (I receive Slurm updates via email), it looks like it started from 19:40 Pacific Time, and has subsequently gone through this re-queue + fail sequence every few minutes. For this job, I am requesting nodes=56, ntasks=7168 on partition ""wide"". The specific job\\_id = 9621537, name = charles86M\\_stats. My account name is x-jyamasaki (part of account cts190021). My colleague x-sdai (who is also part of the same account) has reported the same issue with his runs. We are currently preparing simulation results for an upcoming conference presentation, as well as a program review with our sponsor (Office of Naval Research). We would therefore be very grateful for any insight or assistance. Thank you in advance, and we look forward to hearing from you. Best, name Yamasaki ; name, As noted in your other ticket, Anvil had an unscheduled outage over the weekend, which caused this. I apologize for the inconvenience this has caused, but it should be resolved as of now. If you're still facing problems, please let me know and I will forward to our engineering team. Thanks, name, Since I haven't heard from you in a while, I'm tentatively marking this ticket as resolved. If you are still facing problems, please respond to this ticket within 7 days to reopen it. Otherwise, you can always submit a new ticket. Thanks, name ;",jyamasaki@access-ci.org,Jun Yamasaki,Michael Carlson,,Anvil,4,10,8,2025,2025-02-17
ATS-14440,Access denied when using VASP on Anvil,2025-02-27,2025-03-04,"Lmod has detected the following error: WARNING: this software has a license restricted to approved users. Users have to show their licenses and be confirmed by the VASP team that they are registered users under that license. Please send a ticket request access. While processing the following module(s): Module fullname Module Filename ; vasp/6.3.0 /opt/spack/cpu/openmpi/4.1.6-745pfv4/gcc/11.2.0/vasp/6.3.0.lua Currently Loaded Modules: 1) gmp/6.2.1 3) mpc/1.1.0 5) gcc/11.2.0 7) openmpi/4.1.6 2) mpfr/4.0.2 4) zlib/1.2.11 6) numactl/2.0.14 ; mpirun was unable to find the specified executable file, and therefore did not launch the job. This error was first reported for process rank 0; it may have occurred for other processes as well. NOTE: A common cause for this error is misspelling a mpirun command line parameter option (remember that mpirun interprets the first unrecognized command line token as the executable). Node: a291 Executable: vasp\\_std ;",mbiswas2@access-ci.org,Maitreyo Biswas,,Purdue University,Anvil,1,4,9,2025,2025-02-24
ATS-14241,"Unable to cancelled stalled jobs, jobs shows running in onDemand and showing allocation usage",2025-02-22,2025-03-07,"Dear Anvil Support Staff, I have two slurm batch jobs that are being indicated as running on onDemand, but is stalled according to my output files(and showed numerous error in the error file). I have attempted to cancel the jobs using scancel and through onDemand and have not been successful. I have already submitted a separate ticket regarding all slurm commands not functioning (ATS-14239) on the cluster and that still is the case at the time of writing. I also would like to ask would it be possible for the SUs consumed by these jobs to be refunded. Please provide assistance as soon as possible. Thank you. Sincerely, name, Thank you for contacting RCAC for support. Anvil had an unscheduled outage over the weekend, which is where all these problems stemmed from. Since it was a problem on our end, we will submit name refunds for the jobs that were impacted. Could you send me a list of jobs that were affected by this and I will work on getting those refunds issued? Thanks, name ; Dear name, The jobs that are affected are For x-sdai: 9621453 9623221 For x-jyamasaki: 9621537 Please let me know if you need any further information. Thank you. Sincerely, name, I have refunded the 100860 SUs consumed by those three jobs to the cts190021 account. It should take effect in the next couple of minutes. Note that we are having problems with the 'mybalance' command (and we're working on a fix). But, job submission is not affected at this time. Thank you for your patience, name, Since I haven't heard from you in a while, I'm tentatively marking this ticket as resolved. If you are still facing problems, please respond to this ticket within 7 days to reopen it. Otherwise, you can always submit a new ticket. Thanks, name ;",sdai@access-ci.org,Steven Dai,Michael Carlson,,Anvil,6,10,8,2025,2025-02-17
ATS-14245,VASP license issue ,2025-02-22,2025-03-07,"I have been regularly using the VASP code on the cluster without issues. However, today I encountered the following error message: ""Lmod has detected the following error: WARNING: this software has a license restricted to approved users. Users have to show their licenses and be confirmed by the VASP team that they are registered users under that license. Please send a ticket request access."" Could you help me to resolve this issue? Here are license information: My full name Gokhan Sensoy Affiliation: Recep Tayyip Erdogan University (Recep Tayyip Erdoğan Universitesi) User name: mgsensoy Vasp license number: LICENSE 5-1749 email: : mailto: All the Best Gokhan Sensoy ; name, Thank you for contacting RCAC for support. Over the weekend, Anvil had an unscheduled outage, which may have caused the problem that you were seeing. This has now been remedied, so you should be able to access VASP as normal. Is that the case? If not, I'll dig some more to see what I can find. Thanks, name ; Gokhan, Since I haven't heard from you in a while, I'm tentatively marking this ticket as resolved. If you are still facing problems, please respond to this ticket within 7 days to reopen it. Otherwise, you can always submit a new ticket. Thanks, name ;",mgsensoy@access-ci.org,Mehmet Sensoy,Michael Carlson,,Anvil,3,10,8,2025,2025-02-17
ATS-14452,Access to VASP on Anvil,2025-02-28,2025-03-05,"Hi, I want to access VASP on Anvil and I am currently under Prof. name's (name) VASP license. Can you please grant me access to VASP 6.0 group? Thank you, name ; Hi name, Have you registered ACCESS account and ask name to add you to one of the active allocation? I cannot find you on any active allocations on Anvil. After you are added to Anvil, you should have access to VASP there. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; I have an access account but have not asked name to add me, let me do that and try again, thanks This is a snapshot of my anvil mybalance command line, and I have also requested from rcac access to this allocation. ; Hi name, You have been added to vasp5 and vasp6 groups on Anvil. Your membership will be ready within a few hours. Please check our user guide for VASP calculations on Anvil. https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/vasp: https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/vasp|smart-link Regards, name ; Thank you so much for all the help! ---- ;",rdesai1,Rushik,Nannan Shan,Purdue University,Anvil,6,4,9,2025,2025-02-24
ATS-14596,Need java on ANVIL,2025-03-05,2025-03-05,"Hello, I'm trying to run a program on ANVIL that requires java. I cannot find that this is installed anywhere. Is java installed on ANVIL already? If not, can you suggest a solution to this issue? The program I'm running is /home/x-dafrst/TauP-2.6.1/bin/taup\\_time and the error I'm getting is $ taup\\_time ERROR: JAVA\\_HOME is not set and no 'java' command could be found in your PATH. Please set the JAVA\\_HOME variable in your environment to match the location of your Java installation. Thanks, name ; Hi, You could module load conda and build a virtual environment to install Java. You could search more information. this is what I got: Java can be installed using Conda, particularly through the {{conda-forge}} channel. Here's a breakdown: \\* The {{conda-forge}} community channel is a very important resource for Conda users. It provides a wide range of packages, including Java (specifically OpenJDK). Let us know if you need more help. Best, name ;",dafrst@access-ci.org,Daniel Frost,Xiao Liu,,Anvil,2,1,10,2025,2025-03-03
ATS-12456,AnvilGPT Access Request,2024-11-30,2025-03-10,"Hi, I would like to use AnvilGPT on both UI and API. It's mainly for my personal PhD research project. ; name, Thank you for reaching out to RCAC for support. What are you hoping to do with AnvilGPT? Thanks, name ; Hi, I plan to use \\*llama3\\* to do some prompt engineering work for my research project. Best, name ; Hi name, Thanks for reaching out Best, name ; Thank you for bringing this to our attention. Our team is looking into it and will get back to you. ; Hi name, The issue has been resolved now, and you should be able to generate responses. Please let us know if you have any other questions. ;",qzou,Qinqin Zou,Ashish Malik,Purdue University,Anvil,7,71,48,2024,2024-11-25
ATS-12791,ABAQUS license on anvil,2024-12-17,2025-03-10,"I am trying to run abaqus jobs on anvil. I can submit jobs but the throw an error that I do not have a license. i do have abaqus access on campus through ECN (I am a Purdue Grad student). Previously worked with name. ; Hi name, Thanks for reaching out and visiting Anvil Support Hour today. I would escalate this ticket to name regarding to your question about Abaqus license. Please stay tuned for our updates. Thanks for your patience. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id Hi name came to Anvil SH today. She said she cannot use ABAQUS on Anvil anymore. It might because of the license setup. Would you help to take a look at it. Thank you name ; Hi, I would definitely wait for ECN's respond on this issue as this has clearly indicated license usage issue. BTW, I have tested the Abaqus after I've done the installation and it worked for my account without issues. name ;",gallaway@access-ci.org,Glynn Gallaway,Guangzhen Jin,Purdue University,Anvil,6,60,51,2024,2024-12-16
ATS-13874,unable to see the project,2025-02-10,2025-03-11,"I am the co-PI of the project MAT250002 and would like to run simulations on the Purdue Anvil CPU. However, when I connect to the cluster using my username (x-mgsensoy), I am unable to see the project listed. Could you please assist me in resolving this issue? Any guidance on how to gain access would be greatly appreciated. ; Hi name, It looks like we may have only partially processed your addition a month ago. I repushed that, and everything for your access fell into place. Sorry for the hiccup, and thanks for reporting it to us! You should be good to go now. name ;",mgsensoy@access-ci.org,Mehmet Sensoy,Kevin Colby,Purdue University,Anvil,2,22,7,2025,2025-02-10
ATS-13923,Installing Psi4 Quantum Chemistry package,2025-02-11,2025-03-10,"I would like to install Psi4 Quantum chemistry package for my account ; Hi, Thank you for contacting us. We will get back to you as soon as we have the answer. Best regards, name Purdue RCAC Support ; Hi Harindranath Per the first bullet point of our software request policy (https://www.rcac.purdue.edu/knowledge/anvil/policies/software\\_installation\\_request\\_policy: https://www.rcac.purdue.edu/knowledge/anvil/policies/software\\_installation\\_request\\_policy|smart-link ), I would just recommend you install PSI4 Quantum Chemistry: https://psicode.org/psi4manual/master/index.html: https://psicode.org/psi4manual/master/index.html|smart-link in your Anvil home directory/allocation project space. Since this software is not already included in our Lmod module system you are free to install it locally. If you require any assistance with the actual installation process please let me know. Best regards, name Purdue RCAC Support ; Hi name, I tried to install as you recommended but I failed many times. I may need your help to install it. Psi4 is also provided by anaconda python and it seems I cannot conda install psi4 after loading the anaconda modules. Looking forward to hearing from you, Best wishes, Harin ---- ; Hello Harindranath If you would provide screenshots of the errors you are getting, that would be helpful in helping you install. Best regards, name Purdue RCAC Support ; Hi name, I was trying to install it according to Compiling and Installing from Source: https://psicode.org/psi4manual/master/build\\_planning.html#faq-runordinaryexe, but I always end up with the attached issue. I really appreciate your help with this. Thank you, Harin | Compiling and Installing from Source - PSI: https://psicode.org/psi4manual/master/build\\_planning.html#faq-runordinaryexe How to configure code to use high angular momentum basis sets¶. The Libint integral code handles arbitrary order angular momentum (AM), but compiling that is prohibitive. The build process for Libint2 takes longer than for Libint1, so it's recommended to use the conda packages.The AM controlling keyword MAX\\_AM\\_ERI has definition changed a little from Libint1. psicode.org | ---- ; Hi name, Once again, I tried to install it via conda, and got the attached error. Best wishes, Harin ---- ; Hi Harin, I suggest you take a look at the user guide for conda installation: https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/python/packages: https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/python/packages|smart-link. If you try the tips in the guide and still cannot figure it out, I can also reach out to our conda expert and they can help you with package installation. Best regards, name Purdue RCAC Support ; Hi name, I tried the steps in the link you sent and I got it to work. Thanks so much Regards, name Purdue RCAC Support ;",hambalampitiya2,anonymous,yang2383,,Anvil,10,20,7,2025,2025-02-10
ATS-14072,File Permission Change Request,2025-02-17,2025-03-13,"Hello, I'm Kali from The Data Mine. I'm reaching out to see if I can get the permissions associated with all the files in /anvil/projects/tdm/corporate/pu-athletics-tick/2023/Holloway changed as the owner of those files is no longer part of the team. And none of us can access to those files, and it'd be great if you could change the files' permissions so everyone else in that directory can have read and write permissions. ; Following up to see if there's any update on this ticket. Thank you ; Hi Kali, We have just picked up your ticket after an audit. Is this issue still ongoing? Best Regards, Eli name Purdue IT https://service.purdue.edu ; Nope, the issue has been resolved. Thanks! ;",kqlacy@access-ci.org,Kali Lacy,Elian Inigo Rieza,Purdue University,Anvil,4,19,8,2025,2025-02-17
ATS-14077,AnvilGPT Access Request,2025-02-17,2025-03-13,"I'd like to request access to AnvilGPT. I am an RCAC employee and would like to use both the UI and API for coding. ; Hi I name, Thank you for contacting RCAC. We will get back to you shortly on this issue. Best Regards, Eli name Purdue IT https://service.purdue.edu: https://service.purdue.edu|smart-link ; Hi I name, Your request has been approved. Feel free to use it, and let us know if you have any questions. ;",yirugi@access-ci.org,I Luk Kim,Ashish Malik,Purdue University,Anvil,3,19,8,2025,2025-02-17
ATS-14133,Purdue Anvil BioContainer Help - request newer version of a nextflow module/biocontainer,2025-02-19,2025-03-13,"Good afternoon ACCESS Support, I am an Purdue Anvil user and I am attempting to run the nextflow pipeline: https://pipelines.tol.sanger.ac.uk/blobtoolkit: https://pipelines.tol.sanger.ac.uk/blobtoolkit|smart-link However, the nextflow module (biocontainer) versions currently available on Anvil do not meet the minimum rerquirements to run the blobtools2 pipeline. It requires nextflow version >=23.04.0. Would it be possible for a newer version of the nextflow module to please be made available on Anvil? Many thanks for all of your (continued) help, name ; Hi, Thank you for contacting us. We will get back to you as soon as we have the answer. Best regards, name ; Hi name, Thanks for reaching out. I'd recommend installing {{nextflow}} it in your home directory. Please follow these steps to so: module load openjdk cd ~ curl -s https://get.nextflow.io | bash mkdir -p $HOME/.local/bin/ mv nextflow $HOME/.local/bin/ nextflow -version This will place Nextflow in your local {{$HOME/.local/bin/}} directory, allowing you to manage updates independently. Let me know if you run into any issues name ---- ;",abernard@access-ci.org,Andrea Bernard,Arun Seetharam,,Anvil,4,17,8,2025,2025-02-17
ATS-14273,No access to project directory,2025-02-24,2025-03-12,"I am trying to access my files but get the following error while using ondemand ""Permission denied @ dir\\_initialize - /anvil/projects/x-mch240064"" ; Still waiting for assistance on this issue. Did not resolve after Anvil restored last week. ; Hi name, Thanks for joining the Anvil Support Hour yesterday. I have let colleagues know about this issue and I will reach back to you whenever I hear back. Best, name K ; Hi name, Thank you for your patience. Could you please try again and let me know if the issue is not fixed yet? We had a dashboard maintenance since last week and the issue should be resolved. Best, name, I still receive the same error, see attached. name ; Hi name, We've found the source of this issue and are working on a solution for this afternoon. Update soon. Thanks, name ; Hi name, This issue should be fully resolved now. Please let me know if you are still experiencing any issues. Thanks! name ; Yes, this is resolved! Thank you for your help! name ; Thanks for letting us know. I will mark this ticket as resolved now, but feel free to reach out if you need further assistance. Best, name K ;",gallaway@access-ci.org,Glynn Gallaway,Haniye Kashgarani,Purdue University,Anvil,9,13,9,2025,2025-02-24
ATS-14292,Storage issue,2025-02-24,2025-03-13,"Hi! I started to install an ollama model I need for a project and it exceeded my storage limit. It now does not let me in any apps on anvil. Can you help clear the storage so I can continue to work? Thanks! ; \\*\\*PRIVATE NOTE\\*\\* Hi, We have just picked up your ticket after an audit. Is this issue still ongoing? Best Regards, Eli name Purdue IT https://service.purdue.edu: https://service.purdue.edu|smart-link ; Hi, We have just picked up your ticket after an audit. Is this issue still ongoing? Best Regards, Eli name Purdue IT https://service.purdue.edu: https://service.purdue.edu|smart-link ; Issue has been resolved! ---- ; Resolved as indicated by user ;",svedantham@access-ci.org,Shrey Vedantham,Elian Inigo Rieza,Purdue University,Anvil,5,14,9,2025,2025-02-24
ATS-14293,Job run in ANVIL,2025-02-24,2025-03-14,"I submitted several jobs (Job IDs: 9622424, 9622377, 9622422, 9622386, 9622379, etc.) last Thursday, February 21, 2025. However, I noticed that these jobs did not run. I received multiple email notifications indicating that the jobs had started but were then requeued. When I checked today, none of the jobs were running, and they are no longer in the queue and there is no error message also. Could you please provide insight into the reason for this? Additionally, would simply resubmitting the jobs resolve the issue, or is there an underlying problem that needs to be addressed? I appreciate your help. ; Hi, We have just picked up your ticket after an audit. Is this issue still ongoing? Best Regards, Eli name Purdue IT https://service.purdue.edu: https://service.purdue.edu|smart-link ; No. Now it's working fine. Thank you. Best regards Md. Mehedi name ; \\*\\*PRIVATE NOTE\\*\\* /templa ; Hi, Glad to hear this. This ticket will now be closed as a consequence. Best Regards, Eli name Purdue IT https://service.purdue.edu ;",mhasan1@access-ci.org,MD MEHEDI HASAN,Elian Inigo Rieza,,Anvil,5,15,9,2025,2025-02-24
ATS-13517,Unable to install any version of nektar++ software in anvil,2025-01-27,2025-03-20,"Hi. I am unable to compile the nektar https://www.nektar.info/getting-started/repository/: https://www.nektar.info/getting-started/repository/|smart-link software,v5.7.0. I load the modules like intel,cmake,intel-mkl,fftw,boost turning on things like MPI,FFTW,etc in the compilation process, but I always get an error. I would be glad if I could get any help to install this. Binayak ; Hi, I hope you're doing well. I sincerely apologize for the delay in following up on your ticket. I lost track of our conversation and apologize for the inconvenience this has caused. I'm reaching out to see if you're still experiencing any issues with your request. If so, please let me know, and I'm happy to assist if needed. Feel free to reach out if you have any further questions. Best regards, name Purdue IT https://service.purdue.edu/: https://service.purdue.edu/ ;",blohani@access-ci.org,Binayak Lohani,Ansh Gangapurkar,Purdue University,Anvil,2,39,5,2025,2025-01-27
ATS-14442,"Please can you extend my time on running job ID: 9665892. This is a genome assembly run, I have requested the maximum time on the queue but I am running out of time at this stage. Please would you be able to extend it ",2025-02-27,2025-03-14,"Please can you extend my time on running job ID: 9665892. This is a genome assembly run, I have requested the maximum time on the queue but I am running out of time at this stage. Please would you be able to extend it ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id:id-0296-44c2-8aaa-9a36b2662a58 has been helping this user. If it's not possible to extend the time on this job, maybe we can setup a custom QoS for them to be able to run longer jobs in the future. ; ~accountid:id:id-660f-4a53-a67a-50036106f59a:3f3079e1-f647-445c-a7d7-2d34551a8391 Please resubmit the job. If it has already completed a major step, use {{--resume-from}} to restart from that point, or {{--resume}} to continue from where it left off. If you need a walltime extension, reply here, and I'll increase it. PS: assuming you are running Flye. ; I was running FLYE; yes, it was running for 4 days. I don't know how far it was. Is there a way to check? Please, can I have an extension time, I use the resume function wehn I submit the job or within my bash script?? Thanks Regards, Dominique ; Yes, edit the Flye command in your slurm script and add the {{--resume}} option. It should resume from where it left off. Since the job ended, I can't extend the walltime, but for the next run, please let me know here and I will do it. PS: I will be out of office starting next Thr onwards ; Okay, I will edit the script now and resubmit the job. Do I notify you once I've submitted? But actually, if I can resume, maybe in another 4 days it should be done... I would hope. Thank you for the help Regards, Dominique ; \\*\\*PRIVATE NOTE\\*\\* Hi Dominique, Just checking in - what did you decide to do with the low coverage data? Do you have any close relative for that species so you could try re-sequencing based assembly? Thanks, name ; Hi name Sorry for not getting back to you. My assembly completed within that time so all is fine now. Thank you Regards, Dominique ;",dpaynee@access-ci.org,Dominique Paynee,Arun Seetharam,,Anvil,8,12,9,2025,2025-02-24
ATS-14516,Incorrect usage for for Purdue Anvil CPU,2025-03-03,2025-03-10,"Dear Help Desk, I notice an unreasonably high usage (> 3M SUs) has appeared on my account for Purdue Anvil CPU since the outage last week, and the computational time on our allocation EAR160027 ran out because of that. Currently, I cannot run jobs on Anvil because of this issue. When checking the dashboard on Anvil, I noticed a job (Job\\_id=8022348) that ran for 131 days and spent >3M SUs (screenshot attached). I am quite sure it is incorrect. Obviously jobs are not allowed to run for that long on Anvil. I am also attaching screenshots of email notifications I received regarding this job, which shows it had ended on Oct 13, 2024 after a node failure, requeue, restart and cancellation. I urgently need computational time to complete some work this month. Could you please check and fix this issue? Thank you very much for looking into this issue and for your supportjob.png: thumbnail name ---- ; Awesome! Then, I will mark this ticket as resolved. Feel free to reach us again if you have any other issues. Best, name K ;",jqfang@access-ci.org,Jiaqi Fang,Haniye Kashgarani,,Anvil,7,6,10,2025,2025-03-03
ATS-14524,AnvilGPT Access Request,2025-03-03,2025-03-10,"Allocation: CIS240473 Users: bkeene and mfakhan Requesting access to both UI and API We are interested in building something similar to support our researchers, we wish to compare AnvilGPT to other solutions provided (commercially or from internal teams) ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id:id-248a-43b5-a841-66499835a741 ~accountid:id ; Hi name, Your request has been approved. Feel free to use it, and let us know if you have any questions. ;",bkeene@access-ci.org,Benjamin Keene,Ashish Malik,,Anvil,3,6,10,2025,2025-03-03
ATS-14788,need to extend time limit on job for 9883785 x-olsonman,2025-03-12,2025-03-12,"Hello! I'm running an analysis I haven't run before and I gave it 23 hours as a time limit. I don't know if it will be enough time, and given the resources I've already used, it seems more efficient to add time rather than start over. Is it possible to extend the time after a job has started running. It's already been going 16 hours. The jobID is 9883785. I tried {{scontrol update jobid= TimeLimit=}}, but of course that didn't work :) ; Hi, Sure, we could help with it. How long do you want to extend your job to? Best, name ; It's been going for 22 hours. Could we add 2 more days? (48 more hours) ; Hi, Job extended now: \\*:\~]\\* $ jobinfo 9883785 Name : snp\\_calling User : x-olsonman Account : bio250083 Partition : shared Nodes : a082 Cores : 109 GPUs : 0 State : RUNNING ExitCode : -- Submit : 2025-03-11T18:05:55 Start : 2025-03-11T18:06:06 End : -- Waited : 00:00:11 Reserved walltime : 2-23:00:00 Used walltime : 22:43:47 Used CPU time : 00:00:00 % User (Computation): -- % System (I/O) : -- Mem reserved : 200G Max Mem used : -- Max Disk Write : -- Max Disk Read : -- Best, name ; Thank you! ;",olsonman@access-ci.org,Carrie Olson-Manning,Xiao Liu,,Anvil,5,1,11,2025,2025-03-10
ATS-8630,Network connection to tool session pods on nanohub is slow,2024-06-11,2025-03-18,"So it looks like when we have a high number of users and tool sessions the network connection between nanohub.org: http://nanohub.org and the Anvil pods is slow, some tool sessions take 5 minutes or more to connect to the Anvil pods. Is there a way to optimize the network so that performance is faster for users? ; Has this improved in the past couple days or is it still an issue? ; The performance has improved over the past few days, but we were also doing a more gradual rollout of tool sessions. Namely, having groups of 10 to 15 students creating tool sessions so as to not overwhelm the system. We are just trying to figure out what is causing the bottle neck, was it the network or was the exechost being overwhelmed. We did see that CPU usage was extremely high for exechost. ; name, I'm going to mark this one resolved. Let me know if we can be of further assistance. ;",jjones4@access-ci.org,James Jones,Erik Gough,Purdue University,Anvil,4,201,24,2024,2024-06-10
ATS-9003,Prometheus monitors don't show data,2024-07-01,2025-03-18,"Hello, I'm trying to monitor the memory usage and CPU of the nanohub deployment in Anvil and while I can watch over it most of the time the dashboards sometimes go blank and have a error indicator on them. The error says ""server error: 503"", it appears to be a service unavailable error. This happens periodically throughout the day and makes monitoring difficult. But often corrects itself over time. Can this be investigated so that we can maintain monitoring of the system? name ; Hello name ; Hi name, One of the prometheus components was getting OOM killed occasionally. I increase the memory 2x to help with the issue. -name ; Thank you, this was making usage monitoring a bit difficult. name, I'm going to mark this one resolved. Let me know if we can be of further assistance. ;",jjones4@access-ci.org,James Jones,Erik Gough,Purdue University,Anvil,6,187,27,2024,2024-07-01
ATS-9687,Notification of upcoming PVC expansion in Anvil,2024-08-02,2025-03-18,"Hello, I will be expanding the PVC for nanohub-home on Friday, Aug 2 at 1pm. I just wanted to notify RCAC to be on the lookout for any errors associated with the update. The target time to have everything ready for new sessions is 4pm that afternoon. Thank you in advance, name ; I am seeing some errors rolling in saying NodeExpandVolume.NodeExpandVolume failed for volume ""pvc-fb06da00-c68c-497f-803b-a268aa4e9d2f"" : Expander.NodeExpand found CSI plugin kubernetes.io/csi/rook-ceph.cephfs.csi.ceph.com: http://kubernetes.io/csi/rook-ceph.cephfs.csi.ceph.com to not support node expansion But it doesn't seem to impact performance as I can still create tool sessions in Anvil, but the errors are a little concerning. ; Hi name, I think you will need to restart all pods that are using this PVC so the volume will properly resize. This seems to be a bug in the current version of Rook we are using. -name, I'm going to mark this one resolved. Let me know if we can be of further assistance. ;",jjones4@access-ci.org,James Jones,Erik Gough,Purdue University,Anvil,4,163,31,2024,2024-07-29
ATS-11901,I cannot submit my script as sbatch ,2024-11-04,2025-03-20,"# We're working on your request and will get back to you as soon as we have a solution. Please allow up to one business day for our response. Best regards, name Purdue IT https://service.purdue.edu: https://service.purdue.edu/ ; Hi name, Thank you for reaching out to RCAC Support! I apologize for the late response. The problem is that the submission script doesn't specify a partition for your GPU job, so it defaults to the ""shared"" partition. Specifying a GPU partition in your submission script should fix this QOS error. Please let me know if this resolves your error or if you have any further questions. Best regards, name Purdue IT ; Hi, I have specified the partition as ""-p wholenode"" and tried ""--partition=wholeneode"" but I am still immediately receiving this error ""sbatch: error: Batch job submission failed: Invalid qos specification"". Thank you, name Hendrix ; Hi name, For the partition specification, please ensure you're using only the ""gpu"" partition. You can refer to the following page for more information: https://www.rcac.purdue.edu/knowledge/anvil/run/examples/slurm/gpu: https://www.rcac.purdue.edu/knowledge/anvil/run/examples/slurm/gpu. Here's the correct submission script line for the partition: #SBATCH -p gpu # Queue (partition) name Please let us know if you have any further questions or issues. Best regards, name Purdue IT ;",ehendrix1@access-ci.org,Emily Hendrix,Ansh Gangapurkar,Purdue University,Anvil,5,99,45,2024,2024-11-04
ATS-12097,Transfering Fortran software to Anvil ,2024-11-12,2025-03-20,"Hi, I am transferring my Fortran-based software from another supercomputer to Anvil. On Anvil, I need to adjust its required libraries and modules. The software works with the following modules: intel/2022.1.2 (intel), impi, mkl, fftw. A sample of the compiler bash file is provided in the following directory: ""/home/x-armkian/boundarylayer\\_DNS/v013/compile.sh"" Now, I faced difficulties in compiling and running the software on Anvil. Thus could you guide me to adjust it accordingly on Anvil? Best, name Kianfar ; Hi name: Thanks for contacting RCAC support! Taking look at your compiler bash file, it looks like you need intel/2022.1.2, but on Anvil the available versions of intel compilers are: \\* intel/19.0.5.281 \\* intel/19.1.3.304 \\* intel/2024.1 Please let us know if there's any other questions you might have or want clarified. Thanks, name Purdue University RCAC Support ; \\*\\*PRIVATE NOTE\\*\\* Anvil Application Team: https://access-ci.atlassian.net/jira/people/team/0f5fcf8a-26ef-4d24-a346-4a2ef3a7afda?ref=jira$&src=issue (~accountid:id ~accountid:id:id-bd45-4e12-b7de-6550f017a297 ~accountid:id:id-0296-44c2-8aaa-9a36b2662a58 ~accountid:id ~accountid:id:id-5a0e-4ef9-9dae-4ff21198071b ~accountid:id ~accountid:id ~accountid:id:id-c12e-4112-bfdf-3503868fdf94 ~accountid:id ~accountid:id ~accountid:id ~accountid:id) ; Hi name, Thanks for the response. I tested the default intel compiler; however, it did not work. I am wondering whether it is possible to set up a meeting so I can explain the code's requirements and receive guidance from you on how to make it work on Anvil. Best, name ---- ; Hi name: To our knowledge, we believe the problem has been solved during Anvil Support hour and are available for any other questions during Anvil support. After visiting the Anvil Support Hour, do you still want to keep this ticket open? Thanks, name Purdue RCAC Support ;",armkian@access-ci.org,Armin Kianfar,Ansen Shia,,Anvil,5,93,46,2024,2024-11-11
ATS-12714,Software install request,2024-12-12,2025-03-20,"We found GAMESS on Purdue clusters Bell, name, Scholar, Gilbreth, and Workbench on but not on ANVIL. Can you add an updated GAMESS module to ANVIL? ; Hi , Thank you for contacting Anvil support team. I need what options we can provide in this regard. I should come back as soon as I have an update. Best, I.name: http://i.name/ Anvil support team ; Is there any update yet? ; I still do not see gamess module on Anvil ; Hi Mandy, Thanks for reaching out Thanks Mandy name ---- ; Hi Mandy, Yeah, we have GAMESS on Purdue Community Clusters, like name or name, the access to them is paid by Purdue users. We did not put it on Anvil as only a few groups asked about it. :T Let me try to install GAMESS on Anvil, and get back to you later. Regards, name ; Hi Mandy, I tried to install GAMESS to my own scratch folder and I did not recognize abnormal things. Can you follow my note and try on your end? Let me know if you still see issues. sinteractive -N1 -n128 -t 8:00:00 #landed on a132.anvil cd /anvil/scratch/nshan/apps/gamess/ cp /anvil/projects/itap/nshan/apps/gamess/gamess-current.tar.gz . tar xvf gamess-current.tar.gz cd gamess/ ml --force purge ml gcc/11.2.0 openmpi/4.1.6 intel-mkl/2020.4.304 ml Currently Loaded Modules: 1) gmp/6.2.1 3) mpc/1.1.0 5) gcc/11.2.0 7) openmpi/4.1.6 2) mpfr/4.0.2 4) zlib/1.2.11 6) numactl/2.0.14 8) intel-mkl/2020.4.304 ./config please enter your target machine name: linux64 GAMESS directory? /anvil/scratch/nshan/apps/gamess/gamess GAMESS build directory? /anvil/scratch/nshan/apps/gamess/gamess Please provide a version number for the GAMESS executable. This will be used as the middle part of the binary name, for example: gamess.00.x Version? 00 24 HPC system target for 64-bit Linux system: Please enter your choice of FORTRAN: gfortran Please enter only the first decimal place, such as 8.2 or 11.2: 11.2 Enter your math library choice from one of the options below: 'acml', 'aocl', 'atlas', 'mkl', 'openblas', 'nvblas', 'armpl', 'nvpl', 'none' : mkl This is sometimes referred to as the MKL ROOT folder. MKL pathname? /apps/anvil/external/apps/intel/cluster.2020.4/compilers\\_and\\_libraries\\_2020.4.304/linux/mkl communication library ('serial','sockets' or 'mpi' or 'mixed')? mpi Enter MPI library (hpcx, impi, mpich, mvapich2, mpt, openmpi, sockets): openmpi Please enter your openmpi's location: /apps/spack/anvil/apps/openmpi/4.1.6-gcc-11.2.0-745pfv4 Optional: Build LibXC interface? (yes/no): no Optional: Build MDI support? (yes/no): no Optional: Build MSU CCT3, CCSD3A, ACP & DEA/DIP-EOMCC methods? (yes/no):no Do you want to use LIBCCHEM 2.0? (yes/no): no Build GAMESS with OpenMP thread support? (yes/no): yes Optional: Build GAMESS with VeraChem's VM2 library? (yes/no): no Optional: Build GAMESS with TINKER plug-in? (yes/no): no Optional: Build GAMESS with VB2000 plug-in? (yes/no): no Optional: Build GAMESS with XMVB plug-in? (yes/no): no Optional: Build GAMESS with NEO plug-in? (yes/no): no Optional: Build GAMESS with NBO plug-in? (yes/no): no Optional: Build GAMESS with RISM-SCF-cSED plug-in? (yes/no): no make ddi make -j128 Regards, name ; Good Morning name, that worked well, gamess v 24 is now installed. Please make this as resolved. Mandy ---- ; Awesome --name ;",mcgreen@access-ci.org,Mandy Green,Nannan Shan,,Anvil,15,71,50,2024,2024-12-09
ATS-13006,Unexpected CPU Allocation on ACCESS HPC Anvil,2025-01-05,2025-03-20,"My name is name Aguirre, and I am a user of the ACCESS HPC Anvil system managed by Purdue University. I have been submitting a series of batch jobs requesting 2 hours of computation using \\*1 CPU\\* and \\*4 GB of RAM\\* per job. However, upon reviewing the job status, I noticed that each job is being allocated \\*3 CPUs\\*, despite my script specifying only \\*1 CPU\\*. ReqTRES=cpu=1,mem=4G,node=1,billing=1 AllocTRES=cpu=3,mem=4G,node=1,billing=3 The batch jobs are designed as SLURM array jobs, leveraging SLURM's parallelism functionalities. My goal is to utilize only \\*1 CPU\\* per job to optimize resource usage and prevent unnecessary billing for additional CPUs. Could you please advise me on how to enforce the allocation of only \\*1 CPU\\* for these jobs? I have attached: # The header section of one of the batch scripts I am using. #!/bin/bash # FILENAME: name\\_exp320u #SBATCH -A ees240082 # Allocation name #SBATCH --nodes=1 # Total # of nodes (must be 1 for serial job) #SBATCH --ntasks=1 # Total # of MPI tasks (should be 1 for serial job) #SBATCH --time=2:00:00 # Total run time limit (hh:mm:ss) #SBATCH --mem=4GB #SBATCH --cpus-per-task=1 #SBATCH -J name\\_exp320u # Job name #SBATCH --output=/home/x-iaguirrebelm/Documents/logs/slurm\\_output/slurm-%A\\_%a.out #SBATCH --error=/home/x-iaguirrebelm/Documents/logs/slurm\\_error/slurm-%A\\_%a.out #SBATCH -p shared # Queue (partition) name #SBATCH --mail-user= #SBATCH --mail-type=all # Send email to above address at begin and end of job # The job accounting output, which highlights that \\*1 CPU was requested\\*, but \\*3 CPUs were allocated\\*. :8b\\_sobol\\_hpc] $ scontrol show job 9122512\\_41 JobId=9122553 ArrayJobId=9122512 ArrayTaskId=41 JobName=name\\_exp320u UserId=x-iaguirrebelm(7956291) GroupId=x-ees240082(7008398) MCS\\_label=N/A Priority=33783 Nice=0 Account=ees240082 QOS=cpu JobState=RUNNING Reason=None Dependency=(null) Requeue=1 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0 RunTime=00:01:10 TimeLimit=02:00:00 TimeMin=N/A SubmitTime=2025-01-05T16:50:26 EligibleTime=2025-01-05T16:50:27 AccrueTime=2025-01-05T16:50:27 StartTime=2025-01-05T16:50:59 EndTime=2025-01-05T18:50:59 Deadline=N/A PreemptEligibleTime=2025-01-05T16:50:59 PreemptTime=None SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-01-05T16:50:59 Scheduler=Backfill Partition=shared AllocNode:Sid=login07:1887042 ReqNodeList=(null) ExcNodeList=(null) NodeList=a004 BatchHost=a004 NumNodes=1 NumCPUs=3 NumTasks=1 CPUs/Task=1 ReqB:S:C:T=0:0:\\*:\\* ReqTRES=cpu=1,mem=4G,node=1,billing=1 AllocTRES=cpu=3,mem=4G,node=1,billing=3 Socks/Node=\\* NtasksPerN:B:S:C=0:0:\\*:\\* CoreSpec=\\* MinCPUsNode=3 MinMemoryNode=4G MinTmpDiskNode=0 Features=(null) DelayBoot=00:00:00 OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null) Command=/home/x-iaguirrebelm/Documents/plumber/pl2\\_ensembles/8b\\_sobol\\_hpc/8b\\_name\\_main320\\_base.sh WorkDir=/home/x-iaguirrebelm/Documents/plumber/pl2\\_ensembles/8b\\_sobol\\_hpc StdErr=/home/x-iaguirrebelm/Documents/logs/slurm\\_error/slurm-9122512\\_41.out StdIn=/dev/null StdOut=/home/x-iaguirrebelm/Documents/logs/slurm\\_output/slurm-9122512\\_41.out TresPerTask=cpu=1 MailUser= MailType=INVALID\\_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE\\_OUT I look forward to your guidance on resolving this issue. Thank you for your time and support. Best regards, ; Hello name, Thank you for reaching out to RCAC Support! We're working on your request and will get back to you as soon as we have a solution. Best regards, name Purdue IT [https://service.purdue.edu: https://service.purdue.edu/ ; Hi name, On Anvil, each CPU on Anvil is bundled with approximately 1.9GB of RAM. Since your job requests 4GB of RAM + 1 CPU, Slurm has to allocate 3 CPUs to meet the minimum memory requirement of 4GB. To make sure that your job is allocated only 1 CPU, you must remove the RAM request (#SBATCH --mem=4GB). This will allow Slurm to assign the appropriate resources based on the default CPU-memory bundling. Try modifying your script by removing the --mem=4GB line and resubmitting the job, and let me know if this resolves the issue. Best regards, name Purdue IT https://service.purdue.edu: https://service.purdue.edu ;",iaguirrebelmar@access-ci.org,Ignacio Aguirre Belmar,Ansh Gangapurkar,Purdue University,Anvil,3,54,1,2025,2024-12-30
ATS-13277,Quota on Anvil project,2025-01-17,2025-04-02,"Hi, I have a project x-bio220114 on Anvil, and the file size quota shows that we have used 4.9TB out of 5.0TB. However, when I checked the project directory, we only used 275G, by running \\*name -lh\\*. I wonder how to further reduce the files to get more space. Best, Pin-name ; Hello name ; Hi name, Do you have any updates on it? The disk quote issue has been hindering our project significantly. I checked again today, and we are only using 275G, but the entire disk space (5T) is full. Best, Pin-name ---- ; Hi Pin-name, Thank you for your patience, and sorry for the delayed response. I will be handling this ticket from now on since name is currently unavailable, and the ticket was lost in our queue. I see your point. When I run the {{ncdu}} command on your project directory, I see that your total disk usage is 242.9 GB. I will report this issue to our storage team and keep you posted. Best, name K ; Hi Pin-name, After discussing with the team and investigating the storage quota issue, we've identified the likely cause: \\*block size allocation\\*. Here's the breakdown: Less than 1% of your files actually reach 16MB in size. However, the system allocates a minimum block size (typically 4-16MB) to every file, regardless of its actual size. This means even tiny files (e.g., those under 1KB) consume an entire block. With a third of your files being under 1KB, this inefficiency adds up quickly, leading to the reported ~5TB usage. To resolve this, we recommend bundling small files into tarballs (compressed archives). This would eliminate the per-file block overhead and could save terabytes of space immediately. Let me know if you need further assistance. Best, name K ; Hi name, Do you have a way to quickly identify those files? Best, Pin-name ---- ; You can use this command to find Small Files (e.g., <1KB): find . -type f -size -1k -exec ls -lh {} \; | sort -k5h Best, name K ; Hi name, This is very helpful. I was able to find those files. A related question is if I have users leave the group/project, how can I remove their files? Best, Pin-name ---- ; The PI of the allocation needs to let us know and we will grant write permission so you can remove the files. Best, name K ; Hi, I have removed the access of the user \\*ylin10\\* on the project. Can you grant me (PI) the write permission to remove the files? Best, Pin-name ---- ; Hi, You should have access to the files. Let me know if there's any other issues. Best, name K ; It works. Thank you very much for your help! You can close the ticket. Best, Pin-name ---- ; Awesome! I will mark the ticket as resolved. Feel free to reach out again with any questions. Best, name K ; Hi name, My students have removed all the small files as suggested. The disk quota still shows projects x-bio220114 4.9TB 5.0TB 100.0% 3.3K 1.0M 0.3% What else can we do to resolve this? Best, Pin-name ---- ; Thanks for reaching out. I will discuss this issue with my colleagues and get back to you as soon as possible. Best, name K ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id:id-6f55-4972-a4c9-1abbc8b28d3f Could you please check this ticket and see what can be done to resolve this issue? ; Hi name, I reported the issues still exist, and you replied to me on March 26 that you will discuss this issue with your colleagues and get back to me as soon as possible. I have not heard from you a potential solution. Please keep this ticket open. Best, Pin-name ---- ; Hi Pin-kaung, Sorry it was a mistake on my side and I resolved your ticket by mistake, and then reopened it immediately. I have reached out to my colleagues and will update you ASAP. Best, name K ; Hi Pin-Kaung, I checked with our storage team regarding this issue. The problem you're experiencing is due to the quotas being out of sync. This is a known issue, and while there is a fix, it requires significant system resources and the cluster needs to be less busy for it to be applied. Since it's not possible to address the root cause at the moment, we've doubled your project folder quota to 10TB as a workaround. Let me know if you have any questions. Best, name K ; Hi name, I have seen the storage quota being increased to 10TB. You can close the ticket. Best, Pin-name ---- ; Thanks for letting me know. Feel free to reach out again with any questions. Best, name K ; Hi name, The disk quota reaches 100% again after recently being added to 10TB. We did not generate so much new data on the project directory. Now, we can not write new files. Best, Pin-name ---- ; Hi Pin name, Thanks for letting me know. Let me check this with storage team again. Best, name K ;",laip416@access-ci.org,PIN-KUANG LAI,Haniye Kashgarani,Purdue University,Anvil,23,54,3,2025,2025-01-13
ATS-13616,Creating Project/Namespace on Anvil composable.,2025-01-30,2025-03-18,"Greetings, This is name from Purdue SSG. We've recently got approved the project on Anvil for \\*CIS250069: Integrating ML/AI workflows in StreamCI Sensor Data Management and Processing Platform\\*. Could you please create a project on Anvil composable for that? We initially need 64CPU, 256GB memory, and 4 TB of storage. It looks like I don't have a permission for that. Thank you! ; This is configured. -name ;",nujwoo@access-ci.org,Shin Jaewoo,Erik Gough,Purdue University,Anvil,2,34,5,2025,2025-01-27
ATS-14007,Anvil faulty node,2025-02-14,2025-03-28,"I kept getting ""Uncorrectable ECC error"" when training in node g-008. According to what I looked up, this error came from hardware failure. I wonder if this node is having issues? ; Hello, I hope you are doing well. Thank you for reaching out to RC Support with your question! We are actively working on addressing the issue. Rest assured, we will provide you with a response as soon as possible. Best regards, name RCAC Support ; Hello, I apologize for the very delayed response. Are you still experiencing this issue? name RCAC Support ; Hello, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best Regards, name RCAC Support ;",clu1@access-ci.org,Chen-yi Lu,Ankitha Mallekav,Purdue University,Anvil,4,31,7,2025,2025-02-10
ATS-14031,Follow-up on Ticket ATS-11740 - Job Priority Issue for MTH210005,2025-02-14,2025-03-19,"I am following up on ticket \\*ATS-11740\\* regarding the persistent low priority of jobs submitted under our project \\*MTH210005\\* since last October. In the previous response, it was mentioned that system engineers would take a closer look, but we have not received any updates in the next half years. We would like to emphasize that our conclusion about the low priority is based on the \\*sprio\\* command, which is the SLURM tool for checking job priorities. While we understand that \\*Anvil's scheduling system is designed to prioritize jobs equally\\*, the SLURM output consistently shows that our job priorities remain extremely low. This concern is \\*not about the policy itself but whether the queueing system is correctly enforcing the policy\\*. While we understand that priority can be temporarily low if we have submitted too many jobs recently, our situation has persisted for nearly \\*six months\\*, significantly preventing us from running any GPU jobs, let alone heavier workloads. Could you please provide an update on the investigation and whether any adjustments can be made to address this issue? We appreciate your time and assistance. ; Liyao, Thank you for contacting RCAC for support. I am working with our engineers to see what is happening with our priority system. Thank you for your patience. Thanks, name ; Liyao, I apologize for the long delay in response, we have many projects and maintenances going on. I wanted to clarify, are you concerned about the priority of GPU jobs, or of CPU jobs? Or both? As far as I'm aware, slurm doesn't use priority for GPU jobs and they are distributed according to resources available and requested. Could you send me some examples of job IDs that waited a long time? I also apologize that my earlier response was not transmitted to you, our issue tracking software changed some settings on me, so it defaulted to be an internal note instead of a response to you. Thanks, name ; Hi name, Thank you for your response. I appreciate the clarification. My concern is specifically about the priority of GPU jobs. From my observations, my job priority has been significantly lower than others for the past six months. Below is an example of the \\*sprio\\* command output from last week, which shows my job priority was \\*10,000 points lower\\* than other users: ``` :~ $ sprio -p gpu -l JOBID PARTITION USER ACCOUNT PRIORITY SITE AGE ASSOC FAIRSHARE JOBSIZE PARTITION QOSNAME QOS NICE TRES 9548323 gpu anand211 ai240101 48151 0 0 0 38151 0 10000 gpu 0 0 9548332 gpu x-lyuliy mth21000 38139 0 0 0 28140 0 10000 gpu 0 0 ``` However, when I checked just now, my priority value seemed to have increased: ``` :~ $ sprio -u x-lyuliyao JOBID PARTITION USER PRIORITY SITE AGE FAIRSHARE JOBSIZE PARTITION QOS 9744959 gpu x-lyuliy 60000 0 0 50000 0 10000 0 ``` Even though the priority is now higher, I believe it would be beneficial to investigate what caused this issue and consider documenting it for Anvil users. Let me know if you need more details. Best, Liyao ; Liyao, I just had a discussion with one of our engineers and your ticket brings up a good point about how our priority is calculated. We are discussing how we can effectively change it to better prioritize jobs. I'll keep you updated as we make changes. Thanks, name ; Liyao, Today, we are changing the way that job priority is calculated. Before, fair share was the main contributing factory to how soon a job will be run. However, we are now balancing it so that wait time, fair share, and job size all contribute equally to the priority of a job. Hopefully, this is an improvement to how it currently works. Thanks, name ; Liyao, Since it's been a while since I've heard from you, I am tentatively marking this ticket as resolved. If you are still facing problems, please respond to this ticket within 7 days to reopen it. Otherwise, you can always submit a new ticket. Thanks, name ; Thank you for your update and help. I think the problem is solved. I was busy with traveling and thesis recently. Sorry for the late response. Best wishes, Liyao Lyu ;",lyuliyao@access-ci.org,Liyao Lyu,Michael Carlson,,Anvil,8,24,7,2025,2025-02-10
ATS-14062,Regarding importing larger language model in anvil,2025-02-17,2025-04-03,"Hello, I am name. I am a graduate student at Purdue and our research group was exploring if it is possible for us to import a large parameter fine tuned model like llama 3.1 405b parameter model or Deepseek r1 670b parameter model in Anvil, we are planning to fine tune them in Gilbreth and then transfer to Anvil. Would there be any issue if this big models are loaded in Anvil? Thank you! ; Hi name, You should be able to access (or request to access) AnvilGPT: https://anvilgpt.rcac.purdue.edu/auth/ where you are able to request a model being uploaded. We can schedule a meeting to carry this out, however, there is no issue with any large-parameter models being uploaded. Alternatively, you are also able to access GenAI : http://genai.rcac.purdue.edufor non-Anvil and free model uploads without request. Please note that Purdue RCAC's prevents users storing any HIPAA data on non-encrypted or common access storage solutions such as Data Depot which might encompass trained models' training data. Please see here: https://www.purdue.edu/legalcounsel/HIPAA/ for more info. Best Regards, Eli name Purdue IT https://service.purdue.edu ; Hello, Thank you for your response. We have not yet completed our fine-tuning. We can schedule a meeting once it is done. I asked because all the models I saw on Anvil had a maximum of 70B parameters. So, I was unsure whether Anvil could handle models larger than 70B. Thank you. ---- ; Hi name, I would like to correct a claim in the previous response. Any large models (such as Deepseek-671b) need to be overlooked by our Lead Data Researcher, name. In the case that you are able to carry out research on the moderate-sized 70b models provided then there would be no issue. The latter also applies to requesting to upload models around the 70b parameter mark. Please let us know if your group need the higher-parameter models upload and I shall get you in contact with her. Best Regards, Eli name Purdue IT https://service.purdue.edu ; Hello, We have decided not to use any model over 70B parameter, we would be finetuning the Llama 3.3 70B model itself. I also wanted to know if the Llama 3.3 70B which you have on Anvil is already finetuned on something? If it is okay with you then we would like to finetune same model in Anvil cluster itself using name, please let me know if its possible to finetune on Anvil cluster itself rather than uploading from somewhere else? Thank you! name. ---- ; Hi name, We shall get back to you on this as the details of AnvilGPT and the models hosted on it are overlooked by name. However, the Llama models on Anvil (not the Deepseek model) are not finetuned and are as-is. Best Regards, Eli name Purdue IT https://service.purdue.edu ; \\*\\*PRIVATE NOTE\\*\\* Resolved by default ;",rdeotale@access-ci.org,Rushikesh Prafulla Deotale,Elian Inigo Rieza,,Anvil,7,34,8,2025,2025-02-17
ATS-14184,install FLAIR,2025-02-20,2025-03-28,"Would it be possible to install FLAIR https://github.com/BrooksLabUCSC/flair: https://github.com/BrooksLabUCSC/flair|smart-link on Anvil? ; Hello, I hope you are doing well. Thank you for reaching out to RC Support with your question! We are actively working on addressing the issue. Rest assured, we will provide you with a response as soon as possible. Best regards, name RCAC Support ; Hello Petra, Thank you for your patience. I recommend following the steps outlined in the Flair documentation: https://flair.readthedocs.io/en/latest/requirements.html to install it independently. If you encounter any errors during installation, you can reach out to us, and we'll be happy to assist further. Best, name RCAC Support ; Hello, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best Regards, name RCAC Support ;",ppopovics@access-ci.org,Petra Popovics,Ankitha Mallekav,,Anvil,4,27,8,2025,2025-02-17
ATS-14270,No permission access to a directory,2025-02-24,2025-04-03,"I'm writing to request access to the directory \\_/anvil/projects/x-cis220051/dashboard.\\_ I previously had access and stored important code there, but I can no longer reach it. If you could restore my permissions—or alternatively, allow me to copy the contents to my home directory—I can continue working on the code while the team investigates the permission issue. Your assistance would be greatly appreciated. ; Hi, I hope you're doing well. I sincerely apologize for the delay in following up on your ticket. I lost track of our conversation and apologize for the inconvenience this has caused. I'm reaching out to see if you're still experiencing any issues with your request. If so, please let me know, and I'm happy to assist if needed. Feel free to reach out if you have any further questions. Best regards, name Purdue IT https://service.purdue.edu/: https://service.purdue.edu/ ; Hi, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best Regards, name Purdue IT https://service.purdue.edu: https://service.purdue.edu|smart-link ;",aarroyo@access-ci.org,Ashley Arroyo,Ansh Gangapurkar,Purdue University,Anvil,3,29,9,2025,2025-02-24
ATS-14272,trouble accessing project directory,2025-02-24,2025-04-03,"I am using Anvil CPU for my project. I had an old project that expired and now using a new one but in my account when i go to $PROJECT it always shows the old project directory. Although upon using myquota or myallocations command i see both. how to access the new project directory in anvil? ; Hi, I hope you're doing well. I sincerely apologize for the delay in following up on your ticket. I lost track of our conversation and apologize for the inconvenience this has caused. I'm reaching out to see if you're still experiencing any issues with your request. If so, please let me know, and I'm happy to assist if needed. Feel free to reach out if you have any further questions. Best regards, name Purdue IT https://service.purdue.edu/: https://service.purdue.edu/ ; Hi, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best Regards, name Purdue IT https://service.purdue.edu: https://service.purdue.edu ;",ashah7@access-ci.org,Aanal Jayesh Shah,Ansh Gangapurkar,,Anvil,3,29,9,2025,2025-02-24
ATS-14279,about Anvil machine,2025-02-24,2025-04-03,"Hi officer, I have a trouble on using Anvil started last Friday. The dashboard show the mybalance isn't corrected and my job is disappear. Do you know whether it is the problem in the Anvil or is the problem on my account? ; Hi, I hope you're doing well. I sincerely apologize for the delay in following up on your ticket. I lost track of our conversation and apologize for the inconvenience this has caused. I'm reaching out to see if you're still experiencing any issues with your request. If so, please let me know, and I'm happy to assist if needed. Feel free to reach out if you have any further questions. Best regards, name Purdue IT https://service.purdue.edu/: https://service.purdue.edu/ ; Hi, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best Regards, name Purdue IT https://service.purdue.edu: https://service.purdue.edu|smart-link ;",chsu4@access-ci.org,Chun-Yen Hsu,Ansh Gangapurkar,,Anvil,3,29,9,2025,2025-02-24
ATS-14337,Unreasonably high usage for Purdue Anvil CPU,2025-02-25,2025-03-17,"Dear Help Desk, I notice an unreasonably high usage (> 3M SUs) on my account for Purdue Anvil CPU last week, and the computational time on our allocation EAR160027 ran out because of that. Why is there such a high usage, and is it related to the system outage last Friday? I remember one of my job (Job\\_id=9622523) experienced a lot of node failure and requeue on Friday night. These resources are very important for my computations. Could you please check what caused the high usage? Thank you very much for looking into this issue and for your support name ; Hi name, Thanks for reaching out and reporting this to us. We are investigating on this, if we found it is a node failure, we will refund you these SUs. We will keep you posted. Thanks for your patience on this. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Hi name, Thank you for your helpjob.png|width=592,height=401,alt=""job.png""! name ; Hi name, I think we've refunded your SUs to your allocation. Thanks for your patience on this. Please let us know if you have any other questions. Regards, name ;",jqfang@access-ci.org,Jiaqi Fang,Nannan Shan,,Anvil,6,15,9,2025,2025-02-24
ATS-14503,Storage Issue,2025-03-03,2025-03-24,"Hi, I am a first-time anvil user. My quota shows- h1. Type Location Size Limit Use Files Limit Use home x-gmadhukar 19.8GB 25.0GB 79% - - - scratch anvil 0KB 100.0TB 0% 0k 1,000k 0.00% projects x-bio250049 0KB 5.0TB 0% 0k 1,048k 0.00% How can I access the storage for Scratch Anvil and Projects X-bio250049? 25GB is not sufficient for my tasks. I am unable to find the directories for both Scratch Anvil and Projects X-bio250049. Kindly help resolve this issue. Thanks ; Hi, Thank you for reaching out to RCAC Support! We're working on your request and will get back to you as soon as we are able. We appreciate your patience. Please allow up to a couple of business days for a response. Best regards, name Purdue IT https://service.purdue.edu: https://service.purdue.edu ; Hi Geet, Thank you for reaching out and for joining the Support Hour last Thursday. Since we were able to resolve this issue during the session, I will mark this ticket as resolved. However, feel free to reach out if you continue to experience any issues. Best, name K ;",gmadhukar@access-ci.org,Geet Madhukar,Haniye Kashgarani,Purdue University,Anvil,3,16,10,2025,2025-03-03
ATS-14509,Issues with Job I submitted,2025-03-03,2025-03-24,"I submitted a job and its taking more than 48 hours to run and still not producing any result ; Good morning, which resource/system (Bridges, Anvil, Expanse, etc) are you running on? ; I submitted the job in Anvil ---- ; Hi name, Thank you for reaching out. I don't see any pending jobs submitted under your account. I believe the job has already run and executed since you submitted the ticket. However, if you're experiencing any issues, please let me know. Best, name K ; Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name K ;",moyelakin@access-ci.org,Michael Oyekunle Oyelakin,Haniye Kashgarani,Purdue University,Anvil,5,16,10,2025,2025-03-03
ATS-15425,Jobs submission issue,2025-04-02,2025-04-03,"We had to wait for a very long time to get a computation node; it started on Monday. I guess there is some issue with the system. Please check it. ; Hi, Thanks for reaching us. I saw your job has been canceled. I tried to tackle the details of the job to see the reasons but got jobscript NONE. Is that a Jupyter notebook or other interactive application job? Would you like to share the resources you requested? Best, name ; I just submitted a new job, job ID is: 10396739 It seems to be waiting forever. -- Wubin name ; Hi, I still can't see your job script and how many resources you requested. How did you submit the job? \\*:\~\\* $ jobscript 10396739 NONE \\*:\~\\* $ jobinfo 10396739 Name : bash User : x-wding2 Account : mcb130189 Partition : shared Nodes : None assigned Cores : 0 GPUs : 0 State : PENDING (Priority) ((null)) ExitCode : -- Submit : 2025-04-02T16:14:40 Start : -- End : -- Waited : 00:46:13 Reserved walltime : 10:00:00 Used walltime : -- Used CPU time : -- % User (Computation): -- % System (I/O) : -- Mem reserved : 160G Max Mem used : -- Max Disk Write : -- Max Disk Read : -- ; I requested an interactive node using the following command: srun -p shared --mem 160G -c 32 -t 0-10:00:00 --pty bash -- Wubin name ; Hi, This is what I got: \\*:\~\\* $ srun -p shared --mem 160G -c 32 -t 05:00 --pty bash srun: error: Unable to allocate resources: Invalid qos specification You should have -A your\\_account there and add more information. like this: \\*:\~\\* $ sinteractive -A rcac -p shared --mem 160G -N1 -c32 -t 05:00 salloc: Pending job allocation 10407723 salloc: job 10407723 queued and waiting for resources salloc: job 10407723 has been allocated resources salloc: Granted job allocation 10407723 salloc: Waiting for resource configuration salloc: Nodes a133 are ready for job Tip of the day (use ""touch $HOME/.no.tips"" to stop): ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Do you want a robust approach to backup, transfer, and version control? Give git a try; you'll be glad you did. \\*:\~\\* $ ; No, no. You got error because you requested for 5 days (the max is 4 days). I didn't requested 5 days, I only requested 10 hours: \\*+srun -p shared --mem 160G -c 32 -t 0-10:00:00 --pty bash+\\* ---- ; My bad. You requested 5 hours, not 5days. I have been using this command to request an interactive node for more than one year and it works well. Why is it not working now? ---- ;",wding2@access-ci.org,Wubin Ding,,,Anvil,9,2,14,2025,2025-03-31
ATS-14697,Request for Increased Job Runtime & Installation of Yambo 5.3.0 on Anvil,2025-03-09,2025-04-01,"I hope you are doing well and I am reaching out regarding two requests: # \\*Request to increase Maximum Job time\\* I have noticed that the maximum allowed runtime for my jobs is 4 days (96 hours). If I increase it more days, I have seen the following error: fails due to {{QOSMaxWallDurationPerJobLimit}} {{Here is my job script:(please see the attachment)}} However, my simulations require longer runtime (several weeks) due to extensive DFT-based calculations (specially for Yambo software). Would it be possible to increase my max wall time beyond 4 days to accommodate my workload? # \\*Request to install Yambo 5.3.0\\* I would also like to request the installation of Yambo 5.3.0 on Anvil. This software is essential for my DFT-based Many-Body Perturbation Theory (MBPT) simulations. The latest version 5.3.0 can be found at: https://www.yambo-code.eu/download/: https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.yambo-code.eu%2Fdownload%2F&data=05%7C02%7Crcac-help%40purdue.edu%7Cb0fd1e86d7b34f58fa4b08dd5db3ed95%7C4130bd397c53419cb1e58758d6d63f21%7C0%7C0%7C638769750077056069%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C60000%7C%7C%7C&sdata=e6k1XoV%2BHmac9O%2BZpBBLSjx8pMIXBkx3e%2FJlIogEXQ0%3D&reserved=0 I would greatly appreciate your support on these requests. Please let me know if you need any further information from my end. ; Md. name, Thank you for contacting RCAC for support. Regarding your two requests: 1.) The Maximum wall time (which is set at 96 hours) is to make sure that all jobs are allowed to run in a timely manner on Anvil. I would recommend implementing checkpointing into your program, which periodically writes files that your program is able to restart from, picking up where the last one left off. This way, even if something unexpected happens, you're able to restart from a midway point instead of losing weeks of work. 2.) You are able to install programs yourself into any area that you have write access to. Thus, I would recommend downloading and installing Yambo yourself. If you need assistance in doing that, let me know and I can work with you to make that happen. Thanks, name ; Md. name, Since it's been a while since I last heard from you, I am tentatively marking this ticket as resolved. If you are still facing problems, please respond to this ticket within 7 days to reopen it. Otherwise, you can always submit a new ticket. Thanks, name ;",MCH240098,Md. Jahid Hasan Sagor,Michael Carlson,Purdue University,Anvil,4,17,10,2025,2025-03-03
ATS-14701,Open Demand for Purdue Anvil is not opening after loggin in - give 403 Forbidden error,2025-03-09,2025-03-19,"I have been using open demand portal to access my files and research in the Purdue Anvil supercomputer. I last logged in on Friday, March 7th and everything was fine. Today (March 9th)when I tried to log in to the OpenDemand portal gives me 403 Forbidden error. Can someone please help me regain access to my open on demand portal? ; name, Thank you for contacting RCAC for support. There was a blip over the weekend where many users saw the 403 forbidden error when accessing Anvil. This should now be resolved. Try again and let me know if you run into the error. Thanks, name, Since it's been a while since I've heard from you, I am tentatively marking this ticket as resolved. If you are still facing problems, please respond to this ticket within 7 days to reopen it. Otherwise, you can always submit a new ticket. Thanks, name ;",u1077706@access-ci.org,Apoorva Pedgaonkar,Michael Carlson,,Anvil,3,8,10,2025,2025-03-03
ATS-14722,Job submission limited to 2,2025-03-10,2025-03-20,"Currently, the system allows me to submit 2 jobs at a time. Is it restricted to 2 jobs only, or is there a way to overcome that limit? I need to run more jobs simultaneously to complete my project task. We need your urgent help on this. ; Good afternoon - which system are you running on so we can direct your ticket to the proper team. Thanks! ; Hello, Thank you for your email. I am running scripts using anvil account in the RCAC system with highmem and shared nodes. Below are my credentials: : mailto: The project name: EES240045 (Data integration and analysis tools for climate, water, and environmental sustainability). I am copying this to my colleague, who is working under the same project and running scripts using his credentials. Regards, Haider. ; Hi, We just picked up your ticket after an audit, is this still an issue? Best Regards, Eli name Purdue IT https://service.purdue.edu ; Hello, The issue was solved. Thanks for taking care of it. Regards, Haider ;",mhaider1@access-ci.org,Muhammad Rezaul Haider,Elian Inigo Rieza,Purdue University,Anvil,5,9,11,2025,2025-03-10
ATS-11740,The queue time very long and sprio is very long ,2024-10-28,2025-04-10,"Dear Support Team, I am writing to inquire about the extremely low account PRIORITY for my job submissions, and I'm unsure of the reason. I don't believe this is due to job demand, as I have adjusted the time requirements for my jobs. Additionally, I haven't run any jobs in the past 10 days while these jobs have been queued, so recent job activity shouldn't be the cause. Here is the output from {{sprio -u x-lyuliyao}}: {{ JOBID PARTITION USER PRIORITY SITE AGE FAIRSHARE JOBSIZE PARTITION QOS }} {{8039914 gpu x-lyuliy 38926 0 500 28427 0 10000 0 }} {{8039915 gpu x-lyuliy 38926 0 500 28427 0 10000 0 }} {{8224905 gpu x-lyuliy 38426 0 0 28427 0 10000 0}} Could you please help me understand why the account PRIORITY is so low and advise on how I can increase it? Thank you for your assistance. Best regards, ; Hello, Thank you for contacting RCAC Support! We will get back to you as soon as we have the answer. Best regards, name Purdue IT ; Hello, Thank you for reaching out! The jobs you requested are already running, but resources need to be allocated to them. Please allow more time for the allocation of resources. Please let us know if you have further questions. Best regards, name Purdue IT ; Hi name \\* \\*My Question is my\\*\\* \\* \\*sprio\\*\\*\\* \\*is unreasonable low now!\\*\\* Waiting for \\* \\*more than 15 days\\*\\* for one job is not a reasonable time! There is no reason you mark this problem as resolved by just waiting until the job are queued. Best wishes Liyao ; Hello Liyao, I apologize for any frustration. Anvil's scheduling system prioritizes jobs equally, and currently, all GPUs are busy, leading to extended wait times. Because of this, the best solution is to wait until resources become available. Please let us know if you have any further questions. Best Regards, name Purdue IT ; Hi name, I think what Anvil scheduling is using SLURM system. In SLURM system, users can see the priority by running \\*sprio\\* command. I have attached the results of \\*sprio\\* with my job and others job (similar length), where you can see on\\* \\*\\*the third line ""PRIORITY""\\* is much lower than others. Based on this \\*fact\\*, I am asking \\*why this number is so small\\* and \\*what I can do with this\\*. I understand this number will reduce if I run too much jobs recently, but since I have queue for more than two weeks, without any heavy job. I think this number is not normal now. \\*:~]\\* $ sprio -p gpu -j 8246769 JOBID PARTITION PRIORITY SITE AGE FAIRSHARE JOBSIZE PARTITION QOS 8246769 gpu 48409 0 12 38398 0 10000 0 \\*:~\\* $ squeue -j 8246769 JOBID USER ACCOUNT NAME NODES CPUS TIME\\_LIMIT ST TIME 8246769 x-aabdallah cis220051-gpu batch\\_grapheno.s 1 32 1:00:00 PD 0:00 \\*:~\\* $ sprio -p gpu -j 8245991 JOBID PARTITION PRIORITY SITE AGE FAIRSHARE JOBSIZE PARTITION QOS 8245991 gpu 38446 0 24 28423 0 10000 0 \\*:~\\* $ squeue -j 8245991 JOBID USER ACCOUNT NAME NODES CPUS TIME\\_LIMIT ST TIME 8245991 x-lyuliyao mth210005-gpu myjobname 1 10 1-00:00:00 PD 0:00 ; Hello Liyao, I apologize for the misunderstanding and for prematurely marking the ticket as resolved. We've requested the system engineers to take a closer look, and we'll follow up with a detailed update as soon as possible. Thank you again for your patience, and I apologize for the inconvenience. Best Regards, name Purdue IT ; Hi name, It's been weeks since I reported this issue, and I still haven't received a proper response. My job priority is still unreasonably low. The system engineers were supposed to look into it, but I haven't heard back. I need an actual update on what's going on and why my priority remains so low. Waiting for your response. Liyao Lyu ; Dear Access Administrator, We would like to follow up on the issue regarding the low priority and long queue time for our jobs in Anvil. It looks like all the jobs submitted by our project MTH210005 get a very low priority. We have encountered this issue for several months. The progress of our project is delayed with the current slow response. We are very concerned about it. Could you please take a look? Thank you very much, Best, Huan ---- ; Hi Liyao, I sincerely apologize for the delay in getting back to you. I lost track of our conversation and apologize for the inconvenience this has caused. Our engineers have recently revisited how SLURM handles fair share usage and priorities. It should now be improved. To give you more context, staff discovered that Anvil's job scheduling was heavily weighted toward Fairshare, which tracks how much compute time each user/account has used. However, the Fairshare value effectively never decayed. This meant that once a user consumed a lot of resources, their priority would stay low indefinitely, no matter how long they paused usage. This made it hard for users with low Fairshare to regain access, but this should now be improved. Once again, I apologize for the delayed response. Please feel free to reach out if you have any further questions. Best regards, name Purdue IT [https://service.purdue.edu/: https://service.purdue.edu/ ; Hi Liyao, I sincerely apologize for the delay in getting back to you. I lost track of our conversation and apologize for the inconvenience this has caused. Our engineers have recently revisited how SLURM handles fair share usage and priorities. It should now be improved. To give you more context, staff discovered that Anvil's job scheduling was heavily weighted toward Fairshare, which tracks how much compute time each user/account has used. However, the Fairshare value effectively never decayed. This meant that once a user consumed a lot of resources, their priority would stay low indefinitely, no matter how long they paused usage. This made it hard for users with low Fairshare to regain access, but this should now be improved. I will temporarily mark this ticket as resolved. Once again, I apologize for the delayed response. Please feel free to reach out if you have any further questions. Best regards, name Purdue IT https://service.purdue.edu/: https://service.purdue.edu/|smart-link ;",lyuliyao@access-ci.org,Liyao Lyu,Ansh Gangapurkar,Purdue University,Anvil,11,119,44,2024,2024-10-28
ATS-14781,Unable to access VASP on Anvil,2025-03-11,2025-03-18,"Dear Sir/name'am, I am Deep name, a postdoc at University of Delaware. I am trying to run VASP jobs on Anvil HPC at Purdue through NSF Access credits. Despite following the steps suggested in Anvil documentation and using the Anvil suggested job script for VASP jobs, I am unable to run a sample VASP job (path: /home/x-dpatel/17/polymers/Pt111). Can you please help me with this? Thanks, Deep ; Thanks for reaching RCAC. Would you please share your workflow and error message that you got? Best, name ; Hi name, Thanks for your availability to help! I am attaching my input files and the error file with this email. I hope this helps. Thanks, Deep ^Pt111.zip] \\_(208 kB)\\_ ; Hi Deep, Thanks for reaching out! I did not see you have access to the central installed VASP on Anvil. If you want to use them to run jobs, please let me know your email address associated with your VASP license. We need to validate your license before we add you to the groups on Anvil. @login01.anvil:~ $ groups x-dpatel17 x-dpatel17 : x-chm250028 Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Hi name, Thank you for your email! My email associated with VASP should be [: mailto: and/or : mailto:. Please let me know if you need more information. Thanks, Deep ; Hi Deep, You (with ++: mailto:) have been added to vasp5 and vasp6 groups on Anvil. Your membership will be ready within a few hours. Please check our user guide for VASP calculations on Anvil. https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/vasp: https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/vasp|smart-link Regards, name ;",dpatel17@access-ci.org,Deep Patel,Nannan Shan,Purdue University,Anvil,6,6,11,2025,2025-03-10
ATS-14890,Access to VASP on the Anvil cluster,2025-03-16,2025-03-17,"I would like to request access to VASP on the Anvil cluster. My Anvil username is \\*x-lpatra (\\*7957873), and my GID is \\*7008502 (x-mch240072)\\*. Please let me know if any additional information is required to process this request. ; Hello! Thanks for reaching out! Can you share your email address which is associated with VASP license? We need to validate your license before we grant you access to VASP to Anvil. All we need is your email address. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Hi name, I work in Prof. Satish name's group and have cc'ed him here. He will share the email address associated with the VASP license. Thanks, Lokanath ---- ; I confirm that Patra Lokanath has been authorized to use VASP license. His email is- Satish. ---- ; Hi Lokanath, You have been added to {{vasp5}} group on Anvil. Your membership will be ready within a few hours. Please check our user guide for VASP calculations on Anvil. https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/vasp: https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/vasp|smart-link Regards, name ; Thanks name. Best, Lokanath ---- ;",lpatra,Lokanath Patra,Nannan Shan,,Anvil,6,1,11,2025,2025-03-10
ATS-14906,Jobs pending for long time,2025-03-17,2025-03-24,"Hello, I have two jobs submitted on anvil (9887973 and 9887974). They are in pending status for 5 days. Could you please help me check if there is anything wrong with these two jobs? Best, Xiaohan ; Hi Xiaohan, Thank you for reaching out. Are you still experiencing this issue? I see that the two jobs you mentioned have been canceled, and you currently have a running job. Let me know how I can help. Best, name K ; Hi name, Thanks for your response. No, I'm not experiencing this issue now. I canceled the two jobs and resubmitted them with a request of shorter running time. Thet were running normally after that. I just want to double check whether the long pending time was simply due to the priority of the jobs instead of other errors. Best, Xiaohan ---- ; Hi Xiaohan, The wait time for a pending job depends on the amount of resources you request from the scheduler. When you reduced the requested time, the job was allocated more quickly. Best, name K ;",xhu9@access-ci.org,Xiaohan Hu,Haniye Kashgarani,,Anvil,4,6,12,2025,2025-03-17
ATS-15015,We started a renewed allocations and the queue waiting time is unusually long,2025-03-20,2025-03-25,"Good morning, I am a user of Anvil and we recently finished an Explore allocation and upgraded to Discover allocation. This is associated with the same project. My balance shows that the account names we used for previous allocations now have new credits so I didn't change the account names in my slurm script. However when I went to submit my jobs on the cluster I encountered an unusually high queue waiting time, which was never the case during the previous allocation (I submitted 30h jobs that requested 1 GPU per job 3 days ago and they are not picking up). Is there a chance that this is happening because of some association with the project that ran out of the allocation or is this now a new standard wait time for the cluster? This is very inhibiting to our research progress. ; Hi Dariia, Thanks for reaching out Regards, name ;",dariia@access-ci.org,Dariia Yehorova,Nannan Shan,,Anvil,5,4,12,2025,2025-03-17
ATS-15035,Increase total run time limit,2025-03-20,2025-03-21,"Hi, I am running MD simulations on Anvil, and my single run takes at least 4 days (roughly 96 hours). However, the Slurm job submission script for GPU does not allow me a total run time limit of more than 48 hours. Because of this, I wait in queue twice—once when I submit a job and again when I extend from the previous checkpoint. Usually, I am waiting for a day or two before my job runs so I kind of waste almost a week's worth of time waiting. If my time limit could be extended to 96 hrs or more I will be able to cut down my waiting time. Please look into this matter and kindly do the needful. Thank You ; Hi Geet, Thanks for reaching out! The GPUs can be busy on Anvil sometimes. Unfortunately we cannot extend the walltime for your jobs on Anvil. The GPUs are shared by all Anvil users. The reason we setup the limit is to ensure each user will get a chance to run their jobs with GPUs on Anvil. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ;",gmadhukar@access-ci.org,Geet Madhukar,Nannan Shan,,Anvil,2,2,12,2025,2025-03-17
ATS-15379,software,2025-04-01,2025-04-04,software installation ; Sorry for opened double tickets. You can mark this ticket as resolved. Thanks. -Xiaoge ;,wangxg@access-ci.org,Xiaoge Wang,yang2383,,Anvil,2,4,14,2025,2025-03-31
ATS-14961,Queue times on Anvil,2025-03-18,2025-04-10,"Hi there, I am using anvil at Purdue through an ACCESS allocation and have noticed in the last week or so that my jobs have not been starting as quickly as I was used to. I see that there is a shutdown scheduled for Wednesday and there is very large job in the queue; are longer wait times something I should expect going forward? Thanks, name ; Hi name: I believe there was an issue with Anvil that the team was working on earlier this week or the previous which might have caused the delay you're mentioning. If you are still experiencing larger wait times than usual for your job after the shutdown on Wednesday, please let me know and I can have the team further look into it(as sometimes updates may unintentionally cause some other issues). Thanks for your patience. name ; Hi name, unfortunately the larger than usual wait times remain. Best, name ; Hi: Are using CPUs or GPUs? GPUs are currently in high demand, which can lead to long wait times. Additionally, wait time is highly dependent on the amount of resources allocated, requesting fewer resources generally results in shorter wait times. I've also been informed by the team that some changes have been made to Anvil's Slurm configuration since the first week of the month, which should have improved this issue. Thanks, name ; These are single-CPU node jobs I am attempting to run for 4 days. I have three jobs in the queue, and non have started in the last roughly two weeks. Best, name ; Hi: Okay, that's a bit odd. I've notified the team and they'll be looking into it further. name ; Hi: It seems there was a blockage because of the slurm's ""Fair Share"" system, where certain requests were allocated based on some rules but caused some users, such as yourself, which experienced long wait times because of it. It's now been changed. However, I was also told there is currently still a large reservation of 512 nodes today, but should be fixed tomorrow. Let me know if this still isn't the case, and apologies for the delay. name ; <\!doctype html> Great, thank you! Best, name ;",nsiemonsen@access-ci.org,http://cilogon.org/serverE/users/140125 Unknownname,Ansen Shia,,Anvil,8,18,12,2025,2025-03-17
ATS-15277,Job Requests Pending Approval for Extended Periods,2025-03-28,2025-04-09,"Hello Anvil Support Team, I am writing to seek assistance regarding an ongoing issue I've encountered with job requests on Anvil through Jupyter Hub. Despite multiple attempts with various configurations, including job durations of 1 hour, my requests have remained in a pending state for several days without being approved. Could you please let me know the reason behind this delay? Additionally, if there are specific configurations (ideal number of hours to ask for) I need to make to ensure my job requests are processed timely, I would appreciate your guidance. Thank you for your attention to this matter. I look forward to your prompt response. Best, Hansi Yasodara ; Hello, I hope you are doing well. Thank you for reaching out to RC Support with your question! We are actively working on addressing the issue. Rest assured, we will provide you with a response as soon as possible. Best regards, name RCAC Support ; Hello, Thank you for your patience. Can you please let me know your previous ticket ID and JobID. Best regards, RC Support ; Hello, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best Regards, name RCAC Support ;",hyasodara@access-ci.org,Hansi Yasodara,Ankitha Mallekav,,Anvil,4,9,13,2025,2025-03-24
ATS-15316,Purdue Anvil: Require guidance using RAM efficiently,2025-03-31,2025-04-08,"Good afternoon, I have been attempting to run fcs-gx for genome decontamination using singularity on Purdue Anvil. https://github.com/ncbi/fcs: https://github.com/ncbi/fcs|smart-link Using the associated quickstart guide: https://github.com/ncbi/fcs/wiki/FCS-GX-quickstart: https://github.com/ncbi/fcs/wiki/FCS-GX-quickstart|smart-link I have successfully downloaded 'FCS-GX' --- steps 1 and 2 (the 'fcs.py' python script and the singularity image '{{fcs-gx.sif}}') and can run them both. I have also downloaded the FCS-GX database using 's5cmd'. \\*My question concerns running the ""Screen the genome"" step efficiently.\\* Prerequisites for the program include (#4): \\*""A host with 512 GiB shared memory to hold the database and accessory files.\\* Execution can utilize up to 48 CPU cores. Not running on a large-RAM server will result in extremely long run times (as much as a 10000x difference in performance)."" Would you be able to please provide me some guidance as to how to properly submit such a job (via a .slurm script) to ensure that I have enough RAM but also am not wasting resources? I'm not sure how to specify Nodes (N) or Cores (n) for such a job using slurm. Any help you could provide would be greatly appreciated. Thanks, name ; Hi name, Thanks for the detailed message - you're right that the 512 GiB shared memory requirement puts the standard nodes (with 256 GiB RAM) below spec for FCS-GX. Fortunately, Anvil does have a {{highmem}} partition with nodes offering ~1 TiB RAM, which should be sufficient for running the full FCS-GX database in memory. To test it out, you can submit your job using something like the following SLURM script: # Thanks, name ; Hi name, Thank you so much for your guidance. I tested the program on a few contigs and then a whole genome - the analysis runs well. Many thanks for your help and quick response. AMB ---- ; \\*\\*PRIVATE NOTE\\*\\* User was able to run the analyses! ;",abernard@access-ci.org,Andrea Bernard,Arun Seetharam,,Anvil,4,7,14,2025,2025-03-31
ATS-15380,software installation,2025-04-01,2025-04-11,"I am wondering if the globus CLI, SDK, and REAST APIs can be made available for use without installation in user home or project space? ; Hi, Thank you for contacting us. We will get back to you as soon as we have the answer. Best regards, name Purdue RCAC Support ; Hi Xiaoge, Thanks for reaching out. In this instance, per our software installation policy https://www.rcac.purdue.edu/knowledge/anvil/policies/software\\_installation\\_request\\_policy?all=true: https://www.rcac.purdue.edu/knowledge/anvil/policies/software\\_installation\\_request\\_policy?all=true|smart-linkGlobus CLI, SDK, and REAST APIs are software that would fall under self installation in your own home directory/allocation project space rather than software that we make centrally available to all users. If you would like assistance in installing, please do not hesitate to ask us questions on installation! Best regards, name Purdue RCAC Support ; Hi name, Thank you for your response. Now you can close this ticket as the question is answered. Best, Xiaoge ; \\*\\*PRIVATE NOTE\\*\\* Resolved. ;",wangxg@access-ci.org,Xiaoge Wang,yang2383,,Anvil,5,9,14,2025,2025-03-31
ATS-15542,Unable To Find Purdue Anvil Login,2025-04-05,2025-04-10,"According to anvil/access/login/sshkeys: ""For your first time login to Anvil, please log in to Open OnDemand +ondemand.anvil.rcac.purdue.edu+: https://ondemand.anvil.rcac.purdue.edu/ using your ACCESS username and password."" Via provided link to log into Open OnDemand: I entered my ACCESS login credentials. Approved the DUO Mobile push. I am then taken to a name screen with the following error message: {{Error -- can't find user for x-hhale Run 'nginx\\_stage --help' to see a full list of available command line options}}. I have tried to login via different browser and through an incognito tab and the error persists. ; Hannah, Thank you for contacting RCAC for support. Could you please try to log in again? There was an issue with our backend for populating your user data onto Anvil. This should now be resolved and you should be able to log into OnDemand. Thanks, name ; It worked. Thank you! ;",hhale@access-ci.org,Hannah Hale,Michael Carlson,Purdue University,Anvil,4,4,14,2025,2025-03-31
ATS-15644,project folder permission denied,2025-04-09,2025-04-09,"Hi Anvil team, We don't have the access to our project folder, could you please check? Thanks, Wenliang ; \\*\\*PRIVATE NOTE\\*\\* Thanks for reporting. Our engineer has worked on the fix, and now it is good to go. Please try it again and let us know if you need more help. https://www.rcac.purdue.edu/index.php/news/7098: https://www.rcac.purdue.edu/index.php/news/7098|smart-link Best, name ;",wangwl@access-ci.org,Wenliang Wang,Xiao Liu,,Anvil,3,1,15,2025,2025-04-07
ATS-15654,Cannot run a usual code due to a sudden missing of a library,2025-04-09,2025-04-09,"There is a problem with a slepc library, which was suddenly missing when running the code. The library has been stored in the project directory /anvil/projects/x-phy130027/libraries/slepc\\_3.19.1/gcc\\_11.2, and it seems the system no longer allows the code to access the repository. ; ./gene\\_anvil: error while loading shared libraries: libslepc.so.3.19: cannot open shared object file: N: file: o such file or directory ; Hi. There was a project permission issue over the cluster around noon, but now our engineer has fixed it. could you try one more time and see if the problem is still there? Best, name ; Yes, the code works now. Thank you so much. --Taweesak On Apr 9, 2025, at 21:14, name wrote: ; Great! I will mark the ticket solved now, feel free to let us know if you need more help. Best, name ;",jitsuk,Taweesak Jitsuk,Xiao Liu,,Anvil,4,1,15,2025,2025-04-07
ATS-15655,Permission Denied for my projects,2025-04-09,2025-04-09,"I logged into the Anvil Cluster yesterday and was able to view and access all of my files and work in /anvil/projects/x-bio240265/ . When I tried to log in using my terminal today (ssh) and using the OnDemand website, I received the ""permission denied"" error. I am also needing to install the bpp program (https://github.com/bpp/bpp?tab=readme-cv-file: https://github.com/bpp/bpp?tab=readme-cv-file) to use for some phylogenomics work that I am doing. I am unsure of how to fix the permission issue and then install the bpp program. ; \\*\\*PRIVATE NOTE\\*\\* Thanks for reporting. Our engineer has worked on the fix, and now it is good to go. Please try it again and let us know if you need more help. https://www.rcac.purdue.edu/index.php/news/7098: https://www.rcac.purdue.edu/index.php/news/7098|smart-link Best, name ;",halloway@access-ci.org,Hannah Alloway,Xiao Liu,,Anvil,2,1,15,2025,2025-04-07
ATS-15657,Can't acess project folder,2025-04-09,2025-04-09,"Hi, I logged on this morning and am getting a permissions denied when trying to access (cd into / ls) my groups projects folder (x-mcb130189). My username is x-aklein2. Thank you for your help, name. ; \\*\\*PRIVATE NOTE\\*\\* Thanks for reporting. Our engineer has worked on the fix, and now it is good to go. Please try it again and let us know if you need more help. https://www.rcac.purdue.edu/index.php/news/7098: https://www.rcac.purdue.edu/index.php/news/7098|smart-link Best, name ;",aklein2@access-ci.org,Amit Klein,Xiao Liu,,Anvil,2,1,15,2025,2025-04-07
ATS-15658,anvil project storage not available,2025-04-09,2025-04-09,"I noticed that I can no longer access my data /anvil/projects/x-che170062 from my shortcut (group\\_storage) in /home/x-mlesniewski. Whenever I try to ls to projects directory or view the realpath of the shortcut, permission is denied - so I am uncertain if this is an access error or if the data is suddenly gone. I was unable to find any notifications about an outage or planned maintenance, so I am not sure if this is a wide sweeping issue with project storage or if this is something specific to our group, so I figured I would write to you guys to figure out whats going on. Any clarity on this issue or help getting access to my data back would be greatly appreciated. Thank you for your time and help, name (user x-mlesniewski) ; \\*\\*PRIVATE NOTE\\*\\* Thanks for reporting. Our engineer has worked on the fix, and now it is good to go. Please try it again and let us know if you need more help. https://www.rcac.purdue.edu/index.php/news/7098: https://www.rcac.purdue.edu/index.php/news/7098|smart-link Best, name ;",mlesniewski@access-ci.org,Maria Lesniewski,Xiao Liu,,Anvil,3,1,15,2025,2025-04-07
ATS-15663,Loss of access to projects directory,2025-04-09,2025-04-09,"On Anvil, I have been using the /anvil/projects/x-phy990002/x-aravishankar directory for simulations, but I have recently lost access to it. I would like to know what happened and if this can be fixed soon so that I may resume simulations. ; Thanks for reporting. Our engineer has worked on the fix, and now it is good to go. Please try it again and let us know if you need more help. https://www.rcac.purdue.edu/index.php/news/7098: https://www.rcac.purdue.edu/index.php/news/7098|smart-link Best, name ;",aravishankar1@access-ci.org,Abhishek Ravishankar,Xiao Liu,,Anvil,3,1,15,2025,2025-04-07
ATS-11796,AnvilGPT Access Request,2024-10-29,2025-04-21,"Hello, I am a software engineer at name Cancer Center, FL, US, and we are working on the Galaxy Bioinformatics platform https://galaxyproject.org/: https://galaxyproject.org/|smart-link , a community-driven project funded by the NIH to support accessible and reproducible bioinformatics research. The platform serves thousands of users globally, providing tools and workflows for advanced biological data analysis. We are currently developing a tool for the Galaxy community that enables users to perform data analysis through natural language interaction. The tool, which is available at cancer.usegalaxy.org: https://cancer.usegalaxy.org under ""Interactive Tool -> Chat with Your Data,"" has already been released, and we have seen considerable enthusiasm from the community. However, we've encountered challenges in providing free and stable API access to large language models (LLMs) for our users. We are seeking to integrate AnvilGPT into our tool to offer free LLM access to data scientists across thousands of universities and hospitals, enhancing the capabilities available to our community. I just registered an access account today, please let me know if I need to provide anything else. We would like access to both the UI and API. Thank you for your assistance. ; Hi Junhao, Could you provide the information for these three questions? # ACCESS Allocation number. # How to intend to use AnvilGPT # What modality you plan to use (API, UI, or both) Thanks, name ; Hi name, Sorry for the delay\ Best, Junhao ---- ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id Can we mark this ticket as resolved? ; \\*\\*PRIVATE NOTE\\*\\* Yes, we can close it. Never heard back. ; Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. and resolve. Best, name K ;",jqiu6@access-ci.org,Junhao Qiu,Ashish Malik,Purdue University,Anvil,6,125,44,2024,2024-10-28
ATS-12290,VASP license permission,2024-11-20,2025-04-21,"The principal investigator of our research group, ACCESS ID: wenhaosun, has a VASP lisence. I plan to run VASP calculations on Anvil and need permissions for my user account to be updated to allow VASP job submissions. ; Hi, could you ask your PI to add you into a valid VASP license first? Then we can verify your valid vase license on VASP community portal to be able to add you. Let us know if you have any questions. Best, name ; Hi, Since I have not heard back from you in a while, I'm tentatively marking this ticket resolved at this point. If you still need assistance, please feel free to reply to this email within the next 7 days to reopen the ticket. Best, name ;",arauf,Abrar Rauf,Xiao Liu,,Anvil,3,109,47,2024,2024-11-18
ATS-12815,"Process keeps getting ""Killed"" on debug nodes for Purdue Anvil",2024-12-18,2025-04-21,"I'm running some light experiments on anvil's debug nodes that require me to allocate ~ 4GB of memory. However, when my process runs I get back a system message: ""Killed"" implying that some resource limit has been triggered. When I look at the output of {{ulimit -a}} I see the following, I don't believe I'm hitting any of these limits. How can I go about debugging this issue? core file size (blocks, -c) 0 data seg size (kbytes, -d) unlimited scheduling priority (-e) 0 file size (blocks, -f) unlimited pending signals (-i) 1029827 max locked memory (kbytes, -l) unlimited max memory size (kbytes, -m) unlimited open files (-n) 20480 pipe size (512 bytes, -p) 8 POSIX message queues (bytes, -q) 819200 real-time priority (-r) 0 stack size (kbytes, -s) unlimited cpu time (seconds, -t) unlimited max user processes (-u) 131072 virtual memory (kbytes, -v) unlimited file locks (-x) unlimited ; Hi, Thanks for reaching. We'd happy to look into it. May I have your job id if you know it? Best, name ; Hi, Since I have not heard back from you in a while, I'm tentatively marking this ticket resolved at this point. If you still need assistance, please feel free to reply to this email within the next 7 days to reopen the ticket. Best, name ;",akhan5@access-ci.org,Arham Khan,Xiao Liu,Purdue University,Anvil,3,89,51,2024,2024-12-16
ATS-13584,SMB passthrough not working with QEMU?,2025-01-29,2025-04-21,"To whom it may concern, I suspect that \\_maybe\\_ the SMB passthrough with QEMU is not working? This happened at least once in the past (see ATS-6916: https://access-ci.atlassian.net/servicedesk/customer/portal/2/ATS-6916). The solution was to replace the samba installation. The windows 11 application on OOD uses smb passthrough, and that application is also not working like it used to. We utilize this feature for some of our students and were wondering if someone could take a look and maybe see if they can fix it? Thanks in advance for any help, -name ; Hi name, Thank you for contacting us. We will get back to you as soon as we have the answer. Best regards, ; Hi name, Could you please attach the error that smb passthrough failed, so that we can repeat and trouble-shooting? Best, name ; Hi name, Sure, I'll attach an image shortly, however, the error can be seen by simply launching the Windows 11 OOD app on https://ondemand.anvil.rcac.purdue.edu: https://ondemand.anvil.rcac.purdue.edu, logging in with the rcacuser23 credential, and trying to click on the home or scratch directory shortcuts. Warm regards, -name ; I just launch the ""Windows 11 Professional"", wait for the VM to launch, then enter the password ""rcacuser23"", then double click on the Anvil Home directory. https://access-ci.atlassian.net/browse/ATS-6916: https://access-ci.atlassian.net/browse/ATS-6916|smart-link comments may be helpful - we had this issue about a year ago. Thanks for the help ; Thanks! I repeated the error and have reported it to name team for fixing it. Will update you once it is fixed. Thanks for your patience. Best, name ; Hi! Any updates on this? We have a few groups of students/companies waiting on this feature to be fixed? Thanks! ; \\*\\*PRIVATE NOTE\\*\\* https://access-ci.atlassian.net/jira/people/team/4c470ffb-7177-4452-aeaf-9be39b647dc2?ref=jira$&src=issue: https://access-ci.atlassian.net/jira/people/team/4c470ffb-7177-4452-aeaf-9be39b647dc2?ref=jira$&src=issue|smart-link (~accountid:id:id-248a-43b5-a841-66499835a741 ~accountid:id ~accountid:id ~accountid:id ~accountid:id:id-deb3-4a00-b421-44f90764017f) ; Sorry for the delay. We're still working on it. We will get back to you as soon as possible. Best, name ; Hi name, How is the progress going with this? Best, -name ; Hi name, I escalated your problem for the team to look into it, but haven't got back yet. I will check its status again and let you know the update. Best, name ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id Hi name, any thoughts about this problem? ; Hi name, I really apologized for the delay. Our expert on this was in parental leave, so we had a difficult time to figure it out about the fixing. But we got the problem immediately fixed once he came back. I've tested it and everything works well now. Please give it a try and let us know if you need more help. Best, name ; Hi, Since I have not heard back from you in a while, I'm tentatively marking this ticket resolved at this point. If you still need assistance, please feel free to reply to this email within the next 7 days to reopen the ticket. Best, name ;",kamstut@access-ci.org,Kevin Amstutz,Xiao Liu,Purdue University,Anvil,14,59,5,2025,2025-01-27
ATS-14373,Modules not found,2025-02-25,2025-04-21,"The sbatch script I have been using to run AMBER MD simulations has started returning errors. This is my script: #!/bin/bash #SBATCH --job-name=""ambersim"" #SBATCH --output=""ambersim.%j.%N.out"" #SBATCH --partition=gpu #SBATCH --nodes=1 #SBATCH --gres=gpu:1 #SBATCH --ntasks-per-node=1 #SBATCH --cpus-per-task=10 #SBATCH --mem=1GB #SBATCH -A bio250064-gpu #SBATCH --no-requeue #SBATCH -t 48:00:00 module reset module load gpu/0.17.3b module load gcc/8.4.0/xiuwkua module load openmpi/4.1.3/v2ei3ge module load amber/22/ulauqq7-omp echo ""starting 11md at '$(date +%H:%M:%S)'"" pmemd.cuda -O -i 11md.in: http://11md.in -o 11md.out -p comp.prmtop -c 10md.rst7 -r 11md.rst7 -inf 11md.info: http://11md.info -x 11md.mdcrd echo ""finished 11md at '$(date +%H:%M:%S)'"" This is the error message: Resetting modules to system default. Resetting $MODULEPATH back to system default. All extra directories will be removed from $MODULEPATH. Lmod has detected the following error: The following module(s) are unknown: ""gpu/0.17.3b"" Please check the spelling or version number. Also try ""module spider ..."" It is also possible your cache file is out-of-date; it may help to try: $ module --ignore\\_cache load ""gpu/0.17.3b"" Also make sure that all modulefiles written in TCL start with the string #%Module Lmod has detected the following error: The following module(s) are unknown: ""gcc/8.4.0/xiuwkua"" Please check the spelling or version number. Also try ""module spider ..."" It is also possible your cache file is out-of-date; it may help to try: $ module --ignore\\_cache load ""gcc/8.4.0/xiuwkua"" Also make sure that all modulefiles written in TCL start with the string #%Module Lmod has detected the following error: The following module(s) are unknown: ""openmpi/4.1.3/v2ei3ge"" Please check the spelling or version number. Also try ""module spider ..."" It is also possible your cache file is out-of-date; it may help to try: $ module --ignore\\_cache load ""openmpi/4.1.3/v2ei3ge"" Also make sure that all modulefiles written in TCL start with the string #%Module Lmod has detected the following error: The following module(s) are unknown: ""amber/22/ulauqq7-omp"" Please check the spelling or version number. Also try ""module spider ..."" It is also possible your cache file is out-of-date; it may help to try: $ module --ignore\\_cache load ""amber/22/ulauqq7-omp"" Also make sure that all modulefiles written in TCL start with the string #%Module starting 11md at '12:29:15' /var/spool/slurm/job9686018/slurm\\_script: line 21: pmemd.cuda: command not found finished 11md at '12:29:15' ; Hi, I could not find the module you listed there on Anvil. You should use {{module spider module\\_name}}to find it first and then load. Here is some modules based on your list that I have loaded. Let us know if you need more help. \\*:\~]\\* $ module list Currently Loaded Modules: # gmp/6.2.1 6) modtree/gpu 11) hdf/4.2.15 # mpfr/3.1.6 7) numactl/2.0.14 12) hdf5/1.10.7 # mpc/1.1.0 8) cuda/11.0.3 13) netcdf-c/4.7.4 # zlib/1.2.11 9) openmpi/4.0.6-cu11.0.3 14) netcdf-fortran/4.5.3 # gcc/8.4.1 10) libszip/2.1.1 15) amber/20 Best, name ; Hi name, Thanks for getting back to me. Was amber downgraded recently from version 22 to 20? I was loading the module fine for amber 22 until a few days ago. ---- ; Hi, I was told that we don't have Amber 22 on Anvil. Please let us know if you need any help after matching the loaded module with the version on Anvil now. Best, name ; Hi name, Can you please ask if there used to be amber 22? Like I said, I was previously able to load the amber 22 module and I still don't understand how it would have loaded previously but not anymore. This is important for work I am planning to publish soon, so I appreciate your support on this. Thank you in advance, name Intravaia -- \\* \\*name Intravaia\\*\\* PhD Candidate Celia Schiffer Lab Dept. of Biochemistry and Molecular Biotechnology University of Massachusetts name Medical School 364 Plantation St. LRB 970D Email: : mailto: LinkedIn: www.linkedin.com/in/name-intravaia: http://www.linkedin.com/in/name-intravaia Lab website: https://www.umassmed.edu/schifferlab/: https://www.umassmed.edu/schifferlab/ ; \\*\\*PRIVATE NOTE\\*\\* The user is confident about amber 22 was there before. Anybody know why it's not there any more? Anvil Application Team: https://access-ci.atlassian.net/jira/people/team/0f5fcf8a-26ef-4d24-a346-4a2ef3a7afda?ref=jira$&src=issue ([~accountid:id:id-bd45-4e12-b7de-6550f017a297 ~accountid:id ~accountid:id ~accountid:id ~accountid:id ~accountid:id ~accountid:id ~accountid:id ~accountid:id ~accountid:id:id-0296-44c2-8aaa-9a36b2662a58 ~accountid:id:id-c12e-4112-bfdf-3503868fdf94 ~accountid:id:id-5a0e-4ef9-9dae-4ff21198071b) ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id:id-ae32-498d-af6a-966ed0fbac97 We've never had such module format (i.e. {{gcc/8.4.0/xiuwkua}}) before and I can confirm we've never had amber 22 as a modulefile unless that's their own defined module. ; Hi name, I have confirmed with my colleagues. We are name sure we never had amber 22 in Anvil as a module. Perhaps it's one of your group-wised module? Please ask your lab manager and see if this is the case. Best, name ; Hi, Since I have not heard back from you in a while, I'm tentatively marking this ticket resolved at this point. If you still need assistance, please feel free to reply to this email within the next 7 days to reopen the ticket. Best, name ;",lintravaia@access-ci.org,Lauren Intravaia,Xiao Liu,,Anvil,9,40,9,2025,2025-02-24
ATS-14810,Job starting but not running,2025-03-12,2025-04-21,"Hello, I have been experiencing some issues with running my simulations on Anvil. I have had a few instances where I would submit my Slurm file, and it would execute the very first steps (e.g. changing directories), but it would stop and not actually execute the line containing srun. Other times, it \\_would\\_ execute the srun, and my simulation would begin its initial process (e.g. reloading files, preparation/checking steps), but would suddenly not go forward from there. For reference, my simulation has a runtime parameter that I usually set to e.g. RUNTIME = 1.8 (hours) so that it records the data well before the job time ends (e.g. if I had specified 2 hours in the Slurm file). Some other members of my lab have experienced this as well on Anvil, and we would greatly appreciate any insight regarding the situation. Also, I was wondering if this would be eligible for a resource refund (job ID is 9892247). Thank you, name Yamasaki ; Hi, Thank you for contacting us. We will get back to you as soon as we have the answer. Best regards, name ; Hi name, Did you cancel the job? I am checking the reasons of why it has been started but if it's ended with status showing CANCELLED,TIMEOUT. I was wondering if you cancel it, or it ended due to beyond the wall time. Best, name ; Hi, Since I have not heard back from you in a while, I'm tentatively marking this ticket resolved at this point. If you still need assistance, please feel free to reply to this email within the next 7 days to reopen the ticket. Best, name ;",jyamasaki@access-ci.org,Jun Yamasaki,Xiao Liu,,Anvil,4,29,11,2025,2025-03-10
ATS-14843,AnvilGPT Access Request,2025-03-13,2025-04-21,"Testing for future AI projects. Plan to use both UI and API. ; Hi name, Can you please provide your access allocation number and a little detail about what kind of AI projects you'll use ANVILGPT for? ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id , this user also didn't get back to us, can we resolve this one as well? ; Hi name, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name K ;",kkalbaugh,Kirby Kalbaugh,Ashish Malik,,Anvil,4,28,11,2025,2025-03-10
ATS-14868,New runs on pending for days,2025-03-14,2025-04-25,"Hi, I am experiencing weirdly long queue time on my newly submitted runs since Wednesday. They have been on queue for two days and didn't start, which I find quite unusual. I tried canceling and re-submitting jobs, and it again seems to have gotten on a long queue. I wish to know whether your system is on maintenance by any chance, or it is just that there are particularly many jobs submitted during this week. Best regards, Sungkyu ; Hi Sungkyu, Thanks for reaching out! We lost track of your ticket and thanks for your patience. I am wondering if you still have questions regarding to this topic. Please feel free to let me know. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ;",skim2@access-ci.org,Sungkyu Kim,Nannan Shan,,Anvil,2,31,11,2025,2025-03-10
ATS-15031,Running Tecplot on Anvil,2025-03-20,2025-05-01,"Our lab has a license for a software called Tecplot and the license is managed by a local computer of our lab. Can we access the license from Anvil and run Tecplot on Anvil? If so, could you advise me on what to do? ; Hello! Thanks for reaching out! Can you confirm that your license of tecplot is a floating license that allows Anvil to connect to? If your license on the local computer with private IPs, Anvil cannot connect to that. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Hi, I've solved the problem by myself in the last 30 days. Thank you for your support. Best, Hiroto ; Thank you for letting me know and apologize for the delays. Glad it is resolved. --name ;",hodaka@access-ci.org,HIROTO ODAKA,Nannan Shan,Purdue University,Anvil,4,31,12,2025,2025-03-17
ATS-15046,Users x-arezvaniboroujeni and x-kxu6 unable to run jobs against cis230083,2025-03-21,2025-04-23,"Hello, I have added users arezvaniboroujeni and kxu6 to project cis230083, who wish to test Purdue Anvil. They plan to write and submit their own ACCESS project. Their usernames on Anvil are x-arezvaniboroujeni and x-kxu6, and when attempting to reach the Purdue Anvil Open OnDemand dashboard are met with an error of the form `User x-… does not exist`. ; Hi name, Thanks for reaching out and your patience on this. This ticket was buried and was out of our monitoring. I just checked the account for both Alale Rezvani Boroujeni and name, their accounts, {{x-arezvaniboro}} and {{x-kxu6}} on Anvil seem fine. Can you let me know if they still have trouble to submit jobs? Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ;",bkeene@access-ci.org,Benjamin Keene,Nannan Shan,,Anvil,2,24,12,2025,2025-03-17
ATS-15135,Requesting increase priority for my anvil account (x-as6481) for time-sensitive simulations,2025-03-25,2025-04-21,"Dear Team, I hope this message finds you well. I am writing to request a temporary increase in the priority of my Anvil user account (x-as6481) for a month in order to complete a critical set of time-sensitive simulations. Currently, I have launched 6 simulations, each with 6 dependencies, where each dependency is expected to run for 4 days. This results in a total simulation time of 24 days for each of the 6 runs. I initiated these simulations with the expectation that the results would be available within a month, as they are essential for an important report due in the last week of April. However, I've noticed that the simulations have been in the queue for the past 5 days. At this rate, I am concerned that I may not be able to obtain the necessary results by the end of April. I would sincerely appreciate any possibility of temporarily increasing the priority of my account over the next month, so I can get as close as possible to the full 24 days of runtime—even if all runs can't be completed, a higher priority would help me make substantial progress towards the goal. If this request cannot be accommodated, I completely understand. I am truly grateful for the support Anvil has provided thus far, which has significantly enhanced the scientific output of our research group. Thanks and regards, name Sunil Sathe, CoPI - atm180022 ; Hi name, Thanks for reaching out --name ;",as6481,Atharva Sunil Sathe,Elian Inigo Rieza,,Anvil,5,20,13,2025,2025-03-24
ATS-15182,how to write a batch script on the Anvil machine that allows me to terminate a job earlier ,2025-03-26,2025-04-18,"Hi officer, I would like to ask how to write a batch script on the Anvil machine that allows me to terminate a job earlier than the requested wall time. I've encountered an issue where the job does not output the final files before it is forcibly canceled when it reaches the time limit, which has resulted in wasted allocation hours. To avoid this problem, I would like to know how to either output the final files or cancel the job safely before the wall time limit, ensuring that the output files are properly written and the job completes successfully. ; Hi: Apologies for the delay, this is to let you know we've picked up your ticket and will get back to you as soon as possible. Thanks, name ; Hi: In general, you should be able to terminate the job according to the ""exit code/termination signal"" coming from your binary file/application being run. If this still doesn't work, could you provide some more details on what the program you're running is? Thanks, name ;",chsu4@access-ci.org,Chun-Yen Hsu,Ansen Shia,,Anvil,3,18,13,2025,2025-03-24
ATS-15239,How long to transfer data off cluster,2025-03-27,2025-04-22,"On March 31, my allocation on Anvil expires, and I have a new allocation that starts on NCSA Delta. How long will I have access to Anvil to transfer my data? Thank you! ; Hello, I would like to follow up on this. Will I still have access to data in my scratch space beyond the expiration date of my allocation? ; Hi name, Sorry for the delay in getting back to you. Are you still experiencing this issue? I can see your files on Anvil—have you already tried transferring them? Globus is a convenient option for moving files. Please also keep our scratch‑space purge policy in mind: files older than 30 days are removed automatically. https://www.rcac.purdue.edu/knowledge/anvil/storage/filesystems: https://www.rcac.purdue.edu/knowledge/anvil/storage/filesystems|smart-link Best, name K ; Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name K ;",omartin@access-ci.org,Olivia Martin,Haniye Kashgarani,,Anvil,4,19,13,2025,2025-03-24
ATS-15266,srun: error: a000: task 0: Exited with exit code 8,2025-03-28,2025-05-01,"I am running a slurm script from one project folder and using a executable in a different project folder. But it is trying to find the executable in a subdirectory of my home project folder. I have the executable installed in two places, in a home subdirectory and in a project subdirectory. I think I need the executable in my project folder, so that other project users can run it too. I do not think the project folder install references my home directory in any way, so I am confused as to why it is looking for the executable in my home directory. the myjob.e\\* file reports: cp /anvil/projects/x-che240200/gamess/AndrewData/1112705.inp /home/x-mcgreen/gamess/restart/1112705.F05 unset echo setenv OUTPUT /home/x-mcgreen/gamess/restart/1112705.F06 setenv PUNCH /home/x-mcgreen/gamess/restart/1112705.F07 unset echo CASINO: Undefined variable. The GAMESS executable gamess.00.x or else the DDIKICK executable ddikick.x could not be found in directory /home/x-mcgreen/gamess, or else they did not properly link to executable permission. srun: error: a000: task 0: Exited with exit code 8 The executable is in both /home/x-mcgreen/gamess/gamess and $PROJECT/gamess/gamess Am I missing a permission? Please advise. ; Hello, I hope you are doing well. Thank you for reaching out to RC Support with your question! We are actively working on addressing the issue. Rest assured, we will provide you with a response as soon as possible. Best regards, name RCAC Support ; Hello Mandy, Thank you for your patience. Exporting the PATH and LD\\_LIBRARY\\_PATH should fix the issue. Please let me know if you still have issues. Best regards, RC Support ; Hi name, I dug in the gamess install readme files. Per /home/x-mcgreen/gamess/ddi/readme.ddi, I think I need to compile the compddi so that mpi works as intended. But that takes modifying the compddi executable, and it scared the crap out of me to be honest. I tried to reinstall GAMESS with sockets today to avoid the compddi issue, but I still have the same output error: The GAMESS executable gamess.00.x or else the DDIKICK executable ddikick.x could not be found in directory /home/x-mcgreen/gamess, or else they did not properly link to executable permission. Regarding the PATH and LD\\_LIBRARY\\_PATH, are you referring to setting them as environmental variables? Thanks for your assistance! RCAC has the best people! Back in the day, name Putnam was my man. Mandy ---- ; Hello Mandy, Thank you for your patience. I am working with my team on your issue and will get back to you as soon as possible. Best regards, name RCAC Support ; Hi Mandy, I apologize for the very delayed response. It took a while for my team to get back to me for this issue. Thanks for your message. It sounds like the issue may be due to how the paths to the GAMESS executables are set in your job script. To help troubleshoot further, could you please share the job script you're currently using? That will help us check how the {{PATH}} and {{LD\\_LIBRARY\\_PATH}} are being set. In the meantime, please ensure that: # Your executables (e.g., {{gamess.00.x}}, {{ddikick.x}}) are located in your project space (not just your home directory). # You explicitly export the paths in your job script, like so: {{export PATH=/path/to/your/gamess/bin:$PATH export LD\\_LIBRARY\\_PATH=/path/to/your/gamess/lib:$LD\\_LIBRARY\\_PATH }} If anything is unclear, you're also welcome to drop by \\*Anvil Support Hour\\* and we'd be happy to walk through it with you. Best, name RCAC Support ;",mcgreen@access-ci.org,Mandy Green,Ankitha Mallekav,,Anvil,6,25,13,2025,2025-03-24
ATS-15279,Computational time increases 100 times in both the wholenode and wide node partitions.,2025-03-28,2025-04-21,"For last two-three days, I observed a surprisingly slow computation time. Previously, for the same number of processors, it used to take 1.2 seconds for 10 time steps, now it takes 80-90seconds. Here is the comparison. The recent computation (slow) are (directory: /anvil/scratch/x-kchand1/rotation/unstratified\\_case/re1400/Nac\\_4.16e-4/pis16/output.txt): Steps: 4420 Time: 154373 CPU Time: 112.644s CFL (zero plane): 0.218895 (in elmt 207) Steps: 4430 Time: 154379 CPU Time: 118.249s CFL (zero plane): 0.218979 (in elmt 207) The faster computation are (directory: /anvil/scratch/x-kchand1/rotation/unstratified\\_case/re1400/Nac\\_2e-4/pis16/output.txt): Steps: 4420 Time: 154373 CPU Time: 1.20421s CFL (zero plane): 0.211812 (in elmt 207) Steps: 4430 Time: 154379 CPU Time: 1.42475s CFL (zero plane): 0.211797 (in elmt 207) I have checked with one more case one day earlier and observed the same behavior (directory:/anvil/scratch/x-kchand1/rotation/unstratified\\_case/re1400/Nac\\_3.2e-4/pis16/output.txt) ; Hello, I hope you are doing well. Thank you for reaching out to RC Support with your question! We are actively working on addressing the issue. Rest assured, we will provide you with a response as soon as possible. Best regards, name RCAC Support ; Hello Krishan, Thank you for your patience. We will need the jobID to check. There might be a specific node showing this behavior. Best regards, name RCAC Support ; Hi name, Thanks for your response. The issue got resolved. I guess it was due to some other job, once that job was finished, it came back to its full speed. But right now, I am facing an issue logging into ANVIL. Best, Krishan ---- ; Hello name, Can you please provide more details on the error message you are seeing while logging in? Best regards, name RCAC Support ; Hello, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best Regards, name RCAC Support ;",kchand1@access-ci.org,Krishan Chand,Ankitha Mallekav,,Anvil,6,17,13,2025,2025-03-24
ATS-15314,Anvil - Purdue frequent outages ,2025-03-31,2025-04-21,"Hello, I have an allocation with Anvil through Purdue. In the past few weeks, I have been sporadically unable to login to Anvil, either through OnDemand or my local terminal through ssh. For OnDemand, the page never loads and for ssh I get this error: ssh: connect to host anvil.rcac.purdue.edu: http://anvil.rcac.purdue.edu port 22: name timed out. Is this an issue with something I am doing or is this an issue Anvil is experiencing? If it is something on my end, please provide some guidance! Thank you so much! ; Hi, Thank you for reaching out to RCAC Support! We're working on your request and will get back to you as soon as we are able. We appreciate your patience. Please allow up to a couple of business days for a response. Best regards, name Purdue IT https://service.purdue.edu: https://service.purdue.edu|smart-link ; Hi Zoe, Thank you for reaching out to Purdue RCAC, and I apologize for the delayed response. On Monday, Anvil experienced outages that coincided with when your ticket was submitted. The outage has since been resolved, but are you still facing this issue? Feel free to reach out if you have any further questions. Best regards, name Purdue IT https://service.purdue.edu/: https://service.purdue.edu/ ; Hi Zoe, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name K ;",zlm9173@access-ci.org,Zoe Muller,Ansh Gangapurkar,,Anvil,4,16,14,2025,2025-03-31
ATS-15337,my jobs are always in the pending mode (even a single job). ,2025-03-31,2025-05-03,"My jobs aren't running any more. They are pending. why this is so ? How can get more computing hours for now and write a grant for bigger allocation? ; Hi name, Could I ask what your sbatch/srun scripts are for said job? Best Regards, Eli name Purdue IT https://service.purdue.edu ; Hi Eli, Thanks for reaching out. I think those jobs were waiting and I mistook if something wasn't right - some of then ran and a few are still running. I am new to Anvil and I have a couple of questions: Q1: I plan to submit many jobs with disparate system size (in this case length of a polymer chain). They have taken a few hours to days. In the shared folder the limit is 96 hours. What is the best option for me ? This is my shell script for each job which is submitted by another job #!/bin/sh #SBATCH -A bio240310 # Allocation name #SBATCH --nodes=1 #SBATCH --ntasks-per-node=1 #SBATCH --time=96:00:00 #SBATCH --job-name=hoomd #SBATCH --output=hoomd-%j.out # ========================================================== module load anaconda/2021.05-py38 source activate hoomd297 # ========================================================== python3 ProteinBulk.py # ========================================================== # MDAnalysis package is not available in Stokes's Conda env # Need to create own env and install it for analysis #conda activate my\\_env conda activate analysis\\_env #python3 long\\_config\\_analysis.py python3 custom\\_config\\_analysis.py Q2: These jobs produce lots of data to be analyzed later. What is the best way to store at Anvil without losing them and for how long ? Q3; This grant is a preliminary grant. Can I apply for the grant with more time now ? is this ""discovery"". Will much appreciate answers. Thanks name Professor of Physics University of Central Florida name, FL 32816 \\_https://sciences.ucf.edu/physics/person/name/: https://sciences.ucf.edu/physics/person/name/ \\_ ; \\*\\*PRIVATE NOTE\\*\\* Closed by default, user has seemed to correct this ;",abhattacharya2@access-ci.org,Aniket Bhattacharya,Elian Inigo Rieza,,Anvil,4,25,14,2025,2025-03-31
ATS-15383,Long wait,2025-04-01,2025-04-22,"Hello, Over the past week I have noticed that there is an unusually long wait for getting into a compute node. I usually do sinteractive -N1 -n64 -t 96:00:00 --wrapper-verbose and get in within a couple of minutes. Now that is not working. Is it due to excessive load / long queues or some other configuration change? I have tried lowering my resource requirement to the lowest level such as sinteractive -N1 -n1 -t 1:00:00 --wrapper-verbose This is not working either. Hope this can be resolved soon. ; Hi name, Thank you for contacting us. We will get back to you as soon as we have the answer. Best regards, name Purdue RCAC Support ; Hi name, Sorry for delay in getting back to you. Do you still experience this issue? I see that you currently only have a running job. Best, name K ; Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name K ;",manojh@access-ci.org,Manoj Hariharan,Haniye Kashgarani,,Anvil,5,16,14,2025,2025-03-31
ATS-15408,Anvil: 60 nodes in standby partition stuck in drng state,2025-04-02,2025-05-01,"To further exacerbate the long shared partition queue times reported on ATS-15378 due to high limits, I see since submitting that ticket there are now 60 nodes on Anvil stuck in the drng state. They have been that way for hours. I only started recording them at 8:00, but you can see they haven't changed in an hour: login01.anvil ~ $ date; sinfo -p shared Wed Apr 2 08:01:01 EDT 2025 PARTITION AVAIL TIMELIMIT NODES STATE NODELIST shared\\* up infinite 2 drain\\* a073,179 shared\\* up infinite 2 down\\* a211,249 shared\\* up infinite 60 drng a057,059,081,087-089,091,095,099,103,114,118-119,136-138,145-146,152-153,156,165-170,183-184,186,189,194-195,197,201,203-207,209-210,212-214,216-218,220-223,230-231,233,235-236,238-239,247 shared\\* up infinite 1 drain a181 shared\\* up infinite 72 mix a026,060-064,066,068-069,072,074-080,085-086,092,094,096,100,102,104,106,115,117,120-122,126,130-131,133,135,139,141-144,148-151,155,157-159,161,163,171-174,178,180,182,188,190-191,193,198,200,202,224-228,232,237 shared\\* up infinite 112 alloc a000-025,027-056,058,065,067,070-071,082-084,090,093,097-098,101,105,107-113,116,123-125,127-129,132,134,140,147,154,160,162,164,175-177,185,187,192,196,199,208,219,229,234,240-246,248 shared\\* up infinite 1 down a215 login01.anvil ~ $ date; sinfo -p shared Wed Apr 2 09:14:10 EDT 2025 PARTITION AVAIL TIMELIMIT NODES STATE NODELIST shared\\* up infinite 2 drain\\* a073,179 shared\\* up infinite 2 down\\* a211,249 shared\\* up infinite 1 comp a053 shared\\* up infinite 60 drng a057,059,081,087-089,091,095,099,103,114,118-119,136-138,145-146,152-153,156,165-170,183-184,186,189,194-195,197,201,203-207,209-210,212-214,216-218,220-223,230-231,233,235-236,238-239,247 shared\\* up infinite 1 drain a181 shared\\* up infinite 73 mix a052,054-055,060,062-064,066,068-069,072,075-076,078-080,083,085-086,092,094,096,100,102,104,106,115,117,120-122,126,130-131,133,135,139,141-144,148-151,155,157-159,161,163,171-174,177-178,180,182,188,190,193,198,202,224-229,232,237,245 shared\\* up infinite 110 alloc a000-051,056,058,061,065,067,070-071,074,077,082,084,090,093,097-098,101,105,107-113,116,123-125,127-129,132,134,140,147,154,160,162,164,175-176,185,187,191-192,196,199-200,208,219,234,240-244,246,248 shared\\* up infinite 1 down a215 Regards, Doug ; It is now up to 89 of the 250 nodes in the shared partition in the drng state. We've seen this before in the past. The count will continue to rise unless you intervene. Please take a look? Regards, Doug ---- \\*From:\\* ACCESS Ticket Submission ; Hi, Thanks for reporting the issue. We've repeated the error and escalated this issue to the name team for repair. We appreciate your patience. Please let us know if you need further help. Best, name ;",dgc@access-ci.org,Doug Crabill,Xiao Liu,,Anvil,3,22,14,2025,2025-03-31
ATS-15499,Nodes down/draining,2025-04-04,2025-05-08,"Doug noticed that our nodes are down and draining: login01.anvil ~ : sinfo -p shared PARTITION AVAIL TIMELIMIT NODES STATE NODELIST shared\\* up infinite 27 drain\\* a057,059,063,073,087,095,098,119,145-146,153,156,165-166,170,179-181,186,195,197,207,210,230-231,233,235 shared\\* up infinite 223 down\\* a000-056,058,060-062,064-072,074-086,088-094,096-097,099-118,120-144,147-152,154-155,157-164,167-169,171-178,182-185,187-194,196,198-206,208-209,211-229,232,234,236-249 He said 604 nodes are also down in the wholenode partition. Very best, -name ; Hi name Thanks for reaching out! Thanks for you patience on this topic. Anvil should behave well right now. Thanks for reporting this to us. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ;",kamstut@access-ci.org,Kevin Amstutz,Bao Luu,,Anvil,2,25,14,2025,2025-03-31
ATS-15582,"Anvil at Purdue seems to be down, but no notification anywhere",2025-04-07,2025-04-22,"Hi there, Since yesterday (Sunday, April 6) I and others in my research group have been having difficulty logging into the Anvil clusters at Purdue (our allocation number is DMR110007). We assume that there has been some sort of outage at RCAC at Purdue, since their website seems to be down as well, but we haven't gotten any notification by email and can't see an outage posted anywhere. If there is an outage for the Purdue Anvil clusters, is it possible to get a time estimate about when this may be fixed? Thanks. ; Hi Ellery, Thanks for reaching out and sorry about the inconvenience. Anvil experienced outages that coincided with when your ticket was submitted. The issue should have been resolved. Let me know if you still experience the issue. Best, name K ; Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name K ;",ehendrix@access-ci.org,Ellery Hendrix,Haniye Kashgarani,,Anvil,3,12,15,2025,2025-04-07
ATS-15585,Anvil node reservation for workshop on April 11th,2025-04-07,2025-04-25,"We are conducting a workshop on April 11th - https://research.gatech.edu/data/NeuroData25: https://research.gatech.edu/data/NeuroData25|smart-link and plan to use Anvil for needed computations. We want to reserve CPUs and GPUs for the workshop date. Time window: 10:00 am ET - 5:00 pm ET Number of CPU nodes - 20 Number of GPU nodes - 2 ; The workshop is on Friday, April 11th 2025. Please let us know if you need any other information. The allocation is CCR140004. The PI is name Marru (: mailto:) ; Hi Eroma, Thanks for stopping by the Anvil Support Hour today. Please find more details about the CPU reservation for your allocation for tomorrow. This reservation is active now, that you can try it out. You can submit jobs with {{CCR140004}} account to {{shared}} partition, they would automatically go to this reservation. Let me know if you see any issues. Like we discussed on the meeting, we cannot find GPUs to reserve for the workshop tomorrow. ReservationName=data\\_cpu StartTime=2025-04-10T14:00:00 EndTime=2025-04-12T00:00:00 Duration=1-10:00:00 Nodes=a013,066,076,084,121-123,131,133,142,146,159,164,171,184,218,228,236-237,244 NodeCnt=20 CoreCnt=2560 Features=(null) PartitionName=shared Flags=IGNORE\\_JOBS,MAGNETIC TRES=cpu=2560 Users=(null) Groups=(null) Accounts=CCR140004 Licenses=(null) State=ACTIVE Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Hi Eroma, I want to check how was the workshop going on Friday. Is there anything we can help with? Please feel free to let me know. Regards, name ;",scigap@access-ci.org,SciGaP Community User,Nannan Shan,,Anvil,4,15,15,2025,2025-04-07
ATS-15665,Need BPP program installed,2025-04-09,2025-04-29,"Hi there ; Hi, Here is an tutorial about how to install software on Clusters: https://www.rcac.purdue.edu/training/software-installation: https://www.rcac.purdue.edu/training/software-installation|smart-link Please feel free to try it with yourself, and let us know if you need any help during the process. Best, name ; Hi, Since I have not heard back from you in a while, I'm tentatively marking this ticket resolved at this point. If you still need assistance, please feel free to reply to this email within the next 7 days to reopen the ticket or start a new one in the future. Best, name ;",halloway,Hannah Alloway,Xiao Liu,,Anvil,3,15,15,2025,2025-04-07
ATS-15671,Very Long Queue Times - Killed Jobs and Node Failures,2025-04-09,2025-05-05,"Hello, I have found that one of my Anvil jobs (JOBID 10388739) has been waiting in the Anvil queue for roughly 1 week now. I have never had a queue time this long, normally my jobs start within a day of submitting them, maybe two days max. Furthermore, this job is running a Molecular Dynamics simulation using GROMACS, and it has actually failed twice, i.e this third submission has been in the queue for a week. The first error appeared to be related to MPI issues, giving a long error message that begins with: a819:2463758:0:2463758 ib\\_mlx5\\_log.c:184 Transport retry count exceeded on mlx5\\_0:1/IB (synd 0x15 vend 0x81 hw\\_synd 0/0) a819:2463692:0:2463692 ib\\_mlx5\\_log.c:184 Transport retry count exceeded on mlx5\\_0:1/IB (synd 0x15 vend 0x81 hw\\_synd 0/0) a819:2463692:0:2463692 ib\\_mlx5\\_log.c:184 DCI QP 0x96df wqe107: SEND s-e rqpn 0x13bd6 rlid 756 va 0x0 len 266 lkey 0xbe12c a819:2463660:0:2463660 ib\\_mlx5\\_log.c:184 Transport retry count exceeded on mlx5\\_0:1/IB (synd 0x15 vend 0x81 hw\\_synd 0/0) The second error did not add a message in the error/output file, but I saw my email notification that it failed due to {{NODE\\_FAIL}}. And since then, the third submission has been waiting in the queue. Please let me know if I can provide any additional detail, e.g. software versions, SLURM submit scripts, log files, etc. Thank you for all of your help, and for all of your work maintaining such an essential system for my research. Best, name ; Hi, Thank you for contacting us. We will get back to you as soon as we have the answer. Best regards name ; Hi, There are only five nodes free right now (as the information as below) , so 16 nodes are probably need to wait for a long time. How many nodes do the jobs you submitted before request? For the job failed with Nodefailure, could you please provide that job's id, so that I could take further look? Best, name \\*:\~\\* $ showpartitions Partition statistics for cluster anvil at Thu Apr 10 15:10:38 EDT 2025 Partition #Nodes #CPU\\_cores Cores\\_pending Job\\_Nodes MaxJobTime Cores Mem/Node Name State Total Idle Total Idle Resorc Other name Max Day-hr:mn /node (GB) wholenode up 750 \\*5\\* 96000 \\*896\\* 0 22090 1 infin infinite 128 257 ; Hi name, Thank you for looking into this. I found the reason my job was waiting in the queue for so long was because it was assigned to a node that appeared to be down. I excluded this node in my submit script and it started right away. Since then I haven't encountered this issue, but I am still having sporadic mpirun issues for which I'm having trouble understanding. The most recent is JobID 10680473. These are the last few lines of the error file: ``` allreduce\\_intra\\_recursivedoubling+0x292)0x146e76b96b92 a516:1473167 16 /apps/spack/anvil/apps/openmpi/4.0.6-gcc-10.2.0-45rbnh4/lib/libmpi.so.40(PMPI\\_Allreduce+0xd6)0x146e76b45ae6 a516:1473167 17 /apps/spack/anvil/apps/gromacs/2021-gcc-10.2.0-ggot423/bin/../lib64/libgromacs\\_mpi.so.6(\\_ZN3gmx19SimulationSignaller14signalInterSimEv+0x65)0x146e7825aa75 a516:1473167 18 /apps/spack/anvil/apps/gromacs/2021-gcc-10.2.0-ggot423/bin/../lib64/libgromacs\\_mpi.so.6(\\_ZN3gmx19SimulationSignaller15finalizeSignalsEv+0x9)0x146e7825ab79 a516:1473167 19 /apps/spack/anvil/apps/gromacs/2021-gcc-10.2.0-ggot423/bin/../lib64/libgromacs\\_mpi.so.6(\\_Z15compute\\_globalsP15gmx\\_global\\_statP9t\\_commrecPK10t\\_inputrecP10t\\_forcerecP14gmx\\_ekindata\\_tN3gmx8ArrayRefIKNSA\\_11BasicVectorIfEEEESF\\_PA3\\_KfPK9t\\_mdatomsP6t\\_nrnbP5t\\_vcmP13gmx\\_wallcycleP14gmx\\_enerdata\\_tPA3\\_fSV\\_SV\\_SV\\_PNSA\\_11ConstraintsEPNSA\\_19SimulationSignallerESI\\_PiPbi+0x3e0)0x146e78230880 a516:1473167 20 /apps/spack/anvil/apps/gromacs/2021-gcc-10.2.0-ggot423/bin/../lib64/libgromacs\\_mpi.so.6(\\_ZN3gmx15LegacySimulator5do\\_mdEv+0x33d3)0x146e78339943 a516:1473167 21 /apps/spack/anvil/apps/gromacs/2021-gcc-10.2.0-ggot423/bin/../lib64/libgromacs\\_mpi.so.6(\\_ZN3gmx8Mdrunner8mdrunnerEv+0x51bf)0x146e7836565f a516:1473167 22 gmx\\_mpi0x4097ab a516:1473167 23 gmx\\_mpi0x4098d8 a516:1473167 24 /apps/spack/anvil/apps/gromacs/2021-gcc-10.2.0-ggot423/bin/../lib64/libgromacs\\_mpi.so.6(\\_ZN3gmx24CommandLineModuleManager3runEiPPc+0x26a)0x146e77dd9cea a516:1473167 25 gmx\\_mpi0x4065c7 a516:1473167 26 /usr/lib64/libc.so.6(\\_\\_libc\\_start\\_main+0xe5)0x146e75b8a7e5 a516:1473167 27 gmx\\_mpi0x40663e a516:1473167 \\*\\*\\* End of error message \\*\\*\\* ; mpirun noticed that process rank 128 with PID 955804 on node a283 exited on signal 6 (Aborted). ; ``` Have you encountered this issue before? It happened before to a job a few weeks ago, then it went away, but I just encountered it again on my last two jobs, 10651979 and 10680473. Thank you, and please let me know if I can provide any more information. Best, name ; Hi name, Sorry for the delayed response. the MPI {{Allreduce}} error you're seeing is likely a consequence of the lower-level UCX memory registration failures. I am not sure what cause these though. Perhaps diagnosing and resolving the ""Bad address"" and ""Input/output error"" issues reported by UCX? do you still have the problem for these jobs? Best, name ; Hi name, No problem! That's interesting, I haven't encountered memory registration errors like this before. The issue didn't come up again for the remainder of the simulation that these jobs were running, and since then I've been performing additional simulations of new systems, and I'm not seeing this issue anymore. Of course the intermittent issue makes debugging difficult, but let me know if I can provide any more information on the jobs where this error occurred, and I will let you know if it comes up again on any new jobs moving forward. Thanks and best regards, name ; Glad to hear you didn't see this issue for now! Memory bug is alway hard to track and debug. Yes, please let me know if this comes up again. I will mark the ticket solved now, feel free to let us know if you need more help. Best, name ;",jsheppard,Jackson Sheppard,Xiao Liu,,Anvil,7,19,15,2025,2025-04-07
ATS-15725,Change Owner of files,2025-04-11,2025-04-22,"Hello Anvil support, I have had a few people make files in my project x-mcb200143 that are no longer associated with the project. Can you recursively change the ownership of the files to x-kurtshow for the following directory to my account x-kurtshow so I can clean them up. Owner to set: x-kurtshow Directory to change: /anvil/projects/x-mcb200143/em-msstate-notmoved A command like the following should be fine. chown -R x-kurtshow:x-mcb200143 /anvil/projects/x-mcb200143/em-msstate-notmoved Bests, Kurt ; Hello, I hope you are doing well. Thank you for reaching out to RC Support with your question! We are actively working on addressing the issue. Rest assured, we will provide you with a response as soon as possible. Best regards, name RCAC Support ; Hi Kurt, Thanks for reaching out. I changed the permissions based on your request. Let me know if you still have an issue. Best, name K ; Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name K ;",kurtshow@access-ci.org,Kurt Showmaker,Haniye Kashgarani,,Anvil,4,8,15,2025,2025-04-07
ATS-15729,Compiling issues,2025-04-11,2025-04-21,"When compiling code of a software, I encounter an error below, and I'd like your help to resolve the error /apps/anvil/external/apps/intel/oneapi/2024.1/mpi/2021.12/bin/mpiicpx: line 559: icpc: command not found I was able to compile the same code on March 13, but I am not now. Did you make any changes in the system around Intel MPI settings, or do you have any advice on this matter? ; Hello, I hope you are doing well. Thank you for reaching out to RC Support with your question! We are actively working on addressing the issue. Rest assured, we will provide you with a response as soon as possible. Best regards, name RCAC Support ; Hi Hiroto, Thank you for reaching out and thanks for your patience. Could you please let me know which modules are currently loaded besides intel/2024.1? You can give me the list using $ \\*module list.\\* Thanks, name K ; Hi name, x-hodaka @login03 /anvil/scratch/x-hodaka/3d/name/base/ar1a20half\\_name\\_Re400 $20250421-15:58:04$ module list Currently Loaded Modules: 1) xalt/2.10.45 (S) 3) tbb/2021.12 5) oclfpga/2024.1.0 7) zlib/1.2.11 9) impi/2021.12 2) modtree/cpu 4) intel-rt/2024.1.0 6) intel/2024.1 8) numactl/2.0.14 Where: S: Module is Sticky, requires --force to unload or purge Inactive Modules: 1) libfabric/1.12.0 2) openmpi/4.0.6 Best, Hiroto ; Hi Hiroto, I loaded these modules and I could see the icpc visible: $ ml list Currently Loaded Modules: (1) xalt/2.10.45 (S) 5) libfabric/1.12.0 9) oclfpga/2024.1.0 (2) modtree/cpu 6) impi/2019.5.281 10) intel-rt/2024.1.0 (3) intel/19.0.5.281 7) numactl/2.0.14 (4) zlib/1.2.11 8) tbb/2021.12 Where: S: Module is Sticky, requires --force to unload or purge $ which icpc /apps/anvil/external/apps/intel/cluster.2019.5/bin/icpc $ icpc --version icpc (ICC) 19.0.5.281 20190815 Copyright (C) 1985-2019 Intel Corporation. All rights reserved. Can you try and let me know if you see icpc like how I do? If so, please compile again with these modules and let me know what happened. Best, name K ; Hi name, How can I load the module? I've tried x-hodaka @login04 /anvil/scratch/x-hodaka/3d/name/base/ar1a20half\\_name\\_Re400 $20250421-16:15:11$ module --ignore\\_cache load ""icpc"" Lmod has detected the following error: The following module(s) are unknown: ""icpc"" Please check the spelling or version number. Also try ""module spider ..."" It is also possible your cache file is out-of-date; it may help to try: $ module --ignore\\_cache load ""icpc"" Also make sure that all modulefiles written in TCL start with the string #%Module x-hodaka @login04 /anvil/scratch/x-hodaka/3d/name/base/ar1a20half\\_name\\_Re400 $20250421-16:15:25$ module --ignore\\_cache load icpc Lmod has detected the following error: The following module(s) are unknown: ""icpc"" Please check the spelling or version number. Also try ""module spider ..."" It is also possible your cache file is out-of-date; it may help to try: $ module --ignore\\_cache load ""icpc"" Also make sure that all modulefiles written in TCL start with the string #%Module x-hodaka @login04 /anvil/scratch/x-hodaka/3d/name/base/ar1a20half\\_name\\_Re400 $20250421-16:15:33$ which icpc /usr/bin/which: no icpc in (/apps/anvil/external/apps/xalt2/xalt/xalt/bin:/apps/anvil/external/apps/intel/oneapi/2024.1/mpi/2021.12/opt/mpi/libfabric/bin:/apps/anvil/external/apps/intel/oneapi/2024.1/mpi/2021.12/bin:/apps/spack/anvil/apps/numactl/2.0.14-gcc-8.4.1-75uba5t/bin:/apps/anvil/external/apps/intel/oneapi/2024.1/compiler/2024.1/bin:/apps/anvil/external/apps/intel/oneapi/2024.1/compiler/2024.1/opt/oclfpga/bin:/home/x-hodaka/bin:/home/x-hodaka/.local/bin:/usr/libexec/gsissh/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/puppetlabs/bin:/usr/site/rcac/sbin:/usr/site/rcac/bin:/usr/site/rcac/scripts:/opt/thinlinc/bin:/opt/thinlinc/sbin) ; $ ml intel $ ml intel-rt $ ml impi $ ml tbb $ ml oclfpga Let me know it you have any other questions. Best, name K ; Hi name, Now I can compile! Thank you so much. Best, Hiroto ; Awesome! Thanks for letting me know. I will mark this ticket as resolved now but feel free to reach out again with any other questions. Best, name K ;",hodaka@access-ci.org,HIROTO ODAKA,Haniye Kashgarani,,Anvil,9,7,15,2025,2025-04-07
ATS-15746,Jobs start running but program gets stuck,2025-04-12,2025-05-01,"Hi There, My current utilization in anvil/scratch is as follows :projects $ name -sh ./gis-sentinel1-IL 5.4T ./gis-sentinel1-IL :projects $ name -sh ./gis-sentinel2\\_2014\\_2019/ 1.4T ./gis-sentinel2\\_2014\\_2019/ :projects $ name -sh ./gis-sentinel1\\_2014\\_2019/ 2.4T ./gis-sentinel1\\_2014\\_2019/ :projects $ name -sh ./gis-modis\\_2014\\_2019/ 641G ./gis-modis\\_2014\\_2019/ When i schedule a new job (e.g. my last job 10530953). The job starts to run but the program it's trying to run gets stuck. No progress and no error. Is this because I have used up too much space and there is none left for the new job? Thanks, name, You can use the 'myquota' command to see the utilization of spaces you have access to. When I run it for you, I get this: Type Location Size Limit Use Files Limit Use =========================================================================== home x-rtali 8.7GB 25.0GB 35.0% - - - scratch x-rtali 11.3TB 100.0TB 11.3% 217.0K 1.0M 21.7% projects x-agr240009 6.5GB 5.0TB 0.1% 31.9K 1.0M 3.0% projects x-cis220078 0.0KB 5.0TB 0.0% 1 1.0M 0.0% projects x-cts110007 1.3TB 5.0TB 26.4% 585.1K 1.0M 55.8% Which shows me that nothing is at capacity yet. So, it's something else that is causing your program to hang. Can you tell what part of the code is it stopping on? Thanks, name, Since I haven't heard from you in a while, I'm tentatively marking this ticket as resolved. If that's not the case and you're still facing problems, please respond to this ticket within 7 days to reopen it. Otherwise, you can always submit a new ticket. Thanks, name ;",rtali@access-ci.org,Ronak Tali,Michael Carlson,,Anvil,3,14,15,2025,2025-04-07
ATS-15754,Anvil: cannot access $PROJECT to set up directory structure to store output ,2025-04-13,2025-05-01,"Hello, I am accessing Anvil for the first time and am attempting to access and set up directories within $PROJECT where I plan to store output generated in my simulations run on the HPC. However, cd $PROJECT -bash: cd: /anvil/projects/x-mch240074: Permission denied Could you kindly advise me on how to proceed, and if I have to do something else to access the file storage? I am able to access $SCRATCH but I understand this is purged often and won't work for storing data for the duration of my allocation. ; Guatham, Thank you for contacting RCAC for support. We have diagnosed the problem and are working on a fix. This seems to be a widespread issue on Anvil, so we are working on a solution. I will keep you updated as we make progress. Thanks, name ; Guatham, I apologize for the delay, but this should be fixed for you now. Please try it and let me know if it works. Thanks, name ; Hi name, I was just able to access the Project directory. Thank you for your assistance. Regards, Gautham ; Guatham, I left the ticket open for a while to make sure that you didn't run into any troubles. It sounds like it's all working as intended. I'm marking this ticket as resolved, but if you do run into more problems, please respond to this ticket within 7 days to reopen it. Otherwise, you can always submit a new ticket. Thanks, name ;",gautham3@access-ci.org,Gautham Krishnan,Michael Carlson,,Anvil,5,14,15,2025,2025-04-07
ATS-15866,not able to log into Anvil though Purdue,2025-04-17,2025-04-21,"I have not been able to log onto anvil for about 2 weeks now. I type in the 'ondemand……..' into my browser and get brought to the access page. I enter my credentials, get a DUO notification sent to my phone, approve it, and my browser reloads. It is here that I get the error on the screen 'Failed to connect to a061.anvil.rcac.purdue.edu:57590: http://a061.anvil.rcac.purdue.edu:57590'. ; Hi Grace, Thanks for reaching out Best, Grace ; Glad it is working now. Thanks for reaching out! --name ;",enright,grace,Nannan Shan,Purdue University,Anvil,4,3,16,2025,2025-04-14
ATS-15888,help needed for exchanging Anvil hours for Anvil temporary storage,2025-04-17,2025-04-23,"I would like to exchange 200,000 Anvil core hours for temporary Anvil storage. In Resources I can decrease my Anvil balance by 200,000 hours but I find no option for converting that to Anvil storage, including when I populate the exchange box. How do I request such an exchange? ; Hi name, Thanks for reaching out Regards, name ;",pterry@access-ci.org,Paul Terry,Nannan Shan,,Anvil,7,5,16,2025,2025-04-14
ATS-15981,Cannot see project description page,2025-04-21,2025-05-01,"Hi all, I am unable to access the project description page on the ACCESS website. I would like to determine the number of SUs remaining in our lab's project allocation and identify the major users. However, I can access my Anvil account from the terminal and check the project balance there. ; Hello, I hope you are doing well. Thank you for reaching out to RC Support with your question! We are actively working on addressing the issue. Rest assured, we will provide you with a response as soon as possible. Best regards, name RCAC Support ; Hello, You can check your name balance and usage directly from the Anvil terminal by running: {{mybalance -x }} This will show all active allocations, usage, and remaining SUs. Let us know if you need help interpreting the output or checking a specific project. Best, name RCAC Support Team ; Hi name, Thanks for your response. Yes, I can access my information from the terminal, but why can't I see it on the website? My PI, Dr name, wants to know the detailed usage of the project, user by user. In the past, I could pull out that information from the page: https://ondemand.anvil.rcac.purdue.edu/pun/name/dashboard: https://ondemand.anvil.rcac.purdue.edu/pun/name/dashboard. However, I have recently lost access to this webpage. After I do the Duo authentication, I get the following error message. Error -- failed to map user () Best, ---- ; Hi Eeshan, Thanks for the update. The error you're seeing — {{failed to map user ()}} — typically means that your ACCESS identity isn't correctly linked to your Purdue/Anvil system account. This can happen if the mapping between your ACCESS CI username and RCAC username (eeshanb) has changed or wasn't completed. We'll need to update your account mapping on our end. I'll escalate this to the appropriate team to get it resolved. In the meantime, you can continue using the terminal to monitor name usage via: {{mybalance -x }} And for more detailed user-by-user project usage, you can run: {{sacct -A your\\_allocation --format=User,JobID,Elapsed,TotalCPU,MaxRSS,Start,End }} I'll follow up once the web access issue is resolved. Best regards, name RCAC Support Team ; Hi Eeshan, Thanks for your patience. I checked with our team, and it looks like your ACCESS account is currently inactive, even though your Anvil account is fine. Our records show that your allocation was closed in December 2024 and reactivated in March 2025, but it appears ACCESS may not have fully re-associated your identity with the allocation. To resolve this, please ask your PI to re-add you to the ACCESS allocation. If that doesn't work, you may need to contact ACCESS support directly to ensure your account is fully activated on their end. Best, name RCAC Support ;",eeshanb@access-ci.org,Eeshan Basu,Ankitha Mallekav,,Anvil,6,9,17,2025,2025-04-21
ATS-16028,AnvilGPT Access Request,2025-04-23,2025-04-23,"Currently I am using LLMs for my PhD research, such as Llama. Probabky using AnvilGPT will be faster and more realiable than the solutions I am using. I am want to test both the UI and API. ; Your request has been approved. Please let me know if you have any further questions. ;",vdeoliveiralima,Vinicius Lima,Ashish Malik,Purdue University,Anvil,2,1,17,2025,2025-04-21
ATS-16034,"Getting a ""QOSMaxCpuPerUserLimit"" when trying to run jobs on shared node on Anvil",2025-04-23,2025-04-24,"Dear team, I hope you are doing well. For my research project, I've recently launched 24 simulations on anvil in the shared queue, where each simulation uses 96 cores. The Anvil documentation mentions that users can utilize up to 6400 cores for running jobs simultaneously in the shared queue. However, for my simulations, only 13 of them are running, and for the rest, I'm getting a ""QOSMaxCpuPerUserLimit"" error. Since the total number of simulations, if run simultaneously, will use only 2,304 cores, which is below the max limit mentioned in the documentation, I'm unable to understand why I'm getting this error. I'll be grateful if you can guide me on how I can run the desired simulations in the shared queue. Thanks, name. ; Hi, Do you know which partition did you use? Best, name ; Hi name, My apologies if the partition usage was unclear in the ticket. I'm using the shared partition. Each of the 24 simulations use 96 cores. Out of that, 13 are running and for the rest 11, I get the error mentioned. Since the documentation: https://www.rcac.purdue.edu/knowledge/anvil/run/partitions mentions the max limit as 6400 cores in the shared partition, I feel I should not encounter this error given that total number of cores required to simultaneously run the 24 simulations is less than the limit. Hope this provides the required clarification. Please feel free to reach out if you need any additional information. Best, name. ; Hi name, I think there is misunderstanding there. The 6400 in the user guide means for the whole partition, which it can access 6400 cores, but not for individual users. I checked the information of QOS shared partition used. It's 1280 cores, as below. \\*:\~\\* $ sacctmgr show QOS format=Name%30,MaxTRESPU | grep ""part-shared"" \\*part-shared\\* cpu=1280 Please let us know if you have more questions. Best, name ;",as6481@access-ci.org,Atharva Sathe,Xiao Liu,,Anvil,4,2,17,2025,2025-04-21
ATS-16059,Running Jobs,2025-04-24,2025-04-30,"Dear Concern, I hope this message finds you well. We are currently experiencing significant delays when submitting both GPU and CPU jobs on Anvil. Specifically, it is taking approximately \\*3-4 days\\* for jobs to start running after submission. This delay is impacting our workflow and project timelines. Could you please advise if there are any known issues, or suggest possible solutions or best practices to reduce queue times? Thank you for your assistance. ; Hello! Thanks for reaching out! I've checked your pending jobs on Anvil, for CPU jobs, they are pending because there are not enough SUs on your allocation for your jobs. If you use squeue command to check the status, it is showing PENDING (AssocGrpCPUMinutesLimit), meaning there are not enough SUs on your account. For GPU jobs, our A100 GPUs are very busy these days, longer waiting time on the queue will be expected. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ;",mrahman8,MD SAIDUR RAHMAN,Nannan Shan,,Anvil,2,5,17,2025,2025-04-21
ATS-16124,Need to exchange ACCESS credits for more Purdue Anvil GPU credits,2025-04-28,2025-04-28,"Hi I had previously exchanged ACCESS credits for 50 credits on Purdue Anvil GPU. But I would like to exchange more credits for the same. Could you please help? Thanks, Ananya ; Hello, You are able to submit another exchange request. You can find instructions on how to do so here: https://allocations.access-ci.org/how-to#exchange-credits: https://allocations.access-ci.org/how-to#exchange-credits|smart-link . Best, name Lehosky ACCESS Allocations Team ;",ajana1@access-ci.org,Ananya Jana,jlehosky,,Anvil,2,1,18,2025,2025-04-28
ATS-16151,Requested Node Configuration Not Available,2025-04-29,2025-05-09,"Every time I try to submit a job, I get an error that says, ""sbatch: error: Batch job submission failed: Requested Node Configuration is not Available"". ; Hi, Thank you for contacting us. We will get back to you as soon as we have the answer. Best regards, name Purdue RCAC Support ; Hi Ricky, Are you still experiencing this issue? One of our team members was also able to recreate the issue however, it seems it has resolved itself now. Best, name Purdue RCAC Support ;",rsteinel@access-ci.org,Ricky Steinel,yang2383,Purdue University,Anvil,4,9,18,2025,2025-04-28
ATS-16168,Possibility to shift some CPU resources to GPU on RCAC Purdue,2025-04-29,2025-04-30,"Hi Support Team, I am a member of the research group x-mca99s008 on RCAC Anvil. We are currently exploring the possibilities of accelerating some of our simulation codes through GPU parallelization. However, since we haven't applied to any GPU resources before, the PI of the group wants to see if it is possibile to convert some of our CPU resources to GPU resources so we can run some tests. Please let us know how to do it if it's possible. Best, name ; Hello I hope your Wednesday is going well. Yes, you are welcome to submit an \\*Exchange Request\\*. An Exchange Request allows you to \\*transfer time or resources from one system to another\\*, depending on your project's evolving needs. You can find detailed guidance on how to submit an Exchange Request here: 👉 https://allocations.access-ci.org/how-to#exchange-credits: https://allocations.access-ci.org/how-to#exchange-credits|smart-link For your convenience, we've also outlined the steps below: h3. \\*How to Submit an Exchange Request\\* # Log in to allocations.access-ci.org: https://allocations.access-ci.org/. # You'll see your project dashboard, or a list of your projects if you have multiple. # Click on the \\*""Credits + Resources""\\* tab. # You may request multiple resources within a single exchange. # For the resource you'd like to \\*transfer from\\*, reduce the number in the ""Balance"" column to reflect your desired remaining balance. # For the resource you'd like to \\*transfer to\\*, increase the number in the ""Balance"" column accordingly, or click on \\*""Add a resource to your exchange""\\* to request a new one. # Provide a brief \\*justification\\* for the request. # Click \\*""Submit for Approval.""\\* # A confirmation window titled \\*""Complete Your Exchange""\\* will appear. # Review the request, and once everything is accurate, click \\*""Submit.""\\* After submitting, you'll receive an \\*email confirmation\\* of your successful request. Once a decision has been made, you will receive a separate notification with the outcome. If you have any questions or run into any issues during the process, feel free to reach out — we're happy to assist you at any step! Let us know if you have any questions along the way. If you have any questions in the future, please visit this site (https://support.access-ci.org/help-ticket: https://support.access-ci.org/help-ticket|smart-link ) and submit a ticket. name Pusateri ACCESS Allocations ;",yguo11@access-ci.org,Yuheng Guo,brandonp,,Anvil,2,2,18,2025,2025-04-28
ATS-16203,long queue time on Anvil,2025-04-30,2025-05-09,"Hi there, I am an Anvil user, x-myin. Recently, I found the pending time of my submitted jobs on Anvil is very slow, significantly longer than before. There is still allocation in my account ""mde240004"", but I just wonder what could be the possible reasons that lead this? Is it normal? When would it can be faster? Thank you so much Minglang ; Thanks for reaching out. could you please share you job id? Best, name ; Hi name, Sure. 10868831. I submitted a batch of jobs last night, and this is just one of them. What I am reporting is a long-pending time for all users under ""mde240004"" (my colleagues have found the same issue since the beginning of Apr). Is there any issue either on the machine, or our allocation? Have you recently seen a surge on the number of job submission? PS: When I used Anvil last year, it was super fast, and the typical pending time is under 30 name. Best Minglang ; Hi Minglang, jobinfo shows this job in pending with priority reason. I checked that you have a long list of jobs submitted to slurm (you could see all of them by typing squeue in your terminal), which might be the reasons that you job couldn't get the resource, given right now there are only 11 nodes idle and you already have a job running(based on fair-share rule slurm set, running jobs would decrease the priority in the queue.) Also I have a question why you use whole node for these jobs, each only use 48 cores which will leave the rest 80 cores idle? Best, name ; Hi name, That's the Slurm script I received from the technician in our group. Will removing this line make my jobs have a higher priority? Also, I've been using Anvil since last year and my impression was that all of the submitted (a series of parallel) jobs can be executed very fast. Is Anvil getting more crowded recently? Thank you for your help! Minglang ; Hi Mingling, Reducing your total running jobs will make your jobs have a higher priority. Changing from 48 cores to 128 won't but will make your job faster. Honestly I don't how Anvil looks like last year, but I guess more people are using it as time goes. Feel free to reach out if you have more questions. Best, name ;",myin@access-ci.org,Minglang Yin,Xiao Liu,,Anvil,6,8,18,2025,2025-04-28
ATS-16286,Request of VASP access,2025-05-02,2025-05-09,"Dear ACCESS team, When I tried to load the VASP module in Purdue Anvil CPU cluster, it shows the following error message: x-ypeng5@login07:/anvil/scratch/x-ypeng5$ module load vasp/6.3.0 Lmod has detected the following error: WARNING: this software has a license restricted to approved users. Users have to show their licenses and be confirmed by the VASP team that they are registered users under that license. Please send a ticket request access. While processing the following module(s): Module fullname Module Filename ; vasp/6.3.0 /opt/spack/cpu/openmpi/4.1.6-745pfv4/gcc/11.2.0/vasp/6.3.0.lua The license of our research group is attached. My name, can be found on page 5 of the license. Could you please list me as a registered user so that I can use the VASP module? Best, name ; ^VASP\\_5u6\\_License\\_Agreement\\_academic\\_6users\\_filled 2.pdf] ; Hi name, Thanks for reaching out Best, name ; Hi name, I do not need your supervisor's email. I need YOUR email. Every user wants to use central VASP on Anvil should be under a valid VASP license. Please ask your advisor to add you to the license and let me know which email address you used. So I can validate your status on VASP license. Regards, name ; Hi name, My email address : mailto: and my full name have just been added to the VASP license 22-0313. You can validate now. Best, name ; Hi name, You have been added to vasp5 and vasp6 groups on Anvil. Your membership will be ready within a few hours. Please check our user guide for VASP calculations on Anvil. https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/vasp: https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/vasp|smart-link Regards, name ;",ypeng5@access-ci.org,Yihang Peng,Nannan Shan,,Anvil,7,6,18,2025,2025-04-28
ATS-16042,Cannot compile stan program,2025-04-23,2025-05-15,"Hi, I'm trying to use Anvil to compile and run a stan program. I use R to do this, either with cmdstanr or stanr. I have tested my R and stan code using amd64 and arm computers running Debian Linux. Both are successful with either smcstanr or stanr. However on anvil I get compilation errors for either approach. In slurm load the r/4.4.1 module. When I use stanr, I get this error: Error in compileCode(f, code, language = language, verbose = verbose) : an/stan\\_fit.hpp:1215:18: required from 'SEXPREC\\* rstan::stan\\_fit::call\\_sampler(SEXP) with Model = model308bfe2433012 c\\_\\_namespace::model308bfe2433012c\\_; RNG\\_t = boost::random::additive\\_combine\\_engine, boost::random::linear\\_congruential\\_engine >; SEXP = SEXPREC\\*' file308bfe2402e389.cpp:738:68: required from here /home/x-jreddinger/R/x86\\_64-pc-linux-gnu-library/4.4/RcppEigen/include/Eigen/src/Core/DenseCoeffsBase.h:56:30: warning: ignoring attrib utes on template argument 'Eigen::internal::packet\\_traits::type' {aka '\\_\\_m128d'} -Wignored-attributes 56 | >::type PacketReturnType; | ^~~~~~~~~~~~~~~~ g++: fatal error: Killed signal terminated program cc1plus compilation terminated. make: \\*\\*\\* [/apps/spack/anvil/apps/r/4.4.1-gcc-11.2.0-kth7vej/rlib/R/etc/Makeconf:204: file308bfe2402e389.o Calls: stan ... cxxfunctionplus -> -> cxxfunction -> compileCode Error in sink(type = ""output"") : invalid connection Calls: stan -> stan\\_model -> cxxfunctionplus -> sink Execution halted slurmstepd: error: Detected 1 oom\\_kill event in StepId=10651092.batch. Some of the step tasks have been OOM Killed. When I use cmdstanr, I get this error: > # Compile the model > model <- cmdstan\\_model(paste(this\\_file,"".stan"",sep="""")) Error in `(function (command = NULL, args = character(), error\\_on\\_status = TRUE, …`: ; Hi, I am not sure the reason of the issue, but try to trouble-shoot here. I noticed you only used one core for your compile, which might have a problem. Could you try to use 64 or 128 cores instead to see how things are going? You will revise it ""#SBATCH --ntasks=1"" to ""#SBATCH --ntasks=64"" Let us know if this resolves your issue or not. Best, name ; Hi, Since I have not heard back from you in a while, I'm tentatively marking this ticket resolved at this point. If you still need assistance, please feel free to reply to this email within the next 7 days to reopen the ticket. After that, you could create a new ticket at any time. Best, name ;",jreddinger@access-ci.org,Jonathan Reddinger,Xiao Liu,,Anvil,5,17,17,2025,2025-04-21
ATS-16074,Reservation of 256 nodes on Anvil,2025-04-24,2025-05-16,"Dear Anvil support team, Using our renewed allocation on Anvil (70 Million CPU-hours), we are performing a very high-resolution simulation of magnetohydrodynamic turbulence using a well-tested, MPI-OpenMP hybrid-parallelized, highly-scalable (up to more than 100,000 cores), and very efficient pseudospectral solver. In this ticket, following the earlier suggestion of senior scientist name (Anvil), we would like to request a reservation of 256 nodes to continue our very high-resolution simulation (1024 x 1024 x 2048 spectral modes). The simulation is to be run long enough to allow us to reach a statistically-steady stage of turbulence, which will take around 12 days altogether. A straight 12-day calculation would be the ideal. We are, however, flexible with the number of days that 256 nodes can be reserved at a time. For example, 6 days in one round, followed by 6 days in the next round, could be workable. This numerical calculation is an urgent and important response to the comments by reviewers of our paper, which has gone through the first round of review with positive feedback in the journal \\_Nature\\_. We would greatly appreciate your kind consideration of this urgent calculation. Please let us know if there is anything we could share before 256 Anvil nodes are reserved. Many thanks. Bindesh -- Bindesh name ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id:id-248a-43b5-a841-66499835a741 ; Hi Bindesh, Thanks for reaching out Regards, name ; Dear name, Thank you so very much for reserving those nodes for my jobs. This reservation is wonderful and works perfectly for my calculations. I plan to use all of those nodes for a single extreme resolution simulation at a given time and perform a few such simulations during the reservation time window. This works very well with the number of jobs (which is 1) that I can submit at a given time using ""#SBATCH -q btripathi"". This limit was added in the past when the queue was created. During this reservation time window, I might need to occasionally submit 2 simulation jobs at the same time in case there arises a need. I am curious if it would be possible to allow to submit 2 jobs at the same time (the total number of nodes for these 2 jobs is still the same: 256). If this is not possible, that is perfectly okay. I will then submit one job at a time. I am very happy with this provision that you have made for us. Over a large majority of this reservation time, I will be running one extreme-resolution simulation at a given time and let it complete and start the next one. The SLURM job submission script that I use is appended. This worked well last time when name reserved 512 nodes. I believe the same should work this time around also, using the \\_wholenode\\_ partition. Please let me know if there is anything special about this reservation that I might need to add in the SLURM job submission script. I appreciate your kind help and continued support. Many thanks. Bindesh # -name ;",bindesh@access-ci.org,Bindesh Tripathi,Nannan Shan,,Anvil,17,17,17,2025,2025-04-21
ATS-16434,SU Balance inaccurate,2025-05-07,2025-05-08,"I recently renewed my project (x-chm240035) and exchanged ~270k of Anvil credits. While the name Limit and name Usage (user) are correct when displayed using $ mybalance, the name Balance is not correct. It looks like the name Usage (account) wasn't reset after I renewed my project, so the name Balance is much lower than what is displayed on allocations-ci.org: http://allocations-ci.org. ; Hi, You said name limit and name usage is correct but name Balance is not? but 266665.4 - 259544.9 = 7120.5. Could you pleas clarify which number is not correct in the attached picture? Best, name ; The name Usage (account) is not correct. It's still considering the usage from before this project was renewed. The name Usage (account) and the name Usage (user) should currently be the same number. Thanks, Takashi ; Hi, We fixed your balance issue now. Please let us know if you need more help. {{Allocation Type name Limit name Usage name Usage name Balance Account (account) (user) ============= ==== ========== ========== ========== ========== chm240035 CPU 266666.0 91328.8 91328.8 175337.2}} Best, name ;",tyokokura@access-ci.org,Takashi Yokokura,Xiao Liu,,Anvil,4,2,19,2025,2025-05-05
ATS-12125,Quantum Espresso 7.4 installation,2024-11-13,2025-05-16,"I am an Anvil user through ACCESS. I use Quantum Espresso for my calculations. Quantum Espresso has a new version 7.4, which has bug fixes for the type of calculations that I am doing. https://gitlab.com/QEF/q-e/-/releases: https://gitlab.com/QEF/q-e/-/releases|smart-link Would it be possible to install Quantum Espresso 7.4 in Anvil? my ACCESS user id : bbrogdon ; Hi, Thanks for reaching RCAC. I will bring up your request to the user support team discussion. Will let you know once we have a decision. Best, name ; Hi Brody, Thanks for your patience on this. And appoligize the ticket has been fall out of my monitoring. I am wondering if you still need QE 7.4 on Anvil, any specific functions you are looking for? Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Hello, I have been able to do my research without QE 7.4, so I do not need an update right now. Thanks, Brody Brogdon ---- ; Thanks for letting me know, Brody. Good luck to your research! Regards, name ;",bbrogdon@access-ci.org,Brody Brogdon,Nannan Shan,Purdue University,Anvil,5,133,46,2024,2024-11-11
ATS-14591,Setting up a shared folder on ANVIL,2025-03-05,2025-05-15,"Hello, I was wondering if someone could help me with understanding how I can share a folder with my colleague on ANVIL. I set up an account and are using ACCESS credits. I am in the process of uploading the data. How can I enable her to gain access to my home folder? Is there a shared folder that I should move the data? She has been added as a user for this project. ; Hi, I apologized for the late reply. They cannot access to your home directory directly. However, you could share the data in a directory with them via Globus. Please refer to https://www.rcac.purdue.edu/training/globus: https://www.rcac.purdue.edu/training/globus|smart-link and let us know if you need more help. Best, name ; \\*\\*PRIVATE NOTE\\*\\* Hi, Since I have not heard back from you in a while, I'm tentatively marking this ticket resolved at this point. If you still need assistance, please feel free to reply to this email within the next 7 days to reopen the ticket. After that, you could create a new ticket at any time. Best, name ;",swright1@access-ci.org,Sterling Wright,Xiao Liu,Purdue University,Anvil,3,52,10,2025,2025-03-03
ATS-15771,Script modification for Anvil,2025-04-14,2025-05-13,"I want to run the attached script in anvil, Can you please check and modify the script for Anvil? Thank you so much for your kind support. ; ^3\\_job\\_run (ef5fd904-d186-41f1-a74c-5fbd2e1fbccf).pbs] ^3\\_job\\_run.pbs ; Hi MD SAIDUR, Thank you for reaching out. Please follow our user guide on job scripts and submission methods, available on [https://www.rcac.purdue.edu/knowledge/anvil/run: https://www.rcac.purdue.edu/knowledge/anvil/run|smart-link , and modify your PBS script to a SLURM script. Then let me know if in any steps you have an issue. Best, name, PhD (she/her) Senior Computational Scientist RCAC - Purdue University ; Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name, PhD (she/her) Senior Computational Scientist RCAC - Purdue University ;",mrahman8@access-ci.org,MD SAIDUR RAHMAN,Haniye Kashgarani,,Anvil,4,22,16,2025,2025-04-14
ATS-16106,Job not getting off the Queue,2025-04-27,2025-05-13,"Hi, I have scheduled an interactive Job {{10793127}} for a Jupyter session so that I could work on my model. But the job has been in the queue since last 58 Hours. Could you please give me some idea on how much longer should I wait, and if there's any way I can decrease the wait time? I did check the {{wait\\_time -j 10793127}} and it just shows \\*6 - 12 hours\\* but it has been 58 hours already. And is there a way to add email notifications when the job gets started \\*for interactive Jupyter jobs\\*? I saw the option by using SLURM script, but is there any way I can add that email notification to this already scheduled job? Thank you so much, Bibek ; Bibek, Thank you for contacting RCAC for support. There isn't a way to add email notification for a job that has already been submitted, but before you submit your job, there's a checkbox for ""I would like to receive an email when the session starts"" right above the submit button. As for why your job has been pending for so long, I know that there are a lot of jobs currently on Anvil that are requesting GPUs right now. You can check this yourself by using the command ""squeue -p gpu"", which will show all the jobs (running or pending) on Anvil's GPU partition. Determining wait time is a notoriously difficult problem and an area of active research, as it depends on many different factors, so the ""wait\\_time"" command should be viewed as an estimate and not a source of truth. Thank you for your patience, name ; Bibek, Since it's been a while that I've heard from you, I'm tentatively marking this ticket as resolved. If you are still facing issues with GPU wait times, please respond to this ticket within 7 days to reopen it. Otherwise, you can always submit a new ticket. Thanks, name ;",bneupane,Bibek,Michael Carlson,Purdue University,Anvil,4,12,17,2025,2025-04-21
ATS-16184,Anvil Reservation ,2025-04-30,2025-05-13,"Hi: We would like a reservation on Anvil Compute (20 nodes) and GPU (2 nodes) for a workshop. We plan to use this for hands on for about 30 active participants. We will use scigap community logins and appropriate shared partitions as much as possible. We will be using \\*CCR140004: Cybershuttle Computing Continuum for th Anvil reservation .\\* The workshop is described at https://research.gatech.edu/data/CIforSE: https://research.gatech.edu/data/CIforSE|smart-link . Please let me know if you need anything. Thanks, Sudhakar. ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id:id-248a-43b5-a841-66499835a741] ; Could you please update Amber to i Amber22 if posible on Anvil for the Workshop. Thanks, Sudhakar. ; Hi Sudhakar, Thanks for reaching out Regards, name ; Hi name/Anvil Support: It appears a block to conda-forge at Anivl is causing the requirement downloads for our notebooks for the Workshop to hang/fail. Could you please lift this block asap. Thanks, Sudhakar. Sudhakar Pamidighantam Associate Director Center for Artificial Intelligence in Science and Engineering: https://artisan.research.gatech.edu/ (ARTISAN) Institute of Data Engineering and Science (IDEaS): https://research.gatech.edu/data Georgia Institute of Technology Phone: Email: ; Hi Sudhakar, RCAC systems is experiencing network connectivity issues right now. We cannot fix the network issue but waiting for engineering team to work on it. Apologize for the inconvenience this brought to your workshop. https://www.rcac.purdue.edu/news/7096: https://www.rcac.purdue.edu/news/7096|smart-link Regards, name ;",spamidig,Sudhakar Pamidighantam,Nannan Shan,Purdue University,Anvil,8,10,18,2025,2025-04-28
ATS-16276,Unable to Access Purdue Anvil Open OnDemand Portal from KSU Network,2025-05-02,2025-05-16,"Dear Anvil Support Team, I am experiencing issues accessing the Purdue Anvil Open OnDemand portal (https://ondemand.anvil.rcac.purdue.edu: https://ondemand.anvil.rcac.purdue.edu) from the Kansas State University (KSU) network for molecular dynamics simulations. The portal is accessible using my mobile network, but not from KSU, suggesting a potential network restriction. I can see the request go out from KSU, but it receives no response. Additionally, SSH access may need to be allowed, but I'd like to resolve the web access issue first. Regards, Nandan ; Hi Nandan, Thanks for reaching out! And apologize for the delays here, this ticket has been slipped away from our monitoring. There are a couple of institutions reported that they also had connection issue with their campus network, and we are still investigating on this. At this moment, we do not have a better workaround rather than suggesting you using the network or ways to connect to Anvil. We apologize for the inconvenience. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ;",nkumar6@access-ci.org,Nandan Kumar,Nannan Shan,,Anvil,3,11,18,2025,2025-04-28
ATS-16351,High SU usage on new allocation in mybalance,2025-05-05,2025-05-13,"Hello, A few weeks ago, we received a new allocation (phy230138) and we exchanged Access credits for 1M Anvil SUs. When we first got access to the SUs, the usage for the account was already over 600k. The user usage of 2.5k SUs seems correct. Only one other account (x-medvdev) should have access to this allocation and it has a usage ~1k SUs. The allocation page on the Access portal correctly identifies a usage of ~4k SUs. Here is the relevant output from mybalance today. Allocation Type name Limit name Usage name Usage name Balance Account (account) (user) ============= ==== ========== ========== ========== ========== phy230138 CPU 999999.4 625058.3 2564.1 374941.0 Will these 621k SUs be refunded/available in the future? Thank you, name Yungbluth ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id:id-248a-43b5-a841-66499835a741 ; Hi name, Thank you for reaching out. I am investigating the issue and will get back to you once I hear back from my colleagues. Best, name, PhD (she/her) Senior Computational Scientist RCAC - Purdue University ; Hi name, We were able to correct this, which was purely an internal error in the mybalance Slurm config not clearing the prior usage after the renewal. Please let me know if you are still seeing anything unexpected from these systems now. Thank you, -name ; Hello, the issue seems to be resolved. Thank you, name Yungbluth ; Thanks for letting us know. I will mark the ticket as resolved but feel free to reach out again with any other questions or concerns. Best, name, PhD (she/her) Senior Computational Scientist RCAC - Purdue University ;",jyungblu,Jack Yungbluth,Haniye Kashgarani,,Anvil,6,7,19,2025,2025-05-05
ATS-16362,Very long queue for Purdue Anvil,2025-05-05,2025-05-15,"Hello, I am just inquiring about the duration of queues for job submissions on Purdue Anvil. I have noticed the past few weeks the queues are extremely long. The jobs I'm submitting are taking between 12-36 hours to start, but before a few weeks ago these same jobs would usually be in queue for less than an hour. I was just wondering if this is an issue other people are experiencing and if there's any reason for it. Thank you, -Zach Croft ; \\*\\*PRIVATE NOTE\\*\\* Ticket due to downtime. Closed. ;",zcroft@access-ci.org,Zachary Croft,Elian Inigo Rieza,,Anvil,2,9,19,2025,2025-05-05
ATS-16385,Inquiry about ANSYS,2025-05-05,2025-05-15,"Hi, I am planning to run some ANSYS fluent simulations. Is ANSYS available on Anvil HPC? I didn't find it on the software list but I was unsure if it is a software that I needed to request by putting in a ticket. Thanks, name Rajeev ; Hi name Rajeev, Unfortunately, I must inform you that we do not provide the ANSYS software on Anvil since it is a nationally shared resource (NSF ACCESS). Since ANSYS requires a commercial license, we are not able to provide it as a requestable software on a shared national HPC system. Even to users from Purdue who have a valid ANSYS license, we don't provide ANSYS access on Anvil specifically. Instead they can only use it on one of our Purdue Compute Clusters. I apologize for this inconvenience. Best regards, name Purdue RCAC Support ; Hi, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best, name Purdue RCAC Support ;",rprabhuvenkatesh@access-ci.org,Raghav Rajeev Prabhu Venkatesh,yang2383,,Anvil,3,9,19,2025,2025-05-05
ATS-16430,Jobs are Queued,2025-05-07,2025-05-13,"Hello, I hope you are well. I am currently running a series of jobs on the shared queue for the chm230047 account. It is my understanding that I am able to run 6400 cores concurrently but many of my jobs are pending. I have included my submission script and current jobs. Can you help me understand my limits? #!/bin/sh -l #FILENAME: submsission #SBATCH -A chm230047 #SBATCH --job-name=slab\\_V\\_1 #SBATCH --output=slab\\_V\\_1.out #SBATCH --error=slab\\_V\\_1.err #SBATCH --partition=shared #SBATCH --time=96:00:00 #SBATCH --ntasks=46 #SBATCH --cpus-per-task=2 #SBATCH --mem=190G #SBATCH --nodes=1 h1. Helps the CPUs organize themselves export OMP\\_NUM\\_THREADS=2 h1. Ensure proper MPI execution export I\\_MPI\\_DEBUG=5 # Enables verbose debugging for MPI #export I\\_MPI\\_PINNING=0 # Disable Intel MPI's process pinning #unset I\\_MPI\\_PMI\\_LIBRARY h1. Run Quantum ESPRESSO mpirun /home/x-cchandler/software/qe/qe-7.3.1/build/bin/pw.x -ndiag 16 -npool 2 -in http://input.in: http://input.in|smart-link > output.out JOBID USER ACCOUNT NAME NODES CPUS TIME\\_LIMIT ST TIME 10895373 x-cchandler chm230047 slab\\_V\\_3\\_O 1 92 4-00:00:00 PD 0:00 10895372 x-cchandler chm230047 slab\\_V\\_2\\_O 1 92 4-00:00:00 PD 0:00 10895371 x-cchandler chm230047 slab\\_V\\_1\\_O 1 92 4-00:00:00 PD 0:00 10895370 x-cchandler chm230047 slab\\_Ti\\_3\\_O 1 92 4-00:00:00 PD 0:00 10895369 x-cchandler chm230047 slab\\_Ti\\_2\\_O 1 92 4-00:00:00 PD 0:00 10895368 x-cchandler chm230047 slab\\_Ti\\_1\\_O 1 92 4-00:00:00 PD 0:00 10895367 x-cchandler chm230047 slab\\_Mn\\_3\\_O 1 92 4-00:00:00 PD 0:00 10895366 x-cchandler chm230047 slab\\_Mn\\_2\\_O 1 92 4-00:00:00 PD 0:00 10895365 x-cchandler chm230047 slab\\_Mn\\_1\\_O 1 92 4-00:00:00 PD 0:00 10895364 x-cchandler chm230047 slab\\_Cr\\_3\\_O 1 108 4-00:00:00 R 8:51:41 10895363 x-cchandler chm230047 slab\\_Cr\\_2\\_O 1 108 4-00:00:00 R 16:55:04 10895362 x-cchandler chm230047 slab\\_Cr\\_1\\_O 1 108 4-00:00:00 R 1-16:56:09 10895253 x-cchandler chm230047 slab\\_Cr\\_1 1 108 4-00:00:00 R 3-16:23:51 10895254 x-cchandler chm230047 slab\\_Cr\\_2 1 108 4-00:00:00 R 3-16:23:51 10895255 x-cchandler chm230047 slab\\_Cr\\_3 1 108 4-00:00:00 R 3-16:23:51 10895256 x-cchandler chm230047 slab\\_Mn\\_1 1 108 4-00:00:00 R 3-16:23:51 10895257 x-cchandler chm230047 slab\\_Mn\\_2 1 108 4-00:00:00 R 3-16:23:51 10895258 x-cchandler chm230047 slab\\_Mn\\_3 1 108 4-00:00:00 R 3-16:23:51 10895259 x-cchandler chm230047 slab\\_Ti\\_1 1 108 4-00:00:00 R 3-16:23:51 10895260 x-cchandler chm230047 slab\\_Ti\\_2 1 108 4-00:00:00 R 3-16:23:51 ; Greetings, Hope your Thursday is treating you well! To make sure we can answer correctly, can you confirm what resource your jobs are currently running on (e.g., Delta, Expanse, Ranch, etc.)? Thanks, Cassian McClenny ACCESS Support ; Hello, I am running on Anvil. ---- ; Hi, the partition has max cpus 1280 per user. Please see the information below: \\*:\[~\\*: mailto:\\*\\* $ sacctmgr show QOS format=Name%30,MaxTRESPU | grep ""part-shared"" \\*part-shared\\* cpu=1280 Let us know if you need more help. Best, name ;",cchandler@access-ci.org,Cierra Chandler,,Purdue University,Anvil,4,5,19,2025,2025-05-05
ATS-16531,VASP Access Anvil,2025-05-12,2025-05-13,"I hope this email finds you well. I am part of a research team from Harvey Mudd College using the TAMU ACES High Performance Computer cluster. We are currently running DFT simulations which involves using the VASP software. The VASP license number is 24-0365, the PI who holds the license is name Ritz, and the users added to the license are Larry name (: mailto:) and name (: mailto:). Would it be possible for us to be added to the Anvil VASP group? ; Hi name, Thanks for reaching out! You and Larry name have been added to {{vasp5}} and {{vasp6}} groups on Anvil. Your membership will be ready within a few hours. Please check our user guide for VASP calculations on Anvil. https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/vasp: https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/vasp|smart-link Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ;",axu3@access-ci.org,Andy Xu,Nannan Shan,,Anvil,2,2,20,2025,2025-05-12
ATS-12369,vasp not running on compute nodes,2024-11-24,2025-05-20,"We are experiencing similar issues again with running our own compiled version of VASP. I have traced it down to the number of cores we run: `mpirun -n XX vasp\\_std` If I run with the full node (128 cpus), I get the following errors Assertion failed in file ../../src/mpid/ch4/src/intel/ch4\\_shm\\_coll.c at line 1477: node\\_info->numa\\_num <= ((MPIDI\\_SHMGR\\_SYNCPAGE\\_SIZE / MPIDI\\_SHMGR\\_FLAG\\_SPACE) - 1) Assertion failed in file ../../src/mpid/ch4/src/intel/ch4\\_shm\\_coll.c at line 1477: node\\_info->numa\\_num <= ((MPIDI\\_SHMGR\\_SYNCPAGE\\_SIZE / MPIDI\\_SHMGR\\_FLAG\\_SPACE) - 1) Assertion failed in file ../../src/mpid/ch4/src/intel/ch4\\_shm\\_coll.c at line 1477: node\\_info->numa\\_num <= ((MPIDI\\_SHMGR\\_SYNCPAGE\\_SIZE / MPIDI\\_SHMGR\\_FLAG\\_SPACE) - 1) /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(MPL\\_backtrace\\_show+0x34) 0x14ad3c232154] /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(MPIR\\_Assert\\_fail+0x21) 0x14ad3b839271 /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(+0x23c7db) 0x14ad3b96b7db /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(+0x2d41a4) 0x14ad3ba031a4 /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(MPI\\_Barrier+0x26e) 0x14ad3b846b8e /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/libmpifort.so.12(pmpi\\_barrier+0xc) 0x14ad3c81c73c /home/x-coses/bin/vasp\\_std() 0x419ef0 /home/x-coses/bin/vasp\\_std( Abort(1) on node 42: Internal error /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(MPL\\_backtrace\\_show+0x34) 0x14e73f460154 /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(MPIR\\_Assert\\_fail+0x21) 0x14e73ea67271 /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(+0x23c7db) 0x14e73eb997db /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(+0x2d41a4) 0x14e73ec311a4 /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(MPI\\_Barrier+0x26e) 0x14e73ea74b8e /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/libmpifort.so.12(pmpi\\_barrier+0xc) 0x14e73fa4a73c /home/x-coses/bin/vasp\\_std() 0x419ef0 /home/x-coses/bin/vasp\\_std( Abort(1) on node 76: Internal error /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(MPL\\_backtrace\\_show+0x34) 0x14e22fed2154 /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(MPIR\\_Assert\\_fail+0x21) 0x14e22f4d9271 /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(+0x23c7db) 0x14e22f60b7db /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(+0x2d41a4) 0x14e22f6a31a4 /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/release/libmpi.so.12(MPI\\_Barrier+0x26e) 0x14e22f4e6b8e /apps/anvil/external/apps/intel/cluster.2019.5/compilers\\_and\\_libraries\\_2019.5.281/linux/mpi/intel64/lib/libmpifort.so.12(pmpi\\_barrier+0xc) 0x14e2304bc73c /home/x-coses/bin/vasp\\_std() 0x419ef0 /home/x-coses/bin/vasp\\_std( Abort(1) on node 110: Internal error However, vasp does run with 2, 12, and 24 cpus, while still requesting the full node (128 cpus). This is independent of standard, shared, or wholenode queues. The same issues occur on all. These issues do NOT occur if I run the job interactively. 128 cpus is not a problem. ; Hi, Thank you for contacting us. Our VASP expert will take a look at this issue and get back to you soon. Please stay tuned. Best regards, name Senior Computational Scientist Purdue Information Technology ; Hello name, I hope this message finds you well. The error you are encountering is actually the fault of a bug in that version of impi. If you use another MPI library or even a more modern version of IMPI, you shouldn't experience that issue anymore. It tends to crop up above certain core counts as you discovered. We have the following versions on Anvil: impi/2019.5.281 impi/2019.9.304 impi/2021.12 Kind regards, name ; Hi name, Awesome name -- Dr. name Oses Assistant Professor Department of Materials Science and Engineering Johns Hopkins University entropy4energy.ai: https://entropy4energy.ai/ ; Hi name, I am just checking in to see if you've had a chance to try that suggestion out. Let me know the result name -- Dr. name Oses Assistant Professor Department of Materials Science and Engineering Johns Hopkins University entropy4energy.ai: https://entropy4energy.ai/ ; \\*\\*PRIVATE NOTE\\*\\* [~accountid:id, can we resolve this ticket? ; Hello name, I have a few updates for you regarding VASP on Anvil. I verified your license with the folks at VASP and added you to the appropriate groups on Anvil to access our systems installations through the module system. Because I have also not been able to replicate your workflow, I dropped the binary that I built against the Intel OneAPI toolchain in a directory at /home/x-coses/bin/rcac. You will need to change your submission script to load the following modules in order for libraries to resolved at runtime: module load intel/2024.1 module load impi/2021.12 module load intel-mkl/2020.4.304 Please let me know if the system installation of VASP works as well as what the result of running your workflow against this new executable is. Kind regards, name ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id:id-dbd6-4c49-8fbc-94be97295108 Not yet--there has been some correspondence via email and Teams meetings. I just updated the user here. ; Thanks name, I really appreciate it, just submitted the job with the new binary/modules. Let's see what happens once it tries running. Best regards, name -- Dr. name Oses Assistant Professor Department of Materials Science and Engineering Johns Hopkins University ; name it's working !! I am going to try a few more times to make sure everything is consistent. Can you tell me how exactly you compiled the binary? Very excited that we got this working !! name -- Dr. name Oses Assistant Professor Department of Materials Science and Engineering Johns Hopkins University ; Hello name, Great--I am really glad to hear that. Because I haven't heard anything since, can I assume everything has been behaving consistently? This binary was compiled using the installation of Intel OneAPI on Anvil without needing to change the Makefile that you already defined for Anvil. The relevant modules are ""intel/2024.1, impi/2021.12, intel-mkl/2020.4.304"". Sometimes when transitioning from Intel's classic compilers/libraries to the OneAPI toolchain, you will have to change some Fortran syntax, but that was not the case here. Kind regards, name ;",coses@access-ci.org,Corey Oses,rderue,Purdue University,Anvil,21,127,47,2024,2024-11-18
ATS-13030,Assistance with Job Submission on RCAC Anvil Cluster for CP2K and ORCA ,2025-01-06,2025-05-20,"Hello, I hope this email finds you well. I am new to using the RCAC Anvil cluster and would like guidance on submitting jobs for CP2K and ORCA. Specifically, I need to know how to properly configure my job submission scripts for both CPU and GPU usage, as I may require both resources depending on the type of simulation. Could you please provide any example {{sbatch}} files or templates that might help me set up my job submissions for these applications? Additionally, if there are any specific modules or configurations I need to be aware of for optimal performance with CP2K and ORCA on the Anvil cluster, I would greatly appreciate your insights. Thank you for your support. I look forward to your guidance. Best regards, name ; Hi name, Thanks for reaching out/bin/sh #SBATCH --job-name=cp2k #SBATCH --account=your\\_allocation\\_account #SBATCH --partition=shared #SBATCH --nodes=1 #SBATCH --ntasks=64 #SBATCH --time=00:30:00 #SBATCH --output=cp2k.o%j.%N module --force purge module load gcc/11.2.0 openmpi/4.0.6 module load cp2k/8.2 module list mpirun -np $SLURM\\_NTASKS cp2k.psmp ... At this moment, we do not have GPU version of CP2K on Anvil, please expect it in the next few weeks. I think users on Anvil are using their own downloaded ORCA because it does not require a 'real' installation. If you need help to construct a submit script, let me know. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Hello, Thank you very much for your reply. I will be happy to know if GPU version of CP2K comes. Best, name ---- \\*Gönderen:\\* name \\*Gönderildi:\\* 7 Ocak 2025 Salı 23:06 \\*Kime:\\* name \\*Konu:\\* ATS-13030 Assistance with Job Submission on RCAC Anvil Cluster for CP2K and ORCA |---- \\*External Email\\*: Use caution with attachments, links, or sharing data ---- | ; Hi name, Want to share that NGC container, GPU CP2K/2023.1 is available on Anvil now. Please add the following commands to your submit script to use it (please change the number of mpi process accordingly). module --force purge module load modtree/gpu module purge module load ngc module load cp2k/2023.1 module list mpirun -n 4 cp2k.psmp -i xxx.inp Regards, name ;",,Hasan Tuncer,Nannan Shan,Purdue University,Anvil,4,97,2,2025,2025-01-06
ATS-14762,AnvilGPT Access Request,2025-03-11,2025-05-21,"Getting - Your account status is currently pending. For approval, please reach out to the ACCESS help desk (https://support.access-ci.org/open-a-ticket): https://support.access-ci.org/open-a-ticket with the subject/summary line ""AnvilGPT Access Request"". Select ""Some Other Question"" as the user support issue and ""Anvil"" as the resource. ; Hi name, Could you please share the access allocation number? Also, could you clarify the purpose of your request and how you intend to use it for ANVILGPT? Thanks! ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id] , this user also didn't get back to us, can we resolve this one as well? ; \\*\\*PRIVATE NOTE\\*\\* Sure. ; Hello name, I apologize for not getting back to you earlier, I was out of the country. I work for Research Engagement group at Internet2 (Dana Bruson). We interact and engage with the academic research community and also the CaRCC (Campus Research Computing Consortium - https://carcc.org/: https://carcc.org/) and the NAIRR (National AI Research Resource) pilot. I am part of the AI materials working group. We are developing a resource clearing house (among other things) to help facilitators get the resources need to support their researchers. I am currently exploring resources available in the community and would like to see what services Anvil offers (e.g api, pre- training, GPT, …, etc.). Are you the right person answer some of these questions? Best regards, -name ; Hi name, Thanks for reaching out. Yes, I would be the correct person to answer your questions regarding Anvil's services, including API access, pre-training, and GPT capabilities. Feel free to send over your questions or let me know if you'd like to set up a time to chat. ; Hello name, I would like to get access to Anvil to explore what you all have available. I am working on a NAIRR allocation on Vocareum to build classroom material with Jupiter notebooks. I am also working on building a RAG for RCD (Research, Computing, and Data) professionals through CaRCC (Campus Research Computing Consortium). How can I get an account? -name ; \\*\\*PRIVATE NOTE\\*\\* ~accountid:id:id-dbd6-4c49-8fbc-94be97295108 Can you please look at it? Thank you. ; Hi name, Thank you for reaching out. Since the ticket was closed, I didn't notice the notification earlier. To get an Anvil ACCESS Explore allocation, you'll need to visit the ACCESS website and submit a short proposal to ACCESS. Once it's reviewed and approved, you'll receive credits, which you can then transfer to Anvil SUs. You can find more information about the different types of allocations here: [https://allocations.access-ci.org/project-types: https://allocations.access-ci.org/project-types|smart-link Also, regarding the NAIRR allocation — is your NAIRR project associated with Purdue Anvil? If so, could you please share your NAIRR project number? Best, name, PhD (she/her) Senior Computational Scientist RCAC - Purdue University ;",jhicks,John Hicks,Haniye Kashgarani,Purdue University,Anvil,9,52,11,2025,2025-03-10
ATS-15936,Gromacs software upgrade 2024 or higher on PURDUE Anvil HPC. ,2025-04-18,2025-05-23,"Hello, I will be a new user on ANVIL soon, I will be working on a computational platform for rapid DNA Aptamer-Biomarker binding predictions. For these predictions, I will run molecular dynamic simulations through GROMACS. To run these simulations, I would really appreciate if a newer version of Gromacs 2024 or higher to run a specific type of simulation where I could reduce the large number of degrees of freedom of a physical system into few parameters whose statistical distributions can be analyzed individually - this package is known as COLVARS - only available on Gromacs 2024 or higher. Thus, I wanted to see if a newer updated version of Gromacs could be implemented into ANVIL? To my knowledge, the 2025.1 version of Gromacs would need 3.28 CMAKE and 12.8 CUDA toolkit versions to download. I already have a protocol built for my system on Gromacs 2023 - just would need to apply this package which would allow for more thorough and in-depth analysis of the binding energies for my current system. Please let me know if you have any questions, and I'd be happy to help accelerate this process in any way! Josh ; Hi name, Thanks for reaching out! I am wondering if you are requesting CPU version of Gromacs or GPU version? Sounds like you'd like to have GPU version of Gromacs. Our GPU versions of Gromacs come within NGC containers on Anvil, while for CPU versions, we have Gromacs/2024.1 module available on Anvil. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Thank you for letting me know, name! So then I assume the NGC containers would be the most recent gpu version 2025.1 has the colvars module set up? As well do you know if it is configured with OpenMPI processes? Thank you for your help and time, I just want to ensure for my simulations more specifically they can run with the colvars package as this is necessary. Best, Josh ; Hi Josh, Thanks for your patience on this. I checked the NGC container website, the most updated version of GPU Gromacs is 2023.2. So if you need 2025.1 or other versions, the only way is to install it from the source. If you need to other packages like cmake or cuda with higher version. I also recommend to install them into your own project space first, then install Gromacs 2025. Regards, name ;",jchajulloa@access-ci.org,Joshua Chaj Ulloa,Nannan Shan,Purdue University,Anvil,4,26,16,2025,2025-04-14
ATS-16070,Installing ORCA on ANVIL,2025-04-24,2025-06-04,"Hello, I'm running a dihedral scan using ORCA 5.0.1 on a protein-ligand system with MP2 and a 6-31G(d) basis set. The job is crashing with the following error: ORCA finished by error termination in GTOInt Calling Command: mpirun -np 16 /anvil/projects/x-mch240042/orca/orca501/orca\\_gtoint\\_mpi raloxifene\\_dihedral\\_scan\\_penalty1ver3.int.tmp raloxifene\\_dihedral\\_scan\\_penalty1ver3 file orca\\_tools/qcmsg.cpp, line 458]: .... aborting the run The input is fine, because I got it to work on another linux computer in my graduate office. I've tried loading different versions of mpi. It might be a storage, memory or an ORCA compiler issue. I am unsure. Since the system is large I plan to add more than 16 cores in the future. Any suggestions? Thank you ; ^input\\_file.inp ; Hi name, Thanks for reaching out and joining Anvil support hour. I will spend sometime on this issue and I will keep you updated on Tuesday as I am out of office on Monday. Thanks for your patience. Best, name, PhD (she/her) Senior Computational Scientist RCAC - Purdue University ; Hi name, I checked the installation of ORCA 6.0.1, which is compatible with OpenMPI 4.1.6 according to the information on ORCA's website: https://orcaforum.kofo.mpg.name/app.php/dlext/?view=detail&df\\_id=237: https://orcaforum.kofo.mpg.name/app.php/dlext/?view=detail&df\\_id=237|smart-link We have the OpenMPI module available on Anvil. I tried installing it and running your input file, but I'm still getting the same error. I believe there might be an issue with the input file. Are you sure the headers in this input file are the same as the ones you used on the other Linux machine? I will be trying different ways as well and keep you updated. Best, name, PhD (she/her) Senior Computational Scientist RCAC - Purdue University ; Hi name, So, I finally managed to get it working. For some reason, ORCA doesn't work with the centrally installed OpenMPI module, so you need to install your own version of OpenMPI to make it work. I will outline the steps for installing OpenMPI v4.1.6 and ORCA 6.0.1, which are compatible with each other. For other versions, you'll need to check which version of OpenMPI is required by the corresponding ORCA release (available on ORCA's website). Installing OpenMPI 4.1.6: sinteractive -N1 -n16 -t 2:00:00 -A mch240042 cd /anvil/projects/x-mch240042/ mkdir -p software/src && cd software/src wget https://download.open-mpi.org/release/open-mpi/v4.1/openmpi-4.1.6.tar.gz tar -xzvf ./openmpi-4.1.6.tar.gz cd openmpi-4.1.6/ ./configure --prefix=/anvil/projects/x-mch240042/software/openmpi-4.1.6 --enable-mpi-fortran CC=gcc CXX=g++ FC=gfortran make -j 16 # or however many cores you want to use for installation make install Now that OpenMPI is installed you will need to install you ORCA 6.0.1. First download from https://orcaforum.kofo.mpg.name/app.php/dlext/?view=detail&df\\_id=235: https://orcaforum.kofo.mpg.name/app.php/dlext/?view=detail&df\\_id=235|smart-link Then move it to Anvil: scp /path/to/download/orca\\_6\\_0\\_1\\_linux\\_x86-64\\_shared\\_openmpi416.run :/anvil/projects/x-mch240042/software Then login to Anvil and install ORCA 6.0.1: ssh cd /anvil/projects/x-mch240042/software chmod +x ./orca\\_6\\_0\\_1\\_linux\\_x86-64\\_shared\\_openmpi416.run ./orca\\_6\\_0\\_1\\_linux\\_x86-64\\_shared\\_openmpi416.run ORCA 6.0.1 will be installed and now your job script should be like: # I attached a configuration log file. After following the steps I tried to module load openmpi-4.1.1 but it shows up like this. . Later today, I will just download ORCA\\_6\\_0\\_1 and work on installing that instead. [^config.log \\_(6.61 MB)\\_ ; Thanks for the update. Let me know how it goes. Best, name, PhD (she/her) Senior Computational Scientist RCAC - Purdue University ; name, You are amazing You can close the ticket. Thank you again, name ; Awesome! Thanks for letting me know! Best, name, PhD (she/her) Senior Computational Scientist RCAC - Purdue University ;",cugboh@access-ci.org,Chizaram Ugboh,Haniye Kashgarani,Purdue University,Anvil,13,30,17,2025,2025-04-21
ATS-16253,Request for Assistance Installing OVITO on Windows 11 Interactive Desktop (OnDemand),2025-05-01,2025-05-19,"Dear Anvil Support Team, I hope this message finds you well. I am writing to request assistance with installing the atomic structure visualization and analysis software OVITO on the Windows 11 Software Desktop available through the interactive OnDemand sessions on the Purdue Anvil supercomputer. OVITO is essential for the post-processing and visualization of our large-scale atomic simulation results. A colleague in my research group previously attempted to install OVITO on this platform. While the installation initially succeeded, the software was closed shortly after launch. This raised concerns about whether there are specific restrictions for installing third-party software in the interactive desktop environment. Given the importance of OVITO to our research, we would like to know: # What is the correct procedure for installing OVITO on Windows? # Is it possible for the Anvil support team to install OVITO system-wide or make it available in a more permanent and supported way? We would greatly appreciate your guidance or assistance in resolving this issue. Thank you very much for your support. Best regards, name ; Hi name, Thanks for reaching out and sorry for the delay. Are you trying to use OVITO with Windows virtual machine on Anvil? I saw OVITO has linux version and it can be installed directly on Anvil, specifically on your own project space. This is the first time I see OVITO request, so I would recommend to you to install it on your own project space, according to our software request policy. Please let me know if you have encounter any issues. https://www.rcac.purdue.edu/knowledge/anvil/policies/software\\_installation\\_request\\_policy: https://www.rcac.purdue.edu/knowledge/anvil/policies/software\\_installation\\_request\\_policy|smart-link Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Hi name, Thank you for your reply. Yes, I tried to use OVITO with the Windows virtual machine on Anvil but it didn't work. As you mentioned, this software can be installed on a desktop computer with Linux operating system. But I noticed on its official website that: \\* \\*OVITO desktop application cannot function via SSH connections using X11 forwarding, as it requires direct access to graphics hardware (OpenGL direct rendering mode)\\* +https://www.ovito.org/manual/installation.html: https://www.ovito.org/manual/installation.html +. Therefore, I may not be able to directly install the OVITO on my own project space without handling the graphics dependency of this software properly. And due to the large snapshots I have for my project (up to 50 GB per time frame), it's really impossible to run the crystal analysis on any of the desktops available to me. Do you know of any alternative approaches for performing OVITO's crystal analysis within the Anvil environment? Thank you for your time and help! Best, name ; Hi name, We had installed OVITO centrally on Anvil. To use it, you can use the following commands, module --force purge module load ovito ovito For X11 forwarding issue, you can download ThinLinc: https://www.rcac.purdue.edu/knowledge/anvil/access/login/thinlinc to your computer and login Anvil use it. It comes with X11 and you could open Ovito interface from a terminal. Another thing I would recommend is, you might want to start an interactive job when you use Ovito instead of using it on the login nodes. Hope this helps, name ;",yuan95,Yuan Xu,Nannan Shan,,Anvil,4,13,18,2025,2025-04-28
ATS-16311,Request to Increase Storage for /project/ Directory,2025-05-03,2025-05-21,"To Whom It May Concern, I am hoping to increase the file storage under the project 520052 from 5TB to 10TB. I discussed this with name during the call, and I have since checked that the storage required was miscalculated on my part. The project requires the Waymo Dataset and the nuScenes dataset, which are ~4TB and ~0.5TB, respectively. The relevant links are as follows: \\* Waymo Dataset: https://waymo.com/open/: https://waymo.com/open/|smart-link \\* NuScenes Dataset: https://www.nuscenes.org/: https://www.nuscenes.org/ I am hoping to increase the storage for project directory: {{/anvil/projects/ai250052/}} The increased storage would be to fit both the datasets themselves, as well as the relevant checkpoints (which we estimate to be ~1TB) and processed files (which we estimate to be ~2TB). Many thanks ; Hi Katie, Just want to give you an update that I have added the other two members to your project on Anvil. I will increase the scratch quota of file number to 10M for {{x-kluo5}}, {{x-jyoo5}}, {{x-zhuang4}}, {{x-zfeng4}}, and {{x-zliu33}} until 4/8/2026. One thing i want to confirm from you is, as you might remember your project name is not showing correctly right now, and in order to change it, I want to schedule a time with you, during the time, please do not transfer or work with files in your project, then I can make the changes. So, Please let me know which time slot next week I can use to make changes to your project. I need at least 48 hours in the workdays to make changes. Thank you ; Hi Katie, Tuesday and Wednesday works for me. Will start work on it tomorrow. Thank you Regards, Katie ; Hi Katie, Thanks for letting me know. As long as your group feel comfortable with our system, the onboarding meeting is not necessary. I just want to make sure everything is good here. As always, please send us a NAIRR ticket ([https://nairrpilot.org/open-support-request: https://nairrpilot.org/open-support-request) whenever you have questions regarding to your simulations on Anvil. This ticket system is used for only ACCESS Anvil users. Good luck to your research on Anvil! Regards, name ;",kluo5@access-ci.org,Katie Luo,Nannan Shan,,Anvil,13,13,18,2025,2025-04-28
ATS-16323,not able to connect to $PROJECT,2025-05-03,2025-05-19,"I am not able to access the $PROJECT directory (their equivalent of Ocean). When I try to do this I get: :\~] $ cd $PROJECT bash: cd: /anvil/projects/x-cis230106: Permission denied My PI (Marijn Heule, [: mailto:) is not sure how to give me access to $PROJECT. Could you let us know how to do this. This is somewhat urgent as I have a paper deadline this Friday for which I need to run experiments for. ; Amar, There was an issue in the backend system that was preventing you from accessing the project directory. This should be resolved now. Let me know if you still encounter difficulties in accessing the directory. Thanks, name ; \\*\\*PRIVATE NOTE\\*\\* Amar, Since it's been a while that I've heard from you, I am tentatively marking this ticket as resolved. If you are still facing problems with accessing the $PROJECT directory, please respond to this ticket within 7 days to reopen it. Otherwise, you can always submit a new ticket. Thanks, name ;",ashah12@access-ci.org,Amar Shah,Michael Carlson,Purdue University,Anvil,3,11,18,2025,2025-04-28
ATS-16420,Request to Install OVITO on Anvil Windows 10 Desktop,2025-05-07,2025-05-21,"Dear Anvil Administrator, I hope you're doing well. I am a postdoctoral researcher using the Anvil cluster to run large-scale MD simulations for laser-materials interactions. My simulation—modeling laser melting and resolidification of copper—contains over 200 million atoms. Analyzing and visualizing such a large snapshot on my local machine with OVITO is extremely slow (hours per snapshot) due to limited CPU power. I saw that Anvil supports a Windows 10 desktop on a CPU node, which would greatly accelerate my structure-analysis workflow. However, I've been unable to install OVITO successfully. When I launch the installer under the OnDemand Windows 10 environment, the application closes immediately. Could you please help to install (or enable) OVITO on the Anvil Windows 10 desktop? For reference, the software is available here: https://www.ovito.org/: https://www.ovito.org/|smart-link. Thank you very much for your assistance. Best regards, Chaobo ; Hi, We could help you with your installation. When you launch the installer under the OnDemand Windows 10 environment, what is the setting you use? such as cores, memories and partitions? Best, name ; Hi name, Thank you, it will help me a lot. The following is the setting I am using. Allocation: dmr110090 Queue (partition): wholenode Wall Time in Hours: 1 Cores: 128 Thank you again for the help. Best regards, Chaobo ---- ; you're welcome. BTW, do you still have the session id that your windows11 failed to install that software last time? Best, name ; Hi name, Sorry, I cannot find my record. It probably is because I use ""delete"" to kill the job... I can try to do it again. Do you need me to do it again? Thank you, Chaobo ---- ; Hi name, I tried to reinstall it again. The session ID is cc00f661-4489-4397-92be-1f14d230c462. OVITO is installed, but it is closed when I open. Best, Chaobo ---- ; It would be great if you could do it again and keep the session, so that I could trouble-shoot to see what error made it crash. Thanks, name ; Hi name, Sorry for the late reply, I was distracted by a task. I created a session with an ID: c8143826-4baf-4eb5-a439-9343e1cf282a: https://ondemand.anvil.rcac.purdue.edu/pun/name/dashboard/files/fs/home/x-chaobo/ondemand/data/name/dashboard/batch\\_connect/name/win11-pro/output/c8143826-4baf-4eb5-a439-9343e1cf282a. I opened the folders for the OVITO installation package and the folder containing the OVITO software. Please feel free to log in to this desktop and let me know if I need to do anything else. Thank you, Chaobo ---- ; Hi Chaobo, I detect the log that doesn't include any error that seems to crash the system. The job(10935083) of the session you shared yesterday seems to time out after two hours. I was wondering why that but not crash? Were you able to install the software with that job? Best, name ; \\*\\*PRIVATE NOTE\\*\\* \\*:\~]\\* $ sacct -X -u x-chaobo -S 2025-05-07 JobID JobName Partition Account AllocCPUS State ExitCode ; -------- 10919373 OnDemand/+ shared dmr110090 2 TIMEOUT 0:0 10926466 OnDemand/+ shared dmr110090 3 CANCELLED+ 0:0 10933893 mesh wholenode dmr110090 128 COMPLETED 0:0 10933894 mesh wholenode dmr110090 128 CANCELLED+ 0:0 10933896 mesh wholenode dmr110090 128 COMPLETED 0:0 10934140 OnDemand/+ wholenode dmr110090 128 COMPLETED 0:0 10935083 OnDemand/+ wholenode dmr110090 128 TIMEOUT 0:0 10949640 OnDemand/+ shared dmr110090 2 CANCELLED+ 0:0 10955373 OnDemand/+ shared dmr110090 4 RUNNING 0:0 \\*:\~\\* $ jobinfo 10935083 Name : OnDemand/Desktop User : x-chaobo Account : dmr110090 Partition : wholenode Nodes : a733 Cores : 128 GPUs : 0 State : TIMEOUT,CANCELLED ExitCode : 0:0 Submit : 2025-05-07T15:52:44 Start : 2025-05-07T15:59:20 End : 2025-05-07T18:00:19 Waited : 00:06:36 Reserved walltime : 02:00:00 Used walltime : 02:00:59 Used CPU time : 00:00:00 % User (Computation): 0.00% % System (I/O) : 41.82% Mem reserved : 245400M Max Mem used : 264.95M (a733) Max Disk Write : 19.95M (a733) Max Disk Read : 136.49M (a733) ; Hi name, I installed OVITO during that job. The Windows system itself doesn't crash, but the OVITO application closes less than a second after I click to open it. I suspect the issue might be related to the computer's antivirus system, though I'm not sure how to add OVITO to the whitelist. Best regards, Chaobo ---- ; Hi Chaobo, I think I found the reason. Below is the explanation: =========================================================== OVITO is a visualization software that heavily relies on \\*hardware-accelerated 3D graphics rendering\\*, which is typically performed by a \\*GPU (Graphics Processing Unit)\\*. Here's why running OVITO in a CPU-only environment (like a Slurm job on a supercomputer without GPU resources) will almost certainly lead to the application closing immediately: \\* \\*OpenGL Dependency:\\* As mentioned before, OVITO needs OpenGL to render its visualizations. OpenGL is designed to work efficiently with GPUs, offloading complex rendering tasks from the CPU. \\* \\*Lack of Hardware Acceleration:\\* Without a GPU, the virtual machine will be forced to rely on software rendering for OpenGL. Software rendering uses the CPU to perform graphics calculations, which is extremely inefficient and often doesn't fully implement the necessary OpenGL features. \\* \\*Performance Bottleneck:\\* Even if software rendering were to somehow initialize, it would be incredibly slow and likely cause the application to become unresponsive and crash quickly due to the immense computational load on the CPU. \\* \\*Missing Libraries:\\* The virtual machine environment, without GPU drivers and associated libraries, might simply be missing the necessary software components for OVITO to even start its rendering pipeline =========================================================== I was wondering if OVITO could be directly installed on a linux system, instead of Windows? If so we may try that. Best, name ; Hi name, Thank you for the detailed explanation — that makes a lot of sense regarding the issues with running OVITO. It would be great if OVITO could be installed on Anvil. Please go ahead — it would really help us with analyzing our simulation results. Let me know if you need anything from my side. I'd be happy to test the installation and provide some input files. Thanks again, Chaobo ---- ; Okay, I will discuss with the team about the installation in the meeting next Wednesday. Will keep you updated. Thanks for your patience. Best, name ; Is the one you installed OVITO Basic or Pro? name ; I installed the basic one. -Chaobo ---- ; Hi Chaobo, We installed Ovito for you on Anvil. To use it, you use ThinLinc Desktop ([https://www.rcac.purdue.edu/knowledge/anvil/access/login/thinlinc: https://www.rcac.purdue.edu/knowledge/anvil/access/login/thinlinc|smart-link ) and open a terminal there, type as the picture show. Let us know if you need more help. Best, name ; Hi name, Thank you a lot Chaobo ---- ; Hi Chaobo, You're welcome. That is actually a good point for you to test. Feel free to submit a request from here (you could be the PI for the Explore ACCESS): https://allocations.access-ci.org/prepare-requests: https://allocations.access-ci.org/prepare-requests|smart-link Let us know if you need more help. Best, name ;",chaobo@access-ci.org,Chaobo Chen,Xiao Liu,,Anvil,19,11,19,2025,2025-05-05
ATS-16481,Issue with storage space.,2025-05-09,2025-06-05,"I cannot see any output from ""myquota"" command. When I am transferring the data, it gives me an error storage allocation issue. My data will expire on 12th May (1 month). My account and storage location are: \\*x-kchand1\\* and /anvil/projects/x-ees240013/krishan , respectively. ; Hello, I hope you are doing well. Thank you for reaching out to RC Support with your question! We are actively working on addressing the issue. Rest assured, we will provide you with a response as soon as possible. Best regards, name RCAC Support ; Hi, We did not find anything wrong with your account. Could you be more specific about the error and the steps you used so we can take a further look? Please also feel free to join our Anvil Support Hour (https://www.rcac.purdue.edu/anvil/anvil-support-hour#:~:text=Anvil%20Support%20Hour%20happens%20at,Account%20and%20allocation%20on%20Anvil: https://www.rcac.purdue.edu/anvil/anvil-support-hour#:~:text=Anvil%20Support%20Hour%20happens%20at,Account%20and%20allocation%20on%20Anvil|smart-link ) so our staff can help you there interactively. Best regards, name Senior Computational Scientist Purdue Information Technology ;",kchand1@access-ci.org,Krishan Chand,Guangzhen Jin,,Anvil,3,20,19,2025,2025-05-05
ATS-16496,Users having very long wait times for jobs on ANVIL since our allocation was extended,2025-05-09,2025-05-27,"Hi, we had our ACCESS allocation extended, and ever since, the users I support in the Trayanova lab have had very long wait times to run jobs. I looked over some of their jobs, and as far as I could tell on my end, everything looked normal regarding SLURM status. Is there perhaps some kind of name-prioritization happening on these jobs because they are on an extended allocation? Thanks, --name, Thank you for contacting RCAC for support. Recently, we did change how Anvil prioritizes jobs. Before, we were basing priority solely on fairshare and job age. Now, we take into account job size and deprioritize fairshare. When you say 'long wait times', how long are you experiencing? I don't think that the renewed allocation would change how long your jobs will wait. In addition, I do know that Anvil is being heavily used, so wait times are generally longer than they have been in the past. Thanks, name, Since I haven't heard from you in a while, I'm marking this ticket as resolved. If you are still experiencing problems with your jobs not starting, please respond to this ticket within 7 days to reopen it. Otherwise, you can always open a new ticket. Thanks, name ;",btice1@access-ci.org,Brock Tice,Michael Carlson,,Anvil,3,13,19,2025,2025-05-05
ATS-16521,Queue wait time,2025-05-12,2025-05-19,"Hello, I submitted the GPU parallelized simulation job last Friday, where the job id is 10959166 with an account of chm250010-gpu and a name of v.45\\_p2\\_3 on a sinlge node and a single CPUS. But it is still waiting in the queue. Could you please check if my job has been stuck or it is just a common thing? Thanks and I look forward to hearing back. ; Hi, Thank you for reaching out to RCAC Support! We're working on your request and will get back to you as soon as we are able. We appreciate your patience. Please allow up to a couple of business days for a response. Best regards, name Purdue IT https://service.purdue.edu: https://service.purdue.edu ; Hi, Thanks for your patience. Looking into job 10959166, it seems that it was canceled. Was it canceled by you, or did it cancel due to an error? If so, please let me know what error, and I can escalate further. Please let me know if you have any other questions. Best regards, name Purdue IT https://service.purdue.edu/: https://service.purdue.edu/|smart-link ; Hi, Since we haven't heard feedback from you for some time, issues seem to have been solved. I will temporarily mark this ticket as resolved. Feel free to re-open it within the next 7 days if you still need assistance on this issue. Best Regards, name Purdue IT https://service.purdue.edu: https://service.purdue.edu|smart-link ;",jjeong6@access-ci.org,,Ansh Gangapurkar,,Anvil,4,6,20,2025,2025-05-12
ATS-16539,Request access to VASP,2025-05-13,2025-05-19,"I wanted to use VASP in the Anvil server but I couldn't. We have a local subscription to VASP. Earlier we generally run VASP in our local server. Due to some bug in our server, it's now under maintenance. Please help me how to get access to VASP. What do I have to provide for it? Let me know. ; Hello! Thanks for reaching out! Due to the license restriction, users on Anvil who want to use VASP need to bring their own VASP license for us to validate. We need each user's email associated with an active VASP license to check their license status. Thus please share your own email address with us. After we validate your license, we would add you to the central vasp groups on Anvil. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Let's say my professor has a VASP license associated with an Email. Can he use this licence to link with his multiple student's Anvil account to Anvil's central VASP? ; Let's say my professor has a VASP license associated with an Email. Can he use this licence to link with his multiple student's Anvil account to Anvil's central VASP? ;",,Bappy,Nannan Shan,,Anvil,4,5,20,2025,2025-05-12
ATS-16643,CPU Allocation and SU Accounting,2025-05-19,2025-06-04,"Hello, I'm experiencing a discrepancy between my requested resources and what was allocated/charged for a job on the shared partition. I hope you can help clarify this situation. Below are my \\*Job File Directives\\*: #SBATCH -J placeholder #SBATCH -o batch.o%j #SBATCH -e batch.e%j #SBATCH -p shared #SBATCH -N 1 #SBATCH -n 16 #SBATCH -t 95:00:00 #SBATCH --mem-per-cpu=2G \\*Issue:\\* # Despite requesting 16 cores in the job file, the job was allocated 32 cores (as shown in the attached image). # The job completion report shows I was charged 1035.31 SUs, which aligns with a 16-core calculation (16 × 64.71 = 1,035.36 SUs). # However, my account's name Usage shows 2121 SUs used, which is closer to what would be charged for 32 cores (32 × 64.71 = 2070.72 SUs). Could you please explain why the job allocated double the requested cores and clarify which name charge is correct? Thank you for your assistance. Regards, Sultan ; Hi Sultan, Thanks for reaching out, we shall get back to you soon in regards to this question. Best Regards, Eli name Purdue RCAC Support https://service.purdue.edu ; Sounds good Sultan ; \\*\\*PRIVATE NOTE\\*\\* Issue resolved on TDX. User redirected to Jira for future Anvil tickets. ;",salhassanieh@access-ci.org,Sultan Al Hassanieh,Elian Inigo Rieza,,Anvil,7,13,21,2025,2025-05-19
ATS-16770,"Jobs pending on shared partition with error ""QOSMaxCpuPerUserLimit""",2025-05-25,2025-05-28,"I submitted 12 jobs on the shared partition, each with num\\_nodes=1, num\\_tasks=128, cpu\\_per\\_task=1. However, only 10 of these are running, and the others are pending waiting for resource allocation due to ""\\*QOSMaxCpuPerUserLimit"".\\* I experienced this issue few days ago as well. I was able to run several jobs simultaneously (even ~30 jobs) each with 1 node and 128 tasks (1 CPU/task) on the shared partition before, but have been encountering this issue recently. Any help is greatly appreciated ; name, Thank you for contacting RCAC for support. Recently (April 10th), we reduced the number of CPUs one user can occupy in the shared partition (from 6000 cores to 1280 cores) to reduce congestion in that portion of Anvil. You have hit that limit and are being denied more resources until one of your jobs finishes and frees up the cores for a different job. Since it seems as though you are using the entire node for each job, I would recommend moving your jobs to the 'wholenode' partition of Anvil, since that has more nodes available to it (750 vs 250). Let me know if you have any additional questions. Thanks, name ; Hello name, Thanks for the information, now I understand the problem. Is the 1280 cores/user limit applicable to the 'wholenode' partition as well? If not, what is the limit there? Thanks - name, I am marking this ticket as resolved, but if you do run into problems with submitting your jobs, please respond to this ticket within 7 days to reopen it. Otherwise, you can always submit a new ticket. Thanks, name ;",kkethamukkala@access-ci.org,Kaushik Kethamukkala,Michael Carlson,,Anvil,7,3,21,2025,2025-05-19
ATS-16781,installation of VASP for MAT230049,2025-05-26,2025-06-04,"Hi, I had purchased VASP from Materials Design, and have been using it on my university cluster for the past 5 years. Our servers have been down for some maintenance, and I have pending projects, so would like to execute VASP in our project space here on ACCESS. Here are the VASP login details. Kindly let me know if anything else is needed. Kindly let me know once you have installed VASP so that we can start using it. Thanks! You can now download the current VASP6 source code from http://my.materialsdesign.com/download/vasp6.2: http://my.materialsdesign.com/download/vasp6.2 username: Saquib.name (or) : mailto: password: HIDE ; Greetings, Hope your day is going well so far! To make sure we can get your projects up and running, can you confirm what resource you're on? You can double check the list of resources here: https://allocations.access-ci.org/resources: https://allocations.access-ci.org/resources|smart-link Best, Cassian McClenny ACCESS Support ; Yes! It's Purdue ANVIL .. ---- ; Hi! It is Purdue ANVIL ; Hi, just wanted to ping and see if there's any status update? Thanks! ; Hi Saquib, Thanks for reaching out! Please check our user guide about building your own VASP on Anvil. [https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/vasp/build\\_your\\_own\\_vasp\\_6: https://www.rcac.purdue.edu/knowledge/anvil/software/installing\\_applications/vasp/build\\_your\\_own\\_vasp\\_6|smart-link In addition, I've hidden your username and password you shared on your original message, because this is a shared ticket system and we do not want to put these information here. Let me know if you have further questions. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ;",saquibahmed@access-ci.org,Saquib Ahmed,Nannan Shan,Purdue University,Anvil,6,8,22,2025,2025-05-26
ATS-16916,VASP 6 and Gaussian 16 for Anvil,2025-05-30,2025-06-04,"I would like to receive VASP 6 Access for the Purdue Anvil system. I am an authorized user. License number: 20-0409 Is there any other information needed? Also, is it possible to access Gaussian 16 in the Anvil system? From the documentation I have found, it appears to only be available on other Purdue HPC systems. My university (North name State University) has a site license for Gaussian 16. ; Hello, I hope you are doing well. Thank you for reaching out to RC Support with your question! We are actively working on addressing the issue. Rest assured, we will provide you with a response as soon as possible. Best regards, name RCAC Support ; Hi, name: Here is some additional information that may be helpful for receiving my sign up. Email of VASP user: : mailto: For Gaussian 16, address for site license: 1805 NDSU Research name Drive N Fargo, ND 58102 Institution: North name State University ; Hi Hadassah, Thanks for reaching out! You ({{x-hgriffin}}) have been added to {{vasp5}} and {{vasp6}} groups on Anvil. Your membership will be ready within a few hours. Please check our user guide for VASP calculations on Anvil. https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/vasp: https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/vasp|smart-link There is no Gaussian on Anvil as Anvil is for national wide institutions. Purdue got site license as well, that's why Purdue community clusters have Gaussian, but not Anvil. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ;",hgriffin@access-ci.org,Hadassah Griffin,Nannan Shan,,Anvil,4,4,22,2025,2025-05-26
ATS-11527,AnvilGPT API: document uploads,2024-10-19,2025-06-19,"Hi, I am trying to send a query along with text file to AnvilGPT via API. Is there a particular endpoint at that I should be using for this? Currently, I'm testing via a bash script but ultimately I have this implemented in python. I can send my python script if that's helpful but just pasting my bash attempt below for simplicity. It seems like the /generate endpoint might only be looking for particular file formats? (drylands-rag-py3.10) drylands-rag]$ cat tests/test\\_anvil.sh curl -X POST https://anvilgpt.rcac.purdue.edu/ollama/api/generate: https://anvilgpt.rcac.purdue.edu/ollama/api/generate \ -H ""Authorization: Bearer $ANVILGPT\\_JWT\\_TOKEN"" \ -F ""query=Test query"" \ -F ""file=@tests/test.txt"" (drylands-rag-py3.10) drylands-rag$ bash tests/test\\_anvil.sh {""detail"":{""type"":""model\\_attributes\\_type"",""loc"":[""body"",""msg"":""Input should be a valid dictionary or object to extract name from"",""input"":""; cd66e99aa750809e\rContent-Disposition: form-data; name=\""query\""\r\rTest query\r; cd66e99aa750809e\rContent-Disposition: form-data; name=\""file\""; filename=\""test.txt\""\rContent-Type: text/plain\r\r\r; cd66e99aa750809e--\r""}} Thank you in advance -Mitch ;",mhorn108@access-ci.org,Mitchell Horn,Ashish Malik,Purdue University,Anvil,2,174,42,2024,2024-10-14
ATS-15674,FFmpeg on Purdue Anvil,2025-04-09,2025-06-13,"Hi, Is it possible to use FFmpeg on Purdue Anvil? It seems I need sudo privileges to install the software. ; Dear name, Apologies for the late response. We do have this application on Anvil cluster, where module spider ffmpeg shows that we have this version available: ffmpeg/4.2.2 you can load the module directly using the module load I'll be marking this ticket as resolved but feel free to respond back if you think the response provided not fully addressing your inquiry. Best, name Anvil support team ;",mabdullah,Muhammad Abdullah,Ibrahem Alshybani,,Anvil,2,48,15,2025,2025-04-07
ATS-16653,Access to Anvil-PURDUE,2025-05-19,2025-06-10,"I recently enrolled in ACCESS to use computational resources, but I will need help accessing specific resources. For example, I would like to use ANVIL from PURDUE, but I do not know how to do this to submit my jobs. Specifically, I want to run some DFT calculations using the VASP code (I have the license). Thank you for your help. ; Hi name, Thanks for reaching out! There are few modules for VASP on Anvil. If you want to use these modules, we need to validate your VASP license status. Please share your email address associated with your VASP license, I need your own email, not the owner's of the license. @login01.anvil:~] $ module spider vasp ; vasp: ; Versions: vasp/5.4.4.pl2-vtst vasp/5.4.4.pl2 vasp/6.3.0-beef vasp/6.3.0-sol vasp/6.3.0-vtst vasp/6.3.0-wannier90 vasp/6.3.0 ; Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Hello name, I appreciate your reply. The email address is: : mailto:. I own the license. Best, name O. Ogunbunmi, Ph.D. Assistant Professor of Physics Department of Physics and Engineering name University of Louisiana New Orleans, name 70125 NCF 235 Office: ; Hi name, Thanks for the information. You have been added to vasp5 and vasp6 groups on Anvil. Your membership will be ready within a few hours. Please check our user guide for VASP calculations on Anvil. https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/vasp: https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/vasp|smart-link Regards, name ; Hello Hannan, Thank you for your earlier email. However, it seems I have not been added to vasp6 groups based on the error message that I received: slurmstepd: error: execve(): vasp\\_ncl: No such file or directory slurmstepd: error: execve(): vasp\\_ncl: No such file or directory slurmstepd: error: execve(): vasp\\_ncl: No such file or directory ::PrRuSn: mailto::PrRuSn $ ls -l /apps/spack/anvil/external/vasp/vasp.6.3.0-openmpi-4.1.6/bin/vasp\\_ncl -rwxr-x--- 1 rcactest vasp6 17527032 Feb 20 2024 /apps/spack/anvil/external/vasp/vasp.6.3.0-openmpi-4.1.6/bin/vasp\\_ncl Could you please verify that I have been added to the group? Thank you. Best, name ; Hi name, I can confirm you are on vasp6 group. Can you let me know how you submit the VASP job on Anvil? Any jobID or job script I can take a look? @login01.anvil:~ $ groups x-mogunbunmi x-mogunbunmi : x-phy250050 vasp5 vasp6 Regards, name ; Thank you for confirming this. Here is my job script for Submitted batch job 11196773 #!/bin/bash #SBATCH --job-name=PrRuSn\\_SOC #SBATCH --output=PrRuSn\\_SOC.o%j #SBATCH --error=PrRuSn\\_SOC.e%j #SBATCH --nodes=2 #SBATCH --ntasks-per-node=64 #SBATCH --time=02:00:00 #SBATCH --partition=standard #SBATCH --account=PHY250050 #SBATCH [--mail-user=: mailto:--mail-user= #SBATCH --mail-type=END,FAIL # Load modules for Anvil module purge module load vasp/6.3.0 # Adjust if needed # Create and change to scratch directory run\\_dir=$SCRATCH/PrRuSn\\_SOC\\_run mkdir -p $run\\_dir cd $run\\_dir || exit 1 # Copy only necessary VASP input files from submit directory cp $SLURM\\_SUBMIT\\_DIR/{INCAR,KPOINTS,POSCAR,POTCAR} . # Optionally copy WAVECAR and CHGCAR if they exist (for continuation jobs) cp $SLURM\\_SUBMIT\\_DIR/{WAVECAR,CHGCAR} . 2>/dev/null # Run VASP with spin-orbit coupling srun vasp\\_ncl # Copy results back to submission directory cp \\* $SLURM\\_SUBMIT\\_DIR/ Thank you for your help. Best, name ; Thanks for sharing your job script. I think all we need to do is modifying the modules part. You need module --force purge module load gcc/11.2.0 openmpi/4.1.6 module load vasp/6.3.0 Please reference our user guide as well. https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/vasp: https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/vasp|smart-link Regards, name ;",mogunbunmi@access-ci.org,Michael Ogunbunmi,Nannan Shan,,Anvil,8,17,21,2025,2025-05-19
ATS-16694,Anvil and access to AnvilGPT,2025-05-21,2025-06-19,"Hoping to try out AnvilGPT. Nothing significant, just taking a look. ; Can you please provide us with your acess allocation number? ; I don't have a current project. I'm just part of the ACCESS Allocations team. name ; You should have access to ANVILGPT now. Please let me know if you have any other questions. ;",davidlh,Dave Hart,Ashish Malik,,Anvil,3,22,21,2025,2025-05-19
ATS-16869,Ownership/permissions on /anvil/projects/x-mat250043,2025-05-29,2025-06-13,"Hello! I'm the PI for allocation mat250043 on Anvil. I'm unable to cd into my project director y/anvil/projects/x-mat250043 and it says its is currently root:root (drwxrws---+). $ id uid=7958211(x-jboone1) gid=7008809(x-mat250043) groups=7008809(x-mat250043) $ ls -ld /anvil/projects/x-mat250043 drwxrws---+ 2 root root 4096 May 29 12:25 /anvil/projects/x-mat250043 I am able to access both my scratch and home directories. This is my first time on Anvil, so apologies if I'm accessing the Projects directory the wrong way. Could you please grant me access to the project directory, or help me fix it? Thanks, name ; Still unable to access my project directory ; \\*\\*PRIVATE NOTE\\*\\* The user submitted a TDX ticket, TDX-822071: https://service.purdue.edu/TDNext/Apps/33/Tickets/TicketDet?TicketID=822071, which was resolved so I'll be marking this as resolved. ;",,Connor Boone,Ibrahem Alshybani,,Anvil,3,12,22,2025,2025-05-26
ATS-16939,AnvilGPT API stopped responding to requests,2025-06-01,2025-06-19,"I did not change anything in the code, but the LLMs stopped responding to requests from I-GUIDE RAG Pipeline. Sometimes it will answer only the first query and then get stuck, but most of the time there is no response at all. I tried to write a Python script with the same API endpoint and credentials, and it seems to be working fine so the problem seems to be with the interaction with the JavaScript/Node.js server. ; Yunfan, Thank you for contacting RCAC for support. And thank you for bringing this to our attention. Our experts are looking into why the AnvilGPT API endpoint isn't working for the JavaScript/Node.js server and will update you with their progress. Thanks, name ; Hi Yunfan, Thanks for reaching out. Could you please provide the following details to help us troubleshoot further: \\* How many models is your server requesting concurrently? \\* Is your app correctly awaiting the API response? Due to resource constraints, some requests may be queued rather than processed concurrently. \\* If you're using streaming responses, are you handling them correctly? A code snippet of the relevant part where the request to the LLM is made from Node.js would be very helpful. Best, name ; # Just qwen7b-instruct # I did. I have not change the code on I-GUIDE platform prod server and it used to be working fine but stopped working last weekend. # I set the steam parameter to be false. Here is the function I use to call ollama: export async function callLlamaModel(queryPayload) { const llamaApiUrl = process.env.ANVILGPT\\_URL; const anvilGptApiKey = process.env.ANVILGPT\\_KEY; const controller = new AbortController(); const timeout = setTimeout(() => controller.abort(), 30000); // 30s timeout try { const response = await fetch(llamaApiUrl, { method: 'POST', headers: { 'Authorization': `Bearer ${anvilGptApiKey}`, 'Content-Type': 'application/json', }, body: JSON.stringify(queryPayload), signal: controller.signal, }); clearTimeout(timeout); if (response.ok) { const result = await response.json(); return result?.message?.content || null; } const errorText = await response.text(); throw new Error(`Error: ${response.status}, ${errorText}`); } catch (error) { console.error(""Error fetching from Llama model:"", error); throw error; } } # ; Hi Yunfan, Thank you for your patience. The structure of the response has changed in the recent updates, and I'll make sure this is reflected in our documentation as well. In the meantime, please try accessing your text using: {{result.choices0.message.content}}. Best regards, name ;",ykang3@access-ci.org,Yunfan Kang,Mihir Ahlawat,,Anvil,4,14,22,2025,2025-05-26
ATS-17043,Access to VASP License on Anvil,2025-06-05,2025-06-11,"Please provide users (Niusha Niknahad, name Kanmodi & Shuprovo Sikder) access to VASP on Anvil. ; Hi Obioma, Thanks for reaching out! In order to add users to VASP groups on Anvil, we need to verify their license status. Please share the emails of everyone that we can validate them through VASP portal. I do not PI's email, but individuals' emails. Their PI should add them to one active VASP license with their emails, which I needed. Regards, name, PhD (\\_She/Her\\_) Senior Computational Scientist Purdue University ; Hello name, Please see below for the requested information: Niusha Niknahad: name Kanmodi: Shuprovo Sikder: : mailto: Best, Obioma ; Thanks for providing these information. Niushan, name and Shuprovo have been added to {{vasp5}} and {{vasp6}} groups on Anvil. Their membership will be ready within a few hours. Please check our user guide for VASP calculations on Anvil. https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/vasp: https://www.rcac.purdue.edu/knowledge/anvil/run/examples/apps/vasp|smart-link Regards, name ;",oxuche@access-ci.org,Obioma Uche,Nannan Shan,,Anvil,4,5,23,2025,2025-06-02
ATS-17139,Anvil back-end nodes cannot see other campus hosts or outside world,2025-06-09,2025-06-11,"Anvil back-end nodes cannot see other campus hosts or the outside world. This makes many operations impossible. Repeat by getting a session on a back-end node and trying to access a non-RCAC host using ping/ssh/curl/wget/anything: a209.anvil ~ $ ping www.purdue.edu PING www.purdue.edu (128.210.7.200) 56(84) bytes of data. ^C --- www.purdue.edu ping statistics --- 3 packets transmitted, 0 received, 100% packet loss, time 2065ms Regards, Doug ; Broken networking/routing/NAT ; Hi Doug, Thanks for reporting this. I will let the engineer know and update you later. Best, name ; Hi Doug, Our engineer team is able to dig the worm and fix everything now. Please feel free to test and let us know if you still have questions. Best, name ;",dgc@access-ci.org,Doug Crabill,Xiao Liu,,Anvil,4,3,24,2025,2025-06-09
ATS-17224,Request access to VASP,2025-06-11,2025-06-11,"I wanted to use VASP in the Anvil server but I couldn't. We have a local subscription to VASP. Earlier we generally run VASP in our local server. Due to some bug in our server, it's now under maintenance. Please help me how to get access to VASP. What do I have to provide for it? Last time, the anvil support team asked to share the email associated with a VASP subscription. However, the ticket was closed. I have another enquiry, ""Let's say my professor has a VASP license associated with an Email. Can he use this licence to link with his multiple student's Anvil account to Anvil's central VASP?"" I also tried to build the vasp 6 using our license. I placed the executable file in my directory linked the file to my job file and called the required module. But when I submit the job file it takes too much time and generates an error. Please have a look at the error file. In which way I can solve the problem? I have to use VASP for my recent project. Please suggest an easier path. ; ^err.txt] ; Hi, If you have a license with VASP portal ([https://www.vasp.at/sign\\_in/registration\\_form/: https://www.vasp.at/sign\\_in/registration\\_form/|smart-link ), then we can directly add your license to VASP use on Anvil. You just need to provide your email with registering the license on VASP portal (please note here only vasp portal directly, not 3rd-party license which we cannot do on Anvil). Let us know if you need more help. Best, name ;",abappy,Ahammad Ullah,Xiao Liu,,Anvil,3,1,24,2025,2025-06-09
ATS-17225,Cluster access after using up allocation,2025-06-11,2025-06-12,"Hi there, I have been using Anvil CPU within allocation PHY250024. I have now used up the CPU hours, but need continued access to the project space associated with that allocation. Until when will I have access to /anvil/projects/x-phy250024/ ? Best, name ; Hi, Thank you for contacting us. We will get back to you as soon as we have the answer. Best regards, name ; Hi, According to the UG: https://www.rcac.purdue.edu/knowledge/anvil/storage/filesystems(check the table), users should not expect their {{/anvil/projects/projectid}} files to be kept on Anvil more than 90 days after the project allocation expires. Please let us know if you need more help. Best, name ;",nsiemonsen@access-ci.org,http://cilogon.org/serverE/users/140125 Unknownname,Xiao Liu,,Anvil,3,2,24,2025,2025-06-09
ATS-17252,AnvilGPT Access Request,2025-06-11,2025-06-19,"Hello, My name is Kyaw (name) Linn and I am an undergraduate student working under Prof. Bejarano from the CS department. I would like to gain access to the GenAI Studio. I'm not too sure about what an allocation number is. I mainly plan on using the API but I would like to gain access to the UI as well in case I'd like to use it. ; Hi Kyaw, You can access the GenAI Studio using your Purdue credentials. It looks like you're currently trying to access ANVILGPT, which is a different platform from Purdue GenAI. Here's the correct link for GenAI Studio: https://genai.rcac.purdue.edu: https://genai.rcac.purdue.edu/auth?redirect=%2F ;",,Kyaw Linn,Ashish Malik,Purdue University,Anvil,2,7,24,2025,2025-06-09
ATS-17265,"Please may I increases my instance quota to 10 for Jetstream2 G3.L. I am teaching a course that will be using Jetstream2 and I have 9 students enrolled, inlcuding me, that makes 10 instance needed. Thanks. ",2025-06-12,2025-06-13,"I am teaching a course on CT imaging and 3D modeling that will use the Jetstream2 G3.L flavor, which only comes with an instance quota of 6. I have 9 students enrolled, including me (the instructor) we need 10 instances. Can I please increase my quot to 10 for G3.L flavor. Thanks. ; \\*\\*PRIVATE NOTE\\*\\* Dear name, Thank you for contacting Anvil support. Unfortunately, we only support tickets related to Anvil cluster. I suggest you forwarding your inquiry to Jetstream support staff which I believe it's managed by Indianapolis University staff. I'll mark this ticket as resolved and I recommend you create a new one with the right compute provider. Best, name Anvil support team ;",rcarter1@access-ci.org,Richard Carter,Ibrahem Alshybani,Purdue University,Anvil,2,2,24,2025,2025-06-09
ATS-17277,Purdue Anvil slurm unable to connect,2025-06-12,2025-06-12,"On Purdue Anvil squeue returns the following error (as of about 5-10 minutes ago), tested on both login04 and login00 \\*\\*: mailto::\\*~\\*$ squeue slurm\\_load\\_jobs error: Unable to contact slurm controller (connect failure) ; Resolved after ~0.5-1 hour, squeue command works again ;",atran9@access-ci.org,Aaron Tran,,,Anvil,2,1,24,2025,2025-06-09
